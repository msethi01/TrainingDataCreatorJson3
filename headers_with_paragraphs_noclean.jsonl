{"header": "How do I Physical Synthesis Design Flow Overview", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "\u2022 Physical Synthesis Design Flow Overview \u2022 Formal Verification \u2022 Place and Route Design Flow Overview \u2022 Fusion Compiler Concepts \u2022 Working With the 3DIC Compiler User Interfaces \u2022 Entering fc_shell Commands \u2022 Using Application Options \u2022 Using Variables \u2022 Viewing Man Pages \u2022 Using Tcl Scripts \u2022 Adding Changes to a Script With Checkpoints \u2022 Using Setup Files \u2022 Using the Command Log File \u2022 Enabling Multicore Processing For information about working with design data in the Fusion Compiler tool, see the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Formal Verification", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Figure\u00a01 shows the basic physical synthesis design flow.\n       Figure 1 Fusion Compiler Physical Synthesis Flow RTL/ netlist Design (NDM) Ref.\n lib (NDM) Tech.\n data TLU+ files UPF files DEF/Tcl (Optional) SDC files (Optional) Set up the libraries Read RTL files Handle design mismatches and black boxes Apply multivoltage power intent Apply timing and physical constraints Set up clock-gating cells Set up DFT and insert DFT structures Insert multivoltage cells Compile the design Analyze and report QoR Export the design SDC files Design (NDM) Verilog UPF files DEF/ SCANDEF"}
{"header": "How do I Place and Route Design Flow Overview", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Formality tool uses formal techniques to prove or disprove the functional equivalence of two designs.\n It performs RTL-to-RTL, RTL-to-gate, and gate-to-gate verifications.\n Functional equivalence checking does not take into account static timing verification.\n The       following figure shows an overview of the design flow from the Fusion Compiler tool to the Formality tool: Synthesis RTL/ netlist Ref.\n lib (NDM) Tech.\n data TLU+ files UPF files DEF/Tcl (Optional) SDC files (Optional) SVF files Design (NDM) Verilog UPF files Formality"}
{"header": "How do I Fusion Compiler", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Figure\u00a02 shows the basic place and route design flow using the Fusion Compiler tool.\n       Figure 2 Fusion Compiler Place and Route Flow To run the Fusion Compiler place and route flow, 1.\n Set up the library data, preparingtiming librarieslogic libraries libraries and prepare the design data, as described in  Preparing the Design.\n 2.\n Perform design planning and power planning.\n When you perform design planning and power planning, you create a floorplan to determine the size of the design, create the boundary and core area, create site rows for the placement of standard cells, set up the I/O pads, and create a power plan.\n For more information about design planning and power planning, see the  Fusion Compiler Design Planning User Guide.\n 3.\n Perform placement and optimization.\n To perform placement and optimization, use the  place_opt command.\n The  place_opt command placement and optimization addresses and resolves timing closure for your design.\n This iterative process uses enhanced placement and synthesis technologies to generate       legalized placement for leaf cells and an optimized design.\n You can supplement this functionality by optimizing for power, recovering area for placement, minimizing congestion, and minimizing timing and design rule violations.\n 4.\n Perform clock tree synthesis and optimization.\n To perform clock tree synthesis and optimization, use the  clock_opt command.\n Fusion Compiler clock tree synthesis and embedded optimization solve complicated clock tree synthesis problems, such as blockage avoidance and the correlation between preroute and postroute data.\n Clock tree optimization improves both clock skew and clock insertion delay by performing buffer sizing, buffer relocation, gate sizing, gate relocation, level adjustment, reconfiguration, delay insertion, dummy load insertion, and balancing of interclock delays.\n For more information about clock tree synthesis and optimization, see  Clock Tree Synthesis.\n 5.\n Perform routing and postroute optimization, as described in  Routing and Postroute Optimization.\n The Fusion Compiler tool uses Zroute to perform global routing, track assignment, detail routing, topological optimization, and engineering change order (ECO) routing.\n To perform postroute optimization, use the  route_opt command.\n For most designs, the default postroute optimization setup produces optimal results.\n If necessary, you can supplement this functionality by optimizing routing patterns and reducing crosstalk or by customizing the routing and postroute optimization functions for special needs.\n 6.\n Perform chip finishing and design for manufacturing tasks, as described in  Chip Finishing and Design for Manufacturing.\n The Fusion Compiler tool provides chip finishing and design for manufacturing and design for yield capabilities that you can apply throughout the various stages of the design flow to address process design issues encountered during chip manufacturing.\n 7.\n Save the design."}
{"header": "How do I Power Intent Concepts", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "This topic introduces the following concepts used in the Fusion Compiler tool: \u2022 Power Intent Concepts \u2022 UPF Flows \u2022 Multiple-Patterning Concepts"}
{"header": "How do I UPF Flows", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The UPF language establishes a set of commands to specify the low-power design intent for electronic systems.\n Using UPF commands, you can specify the supply network, switches, isolation, retention, and other aspects relevant to power management of a chip design.\n The same set of low-power design specification commands is to be used throughout the design, analysis, verification, and implementation flow.\n Synopsys tools are designed to follow the official IEEE 1801 UPF standard.\n The UPF language provides a way to specify the power requirements of a design, but without specifying explicitly how those requirements are implemented.\n The language specifies how to create a power supply network for each design element, the behavior of supply nets with respect to each other, and how the logic functionality is extended to support dynamic power switching to design elements.\n It does not contain any placement or routing information.\n In the UPF language, a  power domain is a group of elements in the design that share a common set of power supply needs.\n By default, all logic elements in a power domain use the same primary supply and primary ground.\n Other power supplies can be defined for a power domain as well.\n A power domain is typically implemented as a contiguous  voltage area in the physical chip layout, although this is not a requirement of the language.\n Each power domain has a  scope  and an  extent.\n The  scope  is the level of logic hierarchy designated as the root of the domain.\n The  extent is the set of logic elements that belong to the power domain and share the same power supply needs.\n The scope is the hierarchical level at which the domain is defined and is an ancestor of the elements belonging to the power domain, whereas the extent is the actual set of elements belonging to the power domain.\n Each scope in the design has  supply nets and  supply ports at the defined hierarchical level of the scope.\n A  supply net is a conductor that carries a supply voltage or ground throughout a given power domain.\n A supply net that spans more than one power domain is said to be \u201creused\u201d in multiple domains.\n A  supply port is a power supply connection point between two adjacent levels of the design hierarchy, between the parent and child blocks of the hierarchy.\n A supply net that crosses from one level of the design hierarchy to the next passes through a supply port.\n A  supply set is an abstract collection of supply nets, consisting of two supply functions, power and ground.\n A supply set is  domain-independent, which means that the power and ground in the supply set are available to be used by any power domain defined within the scope where the supply set was created.\n However, each power domain can be restricted to limit its usage of supply sets within that power domain.\n You can use supply sets to define power intent at the RTL level, so you can synthesize a design even before you know the names of the actual supply nets.\n A supply set is an abstraction of the supply nets and supply ports needed to power a design.\n Before such a       design can physically implemented (placed and routed), its supply sets must be  refined, or associated with actual supply nets.\n A  supply set handle is an abstract supply set created for a power domain.\n By default, a power domain has supply set handles for the domain\u2019s primary supply set, a default isolation supply set, and a default retention supply set.\n These supply set handles let you synthesize a design even before you create any supply sets, supply nets, and supply ports for the power domain.\n Before such a design can be physically implemented, its supply set handles must be  refined, or associated with actual supply sets; and those supply sets must be refined so that they are associated with actual supply nets.\n A  power switch (or simply  switch ) is a device that turns on and turns off power for a supply net.\n A switch has an input supply net, an output supply net that can be switched on or off, and at least one input signal to control switching.\n The switch can optionally have multiple input control signals and one or more output acknowledge signals.\n A  power state table lists the allowed combinations of voltage values and states of the power switches for all power domains in the design.\n A  level shifter must be present where a logic signal leaves one power domain and enters another at a substantially different supply voltage.\n The level shifter converts a signal from the voltage swing of the first domain to that of the second domain.\n An  isolation cell must be present where a logic signal leaves a switchable power domain and enters a different power domain.\n The level shifter generates a known logic value during shutdown of the domain.\n If the voltage levels of the two domains are substantially different, the interface cell must be able to perform both level shifting (when the domain is powered up) and isolation (when the domain is powered down).\n A cell that can perform both functions is called an  enable level shifter.\n In a power domain that has power switching, any registers that must retain data during shutdown must be implemented as  retention registers.\n A retention register has a separate, always-on supply net, sometimes called the backup supply, which keeps the data stable in the retention register while the primary supply of the domain is shut down."}
{"header": "How do I Multiple-Patterning Concepts", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports both the traditional UPF flow and the golden UPF flow.\n The golden UPF flow is an optional method of maintaining the UPF multivoltage power intent of the design.\n It uses the original \u201cgolden\u201d UPF file throughout the synthesis, physical implementation, and verification steps, along with supplemental UPF files generated by the Fusion Compiler tool.\n       Figure\u00a03 compares the traditional UPF flow with the golden UPF flow.\n Figure 3 UPF-Prime (Traditional) and Golden UPF Flows The golden UPF flow maintains and uses the same, original \u201cgolden\u201d UPF file throughout the flow.\n The Fusion Compiler tool writes power intent changes into a separate \u201csupplemental\u201d UPF file.\n Downstream tools and verification tools use a combination of the golden UPF file and the supplemental UPF file, instead of a single UPF\u2019 or UPF\u2019\u2019 file.\n The golden UPF flow offers the following advantages: \u2022 The golden UPF file remains unchanged throughout the flow, which keeps the form, structure, comment lines, and wildcard naming used in the UPF file as originally written.\n \u2022 You can use tool-specific conditional statements to perform different tasks in different tools.\n Such statements are lost in the traditional UPF-prime flow.\n \u2022 Changes to the power intent are easily tracked in the supplemental UPF file.\n \u2022 You can optionally use the Verilog netlist to store all PG connectivity information, making  connect_supply_net commands unnecessary in the UPF files.\n This can significantly simplify and reduce the overall size of the UPF files.\n To enable the golden UPF flow, use the following application option setting before you load the UPF: fc_shell>\u00a0 set_app_options -as_user_default  \\ -list {mv.upf.enable_golden_upf true} To load supplemental UPF files, use the  -supplemental option with the  load_upf command.\n For more information about using the golden UPF flow, see  SolvNet article 1412864, \u201cGolden UPF Flow Application Note.\u201d"}
{"header": "How do I Mask Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "At the 20-nm process node and below, printing the required geometries is extremely difficult with the existing photolithography tools.\n To address this issue, a new technique, multiple patterning, is used to partition the layout mask into two or more separate masks, each of which has an increased manufacturing pitch to enable higher resolution and better printability.\n  Figure\u00a04 shows an example of double-patterning, where the layout mask is partitioned into two separate masks, MASK A and MASK B.\n Figure 4 Double-Patterning Example To use multiple patterning, you must be able to decompose the layout into two or more masks, each of which meets the multiple-patterning spacing requirements.\n A multiple- patterning violation occurs if your layout contains a region with an odd number of neighboring shapes where the distance between each pair of shapes is smaller than the multiple-patterning minimum spacing.\n This type of violation, which is called an  odd cycle, is shown in  Figure\u00a05.\n       Figure 5 Odd-Cycle Violation If the spacing between any pair in the loop is greater than the multiple-patterning minimum spacing, no violation occurs and the layout can be decomposed.\n For example, in  Figure\u00a06, if the spacing,  x, between segments B and C is greater than the multiple-patterning minimum spacing, there is no odd cycle and the layout can be decomposed.\n Figure 6 No Odd-Cycle Violation The Fusion Compiler tool ensures that the generated layout is conducive to double patterning by considering the multiple-patterning spacing requirements during placement and routing and preventing odd cycles.\n In general, double patterning is performed only on the bottom (lowest) metal layers, which are referred to as  multiple-patterning layers.\n The metal shapes on the multiple-patterning layers must meet the multiple-patterning spacing requirements, whether they are routing shapes or metal within the standard cells and macros.\n The metal shapes on other layers do not need to meet the stricter multiple-patterning spacing requirements.\n       Multiple-patterning considerations affect all parts of the place and route flow.\n Depending on your standard cell library, you follow either an uncolored or precolored multiple- patterning flow.\n \u2022 You use the  uncolored flow if the cells in your standard cell library have sufficient spacing to the cell boundaries to ensure that multiple-patterning violations do not occur during placement.\n This type of library is referred to as a  correct-by-construction library ; most multiple-patterning libraries are correct-by-construction libraries.\n In the uncolored flow, the tool determines the appropriate mask settings for the pins and net shapes.\n \u2022 You use the  precolored flow if the cells in your standard cell library have assigned masks on the metal shapes inside the cells.\n These assigned masks are often referred to as  colors and this type of library is referred to as a  precolored library.\n In the precolored flow, the tool must consider these mask assignments to ensure that multiple-patterning violations do not occur during placement.\n The tool also uses the mask assignments to determine the appropriate mask settings for the pins and net shapes.\n The mask assignments are represented as  mask constraints in the Fusion Compiler tool.\n You must ensure that the mask constraints are properly set before starting place and route.\n For information about the mask constraints, see  Mask Constraints."}
{"header": "How do I Working With the 3DIC Compiler User Interfaces", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Mask constraints indicate the mask requirements for the metal shapes of the physical pins and nets in a block that uses multiple-patterning technology.\n These mask requirements drive placement and routing to ensure that the resulting layout is multiple-patterning compliant.\n Note: Mask constraints are used only for the precolored flow; they are not necessary in the uncolored flow.\n You can set mask constraints on timing-critical nets (net shapes, routing rules, and routing blockages) and vias.\n For nets, the mask constraint is defined in the  mask_constraint attribute.\n For vias, the mask constraints are defined in the  lower_mask,  upper_mask, and cut_mask attributes.\n  Table\u00a01 shows the supported values for these attributes.\n Table 1 Mask Constraint Values Attribute value Description same_mask          Table 1 Mask Constraint Values (Continued) Attribute value Description mask_one    mask_two    mask_three    any_mask"}
{"header": "How do I Starting the CLI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool operates in the X Window environment on Linux.\n IThe tool provides a flexible working environment with both a shell command-line interface and a GUI.\n The CLI is always available during a Fusion Compiler session.\n You can start or exit a session in either the shell or the GUI, and you can open or close the GUI during a session.\n The tool uses Tcl, which is used in many applications in the EDA industry.\n Using Tcl, you can extend the fc_shell command language by writing reusable procedures and scripts (see the  Using Tcl With Synopsys Tools manual).\n The following topics describe how to start and exit the tool using the command-line interface.\n \u2022 Starting the CLI \u2022 Exiting the Fusion Compiler Tool For information about using the GUI, see the  Fusion Compiler Graphical User Interface User Guide.\n The following topics describe how to use the user interfaces of the Fusion Compiler tool: \u2022 Starting the GUI \u2022 Closing the GUI"}
{"header": "How do I Exiting the Fusion Compiler", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The CLI interface is a text-only environment in which you enter commands at the command-line prompt.\n It is typically used for scripts, batch mode, and push-button operations.\n Before you start the command-line interface, ensure that the path to the bin directory is included in your $PATH variable.\n To start fc_shell, \u25baEnter the  fc_shell command in a Linux shell.\n %\u00a0 fc_shell You can include other options on the command line when you start the shell.\n For example, you can use \u2022 -file\u00a0 script_file_name to execute a script \u2022 -x\u00a0 command to execute a command \u2022 -output_log_file\u00a0 file_name to create a log file of your session \u2022 -help to display a list of the available options (without starting the shell) At startup, the tool : 1.\n Creates a command log file.\n 2.\n Reads and executes the setup files.\n 3.\n Executes any script files or commands specified by the  -file and  -x options, respectively, on the command line.\n 4.\n Displays the program header and fc_shell> prompt in the shell.\n See Also \u2022 Using the Command Log File \u2022 Using Setup Files \u2022 Using Tcl Scripts"}
{"header": "How do I Entering fc_shell", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can end the session and exit the Fusion Compiler tool at any time.\n To exit the tool, use the  exit or  quit command.\n Note: When you exit the tool from the command line, the tool exits without saving the open blocks."}
{"header": "How do I Interrupting or Terminating Command Processing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You interact with the Fusion Compiler tool by using fc_shell commands, which are based on the Tool Command Language (Tcl) and include certain command extensions needed to implement specific Fusion Compiler functionality.\n The Fusion Compiler command language provides capabilities similar to Linux command shells, including variables, conditional execution of commands, and control flow commands.\n You can \u2022 Enter individual commands interactively at the fc_shell> prompt in fc_shell \u2022 Enter individual commands interactively on the console command line in the GUI \u2022 Run one or more Tcl scripts, which are text files that contain fc_shell commands (see Using Tcl Scripts ) When entering a command, an option, or a file name, you can minimize your typing by pressing the Tab key when you have typed enough characters to specify a unique name; the Fusion Compiler tool completes the remaining characters.\n If the characters you typed could be used for more than one name, the Fusion Compiler tool lists the qualifying names, from which you can select by using the arrow keys and the Enter key.\n If you need to reuse a command from the output for a command-line interface, you can copy and paste the portion by selecting it, moving the pointer to the fc_shell command line, and clicking with the middle mouse button.\n When you run a command, the Fusion Compiler tool echoes the command output (including processing messages and any warnings or error messages) in fc_shell and, if the GUI is open, in the console log view.\n By default, the tool does not use page mode, so the output might scroll.\n To enable page mode, set the  sh_enable_page_mode variable to true."}
{"header": "How do I Getting Information About Commands", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you enter the wrong options for a command or enter the wrong command, you can interrupt command processing and remain in fc_shell.\n interupting comandscomandsinteruptingterminatingterminating comands To interrupt or terminate a command, press Ctrl+C.\n Some commands and processes cannot be interrupted.\n To stop these commands or processes, you must terminate fc_shell at the system level.\n When you terminate a process or the shell, no data is saved.\n When you use Ctrl+C, keep the following points in mind: \u2022 If a script file is being processed and you interrupt one of its commands, the script processing is interrupted and no further script commands are processed.\n \u2022 If you press Ctrl+C three times before a command responds to your interrupt, fc_shell is interrupted and exits with this message: Information:\u00a0Process\u00a0terminated\u00a0by\u00a0interrupt."}
{"header": "How do I Displaying Command Help", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following online information resources are available while you are using the Fusion Compiler tool: \u2022 Command help, which is information about an Fusion Compiler command \u2022 Man pages See Also \u2022 Viewing Man Pages"}
{"header": "How do I Using Application Options", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Command help consists of either a brief description of aFusion Compiler command or a list of the options and arguments supported by an Fusion Compiler command.\n \u2022 To display a brief description of a Fusion Compiler command, enter the  help command followed by the command name.\n For example, to display a brief description of the report_timing command, use the following command: fc_shell>\u00a0 help report_timing \u2022 To display the options supported by a Fusion Compiler command, enter the command name with the  -help option on the command line.\n For example, to see the options supported by the  report_timing command, use the following command: fc_shell>\u00a0 report_timing -help"}
{"header": "How do I Using Variables", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool uses application options to control the tool behavior.\n Application options use the following naming convention: category [.\n subcategory ].\n option_name where  category is the name of the engine affected by the application option.\n Some application option categories have subcategories to further refine the area affected by the application option.\n Application options have either a global scope or a block scope.\n \u2022 Block-scoped application options apply only to the block on which they are set.\n They are saved in the design library and are persistent across tool sessions.\n \u2022 Global-scoped application options apply to all blocks, but only within the current session.\n They are not saved in the design library; you must specify them in each fc_shell session.\n You might want to consider adding the global settings to your.synopsys_fc.setup file.\n To get a list of available application options, use the  get_app_options command.\n By default, this command lists all application options.\n To restrict the reported application options, provide a pattern string as an argument to the command.\n For example, to list all available application options, use the following command: fc_shell>\u00a0 get_app_options To list all available timer application options, use the following command: fc_shell>\u00a0 get_app_options timer.* To generate a report of application options, use the  report_app_options command.\n For detailed information about application options, see Application Options in the  Fusion Compiler Data Model User Guide.\n See Also \u2022 Using Setup Files"}
{"header": "How do I Viewing Man Pages", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In general, the Fusion Compiler tool modifies default behavior by using application options rather than application variables; however it does support user-defined Tcl variables, as well as a minimal number of application variables, such as the  search_path variable.\n       To list the variables and their values, use the  printvar command.\n For example, to list all variables defined in the current session, use the following command: fc_shell>\u00a0 printvar * To print the value of the search_path variable, use the following command: fc_shell>\u00a0 printvar search_path See Also \u2022 Defining the Search Path"}
{"header": "How do I Using Tcl Scripts", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To display the man page for a Fusion Compiler command or application option, enter the man command followed by the command or application option name.\n For example, to see the man page for the  report_timing command, use the following command: fc_shell>\u00a0 man report_timing To display the man page for a Fusion Compiler application option, enter the  man command followed by the option name.\n You can also view the following types of summary pages for application options: \u2022 Category summaries To view a man page that summarizes all of the application options for a specific category, enter the  man command followed by  category _options.\n For example, to see the man page that summarizes all timer application options, use the following command: fc_shell>\u00a0 man timer_options \u2022 Subcategory summaries To view a man page the summarizes all of the application options for a specific subcategory, enter the  man command followed by  category.\n subcategory _options.\n For example, to see the man page that summarizes all common route application options, use the following command: fc_shell>\u00a0 man route.common_options       \u2022 Command summaries To view a man page the summarizes all of the application options for a specific command, enter the  man command followed by  command _options.\n For example, to see the man page that summarizes all application options that affect the  report_timing command, use the following command: fc_shell>\u00a0 man report_timing_options If you enter the  man command on the fc_shell command line, the man page is displayed in the Fusion Compiler shell and in the console log view if the GUI is open.\n If you enter this command on the console command line in the GUI, the man page is displayed in the GUI man page viewer."}
{"header": "How do I Adding Changes to a Script With Checkpoints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use Tcl scripts to accomplish routine, repetitive, or complex tasks.\n You create a command script file by placing a sequence of Fusion Compiler commands in a text file.\n Any Fusion Compiler command can be executed within a script file.\n In Tcl, a pound sign (#) at the beginning of a line denotes a comment.\n For example, #\u00a0This\u00a0is\u00a0a\u00a0comment For more information about writing scripts and script files, see the  Using Tcl With Synopsys Tools manual.\n Use one of the following methods to run a Tcl script: \u2022 Use the  -file option with the  fc_shell command when you start the Fusion Compiler tool.\n \u2022 Use the  source command from the fc_shell command line.\n \u2022 Choose File > Execute Script in the GUI.\n If an error occurs when running a command, the Fusion Compiler tool raises the TCL_ERROR condition, which immediately stops the script execution.\n To tolerate errors and allow the script to continue executing, either \u2022 Check for TCL_ERROR error conditions with the Tcl  catch command on the commands that might generate errors.\n \u2022 Set the  sh_continue_on_error variable to  true in the script file.\n       See Also \u2022 Starting the CLI \u2022 Adding Changes to a Script With Checkpoints"}
{"header": "How do I Defining Checkpoints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When running experiments on a block, you might might modify your golden flow scripts in two ways: \u2022 By making flow changes, such as setting application options, modifying constraints, or making other changes to improve the quality of results \u2022 By generating reports (either additional reports or reports at new places in the flow) to help debug an issue In most flows, you apply changes through a small number of static, modifiable files.\n Here is a typical example to run the place_opt flow, where you source a pre_place_opt_settings.tcl file to add flow changes and a generate_reports.tcl file to run all your reporting at the end of the script: open_block\u00a0./design:init_design source\u00a0./scripts/pre_place_opt_settings.tcl remove_buffer_trees\u00a0-all place_opt\u00a0-from\u00a0initial_place\u00a0-to\u00a0initial_drc create_placement\u00a0-incremental\u00a0-timing_driven\u00a0-congestion place_opt\u00a0-from\u00a0initial_drc\u00a0-to\u00a0-initial_opto place_opt\u00a0-from\u00a0final_place\u00a0-to\u00a0final_opto source\u00a0./scripts/generate_reports.tcl In some cases, complex changes require modifying your golden flow script directly, which might be discouraged or difficult to do in many design environments.\n These changes can be time consuming to implement, especially if you are implementing them at multiple stages in the design flow, across multiple blocks, or for several different flow experiments.\n The checkpoint system streamlines this process and allows you to run experiments without modifying your golden flow scripts.\n When you use the checkpoint system, you define checkpoints for important steps in your golden flow.\n These checkpoints enwrap the commands associated with the given steps.\n By default, the checkpoints run only the code they enwrap.\n That is, simply inserting checkpoints in your script does not change your flow.\n However, you can associate these checkpoints with flow changes or reports that you want to run before, after, or in place of the code the checkpoints enwrap.\n By defining these       associations in a portable configuration file, you isolate your golden flow scripts from the changes you want to apply for a particular run.\n The following figure shows how you can use checkpoints to instantly apply a set of flow changes or reports to multiple designs, without modifying each design's golden flow script.\n In this case, the configuration file has been copied to each design's run directory.\n In addition, when multiple users are working on a project, each user can have an individual checkpoint.config.tcl file with his or her preferred settings: The checkpoint system also allows you to \u2022 Insert flow changes and reports with more precision than you could using a typical non- checkpointed flow script \u2022 Reference a single source of truth where you can find all changes that have been applied to your default golden flow \u2022 Report a history of the checkpoints that were run, including the flow changes or reports that were run at those checkpoints       \u2022 Report runtime and memory information for each checkpoint that was run \u2022 Generate unique and descriptive report names The general process for using the checkpoint system is as follows: 1.\n  Insert checkpoints in your script.\n 2.\n  Configure your checkpoints by \u25e6 Defining the flow changes or reports you want to associate with the checkpoints \u25e6 Associating the flow changes or reports you defined with your checkpoints 3.\n Run your script."}
{"header": "How do I Configuring Checkpoints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a checkpoint, insert the  eval_checkpoint command in your script.\n Specify a unique name for the checkpoint and wrap the checkpoint around a block of code.\n Note the following: \u2022 If you define a checkpoint with the same name as an existing checkpoint, the tool automatically adds a unique suffix to the name of the newly-defined checkpoint when it encounters the checkpoint in a run.\n For example, if you duplicate a checkpoint named placement, the tool renames the duplicate to placement2 when it encounters the checkpoint in a run.\n \u2022 Do not nest checkpoints within other checkpoints.\n Although the tool does not prevent you from defining nested checkpoints, the tool ignores nested checkpoints during a run, executing only the outermost checkpoints (note that the Tcl code inside nested checkpoints still runs, but runs as though the checkpoints do not exist).\n Suppose you have a simple place_opt script: open_block\u00a0./design:init_design source\u00a0./scripts/pre_place_opt_settings.tcl remove_buffer_trees\u00a0-all place_opt\u00a0-from\u00a0initial_place\u00a0-to\u00a0initial_drc create_placement\u00a0-incremental\u00a0-timing_driven\u00a0-congestion place_opt\u00a0-from\u00a0initial_drc\u00a0-to\u00a0-initial_opto place_opt\u00a0-from\u00a0final_place\u00a0-to\u00a0final_opto The following example wraps a checkpoint around each major step in your golden flow.\n The checkpoints are named remove_buffers, place_opt_to_initial_drc, incr_placement, place_opt_to_initial_opto, and place_opt_to_final_opto.\n open_block\u00a0./design.nlib:init_design source\u00a0./scripts/pre_place_opt_settings.tcl        eval_checkpoint\u00a0remove_buffers\u00a0{ remove_buffer_trees\u00a0-all }  eval_checkpoint\u00a0place_opt_to_initial_drc\u00a0{ place_opt\u00a0-from\u00a0initial_place\u00a0-to\u00a0initial_drc }  eval_checkpoint\u00a0incr_placement\u00a0{ create_placement\u00a0-incremental\u00a0-timing_driven\u00a0-congestion }  eval_checkpoint\u00a0place_opt_to_initial_opto\u00a0{ place_opt\u00a0-from\u00a0initial_drc\u00a0-to\u00a0initial_opto }  eval_checkpoint\u00a0place_opt_to_final_opto\u00a0{ place_opt\u00a0-from\u00a0final_place\u00a0-to\u00a0final_opto } By default, the checkpoints run the Tcl code they enwrap.\n That is, simply inserting checkpoints with the  eval_checkpoint command does not change your flow.\n However, you can associate these checkpoints with flow changes or reports that you want to run before, after, or in place of the code the checkpoints enwrap, as described in  Configuring Checkpoints.\n See Also \u2022 Configuring Checkpoints \u2022 Querying Checkpoints and Checkpoint Behaviors"}
{"header": "How do I Defining Checkpoint Behaviors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For a checkpoint to affect your flow, you must associate it with a flow change or report that you want to run before, after, or in place of the code the checkpoint enwraps.\n The process of defining flow changes and reports and associating them with individual checkpoints is described in the following topics: \u2022 Defining Checkpoint Behaviors \u2022 Associating Checkpoints and Checkpoint Behaviors"}
{"header": "How do I Associating Checkpoints and Checkpoint Behaviors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can define two types of checkpoint behaviors: reports and actions.\n Define a checkpoint report to generate one or more reports supported by the tool or custom reports you create yourself.\n Define a checkpoint action to execute any kind of flow change before,       after, or in place of the code block enwrapped by a checkpoint.\n For example, you might set an application option to a specific value before a particular checkpoint.\n Define these behaviors in your checkpoint.config.tcl file, which is automatically sourced by the checkpoint system.\n Defining Checkpoint Reports To define a checkpoint report, use the  create_checkpoint_report command in your checkpoint.config.tcl file.\n Specify a unique name for the report and define the Tcl commands to generate the report.\n The following example defines a checkpoint report named timing, which writes the output of the  report_qor and  report_timing commands to disk: create_checkpoint_report\u00a0timing\u00a0{ set\u00a0name\u00a0[get_current_checkpoint\u00a0-name] set\u00a0pos\u00a0[get_current_checkpoint\u00a0-position]  report_qor\u00a0-nosplit\u00a0>\u00a0./checkpoint/$name.$pos.qor.rpt report_qor\u00a0-summary\u00a0-nosplit\u00a0>>\u00a0./checkpoint/$name.$pos.qor.rpt  report_timing\u00a0-nosplit\u00a0-max_paths\u00a010\u00a0\\ >\u00a0./checkpoint/$name.$pos.path.rpt } Notice the use of the  get_current_checkpoint command with the  -name and -position options to give the generated reports a meaningful name.\n When these reports are generated, their names reflect the checkpoint that triggered them ( get_current_checkpoint\u00a0-name ), as well as whether they were generated before or after the checkpoint ( get_current_checkpoint\u00a0-position ).\n For example, if this checkpoint report is executed after a checkpoint named checkpoint_A, the generated reports are saved to the checkpoint directory, and the name of the QoR report is checkpoint_A.after.qor.rpt.\n The next example defines a checkpoint report named app_options, which writes all your non-default application options to disk: create_checkpoint_report\u00a0app_options\u00a0{ set\u00a0name\u00a0[get_current_checkpoint\u00a0-name] set\u00a0pos\u00a0[get_current_checkpoint\u00a0-position]  report_app_options\u00a0-non_default\u00a0\\ >\u00a0./checkpoint/$name.$pos.app_options.rpt } Defining Checkpoint Actions To define a checkpoint action, use the  create_checkpoint_action command in your checkpoint.config.tcl file.\n Specify a unique name for the action and define the Tcl commands that constitute the action.\n       The following example defines a checkpoint action named gropto, which enables global- route based buffering: create_checkpoint_action\u00a0gropto\u00a0{ set_app_options\u00a0-name\u00a0place_opt.initial_drc.global_route_based\u00a0\\ -value\u00a0true } The next example defines a checkpoint action named placer_high_effort_cong, which runs high-effort congestion reduction: create_checkpoint_action\u00a0placer_high_effort_cong\u00a0{ set\u00a0placer_command\u00a0[get_current_checkpoint\u00a0-script] set\u00a0cong_option\u00a0\"-congestion_effort\u00a0high\" eval\u00a0$placer_command\u00a0$cong_option } Notice the use of the  get_current_checkpoint\u00a0-script command and option, which retrieves the command originally enwrapped by the checkpoint and sets its congestion effort to high ( -congestion_effort\u00a0high ).\n The  -script option is typically used to define actions that replace the contents of a command.\n In this example, the action modifies the  -congestion_effort option of the command that is enwrapped by the checkpoint associated with this action."}
{"header": "How do I Querying Checkpoints and Checkpoint Behaviors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After defining checkpoints with the  eval_checkpoint command and checkpoint behaviors with the  create_checkpoint_* command, you must associate the two so that the tool executes the behaviors when it encounters the checkpoints in a run, as described in the following topics: \u2022 Associating Checkpoints With Checkpoint Reports \u2022 Associating Checkpoints With Checkpoint Actions See Also \u2022 Defining Checkpoints \u2022 Defining Checkpoint Behaviors Associating Checkpoints With Checkpoint Reports To associate a checkpoint report with one or more checkpoints, use the associate_checkpoint_report command in your checkpoint.config.tcl file.\n       \u2022 Specify the checkpoint report name with the  -enable option.\n \u2022 To enable the report to run before one or more checkpoints, specify the checkpoint names with the  -before option.\n \u2022 To enable the report to run after one or more checkpoints, specify the checkpoint names with the  -after option.\n When associating a report with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined three checkpoints in your script named remove_buffers, place_opt_to_initial_opto, and place_opt_to_final_opto using the  eval_checkpoint command, and two checkpoint reports named timing and app_options using the create_checkpoint_report command.\n To enable your timing report to run after the place_opt_to_initial_opto and place_opt_to_final_opto checkpoints, use the following command: associate_checkpoint_report\u00a0-enable\u00a0timing\u00a0\\ -after\u00a0{\u00a0place_opt_to_initial_opto\u00a0place_opt_to_final_opto\u00a0} To enable your app_options report to run before all the checkpoints in your script, use the following command: associate_checkpoint_report\u00a0-enable\u00a0app_options\u00a0-before\u00a0* You can also add the command like this, which enables the report to run before the remove_buffers checkpoint and any checkpoints beginning with the phrase place_opt: associate_checkpoint_report\u00a0-enable\u00a0app_options\u00a0-before\u00a0remove_buffers place_opt* The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in the run.\n \u2022 The code that is commented out identifies the original script body \u2022 The blue code identifies the checkpointed Tcl commands in your golden flow \u2022 The green code identifies the app_options report, configured to run before each checkpoint \u2022 The purple code identifies the timing report, configured to run after the place_opt_to_final_opto checkpoint       Associating Checkpoints With Checkpoint Actions To associate a checkpoint action with one or more checkpoints, use the associate_checkpoint_action command in your checkpoint.config.tcl file.\n \u2022 Specify the checkpoint action name with the -enable option.\n \u2022 To enable the action to run before one or more checkpoints, specify the checkpoint names with the  -before option.\n \u2022 To enable the action to run after one or more checkpoints, specify the checkpoint names with the  -after option.\n \u2022 To enable the action to run instead of the code block enwrapped by the checkpoint, specify the checkpoint names with the  -replace option.\n When associating an action with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined two checkpoints in your script named place_opt_to_initial_drc and incr_placement with the  eval_checkpoint command, and two checkpoint actions named gropto and placer_high_effort_cong with the  create_checkpoint_action command.\n To enable your gropto action to run before the place_opt_to_initial_drc checkpoint, use the following command: associate_checkpoint_action\u00a0-enable\u00a0gropto\u00a0\\ -before\u00a0place_opt_to_initial_drc       To enable your placer_high_effort_cong action to run instead of the code block enwrapped by the incr_placement checkpoint, use the following command: associate_checkpoint_action\u00a0-enable\u00a0placer_high_effort_cong\u00a0\\ -replace\u00a0incr_placement The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in a run.\n \u2022 The code that is commented out identifies the original script body \u2022 The blue code identifies the checkpointed Tcl commands in your golden flow \u2022 The green code identifies the gropto action, configured to run before the place_opt_to_initial_drc checkpoint \u2022 The purple code identifies the placer_high_effort_cong action, configured to run in place of the code block enwrapped by the incr_placement checkpoint       Associating a Checkpoint With Multiple Behaviors When you associate a checkpoint with multiple behaviors, the tool executes those behaviors in the following order: \u2022 Any reports configured to run before the checkpoint \u2022 Any actions configured to run before the checkpoint \u2022 The checkpointed code block, or any actions configured to replace it \u2022 Any actions configured to run after the checkpoint \u2022 Any reports configured to run after the checkpoint If multiple reports or multiple actions are configured to run at the same position ( -before, -after, or  -replace ) in the same checkpoint, the tool executes them in the order in which they were associated with the checkpoint with the  associate_checkpoint_* commands.\n For example, suppose you define a timing report before an area report.\n If you associate the area report to run after a checkpoint before you associate the timing report to run after the same checkpoint, the tool runs the area report first when it encounters the checkpoint.\n See Also \u2022 Defining Checkpoints \u2022 Defining Checkpoint Behaviors \u2022 Querying Checkpoints and Checkpoint Behaviors"}
{"header": "How do I Viewing Your Checkpoint History", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To return a list of all the checkpoints or checkpoint behaviors in the current session, or to return detailed information for any checkpoint or checkpoint behavior, use the get_checkpoint_data command.\n \u2022 To return a list of all the checkpoints that have been executed, specify the -list_names option: fc_shell>\u00a0 get_checkpoint_data -list_names remove_buffers\u00a0place_opt_to_initial_drc incr_placement\u00a0place_opt_to_initial_opto place_opt_to_final_opto \u2022 To return detailed information for a checkpoint, specify the checkpoint with the  -name option.\n The tool returns the output as a Tcl dictionary: fc_shell>\u00a0 get_checkpoint_data -name place_opt_to_initial_drc memory\u00a0173.85\u00a0start_time\u00a02.34\u00a0end_time\u00a02.34\u00a0before_runtime\u00a02.34 before_report_runtime\u00a00.00\u00a0after_report_runtime\u00a00.00\u00a0self_runtime       0.00\u00a0before_reports\u00a0{}\u00a0after_reports\u00a0{app_options\u00a0timing} before_actions\u00a0{gropto}\u00a0after_actions\u00a0{}\u00a0replace_actions\u00a0{} \u2022 To return a list of all the checkpoint behaviors defined in your configuration, specify the -list_reports or  -list_actions option: fc_shell>\u00a0 get_checkpoint_data -list_reports timing\u00a0app_options  fc_shell>\u00a0 get_checkpoint_data -list_actions gropto\u00a0placer_high_effort_congestion \u2022 To return the contents and associations of a checkpoint report or action, specify the report or action with the  -report or  -action option: fc_shell>\u00a0 get_checkpoint_data -report app_options contents\u00a0{ set\u00a0name\u00a0[get_current_checkpoint\u00a0-name] set\u00a0pos\u00a0[get_current_checkpoint\u00a0-position]  report_app_options\u00a0-non_default\u00a0\\ >\u00a0./checkpoint/$name.$pos.app_options.rpt }\u00a0before_patterns\u00a0{*}\u00a0after_patterns\u00a0{} See Also \u2022 Viewing Your Checkpoint History"}
{"header": "How do I Using Setup Files", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To view your checkpoint history, navigate to the checkpoint directory.\n This directory contains a checkpoint_history.rpt file that captures the history of the checkpoints the tool encounters during each run, along with the runtime and memory usage for each checkpoint.\n The checkpoint directory also contains any checkpoint reports you have written to it.\n In some cases, you might want to clear the full or partial contents of your checkpoint history.\n A typical example is when a checkpointed run fails and you want to clear some or all of the data associated with that run, depending on whether you plan to rerun a portion of the flow or the entire flow.\n \u2022 To clear your full checkpoint history, use the  reset_checkpoints command.\n fc_shell>\u00a0 reset_checkpoints The  reset_checkpoints command clears the full contents of the checkpoint directory, including any reports you have written to it.\n However, before clearing the checkpoint directory, the  reset_checkpoints command saves a timestamped copy of the directory in your run directory.\n       \u2022 To clear a portion of the data in your checkpoint_history.rpt file, use the  -from option to specify the name of a checkpoint.\n This option removes all checkpoints including and following the specified checkpoint from your checkpoint_history.rpt file; it does not remove any checkpoint reports you have written to the checkpoint directory.\n For example, suppose your checkpoint_history.rpt file contains the following data after your run a full checkpointed flow: Checkpoints\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Memory\u00a0\u00a0\u00a0\u00a0\u00a0StartTime\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0...\n remove_buffers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a032290.86\u00a0\u00a0\u00a02020-03-23_14:34:17\u00a0\u00a0...\n place_opt_to_initial_drc\u00a0\u00a0\u00a0\u00a036389.15\u00a0\u00a0\u00a02020-03-23_17:21:56\u00a0\u00a0...\n incr_placement\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a037002.09\u00a0\u00a0\u00a02020-03-23_19:13:02\u00a0\u00a0...\n place_opt_to_initial_opto\u00a0\u00a0\u00a045655.59\u00a0\u00a0\u00a02020-03-23_23:44:36\u00a0\u00a0...\n place_opt_to_final_opto\u00a0\u00a0\u00a0\u00a0\u00a046322.34\u00a0\u00a0\u00a02020-03-23_30:12:55\u00a0\u00a0...\n Suppose you want to rerun your flow beginning with incremental placement.\n To clear the last three checkpoints from your checkpoint_history.rpt file before rerunning that portion of your flow, use the following command: fc_shell>\u00a0 reset_checkpoints -from incr_placement After clearing the checkpoints, your checkpoint_history.rpt file lists only the first two checkpoints in your flow: Checkpoints\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Memory\u00a0\u00a0\u00a0\u00a0\u00a0StartTime\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0...\n remove_buffers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a032290.86\u00a0\u00a0\u00a02020-03-23_14:34:17\u00a0\u00a0...\n place_opt_to_initial_drc\u00a0\u00a0\u00a0\u00a036389.15\u00a0\u00a0\u00a02020-03-23_17:21:56\u00a0\u00a0...\n Similarly, the  get_checkpoint_data\u00a0-list_names command returns only the remove_buffers and place_opt_to_initial_drc checkpoints: fc_shell>\u00a0 get_checkpoint_data -list_names remove_buffers\u00a0place_opt_to_initial_drc"}
{"header": "How do I Using the Command Log File", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you start the Fusion Compiler tool, it automatically executes the commands in the.synopsys_fc.setup file.\n The tool looks for this file both in your home directory and in the project directory (the current working directory in which you start the Fusion Compiler tool).\n The file is read in the following order: 1.\n The.synopsys_fc.setup file in your home directory 2.\n The.synopsys_fc.setup file in the project directory       The setup files can contain commands that perform basic tasks, such as initializing application options and setting GUI options.\n You can add commands and Tcl procedures to the setup files in your home and project directories.\n For example, \u2022 To set application options that define your Fusion Compiler working environment, create setup files in your home directory.\n \u2022 To set project- or block-specific application options that affect the processing of a block, create a setup file in the design directory.\n See Also \u2022 Working With the 3DIC Compiler User Interfaces \u2022 Using Application Options \u2022 Using Variables \u2022 Using Tcl Scripts"}
{"header": "How do I Enabling Multicore Processing", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The command log file records the commands processed by the Fusion Compiler tool, including setup file commands and application option settings.\n By default, the Fusion Compiler tool writes the command log to a file named fc_command.log in the directory from which you invoked fc_shell.\n You can change the name of the command log file by setting the  sh_command_log_file variable in your.synopsys_fc.setup file.\n You should make any changes to this variable before you start the Fusion Compiler tool.\n If your user-defined or project-specific setup file does not contain this variable, the Fusion Compiler tool automatically creates the fc_command.log file.\n Each Fusion Compiler session overwrites the command log file.\n To save a command log file, move it or rename it.\n You can use the command log file to \u2022 Produce a script for a particular implementation strategy \u2022 Record the physical implementation process \u2022 Document any problems you are having"}
{"header": "How do I Configuring Multithreading", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Several functions in the Fusion Compiler tool support multicore processing, whether through multithreading, distributed processing, or parallel command execution.\n Multicore       processing improves turnaround time by performing tasks in parallel much more quickly than if they were run sequentially on a single core.\n Note: A single machine has one or more CPUs and each CPU has one or more cores.\n The total number of cores available for processing on a machine is the number of CPUs multiplied by the number of cores in each CPU.\n When using multicore processing, you need one Fusion Compiler license for every 16 parallel tasks.\n For example, to run 17 parallel tasks, you need 2 Fusion Compiler licenses.\n In most cases, you configure multicore processing by using the  set_host_options command.\n The following topics describe how to use the  set_host_options command to configure multicore processing: \u2022 Configuring Multithreading \u2022 Configuring Distributed Processing \u2022 Reporting Multicore Configurations \u2022 Removing Multicore Configurations The following topic describes how to use distributed processing to run the same task on several blocks in a hierarchical design: \u2022 Running Tasks in Parallel The following topic describes how to use parallel command execution for checking and reporting commands: \u2022 Running Commands in Parallel on Your Local Host"}
{"header": "How do I Configuring Distributed Processing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Multithreading performs tasks in parallel by using multiple cores on the same machine, using a single process memory image.\n When using multithreading, each parallel task is called a thread.\n For the best performance during multithreading, you should limit the number of threads to the number of available cores, which is the number of CPUs in the machine times the number of cores per CPU.\n The following commands support multithreading configured by the  set_host_options command: \u2022 place_opt \u2022 clock_opt       \u2022 check_legality, when advanced legalization is enabled by setting the place.legalize.enable_advanced_legalizer application option to  true.\n \u2022 insert_via_ladders \u2022 route_auto,  route_global,  route_track,  route_detail, and  route_eco Note: When you run routing with a single thread, the result is deterministic; if you start with the same block, you always get the same result.\n However, if you use multiple threads, the routing results are not deterministic; the final routing is slightly different between runs due to the varying division of tasks between threads.\n Global routing supports a deterministic mode for multicore routing.\n To enable this mode, set the  route.global.deterministic application option to  on.\n \u2022 route_opt \u2022 signoff_check_drc \u2022 signoff_fix_drc \u2022 signoff_create_metal_fill \u2022 signoff_fix_isolated_via \u2022 write_def By default, all commands use a single thread.\n To enable multithreading for those commands that support it, set the  -max_cores option of the  set_host_options command to a value greater than one and less than or equal to the number of cores available on your machine, which is the number of CPUs in the machine times the number of cores per CPU.\n The number of cores specified by the  -max_cores option applies to all commands that support multithreading.\n When you enable multithreading, multithreaded commands create and use the specified number of threads, even if the number is more than the number of available cores.\n You must set an appropriate number of threads, so that the command does not try to use more resources than it has.\n Overthreading can reduce performance because the extra threads compete for resources.\n For best performance, do not run more than one thread per available core.\n For example, if your machine has two CPUs and each CPU has three cores, specify six as the maximum number of threads: fc_shell>\u00a0 set_host_options -max_cores 6"}
{"header": "How do I Reporting Multicore Configurations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Distributed processing performs tasks in parallel by using multiple machines; each process uses its own process memory image.\n When using distributed processing, each parallel task is called a process.\n For the best performance during distributed processing, you should limit the number of processes to the number of available cores, which is the sum of the number CPUs times the number of cores per CPU for each host machine.\n The following commands support distributed processing configured by the set_host_options command: \u2022 analyze_rail \u2022 create_placement\u00a0-floorplan \u2022 signoff_check_drc \u2022 signoff_fix_drc \u2022 signoff_create_metal_fill \u2022 signoff_fix_isolated_via When you configure distributed processing, you can specify one or more of the following settings: \u2022 The job submission command (the  -submit_command option) If you do not specify this option, the tool uses the  rsh command to submit the parallel processes.\n \u2022 The list of host machines (the  host_names argument) \u2022 The maximum number of processes (the  -num_processes option) By default, the tool assigns a name to each configuration you define with the set_host_options command.\n To specify the configuration name, use the  -name option.\n You use the configuration name to select the configuration to use for specific commands and to remove a configuration.\n For example, to specify a distributed processing configuration that uses the qsub command to submit the parallel processes, use the following command: fc_shell>\u00a0 set_host_options -name dp_config \\ -submit_command [list qsub -P bnormal -cwd]"}
{"header": "How do I Removing Multicore Configurations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the values set by the  set_host_options command, use the report_host_options command."}
{"header": "How do I Running Tasks in Parallel", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove the multicore configurations defined by the  set_host_options command, use the  remove_host_options command.\n To remove all multicore configurations, use the -all option.\n To remove a specific multicore configuration, specify the configuration name with the  -name option."}
{"header": "How do I Running Commands in Parallel on Your Local Host", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To efficiently run the same task on several blocks in your design, you can use the run_block_script command to enable distributed processing and perform the tasks in parallel.\n The  run_block_script command accepts a Tcl script and applies the commands in the script to the blocks you specify.\n For example, to compile the subblocks of a design in parallel in a hierarchical flow, 1.\n Write the script to run on the blocks in the design.\n The following example performs the steps necessary to compile each subblock in the design.\n You can add additional commands to the script as needed to perform other operations.\n open_lib\u00a0$block_libfilename open_block\u00a0$block_refname.design commit_upf set_editability\u00a0-from_level\u00a01\u00a0-value\u00a0false compile_fusion\u00a0-from\u00a0initial_map\u00a0-to\u00a0initial_map create_abstract\u00a0-read_only create_frame save_block\u00a0$block_refname\u00a0-as\u00a0$block_refname/initial_map compile_fusion\u00a0-from\u00a0logic_opto\u00a0-to\u00a0logic_opto create_abstract\u00a0-read_only create_frame save_block\u00a0$block_refname\u00a0-as\u00a0$block_refname/logical_opt compile_fusion\u00a0-from\u00a0initial_place\u00a0-to\u00a0initial_place create_abstract\u00a0-read_only create_frame save_block\u00a0$block_refname\u00a0-as\u00a0$block_refname/initial_place save_block save_lib close_block\u00a0-force\u00a0-purge close_lib 2.\n Run the  run_block_script command to process each block in parallel by using the script created in step 1.\n The following example specifies the settings for distributed processing with the set_host_options command and runs the block_synthesis.tcl synthesis script on the subblocks in parallel by using the Load Sharing Facility (LSF).\n The command writes data and log files to the my_work_dir directory.\n fc_shell>\u00a0 set block_list [get_attribute \\ [get_cells -hierarchical -filter \"is_soft_macro==true\" \\ ref_full_name] fc_shell>\u00a0 set block_list [lsort -unique $block_list] fc_shell>\u00a0 set_host_options -name myhost -submit_command \"sh\" fc_shell>\u00a0 run_block_script \\ -host_options myhost \\       -script block_synthesis.tcl \\ -blocks $block_list \\ -work_dir my_work_dir To control the order in which blocks are processed, use the  -run_order option with the top_down or  bottom-up argument.\n When you specify the  -run_order\u00a0top-down option, the tool delays processing for a child block until all parent blocks for the child block are processed.\n When you specify the  -run_order\u00a0bottom-up option, the tool begins by processing the child blocks, then processes the parent blocks.\n By default, blocks are processed in a bottom-up order."}
{"header": "How do I Running Commands in the Background", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can improve runtime by running checking and reporting commands in parallel on your local host.\n You can run the commands either in the background (with the  redirect -bg command) or in the foreground (with the  parallel_execute command).\n These techniques do not require the use of additional licenses beyond the licenses required for the parent run.\n They also do not require you to use or configure distributed processing.\n When you use these techniques, consider the following guidelines: \u2022 To reduce runtime and memory usage, run the  update_timing command before running the commands in parallel; otherwise, each command that requires updated timing runs the  update_timing command independently.\n \u2022 To pass variables from a child process to the parent process, you must write the contents of the variables to a file during the child process, and then read that file in the parent process.\n See Also \u2022 Running Commands in the Background \u2022 Running Commands in Parallel"}
{"header": "How do I Running Commands in Parallel", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve runtime, you can run checking and reporting commands in the background while you run other commands in the foreground.\n This is useful in interactive sessions when you want to continue your work while the tool generates a report.\n To run commands in the background, use the  redirect command with the  -bg option.\n When you use this command, fc_shell returns immediately to execute the next command.\n If you issue an  exit command in the parent process, the tool waits for all  redirect\u00a0-bg commands to complete before exiting.\n To list the commands supported by the  redirect\u00a0-bg command, use the  list_commands -bg command.\n You can run either a single command or source a Tcl script that contains       only supported commands.\n If the command or script includes a  redirect\u00a0-bg command, the  -bg option is ignored.\n You can run at most two jobs in the background.\n If you specify more than two background jobs, they are queued.\n To specify the maximum number of cores to use for the background jobs, use the -max_cores option with the  redirect command.\n The number of cores available for the parent process (as specified by the  -max_cores option of the  set_host_options command) is reduced by the number of cores allocated for background jobs.\n The following example redirects a Tcl script to run in the background: fc_shell>\u00a0 set_host_options -max_cores 8 fc_shell>\u00a0 redirect -bg -max_cores 3 -file bg_log.out \\ {source bg_script.tcl} Information:\u00a0redirect\u00a0-bg\u00a0with\u00a0max_cores\u00a03\u00a0started.\n The\u00a0maximum\u00a0number\u00a0of cores\u00a0available\u00a0in\u00a0parent\u00a0is\u00a0reduced\u00a0to\u00a05.\n (BGE-004) Reporting Background Jobs To report the background jobs submitted with the  redirect\u00a0-bg command, use the report_background_jobs command.\n This command reports both the completed jobs and the jobs currently running in the background, as shown in the following example: fc_shell>\u00a0 report_background_jobs JOB\u00a0'redirect\u00a0-bg\u00a0\u00a0-file\u00a0{background.log}\u00a0source\u00a0bg_script.tcl -max_cores\u00a04\u00a0'\u00a0completed JOB(pid:13010)\u00a0'redirect\u00a0-bg\u00a0\u00a0-file\u00a0{background_1.log} source\u00a0bg_script_1.tcl\u00a0\u00a0-max_cores\u00a03\u00a0'\u00a0is\u00a0running To omit the completed jobs, use the  -reset option with the  report_background_jobs command."}
{"header": "How do I 2", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "To improve runtime, you can run checking and reporting commands in parallel and return to the parent process after the longest running command in the parallel execution list completes.\n This is useful in batch scripts.\n To run commands in parallel, use the  parallel_execute command, as shown in the following example: fc_shell>\u00a0 update_timing fc_shell>\u00a0 parallel_execute { report_cmd1 log_file1 report_cmd2 log_file2 report_cmd3 log_file3...\n }       To list the supported commands, use the  -list_allowed_commands option with the parallel_execute command.\n To specify the maximum number of cores to use when running the  parallel_execute command, use the  -max_cores option.\n If you do not use this option, the tool uses the value of the  -max_cores option from the  set_host_options command.\n If you do not specify the maximum number of cores with either command, the tool runs the commands sequentially instead of in parallel.\n To run commands in parallel as a background job, use the  redirect\u00a0-bg command to run the  parallel_execute command, as shown in the following example: fc_shell>\u00a0 redirect -bg -max_cores 3 -file bg_log.out { parallel_execute { report_cmd1 log_file1 report_cmd2 log_file2 } }"}
{"header": "How do I Defining the Search Path", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool uses a design library to store your design and its associated library information.\n This topic describes how to create a design library and how to prepare and save your design.\n These steps are explained in the following topics: \u2022 Defining the Search Path \u2022 Setting Up Libraries \u2022 Using Pin Access Checker Utility \u2022 Analyzing Libraries \u2022 Reading the Design \u2022 Mitigating Design Mismatches \u2022 Importing the Floorplan Information \u2022 Setting Up Multivoltage Designs \u2022 Specifying Timing Constraints and Settings \u2022 Specifying Logical Design Rule Constraints \u2022 Specifying Clock Gating Constraints \u2022 Specifying Physical Constraints for Placement and Legalization \u2022 Specifying Placement Settings \u2022 Specifying Legalization Settings \u2022 Controlling the Optimization of Cells, Nets, Pins, and Ports \u2022 Specifying Settings for Preroute Optimization \u2022 Setting Up for Power-Related Features \u2022 Specifying the Routing Resources       \u2022 Handling Design Data Using the Early Data Check Manager \u2022 Applying Mega-Switch Command Settings"}
{"header": "How do I Setting Up Libraries", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool uses a search path to look for files that are specified with a relative path or with no path.\n To specify the search path, use the  set_app_var command to set the  search_path application variable to the list of directories, in order, in which to look for files.\n When the tool looks for a file, it starts searching in the leftmost directory specified in the search_path variable and uses the first matching file it finds.\n You can also use the Tcl  lappend command to add your directories to the default search path, which is the directory from which you invoked the tool.\n For example, fc_shell>\u00a0 lappend search_path./mylibdir"}
{"header": "How do I Working With Design Libraries", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A  block is a container for physical and functional design data.\n A  design library is a collection of related blocks, together with technology data that applies to the block collection.\n A  chip design consists of one or more blocks, often stored in different design libraries.\n A design library uses instances of blocks defined in lower-level libraries, called reference libraries.\n A design library can serve as a reference library for another design library.\n To learn about setting up libraries, see the following topics: \u2022 Working With Design Libraries \u2022 Setting Up Reference Libraries \u2022 Library Configuration \u2022 Restricting Library Cell Usage \u2022 Restricting the Target Libraries Used \u2022 Specifying Library Subset Restrictions"}
{"header": "How do I Setting Up Reference Libraries", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create, open, query, save, or close a design library, using an absolute path, a relative path, or no path, by using the following commands: \u2022 create_lib This command creates the library in memory and sets it as the current library.\n When you run this command to create a new design library, you must specify the library name.\n Slash (/) and colon (:) characters are not allowed in library names.\n The following command creates the my_libA library using a relative path: fc_shell>\u00a0 create_lib../my_lib_dir/my_libA {my_libA} \u2022 open_lib This command opens the specified library, makes that library the current library, and opens all its associated reference libraries.\n Opening a library means loading it into memory and making its blocks accessible.\n The following example opens the my_libA library saved on disk: fc_shell>\u00a0 open_lib my_libA Information:\u00a0Loading\u00a0library\u00a0file\u00a0'/usr/lib/StdCells.ndm'\u00a0(FILE-007) Information:\u00a0Loading\u00a0library\u00a0file\u00a0'/usr/lib/RAMs.ndm'\u00a0(FILE-007) Information:\u00a0Loading\u00a0library\u00a0file '/usr/lib/PhysicalOnly.ndm'\u00a0(FILE-007) {my_libA} \u2022 current_lib By default, the library most recently opened is the current library.\n You can explicitly set any open library to be the current library by using the  current_lib command.\n For example, fc_shell>\u00a0 current_lib my_libA {my_libA} \u2022 save_lib When you create or change a library, the changes are stored in memory only.\n To save a library to disk, use this command.\n For example, fc_shell>\u00a0 save_lib lib_A Saving\u00a0library\u00a0'lib_A' 1 \u2022 close_lib       When you no longer need access to data in a library, you can close it by using the close_lib command.\n Be sure to save the changes in the library before you close it.\n For example, fc_shell>\u00a0 close_lib Closing\u00a0library\u00a0'lib_A' 1 In addition, you can use the  current_lib,  get_libs, and  report_lib commands to query design libraries.\n For more information, see the Design Libraries topic in the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Library Configuration", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify a reference library list for a design library when you create the design library by using the  -ref_libs option of the  create_lib command.\n You can also change the reference library list at any time by using the  set_ref_libs command.\n Use the following commands to specify, rebind, and report reference libraries: \u2022 create_lib\u00a0-ref_libs You can specify a relationship between a new design library and its lower-level reference libraries by using the  create_lib command.\n For example, fc_shell>\u00a0 create_lib lib_B \\ -ref_libs {../LIBS/lib_c../STND/stdhvt.ndm}...\n {lib_B} \u2022 set_ref_libs\u00a0-ref_libs For an existing design library, open the library and then use the  set_ref_libs command to specify the reference libraries.\n For example, fc_shell>\u00a0 current_lib {lib_B} fc_shell>\u00a0 set_ref_libs \\ -ref_libs {../LIBS/lib_C../STND/stdhvt.ndm}../LIBS/lib_C\u00a0../STND/stdhvt.ndm \u2022 report_ref_libs To report the reference libraries of a design library, use the  report_ref_libs command.\n       For example, fc_shell>\u00a0 create_lib lib_A -ref_libs \\ {../libs/SCLL.ndm../libs/SCHH.ndm../BLOCKS/MACROS} {lib_A} fc_shell>\u00a0 report_ref_libs...\n Name\u00a0Path\u00a0Location --------------------------------------------------------------- *+\u00a0SCLL\u00a0../libs/SCLL.ndm\u00a0/remote/project/libs/SCLL.ndm *+\u00a0SCHH\u00a0../libs/SCHH.ndm\u00a0/remote/project/libs/SCHH.ndm *\u00a0MACROS\u00a0../BLOCKS/MACROS\u00a0/remote/project/BLOCKS/MACROS \"*\"\u00a0=\u00a0Library\u00a0currently\u00a0open \"+\"\u00a0=\u00a0Library\u00a0has\u00a0technology\u00a0information \u2022 set_ref_libs\u00a0-rebind When you make a change that invalidates the reference library list, such as moving a reference library to a new location, you need to rebind the reference libraries.\n To do so, use the  -rebind option, which rebinds each reference library path specified by the search_path variable to libraries that are currently loaded in memory.\n For example, fc_shell>\u00a0 current_lib {lib_A} fc_shell>\u00a0 set_app_var search_path {.\n../REFLIBS../CLIBS}.\n../LIBS\u00a0../BLOCKs fc_shell>\u00a0 set_ref_libs -rebind../REFLIBS/lib_C\u00a0../REFLIBS/lib_D\u00a0../CLIBS/stdhvt.ndm} Rebinding a library does not affect the bindings of blocks already existing in the design library.\n To rebind these blocks using an updated reference library list, use the  -rebind option with the  link_block command."}
{"header": "How do I Restricting Library Cell Usage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Library configuration allows you to specify which vendor libraries to use as reference libraries for the current design.\n You specify the technology file, physical libraries, and logic libraries by using the  search_path and  link_library variables, and then you use the create_lib or  set_ref_libs command to assemble the cell libraries.\n       During library configuration, \u2022 The Fusion Compiler tool automatically calls the Library Manager tool without user intervention to generate cell libraries, as shown in the following figure:.frame files ASCII technology file.db files Cell libraries Synthesis \u2022 The tool saves the generated cell libraries to disk and adds them to the reference library list of the design library.\n \u2022 These cell libraries are the same as when the cell libraries are created during library preparation in the Library Manager tool.\n For more information, see the Configuring Cell Libraries topic in the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Restricting the Target Libraries Used", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the Fusion Compiler tool can use all of the library cells available in the cell libraries when performing optimization or clock tree synthesis on the block.\n To restrict the cell usage, use the  set_lib_cell_purpose command after the block is in memory.\n The command has a block scope and is persistent across tool sessions.\n The specified settings are restored when the block is reopened.\n To specify how the tool can or cannot use library cells, use the  -include and  -exclude options with the  set_lib_cell_purpose command.\n Both of these options accept one or more of the following values:  all,  cts,  hold,  optimization,  none.\n \u2022 The  -include option sets the  included_purposes attribute on the specified library cells.\n \u2022 The  -exclude option sets the  excluded_purposes attribute on the specified library cells.\n       Note: If a library cell has a  dont_use attribute, it is excluded from all uses, which is the same as if you specified  set_lib_cell_purpose\u00a0-include\u00a0none for that cell.\n When the tool performs optimization, which includes setup, hold, and logical DRC fixing, it can use library cells that have an included purpose of  optimization,  hold, or both.\n When the tool performs clock tree synthesis, it can use library cells that have an included purpose of  cts.\n For example, to disallow the use of a set of library cells for all uses, use the following command: fc_shell>\u00a0 set_lib_cell_purpose -include none  lib_cells To allow a set of library cells to be used only for clock tree synthesis, use the following commands: fc_shell>\u00a0 set_lib_cell_purpose -include none  lib_cells fc_shell>\u00a0 set_lib_cell_purpose -include cts  lib_cells To allow a set of library cells to be used for all uses except clock tree synthesis, use the following command: fc_shell>\u00a0 set_lib_cell_purpose -exclude cts  lib_cells To use the asterisk wildcard character (*) to query a collection of cells, you must use the get_lib_cells command.\n However, the  set_lib_cell_purpose command excludes synthetic modules by default.\n Therefore, you should use the  set_synlib_dont_use command to exclude synthetic modules.\n For example, fc_shell>\u00a0 set_lib_cell_purpose \\ -include none [get_lib_cells */*01_*_AB] Warning:\u00a0The\u00a0'set_lib_cell_purpose'\u00a0command\u00a0cannot\u00a0be\u00a0used\u00a0on\u00a0synthetic library\u00a0cell\u00a0'standard:*OPMOD.DW01_ADD_AB.timing'.\n (NDMUI-511) 0"}
{"header": "How do I Specifying Library Subset Restrictions", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool can select any library cell from the target library during optimization.\n In some cases, you might want to restrict the library cells used for clock tree synthesis and optimization.\n For example, you might want to exclude specific double-height cells from the target library for some design blocks during optimization.\n To restrict the library cells used for clock tree synthesis and optimization, 1.\n Specify the library subset by using the  set_target_library_subset command.\n By default, the library subset restriction applies to       \u25e6 The top block and all its subblocks To set it for a specific subblock, use the  -objects option.\n \u25e6 Both clock and data paths.\n To set it for only the clock or data paths, use the  -clock or  -data option.\n You can further restrict the target library subset setting as follows: \u25e6 Specify a list of cells from the libraries that should not be used by using the -dont_use option.\n \u25e6 Specify that these libraries cannot be used for any other objects, other than the specified objects, by using the  -only_here option.\n 2.\n Enable the use of the target library subset by setting the opt.common.enable_target_library_subset_opt application option to 1.\n When you set target library subsets, remember the following points: \u2022 The subset restriction applies to hierarchical cells but not to leaf cells.\n \u2022 The command enforces the subset restriction on the specified blocks and their subdesigns in the hierarchy, except those subdesigns where a different subset restriction is set.\n \u2022 A subset specified at a lower level supersedes any subset specified at a higher level.\n Figure 7 Logic Hierarchy of Design       For example, assume your design has a logic hierarchy as shown in  Figure\u00a07  and you want to implement the following library restrictions during optimization and clock tree synthesis: \u2022 Use only the cells from the library named LVT_lib for the Sub1 block and its subblocks, SubA and SubB.\n \u2022 Do not use the cells from this library anywhere else in the design.\n To do so, use the following settings: fc_shell>\u00a0 set_target_library_subset -objects {top/Sub1} \\ -only_here [get_lib_cells LVT_lib/*] [get_libs LVT_lib] fc_shell>\u00a0 set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 In addition to these settings, assume you specify the following setting: fc_shell>\u00a0 set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} Then, when adding buffers on the clock network during clock tree synthesis, the tool uses \u2022 The buf1 and buf2 cells from the LVT_lib library for the block named Sub1 and its subblocks \u2022 The buf1 and buf2 cells from the HVT_lib library for the rest of the design Reporting Target Library Subsets To find out which target library subsets have been defined for a top block or hierarchical cell, use the  report_target_library_subset command.\n Reports that are generated by reporting commands, such as  report_cells and report_timing, show the  td attribute attached to the cells that are specified by the -dont_use or  -only_here option.\n Removing Target Library Subsets To remove a target library subset restriction from a top block or hierarchical cell, use the remove_target_library_subset command."}
{"header": "How do I Using Pin Access Checker Utility", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can restrict the mapping and optimization of sequential cells and instantiated combinational cells to a subset of reference libraries and library cells.\n To specify one or more library subset restrictions, use the  define_libcell_subset command followed by the  set_libcell_subset command.\n       Note: The library subset restrictions apply to leaf cells, but not to hierarchical cells.\n To set library subset restrictions on leaf cells, 1.\n Define a subset of library cells by using the  define_libcell_subset command.\n After the library cells are grouped into a subset, they are not available for general mapping during optimization, but for sequential cells and instantiated combinational cells only.\n 2.\n Restrict the optimization of sequential and instantiated combinational cells by using the set_libcell_subset command.\n During optimization, the tool uses the library subset defined in step 1 to optimize sequential cells (both mapped and unmapped) and mapped combinational cells.\n In the following example, the  define_libcell_subset command groups the SDFLOP1 and SDFLOP2 library cells into a subset called special_flops, and then the set_libcell_subset command restricts the mapping of the LEAF1 leaf cell to the special_flops library subset.\n fc_shell>\u00a0 define_libcell_subset \\ -libcell_list \"SDFLOP1 SDFLOP2\" -family_name special_flops fc_shell>\u00a0 set_libcell_subset \\ -object_list \"HIER1/LEAF1\" -family_name special_flops Reporting Library Subset Restrictions To report library subsets specified for sequential cells and instantiated combinational cells, use the  report_libcell_subset command.\n Removing Library Subset Restrictions To remove library subsets, use the  remove_libcell_subset command."}
{"header": "How do I Analyzing Libraries", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The pin access checker (PAC) utility helps you to identify the pin accessibility issues in the library development stage.\n This helps you to enhance the cell layout as you cannot modify the cell layout later, after the library is finalized and released to the Place and Route group.\n The routing DRCs identify the pin access issues after routing.\n When the cells are abutted or placed too close, two or multiple adjacent pins compete for common routing resources and causes routing DRCs.\n       The benefits of PAC utility are listed as follows: \u2022 Produces a place and route database with various permutations of abutted cell placement.\n \u2022 Generates a place and route database and assesses the ability to place and pin accessibility of the library created based on the reports.\n The PAC performs various checks listed as follows: \u2022 Placement of cells \u2022 Number of accessible tracks for each library cell\u2019s pins \u2022 Legalization check after placement \u2022 Design rule check after routing \u2022 All the earlier listed checks with PG routes You can use the  create_pin_check_lib command to create or open a new library based on the input technology and reference libraries.\n PAC creates and stores blocks in this library.\n You must provide minimum three inputs by using the following application options with the  create_pin_check_lib command: \u2022 Technology file: Use the  -technology option to provide the technology file information.\n \u2022 Reference library: Use the  -ref_libs option to provide the reference library information.\n \u2022 Routing direction for metal layers: Use the  set_attribute\u00a0[get_layers Mx]\u00a0routing_direction\u00a0 horizontal/vertical command to define routing direction in Tcl script.\n You must specify the name of the script using the pin_check.place.preplace_option_file application option.\n To enable the pin access check utility, you can use the  check_libcell_pin_access command.\n You can use this command and the  pin_check.* application option to enable the following pin access checks: \u2022 Legalization \u2022 Router \u2022 Automatic derivation of cell spacing rule Use the  -mode option with the  check_libcell_pin_access command to perform multiple checks by specifying different modes.\n create_pin_check_lib\u00a0myTest.nlib\u00a0-ref_libs\u00a0../lib/refLib.ndm -technology\u00a0../tf/refTech.tf        set_app_options\u00a0-as_user_default\u00a0-name pin_check.place.preplace_option_file\u00a0-value  check_libcell_pin_access\u00a0-mode\u00a0analyze_lib_cell  check_libcell_pin_access\u00a0-mode\u00a0analyze_lib_pin  check_libcell_pin_access\u00a0-mode\u00a0design_under_test If you have been using the earlier Tcl based version, you can translate your old scripts into new Fusion Compiler commands by using the  translate_pin_check_ui command.\n translate_pin_check_ui\u00a0-from\u00a0old_script.tcl\u00a0-to\u00a0new_script.tcl"}
{"header": "How do I Introduction to Redundancies, Outliers, Equivalences, and Gaps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides the following library analysis capabilities, which can help achieve the performance, power, and area goals of your design: \u2022 Identify redundant, outlier, and equivalent cells in library cell families, which you can exclude from optimization during the subsequent steps in the implementation flow.\n \u2022 Identify gaps in library cell families, which you can provide as feedback to your library vendor with the goal of improving the reference libraries.\n \u2022 Compare the delay, power, area, and other characteristics of equivalent cells in different libraries or different versions of the same library, which can help you identify the appropriate libraries to use for design implementation.\n A family of library cells is a collection of cells that share some common properties.\n The tool can identify a family of library cells based on \u2022 User-identified library cells properties, such function, threshold voltage, and so on \u2022 User-defined library cells lexical attributes and settings \u2022 User-specified custom library cell families The following figure shows the high-level flow for performing library analysis.\n       Figure 8 Library Analysis Flow For more information about the different types of library analysis flows, see the following topics: \u2022 Introduction to Redundancies, Outliers, Equivalences, and Gaps in Library Cell Families \u2022 Identifying Redundancies, Outliers, Equivalences, and Gaps in Library Cell Families \u2022 Comparing Libraries"}
{"header": "How do I Identifying Redundancies, Outliers, Equivalences, and Gaps in", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When a family of cells with the same function is ordered in terms of increasing drive strength, specific cell property values should be monotonically increasing or decreasing.\n For example, when a family is ordered in terms of increasing drive strength, the area of cells should be monotonically increasing, power should be increasing, and delay (for the same output load and input slew) should be decreasing.\n       The following figure shows a monotonic distribution of cell area versus timing for a family of cells with the same function.\n Figure 9 Monotonic Distribution in Library Cell Family       A cell is considered redundant if all its metrics, such as area, delay, power, and so on, are equal or worse than another cell, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n Figure 10 Redundant Cell in Library Cell Family       A cell is considered an outlier if its metrics has a very large deviation from the expected values, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n Figure 11 Outlier Cell in Library Cell Family       Cells are considered equivalent if all their properties are the same for all process, voltage, and temperature (PVT) values, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n Figure 12 Equivalent Cells in Library Cell Family       A gap is when there is a large difference between two successive drive strengths, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n Figure 13 Gap in Library Cell Family"}
{"header": "How do I Comparing Libraries", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To identify redundancies, outliers, equivalences, and gaps in cell families, perform the following steps: 1.\n Create a collection of the libraries you want to analyze, which is known as a libset, by using the  create_libset command, as shown in the following example: fc_shell>\u00a0 create_libset -name myLibset -libs {abcd1 abcd2} When you perform library analysis, you can specify the libset name, instead of specifying a list of libraries.\n In addition, the tool uses the libset name, instead of using a list of the library names, when it generates reports, plots, and so on during analysis.\n You can include a cell library in more then one libset.\n 2.\n Set up the library analysis environment by using the  create_environment command.\n       The  create_environment command associates a predefined libset with a process label, process number, voltage, and temperature, which is then used for analyzing the libraries.\n You can specify the process label, process number, voltage, and temperature of the analysis environment by using one of the following methods: \u25e6 Specify the process label, process number, voltage, and temperature values by using the  -ppvt option, as shown in the following example: fc_shell>\u00a0 create_environment -name env1 -libset myLibset \\ -ppvt {{SS1p, 1.0, 0.6, 125}} \u25e6 Specify a predefined operating condition from the reference library by using the -op_conds option, as shown in the following example: fc_shell>\u00a0 create_environment -name env2 -libset myLibset \\ -op_conds SS1p6125 \u25e6 Specify corners from which to infer the process label, process number, voltage, and temperature values by using the  -corners option, as shown in the following example: fc_shell>\u00a0 create_environment -name env3 -libset myLibset \\ -corners nworst \u25e6 Specify that the tool infers the process label, process number, voltage, and temperature values from the scenario and UPF associated with the current design by using the  -auto_infer_design option, as shown in the following example: fc_shell>\u00a0 create_environment -name env4 -libset myLibset \\ -auto_infer_design 3.\n (Optional) Specify a naming convention for library cells and perform lexical classification by using lexical attributes.\n A library cell naming convention can help the tool identify cell families in the subsequent steps of the flow.\n For example, assume a cell in your library is named AND2D4WSULVT.\n This name is the concatenation of the AND2, D4, WS, and ULVT string, which represent cell characteristics that are associated to a lexical attribute, as shown in the following table: Table 2 Lexical Attributes for the Naming Convention of an Example Library Column Lexical Attribute Allowed Pattern Values for Example Cell  lexical_cell_prefix_name         Column Lexical Attribute Allowed Pattern Values for Example Cell  lexical_drive1_name    lexical_well_substrate_bias_arch itecure    lexical_device_threshold_voltage   You can specify the naming convention for this library by using the set_lib_cell_naming_convention command, as shown in the following example: fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 1 -pattern {[a-zA-Z0-9]*} -attribute \"lexical_cell_prefix_name\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 2 -pattern {D[0-9]*} -attribute \"lexical_drive1_name\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 3 -pattern {WS} -attribute \"lexical_well_substrate_bias_architecure\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 4 -pattern {ULVT|SVT|LVT|MVT} -attribute \"lexical_device_threshold_voltage\" Note: For a list of all the predefined lexical attributes, see the man page for the set_lib_cell_naming_convention command.\n After you specify the naming convention, perform lexical classification by using the classify_lib_cell_attributes command, as shown in the following example: fc_shell>\u00a0 classify_lib_cell_attributes -libset myLibset To report the lexical classification results, use the report_lib_cell_classification_attributes command.\n To report the library cells which are not lexical classified under the given naming convention, use the  report_lexical_unclassified_lib_cells command.\n If there are lexically unclassified cells, specify additional naming conventions and rerun lexical classification.\n 4.\n (Optional) Exclude specific cells from library analysis by using the set_use_for_library_analysis command.\n       By default, the tool excludes physical-only cells during library analysis.\n However, you can exclude additional cells, such as library cells with a  dont_use setting, as shown in the following example: fc_shell>\u00a0 set exclude_cells [filter_collection [get_lib_cells $libs/*] \\ \"dont_use == true\"] fc_shell>\u00a0 set_use_for_library_analysis $exclude_cells false To report the cells that are excluded, use the  report_lexical_ignored_lib_cells command.\n 5.\n Identify all library cell families by using the  identify_lib_cell_families command.\n To report the tool-identified library cell families, use the  report_lib_cell_families -all_initial command.\n To manually define library cell families, use the  define_lib_cell_family command.\n To report these user-defined cell families, use the  report_lib_cell_families -all_userdef command.\n 6.\n Analyze the libraries by using the  run_library_analysis command, as shown in the following example: fc_shell>\u00a0 run_library_analysis -name myLibset_run1 -environment env1 The name of the environment you specify with the  -environment option must correspond to an environment you previously created by using the create_environment command.\n 7.\n Identify redundancies in library cell families by using the  find_library_redundancies command, as shown in the following example: fc_shell>\u00a0 find_library_redundancies -analysis myLibset_run1 The name of the analysis you specify with the  -analysis option must correspond to the name of an analysis you previously performed by using the run_library_analysis command.\n In addition to redundant cells, the  find_library_redundancies command also identifies outlier and equivalent cells in library families.\n 8.\n Identify gaps in library cell families by using the  find_library_gaps command, as shown in the following example: fc_shell>\u00a0 find_library_gaps -analysis myLibset_run1 The name of the analysis you specify with the  -analysis option must correspond to the name of an analysis you previously performed by using the run_library_analysis command.\n       9.\n Report the library cell gaps, redundancies, outliers, and equivalence identified during library analysis by using the  report_library_analysis command, as shown in the following example: fc_shell>\u00a0 report_library_analysis -analysis myLibset_run1 \\ -analysis_type redundancy -detail fc_shell>\u00a0 report_library_analysis -analysis myLibset_run1 \\ -analysis_type outlier -detail fc_shell>\u00a0 report_library_analysis -analysis myLibset_run1 \\ -analysis_type equivalent -detail fc_shell>\u00a0 report_library_analysis -analysis myLibset_run1 \\ -analysis_type gap -detail 10.\n Generate plots by using the  gui_plot_lib_cells_attributes command, as shown in the following example: fc_shell>\u00a0 gui_plot_lib_cells_attributes -libset myLibset \\ -lib_cell_type all -x_attrib_name leakage -y_attrib_name avgsl_fall_delay \\ -chart_type scatter"}
{"header": "How do I Reading the Design", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To compare libraries, perform the following steps: 1.\n Create a collection of the libraries you want to analyze, which is known as a libset, by using the  create_libset command, as shown in the following example: fc_shell>\u00a0 create_libset -name myLibset -libs {abcd1.db abcd2.db} When you perform library analysis, you can specify the libset name, instead of specifying a list of libraries.\n In addition, the tool uses the libset name, instead of using a list of the library names, when it generates reports, plots, and so on during analysis.\n You can include a cell library in more then one libset.\n 2.\n Set up the library analysis environment by using the  create_environment command.\n The  create_environment command associates a predefined libset with a process label, process number, voltage, and temperature, which is then used for analyzing the libraries.\n You can specify the process label, process number, voltage, and temperature of the analysis environment by using one of the following methods: \u25e6 Specify the process label, process number, voltage, and temperature values by using the  -ppvt option, as shown in the following example: fc_shell>\u00a0 create_environment -name env1 -libset myLibset \\ -ppvt {{SS1p, 1.0, 0.6, 125}}       \u25e6 Specify a predefined operating condition from the reference library by using the -op_conds option, as shown in the following example: fc_shell>\u00a0 create_environment -name env2 -libset myLibset \\ -op_conds SS1p6125 \u25e6 Specify corners from which to infer the process label, process number, voltage, and temperature values by using the  -corners option, as shown in the following example: fc_shell>\u00a0 create_environment -name env3 -libset myLibset \\ -corners nworst \u25e6 Specify that the tool infers the process label, process number, voltage, and temperature values from the scenario and UPF associated with the current design by using the  -auto_infer_design option, as shown in the following example: fc_shell>\u00a0 create_environment -name env4 -libset myLibset \\ -auto_infer_design 3.\n (Optional) Specify a naming convention for library cells and perform lexical classification by using lexical attributes.\n A library cell naming convention can help the tool identify cell families in the subsequent steps of the flow.\n For example, assume a cell in your library is named AND2D4WSULVT.\n This name is the concatenation of the AND2, D4, WS, and ULVT strings, which represent cell characteristics that are associated to a lexical attribute as shown in the following table: Table 3 Lexical Attributes for the Naming Convention of an Example Library Column Lexical Attribute Allowed Pattern Values for Example Cell  lexical_cell_prefix_name    lexical_drive1_name    lexical_well_substrate_bias_arch itecure    lexical_device_threshold_voltage         You can specify the naming convention for this library by using the set_lib_cell_naming_convention command, as shown in the following example: fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 1 -pattern {[a-zA-Z0-9]*} -attribute \"lexical_cell_prefix_name\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 2 -pattern {D[0-9]*} -attribute \"lexical_drive1_name\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 3 -pattern {WS} -attribute \"lexical_well_substrate_bias_architecure\" fc_shell>\u00a0 set_lib_cell_naming_convention -library $lib \\ -column 4 -pattern {ULVT|SVT|LVT|MVT} -attribute \"lexical_device_threshold_voltage\" Note: For a list of all the predefined lexical attributes, see the man page for the set_lib_cell_naming_convention command.\n After you specify the naming convention, perform lexical classification, by using the classify_lib_cell_attributes command as shown in the following example: fc_shell>\u00a0 classify_lib_cell_attributes -libset myLibset To report the lexical classification results, use the report_lib_cell_classification_attributes command.\n To report the library cells which are not lexical classified under the given naming convention, use the  report_lexical_unclassified_lib_cells command.\n If there are lexically unclassified cells, specifies addition naming conventions and rerun lexical classification.\n 4.\n (Optional) Exclude specific cells from library analysis by using the set_use_for_library_analysis command.\n By default, the tool excludes physical-only cells during library analysis.\n However, you can exclude additional cells, such as library cells with a  dont_use setting, as shown in the following example: fc_shell>\u00a0 set exclude_cells [filter_collection [get_lib_cells $libs/*] \\ \"dont_use == true\"] fc_shell>\u00a0 set_use_for_library_analysis $exclude_cells false To report the cells that are excluded, use the  report_lexical_ignored_lib_cells command.\n 5.\n Identify all library cell families by using the  identify_lib_cell_families command.\n       To report the tool-identified library cell families, use the  report_lib_cell_families -all_initial command.\n To manually define library cell families, use the  define_lib_cell_family command, and to report these user-defined cell families, use the  report_lib_cell_families -all_userdef command.\n 6.\n Analyze the libraries by using the  run_library_analysis command, as shown in the following example: fc_shell>\u00a0 run_library_analysis -name myLibset_run1 -environment env1 The name of the environment you specify with the  -environment option must correspond to an environment you previously created by using the create_environment command.\n 7.\n Compare libraries by using the  compare_libraries command.\n When doing so, you must specify the two libraries you want to compare by using the -ref_lib and  -target_lib options.\n In addition, you must specify the name of the library analysis runs, performed by using the  run_library_analysis command in the previous step, for each of these libraries.\n To do so use the  -ref_lib_analysis and -target_lib_analysis options, as shown in the following example: fc_shell>\u00a0 compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa -verbose -plot When comparing libraries, you might encounter the following situations related to name matching between the cells of the reference and target libraries: \u25e6 The cell names in the reference and target libraries can be an exact match, as in the case when it is two different versions of the same library.\n If so, additional lexical classification is not required.\n \u25e6 The reference and target libraries can have the same naming convention, except less lexical attributes in one library.\n For example, assume a cell named ND2D1SVT in the reference library matches a cell named ND2D1 in the target library.\n In this case, the target library cell names do not contain a  lexical_device_threshold_voltage attribute, as shown in the following table.\n Table 4 Reference and Target Library Lexical Attribute Differences Lexical Attribute Reference Library Target Library lexical_cell_prefix_name   lexical_drive1_name         Lexical Attribute Reference Library Target Library lexical_device_threshold_voltage   In this situation, you should ignore the  lexical_device_threshold_voltage attribute when comparing the two libraries.\n To do so, use the following application option settings before you run the  compare_libraries command: fc_shell>\u00a0 set_app_options -name libra.complib.match_full_cell_name -value false fc_shell>\u00a0 set_app_options -name libra.complib.match_lexical_device_threshold_voltage -value false fc_shell>\u00a0 compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa -verbose -plot Note: For a complete list of application options you can use to control name matching during library comparison, see the man page for the compare_libraries command.\n \u25e6 The reference and target libraries can have a similar naming convention, but the lexical attributes values might not identical.\n For example, assume a cell named ND2D1SVT in the reference library"}
{"header": "How do I Reading the Design", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "matches a cell named nand2_svth_x1 in the target library.\n In this case, the reference and target libraries have the same lexical attributes, which have similar but not the same values, as shown in the following table.\n Table 5 Reference and Target Library Lexical Attribute Differences Lexical Attribute Reference Library Target Library lexical_cell_prefix_name   lexical_drive1_name   lexical_device_threshold_voltage   In this situation, you must create a lexical attribute mapping file that contains the following information: lexical_cell_prefix_name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ND2\u00a0\u00a0nand2 lexical_drive1_name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0D1\u00a0\u00a0\u00a0x1 lexical_device_threshold_voltage\u00a0\u00a0SVT\u00a0\u00a0svth       Then, when you run the  compare_libraries command, you must specify this lexical attribute mapping file by using the  -lex_attr_mapping option, as shown in the following example: fc_shell>\u00a0 set_app_options -name libra.complib.match_full_cell_name -value false fc_shell>\u00a0 compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa \\ -lex_attr_mapping attribute_map_file -verbose -plot \u25e6 The reference and target library naming convention is completely different.\n In this situation, you must create a custom mapping file that contains the cell pairs you want to compare, as shown in the following example: INVD2BWP\u00a0\u00a0\u00a0\u00a0\u00a0INVD1BWPHVT INVD2BWP\u00a0\u00a0\u00a0\u00a0\u00a0BUFFD4BWPHVT ND2D2BWP\u00a0\u00a0\u00a0\u00a0\u00a0ND2D4BWPHVT DFQD4BWP\u00a0\u00a0\u00a0\u00a0\u00a0SDFQD4BWPHVT Then, when you run the  compare_libraries command, you must specify this mapping file, by using the  -custom_pairs option, as shown in the following example: fc_shell>\u00a0 set_app_options -name libra.complib.match_full_cell_name -value false fc_shell>\u00a0 compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa \\ -custom_pairs custom_map_file -verbose -plot"}
{"header": "How do I Reading RTL Files in SystemVerilog, Verilog, or VHDL Format", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you read a design, you must create or open the design library associated with the design, as described in  Setting Up Libraries.\n The tool can read RTL designs in SystemVerilog, Verilog, or VHDL and gate-level netlists in Verilog format.\n Use the following methods to read designs: \u2022 Reading RTL Files in SystemVerilog, Verilog, or VHDL Format \u2022 Reading Designs Using the -autoread Option \u2022 Reading Designs Using the VCS Command-line Options \u2022 Reading Verilog Gate-Level Netlist Files \u2022 Reading Mixed Gate-Level Netlists and RTL Files       By default, when the tool reads the RTL or gate-level netlist files, it creates a block in the current design library and increments its open count.\n The tool determines the top-level module of the block by identifying the module that is not instantiated by any other modules in the specified files and uses the top-level module name as the block name.\n Use the following commands to work with blocks: \u2022 create_block : Creates a block \u2022 open_block : Opens an existing block \u2022 current_block : Sets or reports the current block \u2022 save_block : Saves a block \u2022 close_blocks : Closes a block See Also \u2022 Blocks \u2022 Working With Design Libraries"}
{"header": "How do I Reading Designs Using the -autoread Option", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  analyze and  elaborate commands followed by the  set_top_module command.\n The  analyze command automatically creates HDL template libraries on disk based on the name of the library provided by the  -hdl_library option.\n The location of the HDL template libraries is controlled by the  hdlin.hdl_library.default_dirname application option.\n When the  -hdl_library option is not specified, the default library name is WORK.\n To specify a different default library name, use the  hdlin.hdl_library.default_name application option.\n Note: All of the application options that control the RTL reading behavior have the hdlin prefix.\n The  elaborate command builds the module specified without linking the rest of the design.\n Design linking can be performed only after the entire design is in memory, so linking is not performed by the  elaborate command.\n This allows multiple  elaborate commands to be run before performing the single linking of the entire design.\n The top-level module must be one of the modules that is elaborated.\n Linking of the design and setting the top-level module is done using the  set_top_module command.\n The top-level module is given as an argument to the  set_top_module command.\n The top-level module must be a module that was previously elaborated with the elaborate command.\n The  set_top_module command sets the specified module to be       the top-level design, links the entire design, and creates a single block to be used for the remainder of the synthesis flow.\n The following script reads VHDL files using template libraries and creates a block called top.\n You do not need to specify the location of the template libraries on disk, which is automatically created by the  analyze command based on the  -hdl_library option.\n analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0BOT_HDL_LIB\u00a0bot.vhd analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0MID_HDL_LIB\u00a0mid.vhd analyze\u00a0-format\u00a0vhdl\u00a0top.vhd elaborate\u00a0top set_top_module\u00a0top If the top-level design is analyzed to an HDL template library other than the default library, you should provide the HDL template library name for the top-level design using the -hdl_library option.\n For example, analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0BOT_HDL_LIB\u00a0bot.vhd analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0MID_HDL_LIB\u00a0mid.vhd analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0TOP_HDL_LIB\u00a0top.vhd elaborate\u00a0-hdl_library\u00a0TOP_HDL_LIB\u00a0top set_top_module\u00a0top You can optionally specify the location of the HDL template libraries on disk by using the define_hdl_library command.\n For example, define_hdl_library\u00a0BOT_HDL_LIB\u00a0-path\u00a0./TEMPLATES/BOT_HDL_LIB define_hdl_library\u00a0MID_HDL_LIB\u00a0-path\u00a0./TEMPLATES/MID_HDL_LIB define_hdl_library\u00a0WORK\u00a0-path\u00a0./TEMPLATES/WORK analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0BOT_HDL_LIB\u00a0bot.vhd analyze\u00a0-format\u00a0vhdl\u00a0-hdl_library\u00a0MID_HDL_LIB\u00a0mid.vhd analyze\u00a0-format\u00a0vhdl\u00a0top.vhd elaborate\u00a0top set_top_module\u00a0top"}
{"header": "How do I Reading Designs Using the VCS Command-line Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable the tool to automatically read a list of RTL files, specify the  -autoread option with the  analyze command, as shown in the following example.\n When this option is specified, the RTL language used to analyze the RTL files is automatically determined by the file name extension.\n To control the file name extensions, use the following application options:  hdlin.autoread.verilog_extensions, hdlin.autoread.sverilog_extensions,  hdlin.autoread.vhdl_extensions, and hdlin.autoread.exclude_extensions.\n set\u00a0DESIGN_NAME\u00a0top analyze\u00a0-autoread\u00a0-top\u00a0${DESIGN_NAME}\u00a0${RTL_FILE_LIST} elaborate\u00a0${DESIGN_NAME} elaborate\u00a0-hdl_library\u00a0TOP_HDL_LIB\u00a0top set_top_module\u00a0${DESIGN_NAME}"}
{"header": "How do I Reading Verilog Gate-Level Netlist Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  analyze command with the VCS command-line options provides compatibility with VCS simulation scripts and makes reading large designs easier.\n When you use the VCS command-line options, the tool automatically resolves references for instantiated designs by searching the referenced designs in the specified libraries and then loading these referenced designs.\n To read designs containing many HDL source files and libraries, specify the  -vcs option with the  analyze command.\n You must enclose the VCS command-line options in double quotation marks.\n For example, analyze\u00a0-vcs\u00a0\"-verilog\u00a0-y\u00a0mylibdir1\u00a0+libext+.v\u00a0-v\u00a0myfile1\u00a0\\ +incdir+myincludedir1\u00a0-f\u00a0mycmdfile2\"\u00a0top.v elaborate\u00a0${DESIGN_NAME} set_top_module\u00a0${DESIGN_NAME} To read SystemVerilog files with a specified file extension and Verilog files in one  analyze command, use the  -vcs\u00a0\"+systemverilogext+ext\" option.\n When you do so, the files must not contain any Verilog 2001 styles.\n For example, the following command analyzes SystemVerilog files with the.sv file extension and Verilog files: analyze\u00a0-format\u00a0verilog\u00a0-vcs\u00a0\"-f\u00a0F\u00a0+systemverilogext+.sv elaborate\u00a0${DESIGN_NAME} set_top_module\u00a0${DESIGN_NAME}"}
{"header": "How do I Reading Mixed Gate-Level Netlists and RTL Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  read_verilog command to read Verilog netlist files using a specialized Verilog netlist reader.\n This command cannot be used to read Verilog RTL files.\n Only the  analyze and  elaborate commands should be used to read RTL files.\n Use the  set_top_module command after reading the netlist to specify the top-level module and link the design to create the block.\n read_verilog\u00a0top.netlist.v set_top_module\u00a0top When the file has multiple independent modules, use the  -top option to identify the top- level module.\n For example, read_verilog\u00a0-top\u00a0top2\u00a0netlists.v set_top_module\u00a0top2       To specify a new block name other than  top_module_name.design, use the  -design option.\n For example, read_verilog\u00a0-top\u00a0my_top\u00a0-design\u00a0desA\u00a0../my_data/my_des.v set_top_module\u00a0my_top"}
{"header": "How do I Embedding Tcl Commands in RTL Code", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can read a combination of Verilog netlists and RTL files.\n Use the  read_verilog command to read the Verilog netlists.\n Use the  analyze and  elaborate commands to read the RTL files.\n After all the netlist files and RTL files have been read into the tool, use the set_top_module command to link the designs to create the block for synthesis.\n The following example shows how you can read a mix of netlist and RTL files.\n As shown in this example, when you elaborate the top-level module with parameters, the top- level module name also contains the parameterized module name.\n You can control the naming style for parameterized modules using the following application options: hdlin.naming.template_naming_style,  hdlin.naming.template_parameter_style, and  hdlin.naming.template_separator_style.\n #\u00a0Read\u00a0netlist\u00a0files read_verilog\u00a0NETLIST/bot.v #\u00a0Analyze\u00a0design\u00a0files analyze\u00a0-format\u00a0sverilog\u00a0-hdl_library\u00a0MID\u00a0RTL/mid.sv analyze\u00a0-format\u00a0sverilog\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RTL/top.svd #\u00a0Elaborate\u00a0top\u00a0design\u00a0module elaborate\u00a0-parameters\u00a0\"N=8,M=3\"\u00a0top #\u00a0Set\u00a0the\u00a0top\u00a0level\u00a0module\u00a0to\u00a0resolve\u00a0references set_top_module\u00a0top_N8_M3"}
{"header": "How do I Mitigating Design Mismatches", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To embed Tcl command in RTL code, use the  fc_tcl_script_begin and fc_tcl_script_end directives.\n The following Tcl commands can be embedded in an RTL design: \u2022 set_attribute \u2022 set_ungroup \u2022 set_size_only \u2022 set_dont_touch \u2022 set_dont_retime \u2022 set_implementation \u2022 set_optimize_registers       \u2022 get_modules \u2022 get_cells \u2022 get_pins \u2022 get_nets \u2022 get_ports The following RTL example contains an embedded Tcl command that applies a  size_only setting on all the registers with the iPort1.dout_reg name prefix: module\u00a0bot\u00a0(\u00a0myIntf1.datIn\u00a0iPort1\u00a0); always\u00a0@(posedge\u00a0iPort1.clk\u00a0or\u00a0negedge\u00a0iPort1.rst) begin if\u00a0(iPort1.rst\u00a0==\u00a01'b0) begin iPort1.dout\u00a0<=\u00a0'0; end\u00a0else\u00a0begin iPort1.dout\u00a0<=\u00a0iPort1.iData1\u00a0+\u00a0iPort1.iData2; end end //\u00a0synopsys\u00a0fc_tcl_script_begin //\u00a0set_size_only\u00a0[get_cells\u00a0iPort1.dout_reg*] //\u00a0synopsys\u00a0fc_tcl_script_end endmodule"}
{"header": "How do I Importing the Floorplan Information", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During early design development, frequent design updates can cause incomplete or inconsistent data, such as pin mismatches between a block-level design and the reference to it from a top-level design.\n To enable the tool to successfully link a block even if it has certain types of design mismatch, set a mismatch configuration for the block.\n By default, the tool cannot link any block with inconsistent or mismatching data.\n When you set mismatch configurations, the tool either ignores or fixes several different types of mismatching data and continues the linking process.\n Blocks linked with mismatching data can be used only for feasibility analysis.\n To learn how to mitigate design mismatches, see the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Reading DEF Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A floorplan contains physical constraints such as the core area and shape, port locations, macro locations and orientations, and so on, which are required for performing physical synthesis and optimization.\n       If you have a floorplan for your block, read in the floorplan as a DEF file, as described in Reading DEF Files.\n If you do not have a floorplan for your block, you can perform design planning and generate a floorplan as described in the  Fusion Compiler Design Planning User Guide.\n During the early stages of design process, you can use automatically-generated floorplan information to run physical synthesis, as described in  Using Automatic Floorplanning."}
{"header": "How do I Fixing Site Name Mismatches", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To read the floorplan information from a DEF file, use the  read_def command.\n fc_shell>\u00a0 read_def  block.def Note: When possible, use DEF v5.8 or later, as this version supports more types of physical objects and obstructions than previous versions.\n By default, the  read_def command \u2022 Annotates the floorplan information onto the current block To annotate the information onto a different block, use the  -design option to specify the block name.\n \u2022 Preserves the existing floorplan information In incremental mode, \u25e6 The placement area is imported based on the current core area and site rows in the DEF files \u25e6 Physical constraints that can have only one value are overwritten by the value from the latest DEF file; for example, port location and macro location are overwritten.\n \u25e6 Physical constraints that can have accumulated values are recomputed; that is, core area can be recomputed based on the existing value and the site row definitions in the latest DEF file.\n Placement keepouts from different DEF files are accumulated and the final keepout geometry is computed internally during synthesis.\n To remove the existing floorplan information before annotating the floorplan information from the DEF file, use the  -no_incremental option.\n In this mode, the placement area is imported based on the site rows in the DEF files.\n \u2022 Uses rule-based name matching for macros and ports       Rule-based name matching automatically resolves name differences by using the tool\u2019s intelligent name matching capability.\n By default, when rule-based name matching is enabled, the following characters are considered equivalent: \u25e6 Hierarchical separators { / _.\n } For example, a cell named a.b_c/d_e is automatically matched with the string a/b_c.d/e in the DEF file.\n \u25e6 Bus notations { [ ] __ ( ) } For example, a cell named a [4] [5] is automatically matched with the string a_4__5_ in the DEF file.\n To disable rule-based name matching and require exact name matches between the DEF file and the block, set the  file.def.rule_based_name_matching application option to  false.\n For more information, see \u201cRule-Based Name Matching\u201d in the  Fusion Compiler Data Model User Guide.\n \u2022 Ignores any objects in the DEF file that do not exist in the block, except for PG objects To allow new non-PG objects to be created from the DEF file, use the -add_def_only_objects option to specify the types of objects to create.\n Specify one or more of the following keywords: \u25e6 cells The tool creates the cells that exist only in the DEF file and connects their power and ground pins as defined in the DEF file; it does not connect the signal, clock, or tie pins even if these connections are defined in the DEF file.\n The tool also does not create new hierarchical cells; any hierarchy specified in the DEF file must already exist in the block.\n \u25e6 nets The tool creates the signal, clock, and tie nets that exist only in the DEF file and connects them to the ports specified in the DEF PINS section; it does not connect the nets to any other ports or pins in the netlist even if these connections       are defined in the DEF file.\n The tool does not create new hierarchical nets; any hierarchy specified in the DEF file must already exist in the block.\n \u25e6 ports The tool creates the signal, clock, and tie ports that exist only in the DEF file and connects them to the nets specified in the DEF PINS section.\n \u25e6 all The tool creates the non-PG cells, nets, and ports that exist only in the DEF file, as if you had specified  cells,  nets, and  ports."}
{"header": "How do I Validating DEF Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If the site names used in the DEF file do not match the site names defined in the technology file, use the  -convert_sites option to specify the site name mapping.\n For example, if the DEF file uses a site named CORE, but the technology file defines only a site named unit, use the following command to convert the site names when reading the DEF file: fc_shell>\u00a0 read_def -convert_sites { {CORE unit} }  block.def"}
{"header": "How do I Physical Constraints Extracted From the DEF File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To analyze the input DEF files before annotating the floorplan information on the block, enable check-only mode by using the  -syntax_only option.\n The check-only mode provides diagnostic information about the correctness and integrity of the DEF file.\n The check-only mode does not annotate any floorplan information onto the block.\n fc_shell>\u00a0 read_def -syntax_only  block.def  fc_shell>\u00a0 check_duplicates -remove The  check_duplicates\u00a0-remove command ensures that no duplicate shapes and vias are present in the block due to the execution of the  read_def command."}
{"header": "How do I Using Automatic Floorplanning", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  read_def command extracts physical constraint information from DEF files and annotates it on the block.\n However, only the following physical constraints are extracted and annotated: \u2022 Placement Area \u2022 Port Locations \u2022 Cell Locations \u2022 Placement Blockages       \u2022 Site Rows \u2022 Routing Tracks \u2022 Placement Bounds \u2022 Routing Blockages \u2022 Preroutes To visually inspect the extracted physical constraints, use the layout view in the GUI.\n All physical constraints extracted from the DEF file are automatically added to the layout view.\n Placement Area Placement area is computed based on the site array information.\n Port Locations For each port with the location specified in the DEF file, the tool sets the location on the corresponding port in the block.\n Note: If the DEF file does not contain port-location information, the tool inherits the port locations from the locations of the pad cells, as described in.\n Example 1 DEF Port Location Information PINS\u00a02\u00a0; -Out1\u00a0+\u00a0NET\u00a0Out1\u00a0+\u00a0DIRECTION\u00a0OUTPUT\u00a0+\u00a0USE\u00a0SIGNAL\u00a0+ LAYER\u00a0M3\u00a0(0\u00a00)\u00a0(4200\u00a0200)\u00a0+\u00a0PLACED\u00a0(80875\u00a00)\u00a0N; -Sel0\u00a0+\u00a0NET\u00a0Sel0\u00a0+\u00a0DIRECTION\u00a0INPUT\u00a0+\u00a0USE\u00a0SIGNAL\u00a0+ LAYER\u00a0M4\u00a0(0\u00a00)(200\u00a0200)\u00a0+\u00a0PLACED\u00a0(135920\u00a042475)\u00a0N; END\u00a0PINS Ports with changed names and multiple layers are supported.\n Example 2 DEF Port Locations With Changed Names and Multiple Layers PINS\u00a02\u00a0; -\u00a0sys_addr\\[23\\].extra2\u00a0+\u00a0NET\u00a0sys_addr[23]\u00a0+\u00a0DIRECTION\u00a0INPUT\u00a0+USE SIGNAL +\u00a0LAYER\u00a0METAL4\u00a0(\u00a00\u00a00\u00a0)\u00a0(\u00a0820\u00a05820\u00a0)\u00a0+\u00a0FIXED\u00a0(\u00a01587825\u00a02744180\u00a0)\u00a0N\u00a0; -\u00a0sys_addr[23]\u00a0+\u00a0NET\u00a0sys_addr[23]\u00a0+\u00a0DIRECTION\u00a0INPUT\u00a0+\u00a0USE\u00a0SIGNAL\u00a0+ LAYER METAL3\u00a0(\u00a00\u00a00\u00a0)\u00a0(\u00a0820\u00a05820\u00a0)\u00a0+\u00a0FIXED\u00a0(\u00a01587825\u00a02744180\u00a0)\u00a0N\u00a0; END\u00a0PINS Example 3 DEF Port Orientation Information PINS\u00a01; -\u00a0OUT\u00a0+\u00a0NET\u00a0OUT\u00a0+\u00a0DIRECTION\u00a0INPUT\u00a0+\u00a0USE\u00a0SIGNAL +\u00a0LAYER\u00a0m4\u00a0(\u00a0-120\u00a00\u00a0)\u00a0(\u00a0120\u00a0240\u00a0)       +\u00a0FIXED\u00a0(\u00a04557120\u00a01726080\u00a0)\u00a0S\u00a0; END\u00a0PINS Cell Locations For each cell with a location and the FIXED attribute specified in the DEF file, the tool sets the location on the corresponding cell in the block.\n  Example\u00a04  shows DEF macro location and orientation information, where the letters E and W denote east rotation and west rotation respectively.\n Example 4 DEF Cell Location Information COMPONENTS\u00a02\u00a0; -\u00a0macro_cell_abx2\u00a0+\u00a0FIXED\u00a0(\u00a04350720\u00a08160\u00a0)\u00a0E\u00a0; -\u00a0macro_cell_cdy1\u00a0+\u00a0FIXED\u00a0(\u00a04800\u00a08160\u00a0)\u00a0W\u00a0; END\u00a0COMPONENTS Placement Blockages The  read_def command imports hard, soft, and partial placement blockages defined in the DEF file.\n Note: DEF versions before version 5.7 did not support partial blockages.\n In addition, if your floorplanning tool creates a DEF file with DEF version 5.6, you need to manually add the  #SNPS_SOFT_BLOCKAGE pragma to specify a soft blockage, as shown in  Example\u00a07.\n Example 5 DEF Hard Placement Blockage Information BLOCKAGES\u00a050\u00a0;...\n -\u00a0PLACEMENT\u00a0RECT\u00a0(\u00a0970460\u00a07500\u00a0)\u00a0(\u00a03247660\u00a0129940\u00a0)...\n END\u00a0BLOCKAGES Example 6 DEF Version 5.7 Soft Placement Blockage Information BLOCKAGES\u00a050\u00a0;...\n -\u00a0PLACEMENT\u00a0+\u00a0SOFT\u00a0RECT\u00a0(\u00a0970460\u00a07500\u00a0)\u00a0(\u00a03247660\u00a0129940\u00a0)\u00a0;...\n END\u00a0BLOCKAGES Example 7 DEF Version 5.6 Soft Placement Blockage Information BLOCKAGES\u00a050\u00a0;...\n -\u00a0PLACEMENT\u00a0RECT\u00a0(\u00a0970460\u00a07500\u00a0)\u00a0(\u00a03247660\u00a0129940\u00a0)\u00a0;\u00a0#SNPS_SOFT_BLOCKAGE...\n END\u00a0BLOCKAGES       Example 8 DEF Partial Placement Blockage Information BLOCKAGES\u00a050\u00a0;...\n -\u00a0PLACEMENT\u00a0+\u00a0PARTIAL\u00a080\u00a0RECT\u00a0(\u00a0970460\u00a07500\u00a0)\u00a0(\u00a03247660\u00a0129940\u00a0)\u00a0;...\n END\u00a0BLOCKAGES Site Rows Site row information in the DEF file defines the placement area.\n Example 9 DEF Site Row Information ROW\u00a0ROW_0\u00a0core\u00a00\u00a00\u00a0N\u00a0DO\u00a0838\u00a0BY\u00a01\u00a0STEP\u00a0560\u00a00; Routing Tracks The track information in the DEF file defines the routing grid for designs based on standard cells.\n This information can be used during routing, and track support can enhance congestion evaluation and reporting to make it match more closely with the routing results.\n Example 10 DEF Routing Track Information TRACKS\u00a0X\u00a0330\u00a0DO\u00a0457\u00a0STEP\u00a0660\u00a0LAYER\u00a0METAL1\u00a0; TRACKS\u00a0Y\u00a0280\u00a0DO\u00a0540\u00a0STEP\u00a0560\u00a0LAYER\u00a0METAL1\u00a0; Placement Bounds If REGIONS defining bounds exist in the DEF file, the  read_def command imports those placement bounds.\n Also, if any cells in the related GROUP are attached to the region, fuzzy cell matching occurs between these cells and the ones in the block.matched cells are attached to the bounds in the following ways: \u2022 If there are regions in the block with the same name as in the DEF, the cells in the related group are attached to the region by the  add_to_bound command in incremental mode.\n \u2022 If the region does not exist in the block, it is created with the same name as in the DEF file by applying the  create_bound command; matched cells in the related group are also attached.\n Example 11 DEF Placement Bound Information REGIONS\u00a01\u00a0; -\u00a0c20_group\u00a0(\u00a0201970\u00a040040\u00a0)\u00a0(\u00a0237914\u00a075984\u00a0)\u00a0+\u00a0TYPE\u00a0FENCE\u00a0; END\u00a0REGIONS GROUPS\u00a01\u00a0; -\u00a0c20_group cell_abc1 cell_sm1 cell_sm2       +\u00a0SOFT +\u00a0REGION\u00a0c20_group\u00a0; END\u00a0GROUPS Routing Blockages Routing blockages are extracted similar to the way that placement blockages are extracted.\n Preroutes The tool extracts preroutes that are defined in the DEF file.\n Example 12 DEF Preroute Information SPECIALNETS\u00a02\u00a0; -\u00a0vdd +\u00a0ROUTED\u00a0METAL3\u00a010000\u00a0+\u00a0SHAPE\u00a0STRIPE\u00a0(\u00a010000\u00a0150000\u00a0)\u00a0(\u00a050000\u00a0*\u00a0) +\u00a0USE\u00a0POWER\u00a0;...\n END\u00a0SPECIALNETS"}
{"header": "How do I Creating Constraints for Auto Floorplanning", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During early design stages, a design often undergoes many iterations due to changes such as adding features and macros; as a result, the floorplan contains limited or no physical information.\n Automatic floorplanning can generate high-quality floorplans and create missing physical information early in the design cycle, which allows you to \u2022 Achieve better correlation between the results of RTL synthesis and design implementation \u2022 Identify and fix design issues early in the design cycle \u2022 Generate a better starting point for place and route, eliminating costly iterations During automatic floorplanning, the  compile_fusion command performs the following tasks: \u2022 Creates the die, rows, and tracks \u2022 Shapes and places voltage areas \u2022 Places macros \u2022 Places pins and I/Os By default, the top-level floorplan is created with a core utilization of 0.7.\n For information about setting constraints for automatic floorplanning, see  Creating Constraints for Auto Floorplanning."}
{"header": "How do I Setting Up Multivoltage Designs", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the commands and application options described in this topic to create constraints for auto floorplanning.\n Commands Use the following two commands to set and report auto floorplanning constraints.\n These two commands do not affect explicit floorplanning.\n \u2022 set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile.\n For example, fc_shell>\u00a0 set_auto_floorplan_constraints -core_utilization 0.8 \u2022 report_auto_floorplan_constraints The command reports the constraints set by the  set_auto_floorplan_constraints command.\n To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands: \u2022 Macro placement constraints set_macro_constraints,  create_macro_array,  create_keepout_margin \u2022 Pin placement constraints set_block_pin_constraints,  set_individual_pin_constraints \u2022 Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning.\n \u2022 compile.auto_floorplan.initialize (default:  auto ) \u25e6 auto : Creates missing floorplan information.\n The tool exits with an error when inconsistent information is provided.\n \u25e6 true : Always creates the core and boundary.\n \u25e6 false : Never creates the core and boundary; uses only existing information.\n The tool exits with an error when encountering missing or inconsistent information.\n       By default, the following objects are preserved: \u25e6 Existing placement of fixed macros \u25e6 Existing placement of pins and pads \u25e6 Existing shaping of voltage areas \u2022 compile.auto_floorplan.place_pins (default:  unplaced ) compile.auto_floorplan.place_ios (default:  unplaced ) compile.auto_floorplan.place_hard_macros (default:  unplaced ) compile.auto_floorplan.shape_voltage_areas (default:  unshaped ) \u25e6 all : Always places and shapes objects even if they are fixed.\n Unplaced and unshaped objects will always be placed and shaped.\n \u25e6 unfixed : Places and shapes objects that are not fixed.\n Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify.\n Unplaced and unshaped objects will always be placed and shaped.\n \u25e6 unplaced,\u00a0unshaped : Never places or shapes objects when they are already placed.\n Unplaced and unshaped objects will always be placed and shaped.\n \u25e6 none : Never places or shapes objects even if they are not already placed.\n This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning.\n Application option setting Fixed objects Placed objects Unplaced objects all    unfixed    unplaced,\u00a0unshaped    none    \u2022 compile.auto_floorplan.keep_bounds (default:  auto )       \u25e6 auto : Removes existing bounds if either of the following two application options is set to  all.\n compile.auto_floorplan.place_hard_macros, compile.auto_floorplan.shape_voltage_areas \u25e6 true : Keeps existing bounds.\n \u25e6 false : Removes existing bounds.\n \u2022 compile.auto_floorplan.keep_placement_blockages (default:  auto ) \u25e6 auto : Removes existing placement blockages if either of the following two application options is set to  all.\n compile.auto_floorplan.place_hard_macros, compile.auto_floorplan.shape_voltage_areas \u25e6 true : Keeps existing placement blockages.\n \u25e6 false : Removes existing placement blockages.\n Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: #\u00a0Application\u00a0options\u00a0with\u00a0default\u00a0settings #\u00a0set_app_options\u00a0-name\u00a0compile.auto_floorplan.initialize\u00a0-value\u00a0auto #\u00a0set_app_options\u00a0-name\u00a0compile.auto_floorplan.place_pins\u00a0-value\u00a0unplaced #\u00a0set_app_options\u00a0-name\u00a0compile.auto_floorplan.place_ios\u00a0-value\u00a0unplaced #\u00a0set_app_options\u00a0-name\u00a0compile.auto_floorplan.place_hard_macros\u00a0\\ #\u00a0\u00a0\u00a0\u00a0-value\u00a0unplaced #\u00a0set_app_options\u00a0-name\u00a0compile.auto_floorplan.shape_voltage_areas\u00a0\\ #\u00a0\u00a0\u00a0\u00a0-value\u00a0unshaped  #\u00a0Constraint\u00a0settings\u00a0for\u00a0automatic\u00a0floorplanning set_auto_floorplan_constraints\u00a0-core_utilization\u00a00.75\u00a0-side_ratio\u00a0{1\u00a02} set_macro_constraints\u00a0-preferred_location\u00a0{0\u00a00}\u00a0RAM0 set_block_pin_constraints\u00a0-self\u00a0-sides\u00a0{1\u00a03} set_individual_pin_constraints\u00a0-ports\u00a0[get_ports\u00a0reset]\u00a0-side\u00a01 set_shaping_options\u00a0-guard_band_size\u00a02"}
{"header": "How do I Applying the Multivoltage Power Intent", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe the tasks you need to perform when setting up multivoltage designs: \u2022 Applying the Multivoltage Power Intent \u2022 Preparing the Power Network       \u2022 Defining Voltage Areas \u2022 Inserting Multivoltage Cells \u2022 Controlling the Placement of Multivoltage Cells \u2022 Enabling Improved Buffering for Multivoltage Nets \u2022 Analyzing Multivoltage Information"}
{"header": "How do I Loading and Applying UPF Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To learn about applying the multivoltage power intent, see \u2022 Loading and Applying UPF Information \u2022 Using Incomplete UPF Information \u2022 Specifying UPF Constraints for Physical-Only Cells \u2022 Saving UPF Information"}
{"header": "How do I Using Incomplete UPF Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To load the power intent and apply it to a multivoltage design, 1.\n Read the UPF file by using the  load_upf command.\n fc_shell>\u00a0 load_upf  block.upf 2.\n If you are using the golden UPF flow and have a name-mapping file, read the file by using the  read_name_map command.\n fc_shell>\u00a0 read_name_map  block.nmf 3.\n (Optional) Verify the UPF consistency and identify any PG conflicts among the netlist, floorplan, and power intent.\n To verify the UPF consistency and identify PG conflicts, use the  resolve_pg_nets -check_only command.\n This command identifies any issues and reports the changes that are made to resolve these issues when you commit the power intent.\n If you prefer to resolve the issues differently, you can use manual editing commands to resolve the issues before running the  commit_upf command.\n 4.\n Commit the power intent by using the  commit_upf command.\n fc_shell>\u00a0 commit_upf The  commit_upf command performs global checks for UPF consistency; resolves PG conflicts among the netlist, floorplan, and UPF specification; and associates power strategies with existing multivoltage cells.\n For more information about associating       power strategies with existing multivoltage cells, see  Associating Power Strategies With Existing Multivoltage Cells.\n 5.\n Report the associations made for the multivoltage cells by using the  report_mv_path command.\n If the tool failed to associate any multivoltage cells, the command reports the causes for these failures.\n You must successfully commit the power intent before you continue with the design flow.\n Note: After successfully running the  commit_upf command, the tool issues an error message if you try to use additional UPF commands, except for the set_related_supply_net,  connect_supply_net,  set_design_attributes, set_port_attributes,  find_objects, and  set_scope commands.\n To modify the power intent after running the  commit_upf command, you must remove the existing UPF specification by using the  reset_upf command and then reload the power intent."}
{"header": "How do I Specifying UPF Constraints for Physical-Only Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Early Data Check Manager allows you to check designs for power and multivoltage issues early in the design cycle.\n You can configure different error conditions in different ways.\n The tool provides comprehensive reports about the data checks.\n The general flow is as follows: 1.\n Use the  set_early_data_check_policy command to define the global violation handling policy for data checks.\n 2.\n Proceed with your tool flow.\n The tool detects and responds to violations throughout the flow.\n 3.\n Use the  report_early_data_checks command to obtain a report about all violations or specific data checks.\n 4.\n Use the  get_early_data_check_records command to get a Tcl collection of violations that can be used in other commands.\n 5.\n Use the  write_early_data_check_config command to save the settings in a file for future use.\n 6.\n Use the  remove_early_data_check_records command to clear the data in preparation for another iteration.\n For more information about the Early Data Check Manager, see the  Fusion Compiler Data Model User Guide.\n For a list of power and multivoltage data checks, see the  Fusion Compiler Multivoltage User Guide."}
{"header": "How do I Saving UPF Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The UPF constraints for physical-only cells can cause issues when the UPF file is read into other tools that do not support physical-only cells, such as verification tools.\n Therefore, surround the UPF constraints for physical-only cells with the syntax shown in the following example: if\u00a0{[info\u00a0exists\u00a0snps_handle_physical_only]\u00a0&&\u00a0\\ $snps_handle_physical_only}\u00a0{  /*\u00a0Supply\u00a0net\u00a0connections\u00a0for\u00a0filler\u00a0cells\u00a0*/ connect_supply_net\u00a0VDDS\u00a0-ports\u00a0[get_pins\u00a0FILLER*/VDD]  } By default, the  snps_handle_physical_only variable is set to  true in the Fusion Compiler tool.\n Therefore, when you load and commit the UPF file, the constraints are applied to the physical-only cells.\n When you save a UPF file with the  save_upf command, the tool uses the same syntax for the user-specified and tool-derived UPF constraints for physical-only cells.\n Therefore, these UPF constraints are ignored by any tool that does not have the snps_handle_physical_only variable set to  true.\n To create a UPF file that contains commands only for specific types of cells, use the -include or  -exclude option with the  save_upf command.\n These options accept arguments such as  diode_cells,  pad_cells, and  physical_only_cells.\n See the save_upf command man page for the complete list of arguments.\n Command filtering for specified cell types applies to the  connect_supply_net, set_related_supply_net,  create_power_domain, and  set_isolation commands.\n You can apply command filtering to both block-level and full-chip UPF files."}
{"header": "How do I Preparing the Power Network", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During physical implementation, the tool updates the power intent of the design.\n To generate an updated UPF file, use the  save_upf command.\n You can use this UPF file in the subsequent steps of the design flow.\n The  save_upf command separates the UPF commands based on the input UPF file, and adds a comment indicating the input UPF file and the time it was loaded.\n Assume you load, commit, and save UPF information as shown in the following example script: load_upf\u00a0top_1.upf load_upf\u00a0top_2.upf load_upf\u00a0top_3.upf commit_upf save_upf\u00a0top.upf       The resulting top.upf file contains the following information: ##\u00a0Start\u00a0-\u00a0load_upf\u00a0top_1.upf\u00a0on\u00a0Wed\u00a0Oct\u00a026\u00a017:03:18\u00a02016 \u2026 \u2026 ##\u00a0End\u00a0-\u00a0load_upf ##\u00a0Start\u00a0-\u00a0load_upf\u00a0top_2.upf\u00a0on\u00a0Wed\u00a0Oct\u00a026\u00a017:03:49\u00a02016 \u2026 \u2026 ##\u00a0End\u00a0-\u00a0load_upf ##\u00a0Start\u00a0-\u00a0load_upf\u00a0top_3.upf\u00a0on\u00a0Wed\u00a0Oct\u00a026\u00a017:04:22\u00a02016 \u2026 \u2026 ##\u00a0End\u00a0-\u00a0load_upf"}
{"header": "How do I Creating Logical Power and Ground Connections", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To learn about preparing the power network for physical implementation, see \u2022 Creating Logical Power and Ground Connections \u2022 Creating Floating Logical Supply Nets"}
{"header": "How do I Creating Floating Logical Supply Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you read in the design, you must ensure that there are logical connections between the power and ground nets and the power, ground, and tie-off pins on the cells in your design.\n If your design does not already have these connections, use the connect_pg_net command to create them.\n This command creates the logical power and ground connections for leaf cells, hierarchical cells, and physical-only cells in both single- voltage and multivoltage designs.\n Before creating the logical power and ground connections, you must resolve any PG conflicts among the netlist, floorplan, and UPF specification.\n \u2022 For multivoltage designs, the conflicts are resolved when you commit the power intent, as described in  Loading and Applying UPF Information.\n \u2022 For single-voltage designs, you must run the  resolve_pg_netx command to resolve the conflicts.\n Note that the UPF specification for a single-voltage design is the default power domain generated by the  read_verilog command.\n If your design contains unmapped instances, the tool issues an information message to indicate that only mapped instances are connected.\n       The  connect_pg_net command operates in two modes: \u2022 Automatic In automatic mode, the command derives all power and ground nets, power and ground pins, tie-off pins, and connections from the UPF specification.\n If the supply nets do not exist, the tool creates them.\n To create the logical power and ground connections in automatic mode, use the -automatic option with the  connect_pg_net command.\n \u2022 Manual In manual mode, the command makes the connections that you specify.\n If a specified pin or port has an existing connection, the tool removes the existing connection and then creates the specified connection.\n The tool verifies that the connections match the power intent.\n If it finds a mismatch, the tool issues a warning but still creates the connection.\n To create logical power and ground connections in manual mode, use the  -net option to specify the power or ground net and specify the pins and ports to be connected to that net as an argument to the command.\n For example, to connect the VDD power net to all pins named vdd and the VSS ground net to all pins named vss, use the following commands: fc_shell>\u00a0 connect_pg_net -net VDD [get_pins */vdd] fc_shell>\u00a0 connect_pg_net -net VSS [get_pins */vss] To connect PG nets to power and ground pins only, use the  -pg option.\n To connect PG nets to tie-off pins only, use the  -tie option.\n By default, if neither option is specified, the tool makes connections to all power, ground, and tie-off pins.\n These options cannot be used with an object list or with the  -create_nets_only and  -net options.\n Regardless of the command options used, the tool always creates connections required to build a complete PG netlist structure, such as top-level PG ports and intermediate hierarchical PG pins."}
{"header": "How do I Defining Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A floating logical supply net is a power or ground net that is not connected to any logical pin or port in the block.\n For example, a power feedthrough net created during power planning is a floating supply net.\n To create a floating supply net with the  connect_pg_net command, use the following steps: 1.\n Specify the supply net type in the UPF file by using the  supply_net_pg_type attribute, as shown in the following UPF file example: \u2026 create_supply_net\u00a0VDD \u2026 \u2026 set_design_attributes\u00a0-elements\u00a0VDD\u00a0\\ -attribute\u00a0supply_net_pg_type\u00a0power \u2026 2.\n Enable floating supply nets by setting the  mv.pg.create_floating_pg application option to  true before you create supply nets with the  connect_pg_net command, as shown in the following script example: \u2026 \u2026 #\u00a0Apply\u00a0the\u00a0UPF load_upf\u00a0\u00a0$upf_input_file_name commit_upf \u2026 \u2026 #\u00a0create\u00a0logical\u00a0supply\u00a0nets set_app_options\u00a0\u00a0-as_user_default\u00a0\\ -name\u00a0mv.pg.create_floating_pg\u00a0-value\u00a0true connect_pg_net\u00a0-automatic \u2026 check_mv_design The tool creates the logical supply nets in the topmost hierarchy of the current UPF scope for domain-independent supply nets.\n For domain-dependent supply nets, the tool creates the logical supply nets in the topmost hierarchy of the domain.\n The tool does not create a logical supply net in the following situations: \u2022 There is a conflict between the connection and the supply net type specified with the supply_net_pg_type attribute.\n \u2022 The supply net is connected to a PG pin of an instance.\n \u2022 The  connect_pg_net command is not specified in the current or parent physical hierarchy."}
{"header": "How do I Merging Voltage Area Shapes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A voltage area is a physical placement area for the cells associated with a power domain.\n For multivoltage designs, the power domains are defined in the UPF specification.\n For single-voltage designs, the tool creates a default power domain when you read the Verilog netlist and associates it with a default voltage area, which comprises the core area of the block.\n The placer treats a voltage area the same as an exclusive move bound; it must place the cells in a voltage area within a specified region and it must place all other cells outside of the voltage area.\n Voltage areas can be rectangular or rectilinear.\n In addition, they can be disjoint, nested, or overlapping.\n For overlapping voltage areas, the effective shape of each voltage area is determined by the stacking order of the voltage area shapes.\n To define a voltage area, use the  create_voltage_area command.\n When you define a voltage area, at a minimum, you must specify the power domains associated with the voltage area.\n To specify the power domains, use the  -power_domains option.\n You can specify one or more power domains; however, all specified power domains must have the same primary supply net.\n If you specify a single power domain, the name of the voltage area is derived from the name of the power domain.\n If you specify multiple power domains, you must specify a name for the voltage area by using the  -name option.\n A voltage area consists of one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping.\n To define the boundaries of these shapes, use the  -region option with the  create_voltage_area command (if you are creating a new voltage area) or the  create_voltage_area_shape command (if you are adding shapes to an existing voltage area).\n Note that you can specify one or more shapes when using the  create_voltage_area command, but only a single shape in each create_voltage_area_shape command.\n \u2022 To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly }\u00a0{ urx ury }} \u2022 To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 }\u00a0{ x2 y2 }\u00a0{ x3 y3 }\u00a0{ x4 y4 }\u00a0...} If a voltage area consists of multiple abutting or overlapping shapes, you can merge the shapes into a minimum set of disjoint shapes based on the stacking order of the shapes.\n For information about how to merge the voltage area shapes, see  Merging Voltage Area Shapes.\n The tool also uses the stacking order to resolve overlapping shapes from different voltage areas.\n For information about resolving overlapping voltage areas, see  Resolving Overlapping Voltage Areas.\n       To ensure that no shorts occur at the boundaries of the voltage areas, you can define guard bands for the voltage areas, which act as hard keepout margins surrounding the voltage areas.\n If you define guard bands for a voltage area shape, the guard bands are included in the effective boundary of the shape; however, they are not included in the effective placement area of the voltage area.\n For information about defining guard bands, see  Defining Guard Bands.\n To modify an existing voltage area, use the  set_voltage_area command, as described in Modifying Voltage Areas.\n Multivoltage designs typically have power domains that are shut down and powered up during the operation of the chip while other power domains remain powered up.\n When dealing with shutdown domains, there can be some situations in which certain cells in the shutdown portion need to continuously stay active, such as for implementing retention registers, isolation cells, retention control paths, and isolation enable paths.\n These cells are referred to as always-on cells.\n To define a special placement area for always-on cells (an always-on well) within a voltage area, define an exclusive move bound within the boundary of the voltage area.\n For information about defining exclusive move bounds, see Defining Move Bounds.\n After creating the voltage areas, run the  check_mv_design command to verify that the design does not have any multivoltage violations."}
{"header": "How do I Resolving Overlapping Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To merge the voltage area shapes into a minimum set of disjoint shapes, use the -merge_regions option with the  create_voltage_area,  create_voltage_area_shape, or  set_voltage_area command.\n \u2022 When you use the  create_voltage_area\u00a0-merge_regions command, the merges the shapes specified with the  -region option.\n \u2022 When you use the  create_voltage_area_shape\u00a0-merge_regions command, the merges the shape specified with the  -region option and the existing shapes of the specified voltage area.\n \u2022 When you use the  set_voltage_area\u00a0-merge_regions command, the tool merges all existing shapes of the specified voltage area.\n The tool merges the voltage area shapes based on their stacking order.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The merged shape replaces the top shape of a set of abutting or overlapping shapes; the other shapes in the set are removed and are no longer associated with the voltage area.\n       For example, assume that you use the following command to create a voltage area comprising three rectangle shapes, as shown on the left side of  Figure\u00a014.\n fc_shell>\u00a0 create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } {PD1} fc_shell>\u00a0 get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_1\u00a0VOLTAGE_AREA_SHAPE_2\u00a0VOLTAGE_AREA_SHAPE_3} After you use the  -merge_regions option to merge these shapes, the voltage area consists of a single rectilinear shape, as shown on the right side of  Figure\u00a014.\n The merged voltage area shape is named VOLTAGE_AREA_SHAPE_3, which was the last voltage area shape defined when the voltage area was created.\n fc_shell>\u00a0 set_voltage_area PD1 -merge_regions Information:\u00a0Merging\u00a0abutted\u00a0and\u00a0overlapping\u00a0shapes\u00a0in\u00a0voltage_area 'PD1'.\n (NDMUI-154) 1 fc_shell>\u00a0 get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_3} Figure 14 Merging Voltage Area Shapes To report the stacking order of the voltage area shapes, use the  report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in  Modifying the Stacking Order."}
{"header": "How do I Modifying the Stacking Order", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If voltage area shapes from two or more voltage areas overlap, either completely or partially, the tool uses the stacking order of the shapes to determine the effective shapes of the voltage areas.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The tool assigns the overlapped region to the voltage area associated with the top shape.\n Unlike merging shapes within a voltage area, when the tool resolves overlapping shapes from different voltage areas, it does not remove any shapes; only the interpretation of the shapes changes.\n       For example, assume you want to create nested voltage areas, as shown in  Figure\u00a015.\n Figure 15 Nested Voltage Areas To generate these effective voltage areas, you must specify the outer voltage area first, followed by the inner voltage area, so that the voltage area shape for the inner voltage area is on top: fc_shell>\u00a0 create_voltage_area -power_domains PD1 \\ -region { {0 0} {30 30} } {PD1} fc_shell>\u00a0 create_voltage_area -power_domains PD2 \\ -region { {10 10} {20 20} } {PD2} fc_shell>\u00a0 get_attribute -objects [get_voltage_areas PD2] \\ -name effective_shapes {{10.0000\u00a010.0000}\u00a0{20.0000\u00a020.0000}} fc_shell>\u00a0 get_attribute -objects [get_voltage_areas PD1] \\ -name effective_shapes {{0.0000\u00a00.0000}\u00a0{10.0000\u00a00.0000}\u00a0{10.0000\u00a020.0000}\u00a0{20.0000\u00a020.0000} {20.0000\u00a010.0000}\u00a0{10.0000\u00a010.0000}\u00a0{10.0000\u00a00.0000}\u00a0{30.0000\u00a00.0000} {30.0000\u00a030.0000}\u00a0{0.0000\u00a030.0000}} If you specify the inner voltage area first, the shape for the outer voltage area is on top and it masks the inner voltage area, so it is ignored by the tool, as shown in the following example: fc_shell>\u00a0 create_voltage_area -power_domains PD2 \\ -region { {10 10} {20 20} } {PD2} fc_shell>\u00a0 create_voltage_area -power_domains PD1 \\ -region { {0 0} {30 30} } {PD1} fc_shell>\u00a0 get_attribute -objects [get_voltage_areas PD2] \\ -name effective_shapes fc_shell>\u00a0 get_attribute -objects [get_voltage_areas PD1] \\       -name effective_shapes {{0.0000\u00a00.0000}\u00a0{30.0000\u00a030.0000}} To report the stacking order of the voltage area shapes, use the  report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in  Modifying the Stacking Order."}
{"header": "How do I Defining Guard Bands", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can modify the stacking order of the voltage area shapes by using the set_voltage_area_shape command.\n \u2022 To raise a voltage area shape one position, use the  -raise option.\n \u2022 To lower a voltage area shape one position, use the  -lower option.\n \u2022 To move a voltage area shape to the top, use the  -top option.\n \u2022 To move a voltage area shape to the bottom, use the  -bottom option.\n \u2022 To move a voltage area shape directly above another shape, use the  -above option.\n \u2022 To move a voltage area shape directly below another shape, use the - below option."}
{"header": "How do I Defining Gas Stations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Guard bands define hard keepout margins surrounding the voltage areas in which no cells, including level shifters and isolation cells, can be placed.\n The guard bands guarantee that the cells in different voltage areas are separated so that power planning does not introduce shorts.\n By default, voltage areas do not have guard bands.\n To define guard bands, use the -guard_band option with the  create_voltage_area or  create_voltage_area_shape command to specify the horizontal and vertical guard band width for each shape specified in the  -region option.\n The horizontal guard band width applies to all vertical edges of the voltage area, while the vertical guard band width applies to all horizontal edges of the voltage area.\n Note: If you also use the  -merge_regions option, you must specify the guard band widths for each disjoint shape after merging.\n You would typically use this option only when all the shapes to be merged are abutted or overlapping and therefore merge into a single shape.\n The effective boundary of a voltage area shape includes its guard band; however, the effective placeable area of the shape does not.\n       For example,  Figure\u00a016 shows the guard band around the PD1 voltage area that is defined by the following command: fc_shell>\u00a0 create_voltage_area -power_domains PD1 \\ -region {{0 0} {30 0} {30 10} {40 10} {40 30} {20 30} {20 25} {0 25}} \\ -guard_band { {3 1} } Figure 16 Voltage Area Guard Band To determine the effective guard bands for abutting or overlapping shapes associated with the same voltage area, the tool merges the shapes as described in  Merging Voltage Area Shapes  and then applies the guard bands defined for the top shape to the merged shape.\n For example, assume that you use the following command to define guard bands for the voltage area shapes shown on the right side of  Figure\u00a014 : fc_shell>\u00a0 create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } \\ -guard_band { {1 1} {3 3} {3 1} } {PD1} In this case, the effective guard band is the same as the guard band shown in  Figure\u00a016, which is the guard band defined for the merged shape.\n To determine the effective placement areas and guard bands for overlapping shapes associated with different voltage areas, the tool uses the effective boundaries to resolve the shapes as described in  Resolving Overlapping Voltage Areas.\n The top shape retains it placement area and guard band; the effective placement area and guard bands of lower shapes does not include the overlapping region.\n Note that if abutting shapes have guard bands, they are no longer abutting, but overlapping, due to the effective boundary that includes the guard bands.\n For example, assume that you use the following commands to define guard bands for the voltage areas shown in  Figure\u00a015 : fc_shell>\u00a0 create_voltage_area -power_domains PD1 \\ -region {{0 0} {30 30}} -guard_band { {2 2} } {PD1} fc_shell>\u00a0 create_voltage_area -power_domains PD2 \\ -region {{10 10} {20 20}} -guard_band { {2 2} } {PD2}       In this case, the effective placement area of PD1 is reduced by the effective boundary of PD2, which includes its guard band, as shown in  Figure\u00a017.\n Figure 17 Effective Boundaries of Overlapping Voltage Areas"}
{"header": "How do I Querying Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Gas stations are small voltage areas that are created for the purpose of minimizing the use of dual-rail buffers on physical feedthrough paths.\n Only single-rail repeaters are allowed in gas stations, and only optimization steps can add cells to gas stations.\n You create gas stations by using the  create_voltage_area command during the design planning stage.\n The tool recognizes gas stations automatically and uses them by trading off the cost of a routing detour with the cost of using a dual-rail cell.\n Use the  -nwell and  -pwell options of the  create_voltage_area command to specify n-well and p-well supply nets for a voltage area.\n Defining well supplies for gas station voltage areas provides flexibility for using gas stations for different design styles.\n If you do not use these options for a voltage area, the well bias values are assumed to be the same as the domain supply values.\n The  report_voltage_areas command lists the n-well and p-well supply nets regardless of whether they are explicitly set."}
{"header": "How do I Modifying Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can query the following information about voltage areas: \u2022 The voltage areas in the current block To create a collection of voltage areas in the current block, including the default voltage area, use the  get_voltage_areas command.\n \u2022 Detailed information about the voltage areas       To display detailed information about voltage areas, including the default voltage area, use the  report_voltage_areas command.\n To include information about the voltage area shapes that comprise each voltage area, use the  -verbose option with the  report_voltage_areas command.\n \u2022 Effective placement area of a voltage area To display the effective placement area of a voltage area, query the effective_shapes attribute of the voltage area.\n \u2022 Effective guard bands of a voltage area To display the effective guard bands of a voltage area, query the effective_guard_band_boundaries attribute of the voltage area.\n Note that you can also query this attribute for individual voltage area shapes."}
{"header": "How do I Controlling Physical-Feedthrough Nets in Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you have created voltage areas, you can make the following modifications to a voltage area: \u2022 Change the power domains associated with the voltage area To change the power domains associated with a voltage area, use the -add_power_domains and  -remove_power_domains options with the set_voltage_area command.\n \u2022 Change the voltage area name To change the name of the voltage area, use the  -name option with the set_voltage_area command.\n \u2022 Change the voltage area region To add shapes to a voltage area, use the  create_voltage_area_shape command.\n To remove shapes from a voltage area, use the  remove_voltage_area_shapes command."}
{"header": "How do I Removing Voltage Areas", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A net is considered to be native to a voltage area if one or more segments of that net are in a logical hierarchy of that voltage area.\n If a net must physically route over a nonnative voltage area, then it is a physical feedthrough net of that voltage area, as shown in the following figure.\n       Figure 18 Physical-Feedthrough Nets of Voltage Areas VA0 (PD0 ) VA1 (PD1) N1 Top (PD0) Block1 (PD1) N1 Physical view Logical view By default, physical-feedthrough nets are allowed in voltage areas.\n To prevent physical-feedthrough nets in a voltage area, define a voltage area rule using the create_voltage_area_rule\u00a0-allow_pass_through\u00a0false command, as shown in the following example: fc_shell>\u00a0 create_voltage_area_rule -allow_pass_through false \\ -name VA1_rule -voltage_areas VA1 With this rule, the N1 net detours around the VA1 voltage area, as shown in  Figure\u00a019.\n Figure 19 Physical-Feedthrough Nets Disabled for a Voltage Area VA0 N1 VA1 By default, optimization does not insert buffers on physical-feedthrough nets of voltage areas.\n Inserting a buffer on a physical-feedthrough net can cause a mismatch between the       logical and physical view of the buffer.\n The tool resolves such mismatches by supporting the following types of optimization for such nets: \u2022 Physical-feedthrough buffering During physical-feedthrough buffering the tool performs the following: 1.\n Inserts buffers in the logical hierarchy of its drivers or loads and applies the power domain of the nonnative voltage area on the buffer using power-domain-on-instance (PDOI) constraints 2.\n Places the buffers within the nonnative voltage area To allow physical-feedthrough buffering, use the  create_voltage_area_rule -allow_physical_feedthrough\u00a0true command, as shown in the following example: fc_shell>\u00a0 create_voltage_area_rule \\ -allow_physical_feedthrough true \\ -name VA1_rule -voltage_areas VA1 \u2022 Logical-feedthrough buffering During logical-feedthrough the tool performs the following: 1.\n Adds buffers in the logical hierarchy corresponding to the nonnative voltage area 2.\n Places the buffers within the nonnative voltage area To allow logical-feedthrough buffering, use the  create_voltage_area_rule -allow_logical_feedthrough\u00a0true command.\n To specify logical hierarchies in which feedthrough buffers are allowed or not allowed, use the  -include_logical_feedthrough_hierarchy or -exclude_logical_feedthrough_hierarchy option, respectively.\n The following example enables logical-feedthrough buffering for the VA1 voltage area and limits the feedthrough buffers to only the U1 and U2 hierarchical cells: fc_shell>\u00a0 create_voltage_area_rule \\ -allow_logical_feedthrough true \\ -include_logical_feedthrough_hierarchy {U1 U2}\\ -name VA1_rule -voltage_areas VA1 The following example enables logical-feedthrough buffering for the VA2 voltage area and excludes the U3 hierarchical cell from feedthrough buffering: fc_shell>\u00a0 create_voltage_area_rule \\ -allow_logical_feedthrough true \\ -exclude_logical_feedthrough_hierarchy {U3}\\ -name VA2_rule -voltage_areas VA2       Note: To add a logical-feedthrough buffer to a lower-level block, the tool has to add new boundary ports to that block.\n Therefore, freezing the boundary of a block by using the  set_freeze_ports command prevents the tool from adding a logical-feedthrough buffer to that block.\n Figure 20 Difference in the Logical View After Physical- and Logical-Feedthrough Buffering To create a default rule that applies to all voltage areas that do not have a specific rule, use the  create_voltage_area_rule command with the  -default_rule option, as shown in the following example: fc_shell>\u00a0 create_voltage_area_rule -default_rule \\ -allow_physical_feedthrough true If a voltage area does not have a specific rule, and there is no default rule, feedthrough buffering for that voltage area is controlled by the opt.common.allow_physical_feedthrough application option setting.\n To report voltage area rules, use the  report_voltage_area_rules command.\n To remove voltage area rules, use the  remove_voltage_area_rules command."}
{"header": "How do I Inserting Multivoltage Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove voltage areas from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_voltage_areas command.\n To remove all voltage areas from a block, use the  -all option.\n To remove specific voltage areas from a block, specify the voltage area names."}
{"header": "How do I Inserting Level Shifters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A multivoltage design requires special multivoltage cells, such as level shifters and isolation cells, at the interface between power domains.\n Level shifters are required between power domains that operate at different voltage levels, while isolation cells are required between power domains that are in different states (powered-down versus always-on or powered-up)."}
{"header": "How do I Inserting Isolation Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Level-shifter cells function as the interface between power domains that operate at different voltage levels.\n These cells ensure that the output transition of a driver can cause the receiving cell to switch even though the receiver is operating at a different voltage level.\n To insert level shifters in the current block, use the  create_mv_cells command.\n The tool inserts the level shifters using the cell mapping and strategy defined in the UPF specification.\n When the tool inserts a level shifter, it sets a atributesize_onlysize_only atribute size_only attribute on the level shifter and a atributesdont_touchdont_touch atribute dont_touch attribute on the port-to-level-shifter net.\n By default, the command inserts cells only from the generic library.\n If you use the  -mapped option with the  create_mv_cells command, the command inserts cells only from the user-provided logic library and issues an error if a suitable cell is not available.\n If the tool does not insert a level-shifter cell, you can use the  analyze_mv_design -level_shifter command to obtain more information.\n If you specify a net or pin with the -through option, the report lists the power domains and related supplies for the driver and load sides of the net or pin, along with error messages that indicate why a level-shifter cell was not inserted.\n The report includes errors about the specific insertion point as well as errors that are applicable to the entire path through the net or pin specified with the -through option."}
{"header": "How do I Associating Power Strategies With Existing Multivoltage Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Isolation cells are used to selectively shut off the input side of the voltage interface of a power domain; they do not shift the voltage.\n Isolation cells should be instantiated at the RTL level to prevent formal verification errors.\n However, you can also insert them using the Fusion Compiler tool.\n To insert isolation cells in the current block, use the  create_mv_cells command.\n The tool inserts the isolation shifters using the cell mapping and strategy defined in the UPF specification.\n When the tool inserts an isolation cell, it sets a atributesize_onlysize_only atribute size_only attribute on the level shifter and a atributesdont_touchdont_touch atribute dont_touch attribute on the port-to-level-shifter net.\n By default, the command inserts cells only from the generic library.\n If you use the  -mapped option with the  create_mv_cells command, the command inserts cells only from the user-provided logic library and issues an error message if a suitable cell is not available."}
{"header": "How do I Controlling the Placement of Multivoltage Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool automatically associates power strategies with existing multivoltage cells when you run the  associate_mv_cells or  commit_upf command.\n If this automatic association is not correct, you can manually modify the associations by using the  set_power_strategy_attribute command.\n To determine the power strategies for a power domain, use the  get_power_strategies command."}
{"header": "How do I Enabling Improved Buffering for Multivoltage Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A net that connects a multivoltage cell, such as a level-shifter cell or an isolation cell, to at least one cell in another voltage area is referred to as a multivoltage net.\n To reduce the length of multivoltage nets, enable advanced multivoltage cell placement by setting the place.coarse.enable_advanced_mv_cell_placement application option to  true.\n When you enable this feature, the tool reduces the length of the multivoltage nets by placing the multivoltage cells closer to the voltage area boundaries.\n To optimize multivoltage nets, the tool uses dual-rail buffers.\n By reducing the length of multivoltage nets, the tool can reduce the number of dual-rail buffers used during optimization and prevent unoptimized multivoltage nets due to the unavailability of dual-rail buffers."}
{"header": "How do I Analyzing Multivoltage Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Multivoltage nets are nets that logically or physically cross over more than one voltage area.\n You can enable the use of improved buffering techniques for fixing logical DRC violations on such nets during preroute optimization by setting the opt.buffering.enable_hierarchy_mapping application option to  true.\n This application option affects the  compile_fusion and  clock_opt commands.\n Enabling this feature reduces the number of buffers used to fix logical DRC violations.\n However, it can slightly increase the total negative slack or number of hold violations."}
{"header": "How do I Specifying Timing Constraints and Settings", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To ensure that the design does not have any multivoltage design violations, use the check_mv_design command.\n You can restrict the types of rules to check with the  check_mv_design command.\n For example, the  -isolation option specifies to check isolation strategy and isolation cell rules, while the  -pg_pin option specifies to check rules associated with PG pins.\n To report multivoltage information for your design, use the commands shown in the following table.\n       Table 6 Commands for Reporting Multivoltage Information To do this Use this command  report_mv_design  report_mv_cells  report_mv_lib_cells   report_mv_path  report_power_domains   check_equivalent_power_domains  get_equivalent_power_domains  report_voltage_areas"}
{"header": "How do I Specifying Logical Design Rule Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Timing constraints describe the timing requirements of a design.\n An essential part of timing constraints are accurately specified clocks and clock effects, such as latency and uncertainty.\n When you specify clocks, the tool automatically constrains the paths between the registers driven by these clocks.\n However, you can change the default behavior of these timing paths by specifying timing exceptions such as paths that should not be analyzed (false paths), paths that require multiple clock cycles (multicycle paths), and so on.\n In addition, you can constrain the boundary timing paths by specifying input and output delays for input and output ports.\n The Fusion Compiler tool uses on-chip variation (OCV) mode to perform timing analysis, which models the effects of variation in operating conditions across the chip.\n This mode performs a conservative timing analysis that allows both minimum and maximum delays to apply to different paths at the same time.\n For a setup check, it uses maximum delays for the launch clock path and data path and minimum delays for the capture clock path.\n For a hold check, it uses minimum delays for the launch clock path and data path and maximum delays for the capture clock path.\n A block might operate under several different conditions, such as different temperatures and voltages, and might operate in several different functional modes.\n For timing analysis, each set of conditions is represented by a  corner and each functional mode is represented by a  mode.\n A  scenario is a combination of a corner and mode used to perform timing analysis and optimization.\n Before you start working with a block, you must define the modes, corners, and scenarios that are used for the block, as well as the delay calculation       model and routing layers to use.\n The routing layer information you specify is used for RC estimation during timing analysis.\n For detailed information about specifying \u2022 Clock and clock effects, see the \u201cDefining Clocks\u201d topic in the  Fusion Compiler Timing Analysis User Guide.\n \u2022 Exceptions for timing paths and constraints for boundary paths, see the \u201cConstraining Timing Paths\u201d topic in the  Fusion Compiler Timing Analysis User Guide.\n \u2022 Modes, corners, and scenarios, see the \u201cDefining Modes, Corners, and Scenarios\u201d topic in the  Fusion Compiler Timing Analysis User Guide.\n \u2022 Operating conditions and on-chip variation (OCV) related settings, see the \u201cSpecifying Operating Conditions\u201d topic in the  Fusion Compiler Timing Analysis User Guide.\n \u2022 Parasitic information for RC estimation and extraction, see the \u201cPerforming Parasitic Extraction\u201d topic in the  Fusion Compiler Timing Analysis User Guide.\n \u2022 Routing layers, see  Specifying the Routing Resources."}
{"header": "How do I Specifying Clock Gating Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Minimum capacitance, maximum capacitance, and maximum transition are logical design rule constraints that your design must meet to function as intended.\n They are technology- specific restrictions that are specified in the logic libraries.\n However, you can specify more restrictive design rule constraints by using the constraint commands given in  Table\u00a07.\n During optimization, the Fusion Compiler tries to meet the design rule constraints, even if it means violating optimization constraints such as timing, power, and area goals; these design rule constraints have a higher priority.\n After optimization, you can use the reporting commands given in  Table\u00a07  to identify design rule constraint violations in a block.\n Table 7 Design Rule Commands To do this Use this command   set_min_capacitance   set_max_capacitance   set_max_transition  remove_min_capacitance       Table 7 Design Rule Commands (Continued) To do this Use this command  remove_max_capacitance  remove_max_transition  report_constraints\u00a0-min_capacitance  report_constraints\u00a0-max_capacitance  report_constraints\u00a0-max_transition    set_connection_class  set_attribute\u00a0\\ -name\u00a0connection_class Note: The maximum fanout design rule constraint is not honored by the Fusion Compiler tool.\n However, you can specify a maximum fanout for the data paths in a block by using the  opt.common.max_fanout application option.\n This is a soft optimization constraint.\n During optimization the tool tries to ensure that data path cells do not drive more than the specified maximum fanout."}
{"header": "How do I Specifying Physical Constraints for Placement and Legalization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool identifies preexisting clock-gating cells during the execution of the analyze and  elaborate commands.\n During compile, the tool inserts one more level of clock-gating cells at the leaf level and implements clock-gating logic using the default       clock-gating settings if you do not specify any clock-gating constraints.\n You cannot disable clock gating.\n Before you set up clock-gating constraints, load your design and libraries in memory and then use the following commands to set up the constraints: \u2022 The  set_clock_gate_style command To select the type of integrated clock-gating cell, specify the following options: Option Description -test_point  none before after -observation_output  -target  pos_edge_flip_flop neg_edge_flip_flop -objects  \u2022 The  set_clock_gating_options command To define the netlist structure of the inserted clock-gating cells, specify the following options: Option Description minimum_bitwidth   max_fanout   \u2022 The  set_clock_gating_objects command To control clock gating for specified objects and override the default clock-gating behavior that is set during compile, specify the following options.\n An object can be a hierarchical cell, register, power domain, or module.\n Option Description -include   -exclude        Option Description -clear   -reset  set_clock_gating_objects  \u2022 The default During clock-gating optimization, the tool uses the following setup defaults: Setup Default         For more information, see  Setting Up Clock Gating."}
{"header": "How do I Defining Keepout Margins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During placement and legalization, the floorplan information dictates where cells are placed.\n The following topics describe how to specify additional physical constraints that affect placement and legalization: \u2022 Defining Keepout Margins \u2022 Defining Area-Based Placement Blockages \u2022 Defining Placement Bounds \u2022 Defining Placement Attractions \u2022 Specifying Locations for Unmapped Cells \u2022 Defining Cell Spacing Constraints for Legalization"}
{"header": "How do I Defining an Outer Keepout Margin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A keepout margin is a region (the shaded portions in  Figure\u00a021 ) around the boundary of fixed cells in a block in which no other cells are placed.\n       Figure 21 Placement Keepout Margins left bottom right top  Fixed cell left bottom right top   An outer keepout margin is a region outside the cell boundary, while an inner keepout margin is a region inside the cell boundary.\n The width of the keepout margin on each side of the fixed cell can be the same or different, depending on how you define the keepout margin.\n In addition, keepout margins can be defined as hard or soft.\n Keeping the placement of cells out of such regions avoids congestion and net detouring and produces better QoR.\n kepout marginscel-specific, seting To define a keepout margin, use the set_kepout_margin comandcomandset_kepout_margin create_keepout_margin command.\n By default, the command creates a hard keepout margin.\n To create a soft keepout margin, use the  -type soft option."}
{"header": "How do I Defining an Inner Keepout Margin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can define an outer keepout margin on a hard macro, a hierarchical cell, or a leaf cell.\n When you define an outer keepout margin, you can either specify the keepout distance explicitly or, for hard macros, you can have the tool derive the keepout distance based on the macro pin count.\n To explicitly specify an outer keepout margin, use the  -outer option to specify the margin distance for each side.\n You specify the left, bottom, right, and top margins using the following format:  { lx by rx ty }.\n A value of 0 results in no keepout margin for that side.\n For example, to create a hard outer keepout margin with a margin of 10 on each side for a macro named my_macro, use the following command: fc_shell>\u00a0 create_keepout_margin -outer {10 10 10 10} my_macro To have the tool derive the outer keepout distance for a hard macro based on its pin count, use the  -tracks_per_macro_pin option to specify the track-to-pin ratio.\n When you use this option, the tool calculates the keepout margin from the track width, the number of macro pins, and the specified track-to-pin ratio, which is typically set to a value near 0.5.\n A larger value results in larger keepout margins.\n The derived keepout margin is always hard; the  -type setting is ignored.\n The derived margins are subject the minimum and maximum       values specified by the  -min_padding_per_macro and  -max_padding_per_macro options.\n For example, to have the tool derive the outer keepout margin for a macro named my_macro by using a track-to-pin ratio of 0.6 with a minimum keepout distance of 0.1 and a maximum keepout distance of 0.2, use the following command: fc_shell>\u00a0 create_keepout_margin -tracks_per_macro_pin 0.6 \\ -min_padding_per_macro 0.1 -max_padding_per_macro 0.2 my_macro"}
{"header": "How do I Defining Area-Based Placement Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can define an inner keepout margin on a hierarchical cell, but not on a hard macro or a leaf cell.\n When you define an inner keepout margin, you must specify the keepout distance explicitly.\n To explicitly specify an inner keepout margin, use the  -inner option to specify the margin distance for each side.\n You specify the left, bottom, right, and top margins using the following format:  { lx by rx ty }.\n A value of 0 results in no keepout margin for that side.\n For example, to create a hard inner keepout margin with a margin of 10 on each side for a hierarchical cell named my_hcell, use the following command: fc_shell>\u00a0 create_keepout_margin -inner {10 10 10 10} my_hcell"}
{"header": "How do I Defining a Hard Placement Blockage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "An area-based placement blockage is a rectangular region in which cells cannot be placed or in which the types or number of cells is limited.\n The Fusion Compiler tool supports the following types of area-based placement blockages: \u2022 Hard A hard blockage prevents the placement of standard cells and hard macros within the specified area during coarse placement, optimization, and legalization.\n       \u2022 Hard macro A hard macro blockage prevents the placement of hard macros within the specified area during coarse placement, optimization, and legalization.\n \u2022 Soft A soft blockage prevents the placement of standard cells and hard macros within the specified area during coarse placement, but allows optimization and legalization to place cells within the specified area.\n \u2022 Partial A partial blockage limits the cell density in the specified area during coarse placement, but has no effect during optimization and legalization.\n get_placement_blockages comandcomandsget_placement_blockages To define placement blockages, use the  create_placement_blockage command.\n At a minimum, you must specify the coordinates of the placement blockage.\n To create a rectangular placement blockage, use the  -boundary option to specify the lower-left and upper-right coordinates of the rectangle.\n To create a rectilinear placement blockage, use the  -boundary option to specify the coordinates of the polygon.\n You can also create multiple placement blockages by specifying the boundary polygon as a geo_mask or a collection of physical objects.\n If the resulting area resolves to multiple, noncontiguous polygons, the command creates multiple placement blockages, one corresponding to each polygon.\n By default, the  create_placement_blockage command creates a hard placement blockage.\n To create another type of placement blockage, use the  -type option to specify the blockage type.\n A single  create_placement_blockage command can create just one type of placement blockage.\n You can optionally assign a name to a placement blockage by using the  -name option.\n You can then reference that blockage by name to query or remove the placement blockage."}
{"header": "How do I Defining a Hard Macro Placement Blockage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a hard placement blockage, specify the boundary and optionally a name for the placement blockage.\n For example, to create a hard placement blockage in the area enclosed by a rectangle with corners at (10, 20) and (100, 200), use the following command: create_placement_blockage\u00a0-boundary\u00a0{10\u00a020\u00a0100\u00a0200} Note: Hard placement blockages are honored during placement, legalization, optimization, and clock tree synthesis.\n       Hard placement blockages can also be defined in the DEF as shown in  Example\u00a013.\n Example 13 Placement Blockages in DEF BLOCKAGES\u00a02\u00a0; -\u00a0PLACEMENT RECT\u00a0(\u00a00\u00a0327600\u00a0)\u00a0(\u00a0652740\u00a0327660\u00a0)\u00a0; -\u00a0PLACEMENT RECT\u00a0(\u00a00\u00a0327600\u00a0)\u00a0(\u00a0652740\u00a0327660\u00a0)\u00a0; END\u00a0BLOCKAGES 1"}
{"header": "How do I Defining a Soft Placement Blockage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a hard macro blockage, specify the boundary, type ( -type\u00a0hard_macro option), and optionally the name for the placement blockage.\n For example, to define a hard macro blockage enclosed by a rectangle with corners at (120, 75) and (230, 200), use the following command: create_placement_blockage\u00a0-boundary\u00a0{120\u00a075\u00a0230\u00a0200}\u00a0\\ -type\u00a0hard_macro Note: Hard macro placement blockages are honored during placement, legalization, and optimization.\n This is the only type of placement blockage that is honored by hard macro placement."}
{"header": "How do I Defining a Partial Placement Blockage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a soft blockage, specify the boundary, type ( -type\u00a0soft option), and optionally the name for the placement blockage.\n For example, to define a soft blockage enclosed by a rectangle with corners at (120, 75) and (230, 200), use the following command: create_placement_blockage\u00a0-boundary\u00a0{120\u00a075\u00a0230\u00a0200}\u00a0\\ -type\u00a0soft A soft blockage prevents the initial placement from placing cells within the specified area, but allows legalization, optimization, and clock tree synthesis to do so.\n However, after placement and optimization, during subsequent incremental placement, the tool can move the cells added during legalization, optimization, and clock tree synthesis out of the soft blockage area.\n To prevent this, use the following application option setting: set_app_options\u00a0-name\u00a0place.coarse.enable_enhanced_soft_blockages\u00a0\\ -value\u00a0true       Note: Soft placement blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Define a Blockage of a Predefined Category", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a partial blockage, specify the boundary, type ( -type\u00a0partial option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage with a maximum allowed cell density of 60 percent (a blocked percentage of 40), enclosed by the rectangle with corners at (10, 20) and (100, 200), use the following command: create_placement_blockage\u00a0-boundary\u00a0{10\u00a020\u00a0100\u00a0200}\u00a0\\ -type\u00a0partial\u00a0-blocked_percentage\u00a040 To allow unlimited usage of a partial blockage area, specify a blockage percentage of zero ( -blocked_percentage\u00a00 option).\n Note: Partial placement blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Defining Blockages That Exclude Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A category blockage is a special type of partial blockage that controls the placement of a predefined category of cells within the partial blockage.\n To create a category blockage, 1.\n Create the cell category by defining a user attribute for the category by using the define_user_attribute command and applying it to the affected cell references or instances by using the  set_attribute command.\n To prevent the cell from being placed in the category blockage, set the attribute to true.\n To allow the cell in the category blockage, set the attribute to  false.\n When defining and applying attributes, observe the following rules: \u25e6 A blockage can only be controlled by a single attribute.\n \u25e6 Multiple blockages can be controlled by the same attribute.\n \u25e6 A cell can have multiple attributes, which could impact its placement in multiple category blockages.\n       \u25e6 The same attribute can be applied to a reference and an instance.\n \u25e6 If a cell instance and its reference have different attributes, the attribute on the cell instance takes precedence.\n 2.\n Create the category blockage by using the  create_placement_blockage command with the  -type\u00a0category,  -blocked_percentage, and  -category options.\n The argument to the  -category option is the name of the user attribute.\n The following example defines a blockage that prevents a certain category of cells from being placed within it: define_user_attribute\u00a0-type\u00a0boolean\u00a0\\ -classes\u00a0lib_cell\u00a0dr_cells set_attribute\u00a0[get_lib_cells\u00a0mylib/dr*]\u00a0dr_cells\u00a0true create_placement_blockage\u00a0-boundary\u00a0{{4300\u00a02400}\u00a0{4500\u00a02700}}\u00a0\\ -type\u00a0category\u00a0-blocked_percentage\u00a045\u00a0-category\u00a0dr_cell The following example defines a blockage that allows only a certain category of cells to be placed within it: define_user_attribute\u00a0-type\u00a0boolean\u00a0\\ -classes\u00a0lib_cell\u00a0non_iso set_attribute\u00a0[get_lib_cells\u00a0mylib/*]\u00a0non_iso\u00a0true set_attribute\u00a0[get_lib_cells\u00a0mylib/iso*]\u00a0non_iso\u00a0false create_placement_blockage\u00a0-boundary\u00a0{{4300\u00a02400}{4500\u00a02700}}\u00a0\\ -type\u00a0category\u00a0-blocked_percentage\u00a030\u00a0-category\u00a0non_iso Note: Category blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Defining Blockages That Exclude Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define partial blockages that exclude registers, specify the boundary, type ( -type register option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that excludes registers, but allows a cell density of 50 percent for other cells, use the following commands: create_placement_blockage\u00a0-boundary\u00a0{{10\u00a020}\u00a0{100\u00a0200}}\u00a0\\ -type\u00a0register\u00a0-blocked_percentage\u00a050 Note: Register blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Defining Blockages That Allow Relative Placement Cells Only", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define partial blockages that exclude relative placement groups, specify the boundary, type ( -type\u00a0rp_group option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that excludes relative placement groups, but allows a cell density of 100 percent for all other cells, use the following commands: create_placement_blockage\u00a0-boundary\u00a0{{10\u00a020}\u00a0{100\u00a0200}}\u00a0\\ -type\u00a0rp_group\u00a0-blocked_percentage\u00a00 Note: Relative placement group blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Defining Blockages That Allow Buffers Only", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define partial blockages that allow relative placement cells only, specify the boundary, type ( -type\u00a0allow_rp_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to defines a partial blockage that allows relative placement cells only, with a maximum allowed cell density of 80 percent (a blocked percentage of 20), and enclosed by the rectangle with corners at (10, 20) and (100,200), use the following command: create_placement_blockage\u00a0-name\u00a0rp_only\u00a0\u00a0-type\u00a0allow_rp_only\u00a0\\ -boundary\u00a0{10\u00a020\u00a0100\u00a0200}\u00a0\u00a0-blocked_percentage\u00a020 These blockages allows the tool to place relative placement groups, which are usually large structures, without disturbing the placement of other cells.\n After the tool places and legalizes the relative placement groups, you can remove these blockages and allow the tool to place other cells in them.\n Note: Relative-placement-cells-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Querying Placement Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage\u00a0-boundary\u00a0{{10\u00a020}\u00a0{100\u00a0200}}\u00a0\\ -type\u00a0allow_buffer_only\u00a0-blocked_percentage\u00a070       Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"header": "How do I Removing Placement Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To return a collection of placement blockages in the current block that match certain criteria, use the get_placement_blockages comandcomandsget_placement_blockages get_placement_blockages command."}
{"header": "How do I Defining Placement Bounds", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove placement blockages from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_placement_blockages command.\n To remove all placement blockages from a block, use the  -all option.\n To remove specific placement blockages from a block, specify the placement blockage names."}
{"header": "How do I Defining Move Bounds", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A placement bound is a constraint that controls the placement of groups of cells.\n It allows you to group cells to minimize wire length and place the cells at the most appropriate locations.\n For example, you might want to define a bound for clock-gating cells or extremely timing-critical groups of cells that you want to guarantee will not be disrupted for placement by other logic.\n Table\u00a08 lists the types of placement bounds supported by the Fusion Compiler tool.\n Table 8 Types of Placement Bounds Bound type Description                  Table 8 Types of Placement Bounds (Continued) Bound type Description       opt.buffering.exclusive_hard_bound_buffering_mode    0            To define a placement bound, use the create_bounds comandcomandscreate_bounds create_bound command.\n When you define a bound, you must use the  -name option to specify its name.\n In general, you also specify the cells and ports to be included in the bound.\n If a hierarchical cell is included, all cells in the subdesign belong to the bound.\n However, you can create an empty bound and specify the contents of the bound later by using the  add_to_bound command.\n You can remove objects from a bound by using the remove_from_bound command.\n You must also specify the options required for the specific type of bound you want to create.\n The following topics describe how to create the various types of move bounds: \u2022 Defining Move Bounds \u2022 Defining Group Bounds \u2022 Querying Placement Bounds \u2022 Removing Placement Bounds"}
{"header": "How do I Defining Group Bounds", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A move bound is a fixed region within which to place a set of cells.\n It comprises one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping.\n To define the boundaries of these shapes, use the  -boundary option with the  create_bound command (if you are creating a new move bound) or the  create_bound_shape command       (if you are adding shapes to an existing move bound).\n Note that you can specify one or more shapes when using the  create_bound command, but only a single shape in each create_bound_shape command.\n \u2022 To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly }\u00a0{ urx ury }} \u2022 To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 }\u00a0{ x2 y2 }\u00a0{ x3 y3 }\u00a0{ x4 y4 }\u00a0...} Move bounds can be hard, soft, or exclusive.\n \u2022 To define a soft move bound, use the following syntax: create_bound\u00a0-name\u00a0 name [-type\u00a0soft]\u00a0[-effort\u00a0 effort_level ]\u00a0\\ -boundary\u00a0{ coordinates }\u00a0[ bound_objects ] The default effort is  ultra ; you can also specify  low,  medium, or  high.\n For example, to define a rectangular soft move bound for the INST_1 cell instance with its lower-left corner at (100, 100) and its upper-right corner at (200, 200), use the following command: fc_shell>\u00a0 create_bound -name b1 -boundary {100 100 200 200} INST_1 \u2022 To define a hard move bound, use the following syntax: create_bound\u00a0-name\u00a0 name -type\u00a0hard\u00a0-boundary\u00a0{ coordinates }\\ [ bound_objects ] For example, to define a rectangular hard move bound for the INST_1 cell instance with its lower-left corner at (100, 100) and its upper-right corner at (200, 200), use the following command: fc_shell>\u00a0 create_bound -name b2 -type hard \\ -boundary {100 100 200 200} INST_1 \u2022 To define an exclusive move bound, use the following syntax: create_bound\u00a0-name\u00a0 name -exclusive\u00a0-boundary\u00a0{ coordinates }\u00a0\\ [ bound_objects ] For example, to define a rectangular exclusive move bound for the INST_1 cell instance with its lower-left corner at (100, 100) and its upper-right corner at (200, 200), use the following command: fc_shell>\u00a0 create_bound -name b3 -exclusive \\ -boundary {100 100 200 200} INST_1       To add shapes to an existing move bound, use the  create_bound_shape command.\n To remove shapes from an existing move bound, use the  remove_bound_shapes command."}
{"header": "How do I Querying Placement Bounds", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "move boundcreating A group bound is a floating region within which to place a set of cells.\n Group bounds can be hard, soft, or dimensionless.\n \u2022 To define a soft group bound, use the following syntax: create_bound\u00a0-name\u00a0 name [-type\u00a0soft]\u00a0[-effort\u00a0 effort_level ]\u00a0\\ [-dimensions\u00a0{ width height }\u00a0 bound_objects ] The default effort is  ultra ; you can also specify  low,  medium, or  high.\n For example, to define a soft group bound for the INST_1 and INST_2 cell instances with a width of 100 and a height of 100, use the following command: fc_shell>\u00a0 create_bound -name b4 -dimensions {100 100} \\ {INST_1 INST_2} \u2022 To define a hard group bound, use the following syntax: create_bound\u00a0-name\u00a0 name -type\u00a0hard\u00a0-dimensions\u00a0{ width height }\u00a0\\ [ bound_objects ] For example, to define a hard group bound for the INST_1 and INST_2 cell instances with a width of 100 and a height of 100, use the following command: fc_shell>\u00a0 create_bound -name b5 -type hard -dimensions {100 100} \\ {INST_1 INST_2} \u2022 To define a dimensionless group bound, use the following syntax: create_bound\u00a0-name\u00a0 name [-effort\u00a0 effort_level ]\u00a0\\ [ bound_objects ] The default effort is  medium ; you can also specify  low,  high, or  ultra.\n For example, to define a dimensionless group bound for the INST_1 and INST_2 cell instances in which the tool uses a high level of effort to place the cells closer within the group bound, use the following command: fc_shell>\u00a0 create_bound -name b6 -effort high {INST_1 INST_2}"}
{"header": "How do I Removing Placement Bounds", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the placement bounds in a block, use the report_bounds comandcomandsreport_boundsmove boundreporting report_bounds command.\n To return a collection of placement bounds in the current block that match certain criteria, use the get_bounds comandcomandsget_bounds get_bounds command.\n       To return a collection of bound shapes associated with one or more move bounds, use the get_bound_shapes command."}
{"header": "How do I Defining Placement Attractions", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove placement bounds from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_bounds command.\n To remove all placement bounds from a block, use the  -all option.\n To remove specific placement bounds from a block, specify the placement bound names."}
{"header": "How do I Specifying Locations for Unmapped Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A placement attraction is a constraint that you can use to specify that a large group of cells be placed together in the same vicinity of the placement area.\n It is a soft constraint that the tool considers during initial placement.\n However, it has less effect during subsequent incremental placement stages.\n To specify a more restrictive placement constraint for a smaller group of cells, create a move bound or group bound by using the  create_bound command.\n To define a placement attraction, use the  create_placement_attraction command.\n For example, to specify that the cells from the subblocks named add1 and mult1 be placed in the same vicinity, use the following command: fc_shell>\u00a0 set add1_cells [get_flat_cells add1/*] fc_shell>\u00a0 set mult1_cells [get_flat_cells mult1/*] fc_shell>\u00a0 create_placement_attraction -name add1_mult1 \\ \"$add1_cells $mult1_cells\" You can use the  -region option to specify \u2022 A region in which to place the cells To do so, specify the lower-left and upper-right coordinates of the region, as shown in the following example: fc_shell>\u00a0 set U1_cells [get_flat_cells U1/*] fc_shell>\u00a0 create_placement_attraction -name U1 \\ -region {{0 0} {2000 1500}} $U1_cells \u2022 A straight line along which to place the cells, such as an edge of a macro cell To do so, specify the coordinates of the two ends of the line, as shown in the following example: fc_shell>\u00a0 set U2_cells [get_flat_cells U2/*] fc_shell>\u00a0 create_placement_attraction -name U2 \\ -region {{1000 200} {1000 800}} $U2_cells       \u2022 A location around which to place the cells, such as a port location To do so, specify the coordinates of the location, as shown in the following example: fc_shell>\u00a0 set U3_cells [get_flat_cells U3/*] fc_shell>\u00a0 create_placement_attraction -name U3 \\ -region {{0 700}} $U3_cells The following table shows additional commands available for changing, reporting, and removing placement attractions.\n For more information, see the command man pages.\n Table 9 Commands Related to Placement Attractions To do this Use this command  create_placement_attraction  add_to_placement_attraction  remove_from_placement_attraction  report_placement_attractions  get_placement_attractions  remove_placement_attractions See Also \u2022 Defining Move Bounds"}
{"header": "How do I Defining Cell Spacing Constraints for Legalization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify fixed locations for unmapped leaf cells, so the tool does not move these cells during compile.\n To do so, specify the location coordinates for leaf cells by using the set_cell_location command.\n To prevent the tool from moving a cell during compile, specify a fixed location for the cell by using the  -fixed option with the  set_cell_location command to set the physical_status attribute to  fixed on the cell.\n To change the location of a cell marked with fixed placement status, specify the  -ignore_fixed option with the command.\n The specified coordinates indicate the lower-left corner of the cell boundary.\n After you run the set_cell_location command, the unmapped cell gets the specified location in memory, but the location is not reflected in the layout view before compile.\n To view the placement of the cell, run the  compile_fusion command.\n This example sets the lower-left corner of the out1_reg cell to (20 10) and sets the fixed physical placement status to prevent the tool from moving the cell during compile.\n       fc_shell>\u00a0 set_cell_location -coordinates { 20 10 } out1_reg -fixed"}
{"header": "How do I Reporting Cell Spacing Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Cell spacing constraints control the spacing between a standard cell and another standard cell or a boundary (the chip boundary, a hard macro, a hard macro keepout margin, a hard placement blockage, or a voltage area guard band).\n You assign library cells to groups (the boundaries are in a predefined group named SNPS_BOUNDARY), and then define the required spacing between cells in these groups.\n By default, there are no spacing constraints between standard cells during legalization.\n To enhance yield, you can define the valid spacing between standard cells or between a standard cell and a boundary.\n Note: The support for spacing constraints between standard cells and power or ground nets depends on how the net is represented in the block.\n If the power or ground net is defined as a complete blockage, the legalizer and the check_legality command ignore spacing rule violations between standard cells and the power or ground net.\n If the power or ground net is defined as a partial blockage, the legalizer and the  check_legality command check for spacing rule violations between standard cells and the power or ground net.\n Cell spacing constraints are implemented by attaching labels, which are similar to attributes, to the left and right sides of library cells, assuming that the cell is in its north orientation, and specifying the invalid spacings between these labels.\n To define cell spacing constraints, 1.\n Add labels to the library cells that have spacing constraints by using the set_placement_spacing_label command.\n You must specify the following information for each label: \u25e6 The label name (the  -name option) \u25e6 The library cells to which to apply the label (the  -lib_cells option) \u25e6 The sides of the library cells to which to apply the label (the  -side option, which can take a value of  right,  left, or  both ) The label definitions are additive; you can specify the same label to be used on the right side of some cells and the left side of other cells.\n For example, to assign a label named X to the right side of the cellA library cell and the left side of the cellB and cellC library cells, use the following commands: fc_shell>\u00a0 set_placement_spacing_label -name X \\ -lib_cells {cellA} -side right       fc_shell>\u00a0 set_placement_spacing_label -name X \\ -lib_cells {cellB cellC} -side left You can assign multiple labels to a side of a library cell.\n For example, to assign labels named Y and Z to the right side of the cellB library cell, use the following commands: fc_shell>\u00a0 set_placement_spacing_label -name Y \\ -lib_cells {cellB} -side right fc_shell>\u00a0 set_placement_spacing_label -name Z \\ -lib_cells {cellB} -side right 2.\n Define the spacing requirements between the labels by using the set_placement_spacing_rule command.\n You must specify the following information for each rule: \u25e6 The labels being constrained (the  -labels option) You must specify exactly two labels in each set_spacing_label_rule comandcomandset_spacing_label_rule set_placement_spacing_rule command.\n You can specify any of the labels defined by the set_placement_spacing_label command or the predefined SNPS_BOUNDARY label, which includes the chip boundary, hard macro boundaries, a hard macro keepout margins, hard placement blockages, and voltage area guard bands.\n The two labels can be the same or different.\n \u25e6 The range of invalid spacings, in number of unit tiles For example, to specify that there must be at least one unit tile between labels X and Y (they cannot abut), use the following command: fc_shell>\u00a0 set_placement_spacing_rule -labels {X Y} {0 0} To specify that there must be at least one unit tile between X labels and any boundary, use the following command: fc_shell>\u00a0 set_placement_spacing_rule \\ -labels {X SNPS_BOUNDARY} {0 0} To specify that two X labels cannot have a spacing of two unit tiles, use the following command: fc_shell>\u00a0 set_placement_spacing_rule -labels {X X} {2 2} To specify that labels X and Z must have a spacing of less than two unit tiles or more than four unit tiles, use the following command: fc_shell>\u00a0 set_placement_spacing_rule -labels {X Z} {2 4}       Caution: The cell spacing constraints are not saved with the block; they apply only to the current session and must be redefined in each session."}
{"header": "How do I Removing Cell Spacing Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the cell spacing rules, use the report_spacing_rules comandcomandsreport_spacing_rules report_placement_spacing_rules command.\n This command reports the cell spacing labels defined in the current session, the library cells (and their sides) to which they apply, and the rules defined for them."}
{"header": "How do I Specifying Placement Settings", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove spacing rules, use the remove_al_spacing_rules comandcomandsremove_al_spacing_rules remove_placement_spacing_rules command.\n You must specify which rules to remove.\n \u2022 To remove all spacing rules, use the  -all option.\n \u2022 To remove a specific label and all rules associated with that label, use the  -label option to specify the label.\n \u2022 To remove a rule between labels, use the  -rule option to specify two labels associated with the rule."}
{"header": "How do I Performing Placement With Inaccurate Constraints at Early", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool performs coarse placement at various points during the preroute stage of the design flow.\n The following topics describe settings for controlling coarse placement: \u2022 Performing Placement With Inaccurate Constraints at Early Stages \u2022 Generating Automatic Group Bounds for Clock Gating Cells \u2022 Controlling the Placement Density \u2022 Controlling Congestion-Driven Restructuring During Placement \u2022 Reducing Congestion \u2022 Considering Wide Cell Density During Placement \u2022 Considering the Effects of Cell Pins During Placement \u2022 Considering the Congestion Effects Due to the Nondefault Routing Rules of Clock Nets \u2022 Considering the Effects of Clock Gating Cells of Sequential Arrays During Placement \u2022 Considering Legalization Effects During Placement \u2022 Considering DFT Connections During Placement       \u2022 Considering the Dynamic Power QoR During Placement \u2022 Performing IR-Drop-Aware Placement \u2022 Spreading Repeater Cells During Placement"}
{"header": "How do I Generating Automatic Group Bounds for Clock Gating Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the early stages of a design cycle, placement constraints can be inaccurate causing the tool to exit during coarse placement.\n To continue with placement when a region is overutilized due to it being too small or being covered by blockages, set the place.coarse.handle_early_data application option to  true.\n When you do so, the tool issues warning messages as shown in the following example output: Warning:\u00a0Utilization\u00a0of\u00a0move_bound_0\u00a0is\u00a0109%.\n (PLACE-089) Warning:\u00a0Placement\u00a0continues\u00a0with\u00a0over\u00a0utilized\u00a0regions\u00a0in\u00a0the\u00a0design.\n (PLACE-083) Warning:\u00a0Overutilized\u00a0regions\u00a0for\u00a0move_bound_0\u00a0are\u00a0modified\u00a0by\u00a0removal\u00a0of partial\u00a0and\u00a0full\u00a0blockages.\n (PLACE-084) When you enable this feature, the tool prints a warning message if the utilization of a region is more that 90 percent.\n To change this threshold, use the place.coarse.utilization_warning_threshold application option."}
{"header": "How do I Controlling the Placement Density", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool can automatically generate group bounds for integrated clock gating cells and the sequential cells they drive.\n To do so, use the following application option setting: fc_shell>\u00a0 set_app_options -name place.coarse.icg_auto_bound  \\ -value true When you enable this feature, the tool creates the automatic group bounds at the beginning of placement and removes them at the end of placement.\n The tool does not include cells that already belong to another group bound in the automatic group bounds.\n To limit the maximum number of fanouts that can be included in an automatic bound, use the  icg_auto_bound_fanout_limit application option setting, as shown in the following example: fc_shell>\u00a0 set_app_options \\ -name place.coarse.icg_auto_bound_fanout_limit -value 30 The default fanout limit is 40."}
{"header": "How do I Controlling Congestion-Driven Restructuring During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can control the placement density of a block as described in the following table.\n Table 10 Application Options for Controlling Placement Density To do this Use this application option    place.coarse.auto_density_control -enhanced  place.coarse.auto_density_control false place.coarse.auto_density_control  place.coarse.max_density 0        place.coarse.congestion_driven_max_util 0.93 When specifying the maximum density or maximum utilization, choose a value between 1 and the overall utilization of the block.\n For example, if the utilization of a block is 40 percent, you can choose values between 1 and 0.4, as shown in the following example: fc_shell>\u00a0 set_app_options -name place.coarse.max_density -value 0.6 fc_shell>\u00a0 set_app_options \\ -name place.coarse.congestion_driven_max_util -value 0.8 If you do not specify a value for the maximum density or maximum utilization, the tool automatically derives a value for the maximum density and maximum utilization based on the stage of the design flow, considering the  place.coarse.auto_density_control application option is not set to  false.\n By default, the  place.coarse_auto_density_control application option is enabled and set to  enhanced.\n This improves the total power and wire length for the design.\n Note: It is not necessary to disable the  place.coarse.auto_density_control application option to override the  max_density and congestion_driven_max_util values.\n User settings always take precedence over the tool derived values.\n Throughout placement, the tool prints PLACE-027 information messages indicating the values it uses for these settings.\n       Information:\u00a0Automatic\u00a0density\u00a0control\u00a0has\u00a0selected\u00a0the\u00a0following settings:\u00a0max_density\u00a00.60,\u00a0congestion_driven_max_util\u00a00.77.\n (PLACE-027) The tool applies the maximum density and congestion-driven maximum utilization settings independently to each placeable area such as a voltage area or exclusive move bound, rather than taking an average over the entire block."}
{"header": "How do I Reducing Congestion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool restructures nets to reduce congestion during \u2022 The  create_placement command, except when you use the  -timing_driven option \u2022 The  initial_place stage of the  compile_fusion command You can control the congestion-driven restructuring as follows: \u2022 Specify an effort level by setting the  place.coarse.cong_restruct_effort application option to  low,  medium (default),  high, or  ultra.\n \u2022 Prevent the tool from increasing the path depth by more than three levels of logic by setting the  place.coarse.cong_restruct_depth_aware application option to  true."}
{"header": "How do I Considering Wide Cell Density During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To reduce the congestion of your block, use the following settings: \u2022 Consider the congestion of each layer separately and improve the accuracy of congestion reduction in coarse placement by setting the place.coarse.congestion_layer_aware application option to  true.\n By default, the tool combines the congestion information of all layers during placement.\n By considering the congestion of each layer separately, the tool can identify and fix areas with high pin densities that have insufficient resources on the lower layers for making pin connections.\n \u2022 Expand the virtual area of cells during placement based on the local routing resource needs by setting the  place.coarse.increased_cell_expansion application option to true.\n By increasing the virtual area of cells in areas where there is a shortage of routing resources, the tool can minimize the cell density and congestion.\n By default, the tool expands the cells in the horizontal direction, which helps reduce congestion in the vertical routing layers.\n For designs with congestion mainly in the horizontal routing layers, set the  place.coarse.congestion_expansion_direction application option to  both.\n The default is  horizontal.\n       By default, the tool uses the uses global route congestion map to identify highly congested areas that need cell expansion.\n However, the tool does not consider the congestion due to soft routing rules.\n To consider the congestion effects of soft routing rules, set the  route.global.export_soft_congestion_maps application option to true."}
{"header": "How do I Considering the Effects of Cell Pins During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If a cell cannot straddle the vertical power straps and the width of the cell is more than half the pitch of the power straps, only one such cell can be placed between the power straps.\n Therefore, during placement, the tool must minimize the density of such wide cells to ensure that they can be placed and legalized without large displacements.\n For advanced technology nodes with wide cells, enable wide-cell modeling during placement by setting the  place.coarse.wide_cell_use_model application option to true."}
{"header": "How do I Considering the Congestion Effects Due to the Nondefault", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you specify a technology node setting of  7,  7+,  5,  s5, or  s4 by using the set_technology\u00a0-node command, you can specify that the tool uses a technology- specific pin-cost model during placement by setting the  place.coarse.pin_cost_aware application option to  true.\n The default is  false.\n When you enable this feature, during placement, the tool tries to improve pin accessibility by using a technology-specific model to predict the routing resources required to access each pin.\n For all other technology nodes, you can control the maximum local pin density during placement by setting the  place.coarse.pin_density_aware application option to  true.\n The default is  false.\n Table 11 Settings for Controlling the Effects of Pins During Placement set_technology -node place.coarse.\n pin_cost_aware place.coarse.\n pin_density_aware The tool does this 7 7+ 5 s5 s4 true true false   7 7+ 5 s5 s4 false true   7 7+ 5 s5 s4 false false    true false true         Table 11 Settings for Controlling the Effects of Pins During Placement (Continued) set_technology -node place.coarse.\n pin_cost_aware place.coarse.\n pin_density_aware The tool does this  true false false"}
{"header": "How do I Considering the Effects of Clock Gating Cells of Sequential", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve timing and reduce crosstalk, nondefault routing rules are used extensively for routing clock nets.\n However, these nondefault routing rules require additional space, which can increase the congestion after clock routing.\n To consider the effects of the nondefault routing rules of the clock nets during placement, set the  place.coarse.ndr_area_aware application option to  true."}
{"header": "How do I Considering Legalization Effects During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A sequential array, which is commonly used in storage devices, is a group of registers that are arranged as a two-dimensional array.\n The clock pins of the registers along a row of a sequential array are usually driven by a single clock-gating cell.\n To consider the clock-gating cells of a sequential array during placement, set the place.coarse.seq_array_icg_aware application option to  true.\n Doing so can reduce the congestion caused by the clock nets."}
{"header": "How do I Considering DFT Connections During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To minimize many cells from being displaced during legalization, the tool should be aware of legalization limits and restrictions during coarse placement.\n For example, the tool should be aware that it cannot place a wide cell in a specific location due to the position of the power straps at that location.\n To consider legalization effects during placement, set the place.coarse.enhanced_legalizer_driven_placement application option to  true.\n Use this feature for blocks that have many cells with small to medium displacements during legalization and use the RMS displacement values reported during legalization to see if it reduces the displacement."}
{"header": "How do I Considering the Dynamic Power QoR During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve the DFT logic placement by enhancing the tool's awareness of DFT connectivity, while still optimizing for functional placement, set the place.coarse.enable_dft_modeling application option to  auto.\n The default is  false."}
{"header": "How do I Performing IR-Drop-Aware Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To consider the dynamic power QoR during placement, perform the following steps: 1.\n Annotate switching activity on the design, as described in  Annotating the Switching Activity.\n 2.\n Ensure that at least one scenario is enabled for dynamic-power optimization by using the  set_scenario_status\u00a0-dynamic_power\u00a0true command.\n 3.\n Enable power-driven placement for the  create_placement,  refine_placement, compile_fusion, or  clock_opt command by using one of the following methods: \u25e6 Enable dynamic-power-driven placement by setting the place.coarse.enhanced_low_power_effort application option to  none,  low, medium, or  high.\n The default is  low.\n During dynamic-power-driven placement, the tool tries to improve both the timing and power of timing-critical nets and the power of the other nets.\n This improves the power QoR without affecting the timing QoR."}
{"header": "How do I Controlling IR-Drop-Aware Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During placement, the tool can use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values, which reduces the power density of such areas.\n To perform IR-drop-aware placement, use the following steps: 1.\n Place and legalize the block.\n 2.\n Set up for RedHawk Fusion and perform static or dynamic voltage drop analysis by using the  analyze_rail\u00a0-voltage_drop command as shown in the following example: fc_shell>\u00a0 source redhawk_setup.tcl fc_shell>\u00a0 analyze_rail -voltage_drop static -nets {VDD VSS} For more information, see  Performing Voltage Drop Analysis.\n 3.\n Enable IR-drop-aware placement by setting the  place.coarse.ir_drop_aware application option to  true.\n       4.\n (Optional) Specify additional settings for IR-drop-aware placement, as described in Controlling IR-Drop-Aware Placement.\n 5.\n Rerun placement.\n Note: To perform IR-drop-aware placement, you must have Digital-AF and SNPS_INDESIGN_RH_RAIL license keys."}
{"header": "How do I Spreading Repeater Cells During Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you enable IR-drop-aware placement by setting the  place.coarse.ir_drop_aware application option to  true, the tool creates three categories of cells based on the total number of cells.\n Figure 22 Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in Figure\u00a022.\n \u2022 The upper category consists of the top one percent of the total number of cells with the highest voltage drop values.\n During placement, the tool spreads these cells the most.\n \u2022 The middle category consists of the next five percent of the cells.\n During placement, the tool spreads these cells less than those in the upper category.\n \u2022 The lower category consists of the rest of the cells.\n The tool does not spread these cells.\n       You can change the percentage of cells in the upper and middle categories by using the  place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options.\n The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the  place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false.\n They are  true by default.\n The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa.\n The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\       -value 2.0 fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell>\u00a0 set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command.\n The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell>\u00a0 set_placement_ir_drop_target VA1 high 1.5 fc_shell>\u00a0 set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell>\u00a0 set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell>\u00a0 set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target,  report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"header": "How do I Specifying Legalization Settings", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "If a block has many chains of repeater cells (buffers, inverters, or pipelined registers) along the edges or corners of macro cells or blockages, the tool might clump the cells along the edges or corners, increasing congestion.\n You can reduce this congestion by setting the place.coarse.spread_repeater_paths application option to  true before you run the create_placement,  compile_fusion, or  clock_opt command.\n Then, the tool reduces congestion along the edges and corners by spreading the repeater cells in an orthogonal direction."}
{"header": "How do I Minimizing Large Displacements During Legalization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool performs legalization at various points during the design flow.\n The following topics describe settings for controlling legalization: \u2022 Minimizing Large Displacements During Legalization \u2022 Optimizing Pin Access During Legalization \u2022 Enabling Advanced PG Net Checks       \u2022 Enabling Advanced Legalization Algorithms \u2022 Setting Up for Variant-Aware Legalization \u2022 Checking if Library Cells Are Legally Placeable"}
{"header": "How do I Optimizing Pin Access During Legalization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To minimize large displacements of cells during legalization, enable \u2022 Orientation optimization by setting the  place.legalize.optimize_orientations application option to  true.\n When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization.\n \u2022 Stream placement by setting the  place.legalize.stream_place application option to true.\n When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization.\n You can further control stream placement by using the  place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}
{"header": "How do I Enabling Advanced PG Net Checks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For advanced technology nodes, to improve the routability of areas with high pin densities by redistributing the cells, enable pin optimization during legalization by setting the place.legalize.optimize_pin_access_using_cell_spacing application option to true."}
{"header": "How do I Enabling Advanced Legalization Algorithms", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For advanced technology nodes, such as 12 nanometer, 7 nanometer, or smaller technology nodes, you can enable advanced physical DRC checks between cells and prerouted PG nets by setting the place.legalize.enable_advanced_prerouted_net_check application option to  true.\n When you enable this feature, you can further control the accessibility checks performed for standard cell pins by using the  place.legalize.advanced_layer_access_check and place.legalize.advanced_libpin_access_check application options.\n However, the default behavior of this feature is suitable for most designs."}
{"header": "How do I Setting Up for Variant-Aware Legalization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable advanced legalization algorithms for 2D rule checking and cell interaction, which can reduce legalization runtime, set the  place.legalize.enable_advanced_legalizer application option to  true.\n To specify additional advanced legalization rules that are not automatically detected, set the  place.legalize.enable_advanced_legalizer_rules application option.\n When you enable the advanced legalization algorithms, by default, the tool aligns vertical pin shapes during pin access optimization to improve routability.\n However, you can specify additional strategies for pin access optimization by setting the place.legalize.optimize_pin_access_strategies application option as shown in the following table.\n Table 12 Settings for the place.legalize.optimize_pin_access_strategies Application Option To do this Use this setting  horizontal_align   avoid_high_pin_density   horizontal_align\u00a0avoid_high_pin_density During advanced legalization and legality checking, the tool can simultaneously check for DRC violations between multiple cells and PG net shapes.\n To enable this feature, set the place.legalize.enable_multi_cell_pnet_checks application option to  true.\n To enable multi cell checks at the last run of  route_opt command or after the  route_auto command, set the following application options to  true.\n This helps to improve the runtime for QoR considerations.\n To enable the following application options, set the place.legalize.enable_multi_cell_pnet_checks application option to  true : \u2022 place.legalize.enable_multi_cell_access_check : considers impact on a cell's pin access due to presence of abutting neighbor cells and any prerouted net PG net shapes in the vicinity.\n Default is  false.\n \u2022 place.legalize.enable_multi_cell_track_capacity_check : analyzes the track capacity of the cell's pins and abutting neighbor cells.\n Track capacity estimates the sufficiency of routing tracks in the area to access all the specified pins.\n To enable this application option, set the  place.legalize.enable_multi_cell_access_check application option to  true.\n Default is  false.\n       To enable multithreaded advanced legalization, perform the following steps: 1.\n Enable multithreaded advanced legalization algorithms by setting the place.legalize.enable_threaded_advanced_legalizer application option to true.\n 2.\n Configure for multithreading as described in  Configuring Multithreading.\n To perform multithreaded advanced legality checking, 1.\n Enable advanced legalization algorithms by setting the place.legalize.enable_advanced_legalizer application option to  true.\n 2.\n Configure for multithreading as described in  Configuring Multithreading.\n 3.\n Perform legality checking using the  check_legality command."}
{"header": "How do I Defining Equivalent Cell Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Some libraries provide sets of functionally equivalent cells that can be legalized in different locations.\n This allows the tool to legalize a cell by replacing it with a variant, instead of moving the cell.\n The following figure shows functionally equivalent cells with varying pin locations.\n With variant-aware legalization, if a cell pin does not align with a track, the tool can try using its variant to align the cell pin to the track.\n Figure 23 Equivalent Cells With Different Pin Locations       The following figure shows functionally equivalent cells with different pin colors, which need to be aligned to a track of the same color.\n With variant-aware legalization, if a cell pin does not align with the corresponding colored track, the tool can try using its variant with a different colored pin and try aligning it to the appropriately colored track.\n Figure 24 Equivalent Cells With Pins of Different Colors The following topics describe the tasks you need to perform to set up the reference libraries and design for variant-aware legalization: \u2022 Defining Equivalent Cell Groups \u2022 Enabling Variant-Aware Legalization"}
{"header": "How do I Enabling Variant-Aware Legalization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Library Compiler tool supports creating variant-ready libraries from the Liberty source files.\n The  physical_variant_cells attribute in the Liberty source defines the variants of a cell.\n When the  physical_variant_cells attribute exists in the logic libraries, the compiled library is variant ready.\n If you logic library is not variant ready, you can define the equivalent cell variants during the library preparation stage in the Library Manager tool.\n To do so, create equivalent cell groups by using the  create_cell_groups command.\n The following example adds equivalent cell groups to an existing reference library in the Library Manager tool: lm_shell>\u00a0 create_workspace -flow edit LIB.ndm lm_shell>\u00a0 create_cell_group -name A [get_lib_cells MY_LIB/A_*] lm_shell>\u00a0 create_cell_group -name B [get_lib_cells MY_LIB/B_*]       lm_shell>\u00a0 check_workspace lm_shell>\u00a0 commit_workspace You can report the equivalent cell groups in a library by using the  report_cell_groups command in either the Library Manager tool or the Fusion Compiler tool.\n This command reports equivalent cell groups that are defined in Liberty source files of variant-ready logic libraries as well as those defined by using the  create_cell_groups command in the Library Manager tool."}
{"header": "How do I Checking if Library Cells Are Legally Placeable", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable variant-aware legalization, set the  place.legalize.enable_variant_aware application option to  true.\n When variant-aware legalization is enabled, the tool tries to fix legalization DRC violations by swapping the violating cell with a variant, rather than moving it.\n If the cell has no variants, it is moved to a legal location.\n For pin-track and pin-color alignment during variant-aware legalization, set the following application options to  true : \u2022 place.legalize.enable_prerouted_net_check \u2022 place.legalize.enable_pin_color_alignment_check In addition, you must specify the layers to be aligned by using the place.legalize.pin_color_alignment_layers application option."}
{"header": "How do I Controlling the Optimization of Cells, Nets, Pins, and Ports", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you specify all your placement and legalization constraints and settings, you can check if specific library cells can be legally placed in the block by using the analyze_lib_cell_placement\u00a0-lib_cells command.\n \u2022 To limit the analysis to a specific region of the core area, use the  -region option.\n By default, the command searches the entire core area.\n \u2022 To limit the analysis to a specific number of sites, use the  -trials option.\n By default, the command analyzes 1000 random sites to see if the specified library cells can be placed.\n If you specify a value of 0, the command analyzes all free sites, which can increase runtime \u2022 To ignore physical design constraints or advanced design rules during placement analysis, use the  -no_pdc or  -no_adv option.\n \u2022 To report only the relative placement groups that do not meet a specific threshold, use the  -threshold option.\n The tool reports a cell only if the percentage of sites the cell       can be placed, relative to the total number of sites analyzed, is less than the specified threshold.\n \u2022 To limit the report to a maximum number of cells, use the  -max_cells option.\n The default is 100, starting with the library cell with the worst pass rate.\n If your block contains library cells that have a very low pass rate, they will cause large displacements and increased runtime during legalization.\n In such cases, review the power plan, cell layout, and the legalization settings to improve the pass rate.\n The following example analyzes all the library cells that have instances in the current block: fc_shell>\u00a0 analyze_lib_cell_placement -lib_cells [add_to_collection \\ -unique \"\" [get_attribute [get_cells -physical_context] ref_phys_block]]  Analyzing\u00a0215\u00a0lib\u00a0cell(s).\n Warning:\u00a0Routing\u00a0direction\u00a0of\u00a0metal\u00a0layer\u00a0PO\u00a0is\u00a0neither\u00a0\"horizontal\"\u00a0nor \"vertical\".\n \u00a0PDC\u00a0checks\u00a0will\u00a0not\u00a0be\u00a0performed\u00a0on\u00a0this\u00a0layer.\n (PDC-003)  PDC\u00a0app_options\u00a0settings\u00a0========= place.legalize.enable_prerouted_net_check:\u00a01 place.legalize.num_tracks_for_access_check:\u00a01 place.legalize.use_eol_spacing_for_access_check:\u00a00 place.legalize.allow_touch_track_for_access_check:\u00a01 place.legalize.reduce_conservatism_in_eol_check:\u00a00 place.legalize.preroute_shape_merge_distance:\u00a00.0  Layer\u00a0M1:\u00a0cached\u00a00\u00a0shapes\u00a0out\u00a0of\u00a0869\u00a0total\u00a0shapes.\n Layer\u00a0M2:\u00a0cached\u00a0773\u00a0shapes\u00a0out\u00a0of\u00a0773\u00a0total\u00a0shapes.\n Cached\u00a041757\u00a0vias\u00a0out\u00a0of\u00a099466\u00a0total\u00a0vias.\n 0.0%...2.0%...4.0%...6.0%...8.0%...10.0%........\n  Lib\u00a0Cell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Pass\u00a0Rate ----------------------------------\u00a0\u00a0\u00a0\u00a0--------- saed32_lvt_lsup:LSUPX1_LVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.4450 saed32_lvt_lsup:LSUPX8_LVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.4780 saed32_lvt_lsup:LSUPX2_LVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.4810 saed32_lvt_lsup:LSUPX4_LVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.5040..............\n..............\n..............\n saed32_rvt_std:HADDX1_RVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.8600 saed32_lvt_std:OA21X1_LVT.frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.8610"}
{"header": "How do I Resolving Multiple References With the Uniquify Process", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe how you can control the optimization of cells, nets, pins, and ports: \u2022 Resolving Multiple References With the Uniquify Process \u2022 Preserving Cells and Nets During Optimization \u2022 Restricting Optimization to Cell Sizing Only \u2022 Preserving Networks During Optimization \u2022 Marking the Clock Networks \u2022 Disabling Design Rule Checking (DRC) \u2022 Preserving Pin Names During Sizing \u2022 Preserving Ports of Existing Hierarchies \u2022 Isolating Input and Output Ports \u2022 Fixing Multiple-Port Nets \u2022 Controlling the Addition of New Cells to Modules, Hierarchical Cells, and Voltage Areas \u2022 Specifying a Cell Name Prefix for Optimization"}
{"header": "How do I Preserving Cells and Nets During Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  uniquify command resolves multiple references, except those with the  dont_touch attribute, throughout the hierarchy in the current design.\n The uniquify process copies and renames any multiply referenced design so that each instance references a unique design.\n The process removes the original design from memory after it creates the new and unique designs.\n The original design and any collections that contain it or its objects are no longer accessible.\n After this process finishes, the tool optimizes each design copy based on the unique context of its cell instance.\n To control the names of the reference copies, use the  design.uniquify_naming_style application option.\n The default is  %s_%d, where  %s denotes the name of the existing reference and  %d denotes the smallest integer value that forms a unique design name.\n This example creates unique reference copies of the specified cells A1, A2, and A3.\n fc_shell>\u00a0 uniquify {A1 A2 A3} 3       This example creates unique reference copies for the filtered cells A and B.\n fc_shell>\u00a0 uniquify [get_cells {A B}] 2"}
{"header": "How do I Restricting Optimization to Cell Sizing Only", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To preserve design objects during optimization, use the  set_dont_touch command.\n The command places the  dont_touch attribute on cells, nets, references, and subdesigns in the current design to prevent these objects from being modified or replaced during optimization.\n This table shows how the tool preserves the design objects during optimization.\n Design objects Tool behavior         When you use the  set_dont_touch command, keep the following in mind: \u2022 The command prevents the ungrouping of hierarchy.\n \u2022 A child cell must inherit the same  dont_touch attribute from its parent module.\n For example, you cannot remove the  dont_touch attribute from a child cell when its parent module is marked with the  dont_touch attribute.\n \u2022 Use the command on fully mapped logic only, including cells, modules, and designs, as well as nets with fully mapped surrounding logic.\n \u2022 The  dont_touch attribute has higher precedence over the  boundary_optimization and the  size_only attributes.\n To report design objects marked with the  dont_touch attribute, use the report_dont_touch command.\n This command sets the  dont_touch attribute on cell A.\n fc_shell>\u00a0 set_dont_touch [get_cells A] true       To remove the  dont_touch attribute, use the  remove_attributes command or the set_dont_touch command set to  false, as shown in the following two commands: fc_shell>\u00a0 remove_attributes [get_cells A] dont_touch fc_shell>\u00a0 set_dont_touch [get_cells A] false The following table summaries the commands that you can use to set, remove, or report the  dont_touch attribute on design objects, including modules, cells, nets, and library cells.\n Yes denotes the command operation of the  dont_touch attribute is supported, while No denotes the command operation is not supported.\n Table 13 Command Support for the dont_touch Attribute on Design Objects Command Module Cell (Instance) Net Library cell set_dont_touch     set_attribute     define_user_attribute     get_attribute     remove_attributes     report_dont_touch     set_dont_touch unmapped_object"}
{"header": "How do I Preserving Networks During Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To allow only sizing on cells or instances during optimization, use the  set_size_only command.\n The command places the  size_only attribute on specified cells or instances to prevent them from being modified or replaced except cell sizing.\n To query the  size_only attribute, use the  report_attributes,  get_attribute, or report_cells command.\n To remove the attribute, use the  remove_attributes command or the  set_size_only command set to  false.\n This example sets the  size_only attribute on a specific cell.\n fc_shell>\u00a0 set_size_only [get_cells cell_name] true This example queries the  size_only attribute on the cell_name cell.\n fc_shell>\u00a0 get_attribute [get_cells cell_name] size_only       This example reports all the  size_only information on design objects in the current design.\n fc_shell>\u00a0 report_size_only -all"}
{"header": "How do I Marking the Clock Networks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can preserve networks, such as clock trees, during optimization by using the set_dont_touch_network command.\n The command places the  dont_touch attribute on the clocks, pins, or ports to prevent the cells and nets in the transitive fanout of the network from being modified or replaced.\n By default, the command preserves both clock paths and clock as data paths and propagates the  dont_touch attribute throughout the hierarchy of the network.\n To preserve clock paths only, specify the  -clock_only option.\n To remove the  dont_touch attribute from the network, specify the  -clear option.\n This example sets the  dont_touch attribute on the CLK clock network.\n fc_shell>\u00a0 set_dont_touch_network [get_clocks CLK] This example sets the  dont_touch attribute on the CLK clock paths only.\n fc_shell>\u00a0 set_dont_touch_network [get_clocks CLK] -clock_only This example removes the  dont_touch attribute from the CLK clock network.\n fc_shell>\u00a0 set_dont_touch_network [get_clocks CLK] -clear"}
{"header": "How do I Disabling Design Rule Checking (DRC)", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If a block does not contain clock trees, you should perform optimization using ideal clocks.\n To mark all clock networks as ideal, use the following command: foreach_in_collection\u00a0mode\u00a0[all_modes]\u00a0{ current_mode\u00a0$mode set_ideal_network\u00a0[all_fanout\u00a0-flat\u00a0-clock_tree] } To model the clock tree effects for placement, you should also define the uncertainty, latency, and transition constraints for each clock by using the  set_clock_uncertainty, set_clock_latency, and  set_clock_transition commands.\n Before performing clock tree synthesis, you must use the  remove_ideal_network command to remove the ideal setting on the fanout of the clock trees."}
{"header": "How do I Preserving Pin Names During Sizing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can disable design rule checking (DRC) on clock, constant, scan enable, and scan clock nets by using the  set_auto_disable_drc_nets command.\n To control design rule checking on specific nets in the current design, use the options with the  set_auto_disable_drc_nets command as shown in  Table\u00a014.\n Table 14 Options for the set_auto_disable_drc_nets Command Use this option To do this -none  -all   -constant\u00a0true\u00a0|\u00a0false true false  -on_clock_network\u00a0true\u00a0|\u00a0false true false  -scan\u00a0true\u00a0|\u00a0false true false  For example, to enable design rule checking for all clock, constant, scan enable, and scan clock nets, specify the  -none option: fc_shell>\u00a0 set_auto_disable_drc_nets -none To disable design rule checking on nets connecting to clocks and constants, set the -on_clock_network and  -constant options to  true, as shown in the following example and figure: fc_shell>\u00a0 set_auto_disable_drc_nets \\ -on_clock_network true -constant true       Figure 25 DRC Disabled Clock and Constant Nets Highlighted clkA clkB clkC clksel clkD in logic 1 const_sel clkE DRC disabled clock net DRC disabled constant net"}
{"header": "How do I Preserving Ports of Existing Hierarchies", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, optimization can change the pin names of leaf cells during sizing if the functionality of the resulting circuit is equivalent.\n The Fusion Compiler tool automatically updates its version of the internal constraints to reflect the new pin name if the pin is part of an exception constraint.\n If this occurs, it means that the original constraints used to constrain the block in the Fusion Compiler tool cannot be used for signoff purposes; instead, you must write out the constraints from the Fusion Compiler tool and include these constraints with the resulting block.\n This behavior provides the optimization engine with the most flexibility to select cells and improve the cost functions.\n You can restrict this sizing capability so that the constraints remain unchanged through optimization by setting the  opt.common.preserve_pin_names application option.\n This application option defaults to the setting of  never, and accepts values of either  never or  always.\n       To restrict sizing to pin-name equivalent cells, use the following command: fc_shell>\u00a0 set_app_options \\ -name opt.common.preserve_pin_names -value always To restore the default behavior, use the following command: fc_shell>\u00a0 set_app_options \\ -name opt.common.preserve_pin_names -value never"}
{"header": "How do I Isolating Input and Output Ports", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During optimization and clock tree synthesis, the tool can create new ports on existing hierarchical blocks.\n To prevent the tool from doing so, use the  set_freeze_ports command and set the  freeze_clock_port attribute to  true on the corresponding cell instance.\n You can prevent the tool from adding clock ports, data ports, or both by using the  -clock, -data, or  -all option.\n For example, to prevent the tool from creating additional clock ports on the MBX22 cell instance, use the following command: fc_shell>\u00a0 set_freeze_ports -clock [get_cells MBX22] true To report the freeze-port settings, use the  report_freeze_ports command."}
{"header": "How do I Fixing Multiple-Port Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can isolate input and output ports to improve the accuracy of timing models.\n To insert isolation logic at specified input or output ports, use the  set_isolate_ports command.\n Isolation logic can be either a buffer or a pair of inverters; by default, the command places buffers to isolate \u2022 An input port from its fanout networks \u2022 An output port from its driver When you specify the  -force option with the  set_isolate_ports command, the tool ensures that the library cells specified by the  -driver option are not sized.\n Note that the tool does not place isolation logic on the following ports: \u2022 Bidirectional ports \u2022 Ports defined as clock sources or power pins \u2022 Ports connected to nets that are marked with the  dont_touch attribute       Example The following commands insert isolation logic to \u2022 Input port in3 with a buffer \u2022 Output port out1 with a buffer \u2022 Output port out3 with the LIBCELL_BUFF library cell \u2022 Output port out4 with a pair of inverters fc_shell>\u00a0 set_isolate_ports {in3 out1} fc_shell>\u00a0 set_isolate_ports -driver LIBCELL_BUFF out3 -force fc_shell>\u00a0 set_isolate_ports -type inverter out4 The following figures show the design without and with the isolation logic inserted by the set_isolate_ports commands, including buffers and an inverter pair: Q D Q D Q D Without port isolation Q D Q D Q D After running the port isolation commands in1 clk out3 rst in3 in2 out4 out2 out1 out1 out2 out3 out4 in1 clk rst in2 in3 LIBCELL_BUFF"}
{"header": "How do I Controlling the Addition of New Cells to Modules, Hierarchical", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Multiple-port nets include \u2022 Feedthrough nets, where an input port feeds into an output port \u2022 Nets connected to multiple output ports, logically equivalent outputs       Feedthrough net Logically equivalent outputs Multiple-port nets, which are represented with the  assign statement in the gate-level netlist, might cause design rule violations further in the design flow.\n By default, the tool does not fix multiple-port nets during optimization.\n You can enable multiple-port-net fixing for \u2022 The  logic_opto and  initial_drc stages, which are earlier stages of the compile_fusion command, by using the  set_fix_multiple_port_nets command This command sets the  fix_multiple_port_nets attribute on the specified objects.\n \u2022 The  initial_opto and  final_opto stages, which are later stages of the compile_fusion command, by setting the  opt.port.eliminate_verilog_assign application option to  true This application option is  false by default.\n If you want to fix multiple-port nets, use the  set_fix_multiple_port_nets command and fix these issues during the early stages of the  compile_fusion command, when the tool can perform more optimization techniques.\n If you do not explicitly specify a multiple-port-net setting using the  set_fix_multiple_port_nets command, but you set the opt.port.eliminate_verilog_assign application option to  true, the tool issues the following message and uses the  set_fix_multiple_port_nets\u00a0-all -buffer_constants command setting to fix multiple-port nets during the  logic_opto and initial_drc stages of the  compile_fusion command: Information:\u00a0The\u00a0opt.port.eliminate_verilog_assign\u00a0application\u00a0option\u00a0has been set\u00a0to\u00a0true.\n The\u00a0tool\u00a0will\u00a0run\u00a0set_fix_multiple_port_nets\u00a0-all -buffer_constant\u00a0by internally\u00a0enabling\u00a0MPN\u00a0fixing\u00a0due\u00a0to\u00a0the\u00a0absence\u00a0of\u00a0explicit set_fix_multiple_port_nets constraint.\n (MPN-0004) However, if you explicitly specify a multiple-port-net setting using the set_fix_multiple_port_nets command, the tool honors it.\n For example, the following settings enable multiple-port-net fixing for feedthrough nets during the  logic_opto and       initial_drc stages and all nets during the  initial_opto and  final_opto stages of the compile_fusion command: fc_shell>\u00a0 set_fix_multiple_port_nets -feedthroughs fc_shell>\u00a0 set_app_options \\ -name opt.port.eliminate_verilog_assign  -value true The following settings disable multiple-port-net fixing for all nets during the  logic_opto and  initial_drc stages and enables it for all nets during the  initial_opto and final_opto stages of the  compile_fusion command: fc_shell>\u00a0 set_fix_multiple_port_nets -default fc_shell>\u00a0 set_app_options \\ -name opt.port.eliminate_verilog_assign  -value true During multiple-port-net fixing, the tool performs the following tasks in sequence: 1.\n Rewires the connections to ensure that each net is connected to one hierarchical port, if possible.\n The tool first performs rewiring to avoid unnecessary buffering.\n The tool also rewires across the hierarchy because boundary optimization is enabled by default.\n 2.\n Inserts buffers or inverters to the nets that are not fixed by rewiring."}
{"header": "How do I Specifying a Cell Name Prefix for Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To control the addition of new cells to \u2022 Modules or hierarchical cells, use the  set_allow_new_cells command \u2022 Voltage areas, use the  -allow_new_cells option with the create_voltage_area_rule command You can use these settings to prevent new cells from being added to the top-level hierarchies and voltage areas of abutted designs.\n These settings are saved in the design library and honored by the tool throughout the implementation flow.\n The following example prevents new cells from being added to the top-level module: fc_shell>\u00a0 set_allow_new_cells \\ [get_attribute [current_block] top_module] false The following example prevents new cells from being added to the M1 module: fc_shell>\u00a0 set_allow_new_cells [get_modules M1] false       The following example prevents new cells from being added to the U22 hierarchical cell: fc_shell>\u00a0 set_allow_new_cells [get_cells U22] false The following example prevents new cells from being added to the VA1 voltage area: fc_shell>\u00a0 create_voltage_area_rule -name VA1_rule \\ -allow_new_cells false -voltage_areas VA1"}
{"header": "How do I Specifying Settings for Preroute Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify a name prefix for the cells added on the data nets during optimization by using the  opt.common.user_instance_name_prefix application option.\n The following example specifies a name prefix of \u2022 CF_ for the cells added on the data nets during the  compile_fusion command \u2022 CO_ for the cells added on the data nets during the  clock_opt command \u2022 RO_ for the cells added on the data nets during the  route_opt command fc_shell>\u00a0 set_app_options \\ -name opt.common.user_instance_name_prefix -value \"CF_\" fc_shell>\u00a0 compile_fusion  fc_shell>\u00a0 set_app_options \\ -name opt.common.user_instance_name_prefix -value \"CO_\" fc_shell>\u00a0 clock_opt fc_shell>\u00a0 set_app_options \\ -name opt.common.user_instance_name_prefix -value \"PO_\" fc_shell>\u00a0 route_opt To specify a name prefix for the cells added on the clock network during clock tree synthesis, use the  cts.common.user_instance_name_prefix application option, as described in  Defining a Name Prefix for Clock Cells."}
{"header": "How do I Specifying Parasitic Estimation Settings for the Preroute", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Optimizing the design for performance, power, and area (PPA) is one of the primary goals of the tool.\n The following topics describe how to specify settings for performance, power, and area optimization at the preroute stage: \u2022 Specifying Parasitic Estimation Settings for the Preroute Optimization \u2022 Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization \u2022 Assigning Nondefault Routing Rules to Critical Nets       \u2022 Enabling Area Recovery in Regions of High Utilization \u2022 Enabling Advanced Logic Restructuring"}
{"header": "How do I Enabling Global-Route-Layer-Based (GRLB) Preroute", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe how you can control parasitic estimation during the preroute stage of the design flow: \u2022 Enabling Global-Route-Layer-Based (GRLB) Preroute Optimization \u2022 Enabling Route-Driven Estimation (RDE) for Preroute Optimization"}
{"header": "How do I Enabling Route-Driven Estimation (RDE) for Preroute", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve correlation with the postroute stage of the design flow, you can enable global-route-layer-based RC estimation during the  compile_fusion\u00a0  and  clock_opt commands.\n With this feature, the tool uses global routes for all nets and identifies the layers with the most appropriate per-unit resistance values.\n The nets are then constrained to minimum and maximum layers for preroute RC estimation.\n To enable this feature, use the  opt.common.use_route_aware_estimation application option.\n If you set it to \u2022 auto, the feature is enabled only when there is a variation in the per-unit resistance value of the different routing layers \u2022 true, the feature is enabled irrespective of the variation in the per-unit resistance value of the different routing layers If you enable this feature, use the  remove_route_aware_estimation command to remove all global route based estimation before you perform routing."}
{"header": "How do I Specifying Automatic Via Ladder Insertion Settings for Preroute", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve correlation with the postroute stage of the design flow, the tool can perform global routing, perform extraction based on the global routes, and use this parasitic information when performing optimization.\n If the tool detects that the technology used by the design is an advanced technology node that is less than 16 nm, the tool enables this feature by default.\n To enable it for any technology, set the  opt.common.enable_rde application option to  true.\n When enabled, the tool performs route-driven parasitic estimation during the  final_opt stage of the  compile_fusion and  clock_opt commands.\n The parasitic information is       stored in the design library and used during subsequent optimization steps.\n If you enable this feature, you should enable it for all subsequent preroute optimization steps in the design flow.\n During route-driven estimation, the tool honors the capacitance and resistance scaling factors specified with the  -early_cap_scale,  -late_cap_scale,  -early_res_scale, and  -late_res_scale options of the  set_extraction_options command.\n When route-driven estimation is enabled, the tool ignores the setting of the opt.common.use_route_aware_estimation application option, which enables global- route-layer-based (GRLB) RC estimation."}
{"header": "How do I Specifying Via Ladder Candidates for Library Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A via ladder is a stacked via that starts from the pin layer and extends into the upper routing layers.\n Using via ladders during optimization improves the performance and electromigration robustness of a design.\n The tool can automatically insert via ladders for cell pins on timing-critical paths during the  compile_fusion and  clock_opt commands.\n To perform via ladder insertion during preroute optimization, 1.\n Ensure that the via ladder rules are defined as described in  Defining Via Ladder Rules.\n 2.\n Specify the via ladders that can be used for specific library pins by using the set_via_ladder_candidate command, as described in  Specifying Via Ladder Candidates for Library Pins.\n 3.\n (Optional) Enable high-performance and electromigration via ladder insertion for critical paths by setting the  opt.common.enable_via_ladder_insertion application option to  true.\n 4.\n (Optional) Enable the insertion of global-route-based via ladders on pins with via ladder constraints by setting the  route.global.insert_gr_via_ladders application option to  true.\n 5.\n Perform optimization using the  compile_fusion or  clock_opt command."}
{"header": "How do I Assigning Nondefault Routing Rules to Critical Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify the valid via ladders that can be used for a given library pin during preroute optimization, use the  set_via_ladder_candidate command.\n You can specify only one via ladder each time you use the  set_via_ladder_candidate command.\n To specify multiple via ladder candidates for a library pin, use the command multiple times, as shown in the following example: fc_shell>\u00a0 set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP4\"       fc_shell>\u00a0 set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP2\" The order in which you specify multiple via ladders for the same library pin indicates the priority to use when selecting a via ladder to insert for that pin.\n Specify the via ladder candidates starting with the highest priority.\n In the previous example, the tool gives the VP4 via ladder priority over the VP2 via ladder.\n Note: If both the  pattern_must_join attribute and a via ladder candidate apply to a pin, the via ladder has a higher priority than the pattern-based must-join connection when both methods have the same estimated delay.\n To specify that a library pin requires an electromigration via ladder, set the is_em_via_ladder_required pin attribute to  true, as shown in the following example: fc_shell>\u00a0 set_attribute [get_lib_pins lib1/INV4/A] \\ is_em_via_ladder_required true If you set the  is_em_via_ladder_required pin attribute to  true for a specific library pin, you must specify an electromigration via ladder as a candidate with the set_via_ladder_candidate command.\n A via ladder can be identified as an electromigration via ladder by using one of the following methods: \u2022 By using the  forElectromigration=1 construct when defining the via rule in the technology file, as shown in the following example: ViaRule\u00a0\"EMVP1\"\u00a0{...\n...\n...\n forElectromigration=1 } \u2022 By setting the  for_electro_migration attribute to  true, as shown in the following example: fc_shell>\u00a0 set_attribute [get_via_rules EMVP1] \\ for_electro_migration true See Also \u2022 Defining Via Ladder Rules"}
{"header": "How do I Enabling Area Recovery in Regions of High Utilization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve timing QoR, you can enable the tool to automatically assign nondefault routing rules to nets with critical timing.\n When you enable this feature, the tool \u2022 Chooses candidate nets based on slack and length \u2022 Uses timing-driven optimization to assign nondefault routing rules to the nets \u2022 Optimizes buffering for these nets To enable the feature, follow these steps.\n 1.\n Define nondefault routing rules by using the  create_routing_rule command.\n For details, see  Defining Nondefault Routing Rules.\n 2.\n Report routing rules by using the  report_routing_rules command.\n 3.\n Specify a prioritized list of nondefault routing rules for automatic assignment by using the  opt.common.optimize_ndr_user_rule_names application option.\n 4.\n Enable the automatic assignment of nondefault routing rules during optimization by setting the  compile.flow.optimize_ndr application option.\n The following script example creates two nondefault routing rules, ndr_1w2s and ndr_2w3s, and automatically assigns these nondefault routing rules to timing-critical nets during optimization: create_routing_rule\u00a0\"ndr_1w2s\"\u00a0-multiplier_spacing\u00a02 create_routing_rule\u00a0\"ndr_2w3s\"\u00a0-multiplier_spacing\u00a03\u00a0-multiplier_width\u00a02 #\u00a0Enables\u00a0feature,\u00a0defines\u00a0priority set\u00a0opt.common.optimize_ndr_user_rule_names\u00a0{\u00a0ndr_1w2s\u00a0ndr_2w3s\u00a0} set\u00a0compile.flow.optimize_ndr compile_fusion Controlling Nondefault Routing Rule Assignment To specify a critical range for nondefault routing rule for optimization, set the compile.flow.optimize_ndr_critical_range application option to a value between 0 and 1.\n The default is 0.05.\n The specified value  y, as shown in the following example, is used to calculate the slack range [ y *WNS, WNS] where WNS is the worst negative slack.\n Nets in the timing paths that have a slack value within the range are considered for nondefault routing rule assignment.\n fc_shell>\u00a0 set_app_options \\ -name compile.flow.optimize_ndr_critical_range -value  y       To set the maximum number of nets considered for automatic nondefault routing rules assignment, set the  compile.flow.optimize_ndr_max_nets application option to an integer.\n The default is 2000.\n For example, fc_shell>\u00a0 set_app_options \\ -name compile.flow.optimize_ndr_max_nets -value 5000 When both the  compile.flow.optimize_ndr_critical_range and compile.flow.optimize_ndr_max_nets application options are specified, the stricter constraint has priority."}
{"header": "How do I Enabling Advanced Logic Restructuring", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For designs that cannot be legalized due to areas of high utilization, you can specify that the tool perform area recovery in regions where the utilization is high by setting the opt.common.small_region_area_recovery application option to  true.\n When you enable this feature, the tool performs the area recovery during the compile_fusion and  clock_opt commands.\n However, doing so can slightly degrade the timing QoR."}
{"header": "How do I Setting Up for Power-Related Features", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve the area, timing, and power QoR, you can enable advanced logic restructuring.\n To enable this feature for the  final_opto stage of the  compile_fusion and  clock_opt commands, use the  opt.common.advanced_logic_restructuring_mode application option, as shown in the following table.\n Table 15 Settings for the opt.common.advanced_logic_restructuring_mode Application Option To do this Use this setting  none   area  timing  power  area_timing  timing_power  area_power  area_timing_power       When restructuring, the tool does not \u2022 Restructure across logical hierarchy \u2022 Consider cells with  dont_touch,  size_only, or  fixed attributes \u2022 Accept the results if it increases the wire length However, if your design does not have congestion or routing issues, you can specify that the tool accepts the restructuring results even if it increases the wire length by setting the  opt.common.advanced_logic_restructuring_wirelength_costing application option to  medium or  none.\n The default is  high."}
{"header": "How do I Annotating the Switching Activity", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe the tasks you need to perform for setting up a design for power-related features: \u2022 Annotating the Switching Activity \u2022 Enabling Leakage Power Optimization for the compile_fusion Command \u2022 Enabling Power Optimization for the clock_opt Command \u2022 Improving Yield By Limiting the Percentage of Low-Threshold-Voltage (LVT) Cells \u2022 Updating Activity for Improved Power Optimization \u2022 Enabling the Power Integrity Features"}
{"header": "How do I Using RTL Switching Activity With a Name-Mapping File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When performing low-power placement and dynamic-power optimization, you obtain better power savings if you annotate switching activity on the design.\n You can annotate the switching activity in the following ways: \u2022 Read a switching activity file (SAIF) by using the  read_saif command.\n The switching activity is scenario specific.\n So, when you use this command, ensure that the current scenario is enabled for dynamic power optimization.\n \u2022 Set the switching activity by using the  set_switching_activity command.\n When you use this command, you can set the switching activity for a specific mode, corner, or scenario by using the  -mode,  -corner, or  -scenario options.\n When doing so, ensure that the scenarios you specify or the scenarios corresponding to the modes and corners you specify are enabled for dynamic power optimization.\n       If you do not specify the switching activity, the tool applies the default toggle rate to the primary inputs and black box outputs and then propagates it throughout the design.\n To report the switching activity of a block, use the  report_activity command.\n To remove switching activity of specific nets, pins, ports, or the entire block, use the reset_switching_activity command."}
{"header": "How do I Scaling the Switching Activity", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To use an RTL SAIF file in the Fusion Compiler tool, use the following steps: 1.\n After reading and elaborating the design, use the  saif_map\u00a0-start command, which creates a name-mapping database during synthesis that the tool then uses for power analysis and optimizaiton.\n 2.\n (Optional) Manually change the name mapping as described in  Controlling the Name Mapping.\n 3.\n Read in the same RTL SAIF file by using the  read_saif command.\n Reading an RTL SAIF file does not affect the name-mapping database.\n 4.\n Perform optimization and other design changes.\n 5.\n Generate a binary name-mapping file that maps RTL object names to gate-level objects by using the  saif_map\u00a0-write_map command, which is needed if you want to continue the flow using ASCII files in a later Fusion Compiler session.\n In the subsequent session, use the  saif_map\u00a0-read_map command to read the saved file and begin tracking further changes to object names.\n 6.\n (Optional) Generate an ASCII name-mapping file for use with the PrimePower tool by using the  saif_map\u00a0-write_map\u00a0-type\u00a0primepower\u00a0-essential command.\n Controlling the Name Mapping In the SAIF-map flow, the name-mapping database tracks the changes to pin, port, cell, and net names that occur during optimization.\n It contains the original name for each object, so that the original SAIF can be applied even after optimization.\n You can manually control the name mapping in the database by using the  saif_map command as shown in the following table.\n Table 16 Options for Manually Controlling the Name Mapping To do this Use this option of the saif_map command   -set_name       Table 16 Options for Manually Controlling the Name Mapping (Continued) To do this Use this option of the saif_map command   -add_name -set_name  -add_name  -inverted -set_name  -add_name   -change_name  -report  -remove_name   -reset  -get_saif_names -get_object_names"}
{"header": "How do I Specifying Switching Probability for Supply Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If the clock frequency used in the SAIF file is different from the clock frequency used in the Fusion Compiler tool, you can scale the switching activity by performing the following steps: 1.\n Read in the SAIF file by using the  read_saif command.\n 2.\n Enable scaling by setting the  power.use_generated_clock_scaling_factor application option to  on.\n 3.\n Scale the switching activity by using the  set_power_clock_scaling command.\n When you use this command, you must specify the following: \u25e6 The clock objects associated with the switching activity you want to scale \u25e6 The clock period used in the SAIF file by using the  -period option or the ratio between the clock period used in the SAIF file and the clock period used in the Fusion Compiler tool by using the  -ratio option In addition, you can specify the scenario for which to apply the scaling by using the -scenario option.\n       The following example reads in a SAIF file, enables scaling, scales the switching activity associated with clocks named CLK1 and CLK2 by a ratio of five, and scales the switching activity associated with clock named CLK3 by a ratio of two: fc_shell>\u00a0 read_saif top.saif fc_shell>\u00a0 set_app_options -list \\ {power.use_generated_clock_scaling_factor true} fc_shell>\u00a0 set_power_clock_scaling -ratio 5 {CLK1 CLK2} fc_shell>\u00a0 set_power_clock_scaling -ratio 2 {CLK3} If you run the  set_power_clock_scaling command again for the same clock, the tool scales the already scaled switching activity.\n When you use the  set_power_clock_scaling command, the tool scales only the switching activity applied with the  read_saif command.\n The tool does not scale the following: \u2022 Switching activity applied with the  set_switching_activity command \u2022 Switching activity within block abstracts The scaled switching activity is persistent in the design.\n You can write it out by using the write_saif command and use it in the subsequent steps of the design flow."}
{"header": "How do I Enabling Leakage Power Optimization for the compile_fusion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The leakage power of a block is scaled based on the switching probability of its supply nets, which represents the fraction of time a supply net is in the  on  state.\n You can specify the switching probability for one or more supply nets by using the set_supply_net_probability\u00a0-static_probability command.\n By default, the switching probability is applied to the current scenario and the corresponding mode and corner.\n To specify modes, corners, or scenarios in which to apply the setting, use the -modes,  -corners, or  -scenarios option.\n To get the switching probability of a supply net, use the  get_supply_net_probability command, and to reset the value, use the reset_supply_net_probability command.\n By default, the tool propagates supply net activity through power switches and determines the static probability of the switched supply net based on the UPF power switch constraint.\n For example, consider the following UPF power switch constraint: create_power_switch\u00a0my_switch\u00a0\\ -output_supply_port\u00a0{vout\u00a0VDDS}\u00a0\\ -input_supply_port\u00a0{vin\u00a0VDD}\u00a0\\ -control_port\u00a0{ms_sel\u00a0ctrl1}\u00a0\\ -control_port\u00a0{ms_ctrl\u00a0ctrl2}\u00a0\\ -on_state\u00a0{on\u00a0vin\u00a0{ms_ctrl\u00a0&&\u00a0!ms_sel}}       The tool derives the static probability of the supply net named VDDS, which is connected to the output of the power switch, based on the probability of the power switch being  on.\n This is derived based on the following: \u2022 The Boolean function specified with the  -on_state option, which is ms_ctrl &&!\n ms_sel, and the switching activity (static probability) of the nets connected to the corresponding control ports, which are nets named ctrl1 and ctrl2.\n \u2022 The switching probability of the supply net connected to the input supply port specified with the  -on_state option, which is the supply net named VDD.\n The following application options control whether dynamic and leakage power are scaled based on the supply switching activity: \u2022 The  power.scale_dynamic_power_at_power_off option controls whether dynamic power is scaled.\n The default is  false (no scaling).\n \u2022 The  power.scale_leakage_power_at_power_off option controls whether leakage power is scaled.\n The default is  true (scaling is performed)."}
{"header": "How do I Reporting Leakage Power", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool performs leakage power optimization during compile.\n To produce optimal leakage power optimization, use libraries with multithreshold voltage group cells.\n To set up leakage optimization, 1.\n Enable at least one scenario for leakage power by using the  set_scenario_status -leakage_power\u00a0true command.\n For example, fc_shell>\u00a0 set_scenario_status -leakage_power true SC1 If the block has multiple scenarios enabled for leakage power, the tool uses the worst- case leakage value of all the specified scenarios.\n 2.\n Set the  threshold_voltage_group attribute on the reference library cells.\n For example, fc_shell>\u00a0 set_attribute [get_lib_cells -quiet lib1_name/*] \\ threshold_voltage_group HVT 3.\n Set the  threshold_voltage_group attribute to one of the three built-in threshold voltage group types: high, normal, or low threshold voltage.\n       If there are more than three threshold-voltage groups, you should group them into the three voltage group types as follows: fc_shell>\u00a0 set_threshold_voltage_group_type \\ -type high_vt {HVT HVTX} fc_shell>\u00a0 set_threshold_voltage_group_type \\ -type low_vt {LVT LVTX} fc_shell>\u00a0 set_threshold_voltage_group_type \\ -type normal_vt {RVT RVTX}"}
{"header": "How do I Enabling Power Optimization for the clock_opt Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To check your leakage power, use the  report_power command.\n By default, state- dependent leakage power is used to calculate leakage power.\n To change the leakage power calculation mode, set the  power.leakage_mode application option.\n For example, to set the application option to  average do the following: fc_shell>\u00a0 set_app_options -name power.leakage_mode -value average To report threshold voltage usage, use the  report_threshold_voltage_groups command.\n Classification is based on the  threshold_voltage_group attribute from the reference library cells or the  default_threshold_voltage_group attribute on the library.\n You can also set the attributes on the objects by using the  set_attribute command.\n You can generate several types of reports with the  report_threshold_voltage_groups command.\n For example, the summary report (using the  -summary option) lists the number, area, and percentage of cells in each threshold voltage group.\n The default report (without using any options) shows the cell count and area based on the following groups: repeater, combinational, register, sequential, clock network, and physical-only cells.\n For the repeater, register, and clock network cell groups, you can obtain additional information by using the  -detailed option.\n The  -hierarchy option of the  report_threshold_voltage_groups command generates a report based on the design hierarchy.\n The report shows the cell count, area, and area ratio for a top-level block and its subblocks.\n The  -hierarchy option is mutually exclusive with the other report types, but can be used with the  -datapath_cells_only and  -standard_cells_only options.\n You can restrict the hierarchy-based report to specific threshold voltage groups by using the  -hier_vt_groups option.\n You can also specify to report only the top-level cells that contain more than a specified number of constituent cells by using the  -hier_threshold option.\n These options must be used with the  -hierarchy option.\n If you specify a cell list, a separate report is created for each top-level cell in the list."}
{"header": "How do I Performing Conventional Leakage-Power Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can optimize both dynamic and static (leakage) power.\n \u2022 Dynamic power This is the energy dissipated due to the voltage or logic transitions in the design objects, such as cells, pins, and nets.\n The dynamic power consumption is directly proportional to the number and frequency of transitions in the design.\n \u2022 Static (leakage) power This is the energy dissipated even when there are no transitions in the circuit.\n This is also known as leakage power and depends on the device characteristics.\n The main contributor to leakage power is the sub-threshold-voltage leakage in the device.\n At lower technology nodes, leakage power consumption contributes significantly to the total power consumption of the circuit.\n The following topics describe how to enable the different types of power optimization the tool performs: \u2022 Performing Conventional Leakage-Power Optimization \u2022 Performing Dynamic-Power Optimization \u2022 Performing Total-Power Optimization"}
{"header": "How do I Performing Dynamic-Power Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set up for conventional leakage-power optimization during the preroute optimization stage, perform the following: 1.\n Ensure that at least one scenario is enabled for leakage-power optimization by using the  set_scenario_status\u00a0-leakage_power\u00a0true command and the set_qor_strategy\u00a0-metric\u00a0leakage_power\u00a0|\u00a0total_power command for deciding the target of power flow.\n 2.\n (Optional) Change the effort level for power optimization by setting the set_qor_strategy\u00a0-mode command to  balanced or  extreme_power.\n The default is balanced.\n This effort control for the power flow.\n When you use these settings, the tool performs conventional leakage-power optimization during the  clock_opt command.\n However, it does not perform any dynamic-power optimization."}
{"header": "How do I Performing Total-Power Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set up for dynamic-power optimization during the preroute optimization stage, perform the following: 1.\n Annotate switching activity on the design, as described in  Annotating the Switching Activity.\n 2.\n Ensure that at least one scenario is enabled for dynamic-power optimization by using the  set_scenario_status\u00a0-dynamic_power\u00a0true command.\n When you use these settings, the tool performs dynamic-power optimization during the clock_opt command.\n However, it does not perform any leakage-power optimization."}
{"header": "How do I Improving Yield By Limiting the Percentage of", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Total power optimization considers the combined leakage- and dynamic-power cost during optimization.\n To setup for total-power optimization, 1.\n Setup for leakage-power optimization by performing the following steps: a.\n Ensure that at least one scenario is enabled for leakage-power optimization by using the  set_scenario_status\u00a0-leakage_power\u00a0true command.\n 2.\n Setup for dynamic-power optimization by performing the following steps: a.\n Annotate switching activity on the design, as described in  Annotating the Switching Activity.\n b.\n Ensure that at least one scenario is enabled for dynamic-power optimization by using the  set_scenario_status\u00a0-dynamic_power\u00a0true command.\n When you use this setting, the tool performs total-power optimization during the clock_opt command."}
{"header": "How do I Updating Activity for Improved Power Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can perform percentage-LVT-based optimization.\n By limiting the percentage of LVT cells in a block, you can improve yield of your design.\n You can also use this feature during the early design phases to get an idea of the quality of the RTL.\n To set up for percentage-LVT-based optimization, 1.\n Specify the LVT library cell group as shown in the following example: fc_shell>\u00a0 remove_attributes -quiet  \\ [get_lib_cells -quiet */*] threshold_voltage_group fc_shell>\u00a0 set_attribute [get_lib_cells -quiet *lvt*/*] \\ threshold_voltage_group LVT       fc_shell>\u00a0 set_threshold_voltage_group_type \\ -type low_vt LVT Ensure that the LVT library cells you specify \u25e6 Have a valid purpose defined by using the  set_lib_cell_purpose command and are included in the appropriate target-library subsets defined by using the set_target_library_subset command \u25e6 Do not have a  dont_touch or  dont_use attribute setting 2.\n Specify the percentage limit for LVT cells by using the  set_multi_vth_constraint -low_vt_percentage command.\n To specify the limit as a percentage of the \u25e6 Cell count, use the  -cost\u00a0cell_count option \u25e6 Cell area, use the  -cost\u00a0area option To reset this constraint, use the  reset_multi_vth_constraint command, and to report it, use the  report_multi_vth_constraint command.\n After you set up percentage-LVT-based optimization, when you run the  compile_fusion, clock_opt, or  route_opt command, the tool uses the specified LVT cell percentage constraint for the data path cells in the block.\n However, to minimize QoR disturbance, the tool limits the percentage-LVT-based optimization performed during the  route_opt command.\n Therefore, it is important to enable this feature earlier in the design flow.\n Note: LVT cells have a smaller cell delay, but higher leakage power dissipation.\n Therefore, limiting the number of LVT cells reduces leakage-power dissipation.\n However, to further reduce leakage power, enable leakage power optimization for the different stages of the design flow."}
{"header": "How do I Enabling the Power Integrity Features", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The PrimePower In-Design flow in the Fusion Compiler tool uses input waveform information from the RTL FSDB file and performs time-based analysis to update the activity for enhanced power estimation accuracy.\n  Figure\u00a026 shows the PrimePower in- design flow in the Fusion Compiler tool, indicating points in the flow where you can run the PrimePower tool.\n For the best correlation with standalone PrimePower time-based analysis results, run the PrimePower tool after the  route_opt command.\n       Figure 26 The PrimePower In-Design Flow Use the  set_indesign_primepower_options command to set PrimePower analysis options for the In-Design flow.\n You must specify the RTL activity file with the  -fsdb option and the path to the PrimePower executable with the  -pwr_shell option.\n Other options allow you to specify details about the FSDB file, settings for distributed or concurrent processing, settings for scenarios and libraries, and output files.\n Use the  update_indesign_activity command to perform the analysis, which includes the following tasks: \u2022 Invokes the PrimePower tool and reads the design data which includes the netlist, libraries, PVT settings, constraints, parasitics, essential name mapping data, UPF, and so on.\n Library details come from the design database stored in the Fusion Compiler tool memory.\n \u2022 Reads the RTL FSDB file into the PrimePower tool and performs time-based analysis to generate a gate-level SAIF.\n \u2022 Reads the gate-level SAIF back into the Fusion Compiler tool.\n Set the power scenario as the current scenario before starting analysis with the update_indesign_activity command.\n Activity is refreshed for the current scenario.\n If you specify multiple scenarios using the  -scenarios option of the set_indesign_primepower_options command, the refreshed gate-level SAIF from the PrimePower tool is read back into the Fusion Compiler tool for all of the specified scenarios.\n       The PrimePower In-Design UI allows you to pass input waveforms using the native ZeBu database (ZTDB).\n The  -ztdb option of the  set_indesign_primepower_options command sets up PrimePower In-Design to create a script using the update_indesign_activity command.\n This script uses the PrimePower  read_ztdb command to perform time-based analysis and issues a gate-level SAIF file that is automatically back-annotated into the Fusion Compiler tool.\n Specifying Distributed Analysis For faster runtime, use distributed analysis, which is disabled by default in the PrimePower tool.\n To enable distributed analysis in the PrimePower tool, specify the following options with the  set_indesign_primepower_options command: \u2022 -num_processes : Use this option to specify the number of hosts to launch.\n The value must be greater than 1.\n \u2022 -submit_command or  -host_names : Use either of these options to specify the configuration of host machines.\n \u2022 -max_cores : Use this option to specify the maximum number of cores.\n The default is 4.\n The tool prints the following message if valid options are specified: Information:\u00a0PrimePower\u00a0is\u00a0being\u00a0called\u00a0in\u00a0distributed\u00a0mode"}
{"header": "How do I Setting Up for Dynamic Power Shaping", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides the following techniques for ensuring power integrity of the design: \u2022 Dynamic power shaping (DPS), which reduces transient power by utilizing concurrent clock and data optimization (useful skew) techniques.\n \u2022 Voltage-drop-aware placement, which use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values to reduce the power density of such areas.\n       To set up for the recommended power integrity flow, perform the following steps: 1.\n Enable the power integrity flow by setting the  opt.common.power_integrity application option to  true.\n When you do so, the Fusion Compiler uses the following techniques during the different stages of the design flow: a.\n Dynamic power shaping (DPS) during the  final_opto stage of the compile_fusion command b.\n Voltage-drop-aware placement during the  clock_opt command 2.\n (Optional) Specify that the tool should not reduce the voltage drop at the expense of the timing QoR by reducing the power integrity effort level by setting the opt.common.power_integrity_effort application option to  low.\n The default is  high, and by default the tool tries to reduce the voltage drop to less than eight percent of the supply voltage at the expense of the timing QoR.\n 3.\n (Optional) Specify a maximum voltage drop threshold by using the opt.common.ir_drop_threshold application option.\n The default is eight percent of the supply voltage.\n If you change the default effort level by setting the  opt.common.power.integrity_effort application option to  low, the tool ignores the threshold specified with the  opt.common.ir_drop_threshold application option.\n 4.\n Specify settings for dynamic power shaping as described in  Setting Up for Dynamic Power Shaping.\n 5.\n Specify settings for voltage-drop-aware placement as described in  Setting Up for Voltage-Drop-Aware Placement.\n 6.\n (Optional) Enable IR-driven sizing, which uses the RedHawk dynamic voltage drop analysis results to identify cells involved in voltage drop violations, and then tries to replace those cells with cells having smaller leakage current.\n To enable this feature, set the  clock_opt.flow.enable_irdrivenopt application option to  true, in addition to setting the  opt.common.power_integrity application option to  true.\n Instead of using the recommended power integrity flow setting, you can manually enable dynamic power shaping or voltage-drop-aware placement for the  compile_fusion or clock_opt commands as described in  Manually Enabling Dynamic Power Shaping and Voltage-Drop-Aware Placement"}
{"header": "How do I Setting Up for Voltage-Drop-Aware Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set up for dynamic power shaping, perform the following steps: 1.\n Ensure UPF settings are specified for multiple-power nets.\n 2.\n Ensure both setup and hold scenarios are created and are active.\n 3.\n (Optional) Control the power analysis and optimization performed during dynamic power shaping as follows: \u25e6 Specify the scenarios to focus on by setting the  ccd.dps.focus_power_scenario application option.\n By default, the tool focuses on all active scenarios.\n When the design has many active scenarios, specifying one or two scenarios, as shown in this example, can reduce the runtime.\n fc_shell>\u00a0 set_app_options -name \\ -name ccd.dps.focus_power_scenario -value {{S1 S2}} \u25e6 Control the type of internal power analysis performed by setting the ccd.dps.use_case_type application option.\n By default, this application option is set to  autovector.\n With this setting, the tool runs internal power analysis with a 20 percent probability of toggling a flip-flop and all flip-flops are effectively clocked every cycle.\n However, the clock gating is not modeled.\n If you set this application option to  activity, the tool chooses probability of toggling a flip-flop and the clock-gating model based on the activity.\n \u25e6 Define the overall dynamic power optimization goal by setting the ccd.dps.optimize_power_target_modes application option.\n \u25aa To reduce the global peak current, where the optimization goal is to reduce the total peak current, set this application option to  global_peak.\n \u25aa To reduce the local peak current in windows stepped across the design, where the optimization goal is to reduce voltage drop violations, set this application option to  stepped_psgs, which is the default.\n \u25e6 Specify the tradeoff between power and setup timing during dynamic power shaping by setting the  ccd.dps.optimize_setup_tradeoff_level application option to low,  medium (default), or  high.\n \u25e6 Specify the tradeoff between power and hold timing during dynamic power shaping by setting the  ccd.dps.optimize_hold_tradeoff_level application option to low,  medium (default), or  high.\n       You can further control the power analysis and optimization performed during dynamic power shaping by using application options such as  ccd.dps.use_cases, ccd.dps.auto_targets, and  ccd.dps.auto_target_constraint_parameters, which are more complex to use.\n For more information on these application options, see the corresponding man pages."}
{"header": "How do I Manually Enabling Dynamic Power Shaping and", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set up for voltage-drop-aware placement, perform the following steps: 1.\n Specify the voltage-drop-analysis type by using the  rail.analysis_type application option.\n The valid values are  static,  dynamic (default),  dynamic_vcd, and dynamic_vectorless.\n 2.\n Specify settings required to perform RedHawk voltage drop analysis, as described in Performing Voltage Drop Analysis."}
{"header": "How do I Specifying the Routing Resources", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To manually enable \u2022 Dynamic power shaping for the  compile_fusion command, use the following settings: fc_shell>\u00a0 set_app_option  -name opt.common.power_integrity \\ -value false fc_shell>\u00a0 set_app_option  -name compile.flow.enable_dps \\ -value true \u2022 Voltage-drop-aware placement for the  compile_fusion command, use the following settings: fc_shell>\u00a0 set_app_option  -name opt.common.power_integrity \\ -value false fc_shell>\u00a0 set_app_option  -name compile.flow.enable_irap \\ -value true \u2022 Voltage-drop-aware placement for the  clock_opt command, use the following settings: fc_shell>\u00a0 set_app_option  -name opt.common.power_integrity \\ -value false fc_shell>\u00a0 set_app_option  -name clock_opt.flow.enable_irap \\ -value true"}
{"header": "How do I Specifying the Global Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify the minimum and maximum routing layers both for the block (global layer constraints), for specific nets (net-specific layer constraints), and for unsynthesized clock nets (clock-tree layer constraints).\n If you specify both global layer constraints and net- specific layer constraints, the net-specific constraints override the global constraints.\n In addition to constraining the routing layers, you can also specify a preferred routing direction for each layer.\n The routing layer constraints are used by RC estimation, congestion analysis, and routing.\n Because these constraints affect RC estimation and congestion analysis as well as routing, you should set these constraints before performing placement on the block.\n The following topics describe how to specify routing layer constraints, preferred routing direction, and via ladders : \u2022 Specifying the Global Layer Constraints \u2022 Specifying Net-Specific Layer Constraints \u2022 Specifying Clock-Tree Layer Constraints \u2022 Enabling Level-Based Clock Nondefault Routing Rule \u2022 Setting the Preferred Routing Direction for Layers"}
{"header": "How do I Reporting Global Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify the global layer constraints, use the  set_ignored_layers command.\n By default, the global layer constraints are used for RC estimation, congestion analysis, and as soft constraints for routing.\n Use the following options to set the constraints and change the default behavior.\n \u2022 To specify the minimum and maximum routing layers, use the  -min_routing_layer and  -max_routing_layer options.\n Specify the routing layers by using the layer names from the technology file.\n For example, to use layers M2 through M7 for routing, RC estimation, and congestion analysis, use the following command: fc_shell>\u00a0 set_ignored_layers \\ -min_routing_layer M2 -max_routing_layer M7 \u2022 To allow the use of layers beyond the minimum or maximum routing layer only for pin connections, set the  route.common.global_min_layer_mode and  route.common.global_max_layer_mode application options to allow_pin_connection.\n       \u2022 To change the constraints to hard constraints, set the  route.common.global_min_layer_mode and route.common.global_max_layer_mode application options to  hard.\n \u2022 To specify additional layers to be ignored for RC estimation and congestion analysis, use the  -rc_congestion_ignored_layers option.\n The specified layers must be between the minimum and maximum routing layers.\n For example, to use layers M2 through M7 for routing and layers M3 through M7 for RC estimation and congestion analysis, use the following command: fc_shell>\u00a0 set_ignored_layers \\ -min_routing_layer M2 -max_routing_layer M7 \\ -rc_congestion_ignored_layers {M2} \u2022 To change an existing layer constraint setting, simply reset that option.\n When you reset an option, it overrides the existing value of only that option; the other option settings remain unchanged.\n For example, assume that you used the previous command to set the minimum routing layer to M2 and the maximum routing layer to M7.\n To change the maximum routing layer from M7 to M8, but keep the other settings, use the following command: fc_shell>\u00a0 set_ignored_layers -max_routing_layer M8"}
{"header": "How do I Removing Global Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the ignored layers, use the  report_ignored_layers command.\n For example, fc_shell>\u00a0 report_ignored_layers **************************************** Report\u00a0:\u00a0Ignored\u00a0Layers Design\u00a0:\u00a0my_design Version:\u00a0J-2014.12 Date\u00a0\u00a0\u00a0:\u00a0Wed\u00a0Oct\u00a022\u00a015:58:23\u00a02014 **************************************** Layer\u00a0Attribute\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Value ----------------------------------------------------------------------- Min\u00a0Routing\u00a0Layer\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0M2 Max\u00a0Routing\u00a0Layer\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0M7 RC\u00a0Estimation\u00a0Ignored\u00a0Layers\u00a0\u00a0\u00a0\u00a0PO\u00a0M1\u00a0M2\u00a0M8\u00a0M9\u00a0MRDL 1"}
{"header": "How do I Specifying Net-Specific Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove the global layer constraints, use the  remove_ignored_layers command.\n You must specify one or more of the following options: \u2022 -min_routing_layer This option removes the minimum routing layer setting.\n When you remove the minimum routing layer setting, it also removes the ignored layers for RC estimation and congestion analysis that are below the minimum routing layer.\n \u2022 -max_routing_layer This option removes the maximum routing layer setting.\n When you remove the maximum routing layer setting, it also removes the ignored layers for RC estimation and congestion analysis that are above the maximum routing layer.\n \u2022 -all This option removes the ignored layers for RC estimation and congestion analysis that are between the minimum and maximum routing layers.\n \u2022 -rc_congestion_ignored_layers\u00a0 layer_list This option removes the specified ignored layers for RC estimation and congestion analysis.\n The specified layers must be between the minimum and maximum routing layers."}
{"header": "How do I Removing Net-Specific Routing Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify net-specific layer constraints, use the  set_routing_rule command.\n To specify the minimum and maximum routing layers, use the  -min_routing_layer and -max_routing_layer options.\n Specify the routing layers by using the layer names from the technology file.\n For example, to use layers M2 through M7 when routing the n1 net, use the following command: fc_shell>\u00a0 set_routing_rule [get_nets n1] \\ -min_routing_layer M2 -max_routing_layer M7       By default, net-specific minimum layer constraints are soft constraints, while net-specific maximum layer constraints are hard constraints.\n You can change the default behavior as follows: \u2022 To change the default constraint strength for all net-specific layer constraints, set the route.common.net_min_layer_mode and  route.common.net_max_layer_mode application options.\n Set these application options to  soft to specify a soft constraint, allow_pin_connection to allow the use of lower layers only for pin connections, or hard to specify a hard constraint.\n \u2022 To change the constraint strength for a single net-specific layer constraint, use the -min_layer_mode and  -max_layer_mode options when you define the constraint with the  set_routing_rule command.\n Set these options to  soft to specify a soft constraint,  allow_pin_connection to allow the use of lower layers only for pin connections, or  hard to specify a hard constraint.\n \u2022 To set the cost of violating soft constraints for all net-specific layer constraints, set the  route.common.net_min_layer_mode_soft_cost and route.common.net_max_layer_mode_soft_cost application options.\n Set these application options to  low,  medium (the default), or  high.\n The cost setting controls the effort expended by the router to avoid violations.\n The  high setting can reduce violations at a cost of increased runtime.\n The  low setting can reduce runtime at a cost of increased violations.\n \u2022 To set the cost of violating soft constraints for a single net-specific layer constraint, use the  -min_layer_mode_soft_cost and  -max_layer_mode_soft_cost options when you define the constraint with the  set_routing_rule command.\n Set these options to  low,  medium (the default), or  high.\n The cost setting controls the effort expended by the router to avoid violations.\n The  high setting can reduce violations at a cost of increased runtime.\n The  low setting can reduce runtime at a cost of increased violations."}
{"header": "How do I Specifying Clock-Tree Layer Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove net-specific routing layer constraints, use the  set_routing_rule\u00a0-clear command.\n Note that when you use this command, it also removes any nondefault routing rules assigned to the specified nets."}
{"header": "How do I Enabling Level-Based Clock Nondefault Routing Rule", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify clock-tree layer constraints, use the  set_clock_routing_rules command.\n To specify the minimum and maximum routing layers, use the  -min_routing_layer and       -max_routing_layer options.\n Specify the routing layers by using the layer names from the technology file.\n By default, the  set_clock_routing_rules command assigns the specified layer constraints to all clock trees.\n  Table\u00a017  shows the options used to restrict the layer constraints.\n Table 17 Restricting Clock-Tree Layer Constraints To assign a layer constraint to Use this option  -clocks\u00a0 clocks 1 -net_type\u00a0root 1 -net_type\u00a0sink  1 -net_type\u00a0internal  -nets\u00a0 nets Figure\u00a027 shows the root, internal, and sink nets of a clock tree after clock tree synthesis.\n By default, the root-net layer constraints are applied to all the single-fanout clock nets starting from the clock root up to the point where the clock tree branches out to a fanout of more than one.\n Internal-net layer constraints are applied to the nets from this point until the sink nets.\n Figure 27 Root, Internal, and Sink Clock Net Types 1.\n You can use this option with the  -clocks option to further restrict the assignment.\n This option is not valid with the -nets option.\n       For example, to use layers M4 through M7 when routing the root nets of the CLK1 clock, use the following command: fc_shell>\u00a0 set_clock_routing_rules -clocks CLK1 -net_type root \\ -min_routing_layer M4 -max_routing_layer M7 To specify a transitive fanout limit to use when identifying root nets, use the set_clock_tree_options\u00a0-root_ndr_fanout_limit command.\n For example, to specify that any clock net with a transitive fanout of more than 300 sinks be considered as a root net, use the following command: fc_shell>\u00a0 set_clock_tree_options -root_ndr_fanout_limit 300 Figure\u00a028 shows the root, internal, and sink nets of the same clock tree when a transitive fanout limit of 300 is specified for identifying the clock root nets.\n Figure 28 Using a Fanout Limit for Selecting Root Nets When calculating the transitive fanout of clock nets for the purpose of identifying root nets, the tool includes only the valid clock sinks; It does not include the ignore pins.\n If a net identified as a root net is less than 10 microns, the tool uses internal-net layer constraints for that net.\n Note: Specifying a smaller value with the  set_clock_tree_options -root_ndr_fanout_limit command increases the number of clock nets that are assigned the root-net layer constraints, which can increase routing congestion.\n To remove the transitive fanout limit specified with the  set_clock_tree_options -root_ndr_fanout_limit command, use the  remove_clock_tree_options -root_ndr_fanout_limit command."}
{"header": "How do I Setting the Preferred Routing Direction for Layers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During clock tree synthesis, you can assign continuous nondefault routing rule to nets based on different levels of the clock tree.\n The tool implements the changes only during the initial clock tree synthesis and assigns nondefault routing rule in the following ways: \u2022 Nets connected to pure sink carry sink nondefault routing rule \u2022 Nets connected to both sink and intermediate cells (repeaters or clock gates) must receive internal nondefault routing rule \u2022 Nets at root level until the branching point downstream must get root nondefault routing rule Figure 29 Level-Based Clock Nondefault Routing Rule       As shown in the figure, after clock tree synthesis: \u2022 Without the level-based clock nondefault routing rule: The n1 and n3 nets must get sink nondefault routing rule after compiling the clock tree because they are connected to at least one sink.\n These nets leave the discontinuous nondefault routing rules applied at different levels.\n \u2022 With the level-based clock nondefault routing rule: All the nondefault routing rules in a clock tree path must be in a topologically sorted order from clock root to sinks, that is, Root nondefault routing rule > Internal nondefault routing rule > Sink nondefault routing rule.\n Therefore, n1 and n2 nets are assigned with internal nondefault routing rule while net n3 is assigned to a sink nondefault routing rule.\n To enable the level-based clock nondefault routing rule application, use the following application option: fc_shell>\u00a0 set_app_options -list {cts.compile.topological_ndr true}"}
{"header": "How do I Handling Design Data Using the Early Data Check Manager", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool requires that the preferred routing direction is specified for the routing layers defined in the technology file.\n Typically this information is defined in the cell library.\n To set or change the preferred routing direction for a layer, use the following syntax to set its  routing_direction attribute: set_attribute\u00a0-objects\u00a0 layers -name\u00a0routing_direction -value\u00a0vertical\u00a0|\u00a0horizontal Specify the routing layers by using the layer names from the technology file.\n The layer direction set with this attribute applies only to the current block.\n For example, to set the preferred routing direction to vertical for the M5 and M7 layers, use the following command: fc_shell>\u00a0 set_attribute -objects [get_layers {M5 M7}] \\ -name routing_direction -value vertical Note: Settings made with the  create_routing_guide -switch_preferred_direction command, which changes the preferred direction within the area that is covered by the routing guide, override the routing_direction attribute settings.\n To report the user-defined preferred routing direction for one or more routing layers, use the  get_attribute command.\n To remove the user-defined preferred routing direction for one or more routing layers, use the  remove_attributes command.\n       See Also \u2022 Preparing Routing Layers"}
{"header": "How do I Applying Mega-Switch Command Settings", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the early iterations of a design cycles, the design data might be incomplete or incorrect.\n This can prevent you from implementing the design for exploration purposes and so on.\n The Fusion Compiler Early Data Check Manager allows you to specify how the tool should handle the data checks it performs during the following implementation tasks: \u2022 Design planning \u2022 Multivoltage design implementation \u2022 Optimization \u2022 Placement \u2022 Legalization \u2022 Hierarchical implementation of designs with physical hierarchy The following table shows the Early Data Check Manager commands available for controlling how the tool handles the data checks and for generating related information.\n Table 18 Early Data Check Manager Commands To do this Use this command  set_early_data_check_policy  report_early_data_checks   get_early_data_check_records  write_early_data_check_config   remove_early_data_check_records You should specify the policies for handling the data checks before you begin implementation.\n The following example specifies that the tool should be strict when checking for the SCANDEF information.\n Therefore, the tool does not proceed with the  create_placement command because the SCANDEF information is missing.\n       fc_shell>\u00a0 set_early_data_check_policy -policy strict \\ -check place.coarse.missing_scan_def fc_shell>\u00a0 create_placement Information:\u00a0Policy\u00a0for\u00a0early\u00a0data\u00a0check\u00a0'place.coarse.missing_scan_def' is\u00a0'error'.\n (EDC-001) Error:\u00a0No\u00a0valid\u00a0scan\u00a0def\u00a0found.\n (PLACE-042) Information:\u00a0Ending\u00a0'create_placement'\u00a0(FLW-8001) fc_shell>\u00a0 report_early_data_checks -check place.coarse.missing_scan_def Check\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Policy\u00a0\u00a0Strategy\u00a0\u00a0Fail\u00a0Count ------------------------------------------------------------- place.coarse.missing_scan_def\u00a0\u00a0\u00a0error\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 ------------------------------------------------------------- The following example specifies that the tool should be lenient with regards to all data checks related to coarse placement.\n Therefore, the tool proceeds with the create_placement command without the SCANDEF information.\n fc_shell>\u00a0 set_early_data_check_policy -policy lenient \\ -check place.coarse.* fc_shell>\u00a0 create_placement Information:\u00a0Policy\u00a0for\u00a0early\u00a0data\u00a0check\u00a0'place.coarse.missing_scan_def' is\u00a0'tolerate'.\n (EDC-001) Continuing\u00a0without\u00a0valid\u00a0scan\u00a0def.\n Start\u00a0transferring\u00a0placement\u00a0data.\n Creating\u00a0placement\u00a0from\u00a0scratch.\n...\n...\n For more information about the Early Data Check Manager, see the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Applying Required Settings for Advanced Technology Nodes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use mega-switch commands to apply setting for different stages of the tool flow that are applicable for specific situations with the use of a single command.\n \u2022 Applying Required Settings for Advanced Technology Nodes \u2022 Applying Required Settings for High Performance Cores \u2022 Applying Required Settings for Improving Specific QoR Metrics"}
{"header": "How do I Applying Required Settings for High Performance Cores", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To apply placement, legalization, routing, and extraction setting specific to 12 or 7 nanometer technology nodes, use the  set_technology command with the  -node\u00a012 or -node\u00a07 option.\n       When using this command, perform the following steps before placement, optimization, and routing: 1.\n Load and link the design.\n 2.\n Apply the settings required for the technology nodes by using the  set_technology -node command, as shown in the following example: fc_shell>\u00a0 set_technology -node 7 3.\n (Optional) Report the technology-node settings by using the  set_technology -report_only command.\n 4.\n Apply your design-specific application option or command settings to override the generic setting of the  set_technology command.\n When you save the design library with the  save_lib command, the technology-node setting is saved.\n Note: After you specify a technology node with the  set_technology command, you cannot change it.\n For more information about which ASIC technologies are supported by this command, contact Synopsys Support."}
{"header": "How do I Applying Required Settings for Improving Specific QoR Metrics", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can apply tool settings required for achieving the best QoR for high performance cores by using the  set_hpc_options command.\n The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis.\n To \u2022 List the supported high performance core types and implementation stages, use the -list option \u2022 Specify the type of high performance core, use the  -core option \u2022 Specify the stage of the implementation flow, use the  -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the  set_technology command before you run the  set_hpc_options command, as shown in the following example script: set_technology\u00a0-node\u00a07 set_hpc_options\u00a0-core\u00a0A72\u00a0-stage\u00a0clock_opt_cts...\n clock_opt\u00a0-from\u00a0build_clock\u00a0-to\u00a0route_clock...\n       set_hpc_options\u00a0-core\u00a0A72\u00a0-stage\u00a0clock_opt_opto...\n clock_opt\u00a0-from\u00a0final_opto...\n set_hpc_options\u00a0-core\u00a0A72\u00a0-stage\u00a0route_auto...\n route_auto...\n set_hpc_options\u00a0-core\u00a0A72\u00a0-stage\u00a0route_opt...\n route_opt..."}
{"header": "How do I 3", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "To apply tool settings required for improving specific QoR metrics, use the set_qor_strategy\u00a0-stage\u00a0synthesis command.\n To specify the QoR metrics to improve, use the  -metric option.\n To optimize the block for the best \u2022 Timing, use the  timing setting \u2022 Leakage power and timing, use the  leakage_power setting \u2022 Total power and timing, use the  total_power setting.\n To further improve total power, at the expense of runtime, you can use the  -mode extreme_power option, with the  -metric\u00a0total_power option.\n To specify a target mode for the design flow, use the  -mode option.\n The supported values for this option are: \u2022 balanced, which is the default mode that optimizes the design for the target metrics specified with the  -metric option.\n \u2022 early_design, which is suitable for the early stages of the design flow, when the emphasis is on short turnaround time for prototyping purposes.\n With this mode, you can reduce runtime at the expense of QoR.\n \u2022 extreme_power, which is recommended for further improvement of total power at the expense of runtime.\n This mode should only be specified along with the  -metric\u00a0leakage_power or -metric\u00a0total_power option.\n If you specify this mode with the  -metric\u00a0timing option, the tool ignores the specified mode setting and uses the  balanced mode.\n       When you use this command, the tool applies application option settings that affect synthesis, optimization, placement, legalization, clock tree synthesis, routing, extraction, and timing analysis.\n To review the required setting, use one of the following methods: \u2022 Generate a Tcl script that contains the settings by using the  -output option \u2022 Report the settings by using the  -report_only option \u2022 Report only the settings that are not set to their required values by using the -diff_only option"}
{"header": "How do I Performing Unified Physical Synthesis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool synthesizes the RTL descriptions into optimized gate-level designs, optimizes them to achieve the best quality of results (QoR) in speed, area, and power, and allows early design exploration and prototyping.\n Topics in this section include \u2022 Performing Unified Physical Synthesis \u2022 Controlling Mapping and Optimization \u2022 Performing Multibit Optimization \u2022 Running Concurrent Clock and Data Optimization \u2022 Performing Test Insertion and Scan Synthesis \u2022 Specifying Settings for Performance, Power, and Area Improvement \u2022 Performing Design Analysis"}
{"header": "How do I Using the compile_fusion Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool performs unified physical synthesis.\n The benefits of unified physical synthesis include \u2022 Reduced runtime Unified physical synthesis streamlines the iterations of placement and optimization, and utilizes the initial placement and buffer trees built during synthesis to achieve the best runtime.\n \u2022 Improved quality of results (QoR) The unified preroute optimization framework uses consistent costs in optimization algorithms to improve QoR.\n The best technologies, such as logic restructuring, concurrent clock and data optimization, multibit mapping, and advanced legalizer, are shared throughout the preroute flow.\n The Fusion Compiler compilation includes both top-down and bottom-up (hierarchical) compile strategies.\n In a top-down compile, all environment and constraint settings are       defined with respect to the top-level design.\n Top-down compile provides a push-button approach and handles interblock dependencies automatically, but it requires that all designs must reside in memory at the same time.\n In a hierarchical compile flow, you start optimization of design subblocks using a top-down approach and then continue incorporating the subblocks into higher-level blocks until the top-level design is complete.\n The following topics describe how perform unified physical synthesis: \u2022 Using the compile_fusion Command \u2022 Performing Prechecks \u2022 Generating Verification Checkpoints During Compilation"}
{"header": "How do I Performing Prechecks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform unified physical synthesis, use the  compile_fusion command.\n The  compile_fusion command consists of the following stages: 1.\n  initial_map During this stage, the tool maps the design and performs area optimization.\n 2.\n  logic_opt During this stage, the tool performs logic-based delay optimization.\n 3.\n  initial_place During this stage, the tool merges the clock-gating logic and performs coarse placement.\n 4.\n  initial_drc During this stage, the tool removes existing buffer trees and performs high-fanout-net synthesis and electrical DRC violation fixing.\n 5.\n  initial_opto During this stage, the tool performs physical optimization and incremental placement.\n 6.\n  final_place During this stage, the tool performs final placement to improve timing and congestion.\n 7.\n  final_opto During this stage, the tool performs final optimization and legalization to improve timing, power, and logical DRCs.\n       When you run the  compile_fusion command, by default, the tool runs all stages.\n To run only some of these stages, use the  -from option to specify the stage from which you want to begin and the  -to option to specify the stage after which you want to end.\n If you do not specify the  -from option, the tool begins from the  initial_place stage.\n Similarly, if you do not specify the  -to option, the tool continues until the  final_opto stage is completed.\n Breaking the  compile_fusion command in to stages allows you to perform different tasks between the stages, such as changing constraints or settings, generating reports for analysis, performing other implementation tasks such as design planning or DFT insertion, and so on.\n If you make manual changes to the design between stages, ensure the changes honor the expected state of the design.\n For example, the design is expected to be mapped after the  initial_map stage.\n Therefore, do not introduce unmapped logic to the design after this stage.\n You can repeat a stage; however, ensure that you run all stages in the correct sequence.\n The following example runs the  compile_fusion command until it completes the initial_opto stage, performs analysis, changes an application option setting, and restarts by running the  initial_opto stage again.\n fc_shell>\u00a0 compile_fusion -to initial_opto fc_shell>\u00a0 report_qor fc_shell>\u00a0 set_app_option \\ -name opt.common.advanced_logic_restructuring_mode -value timing fc_shell>\u00a0 compile_fusion -from initial_opto In the following situations, the design can contain unmapped cells after the compile_fusion command: \u2022 Missing the required cells in the library \u2022 User-specified restrictions on the required library cells When a design contains unmapped cells, the  compile_fusion command continues the compilation and provides an estimated area for the unmapped cells.\n Unmapped cells are marked with the  is_unmapped attribute.\n To query unmapped cells in a netlist, use the following command: fc_shell>\u00a0 get_cells -hierarchical -filter \"is_unmapped==true\" Note the following limitations: \u2022 DesignWare operators are not mitigated.\n \u2022 Only placement information is stored in the database after mitigation; routing information is not saved."}
{"header": "How do I Generating Verification Checkpoints During Compilation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Fusion Compiler can perform compile prechecks to prevent compile failures and allow the  compile_fusion command to quickly exit with error messages when incomplete (or inconsistent) setup or constraint issues are encountered.\n This capability is on by default, but these checks can also be enabled by the  compile_fusion\u00a0-check_only command.\n The  compile_fusion command and the  compile_fusion -check_only command perform the prechecks listed in the following table and issue error messages accordingly.\n A check mark (X) indicates the precheck is performed.\n Table 19 Prechecks Performed During the Compile Flow Code Message Default compile prechecks compile_fusion -check_only      Cell     Cell      Cell         hierarchy                     Macro     port     Pad port              Layer         Table 19 Prechecks Performed During the Compile Flow (Continued) Code Message Default compile prechecks compile_fusion -check_only           check_duplicates    Compile Precheck Examples The following two examples show the compile logs with and without compile prechecks.\n When the  -check_only option is set, the  compile_fusion command issues error messages for any failed precheck condition.\n Example 14 Compile Log With Compile Prechecks -------------------------\u00a0Begin\u00a0compile\u00a0flow\u00a0----------------------- (FLW-3001) ->Compile\u00a0in\u00a0progress:\u00a0\u00a0\u00a0\u00a01.0%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(FLW-3778) Error: Layer M1 does not have a preferred direction (OPT-1008)...\n Error:\u00a0Layer\u00a0MRDL\u00a0does\u00a0not\u00a0have\u00a0a\u00a0preferred\u00a0direction\u00a0(OPT-1008)...\n Warning:\u00a0Technology\u00a0layer\u00a0'M1'\u00a0setting\u00a0'routing-direction'\u00a0is\u00a0not\u00a0valid (NEX-001)...\n Warning:\u00a0Technology\u00a0layer\u00a0'MRDL'\u00a0setting\u00a0'routing-direction'\u00a0is\u00a0not\u00a0valid (NEX-001) Example 15 Compile Log Without Compile Prechecks ----------------------\u00a0End\u00a0logic\u00a0optimization\u00a0-------------------- (FLW-3001) ->Compile\u00a0in\u00a0progress:\u00a0\u00a0\u00a027.0%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(FLW-3778) ->Compile\u00a0in\u00a0progress:\u00a0\u00a0\u00a028.0%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(FLW-3778) ->Compile\u00a0in\u00a0progress:\u00a0\u00a0\u00a028.5%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(FLW-3778) Information:\u00a0Corner\u00a0max_corner:\u00a0no\u00a0PVT\u00a0mismatches.\n (PVT-032) Warning:\u00a0Technology\u00a0layer\u00a0'M1'\u00a0setting\u00a0'routing-direction'\u00a0is\u00a0not\u00a0valid (NEX-001)...\n Warning:\u00a0Technology\u00a0layer\u00a0'MRDL'\u00a0setting\u00a0'routing-direction'\u00a0is\u00a0not\u00a0valid (NEX-001) Information:\u00a0Design\u00a0Average\u00a0RC\u00a0for\u00a0design\u00a0top\u00a0\u00a0(NEX-011)"}
{"header": "How do I Controlling Mapping and Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can generate intermediate verification checkpoints during the  compile_fusion command, which you can use in the Formality tool to provide a netlist snapshot of the synthesis design state and verify the intermediate netlists.\n Verification checkpointing allows the Fusion Compiler and Formality tools to synchronize on an intermediate netlist and in turn results in higher completion rates and better QoR.\n To enable verification checkpointing, use the  set_verification_checkpoints command as shown in the following example: fc_shell>\u00a0 set_verification_checkpoints Enabling\u00a0checkpoint\u00a0\"ckpt_logic_opt\" Enabling\u00a0checkpoint\u00a0\"ckpt_pre_map\" When you enable this feature, by default, the  compile_fusion command generates verification checkpoints before mapping and during logic optimization, and the corresponding verification-checkpoint stages are named  ckpt_pre_map and ckpt_logic_opt.\n You can enable verification checkpointing at only one stage as shown in the following example: fc_shell>\u00a0 set_verification_checkpoints {ckpt_logic_opt} Disabling\u00a0checkpoint\u00a0\"ckpt_pre_map\" Enabling\u00a0checkpoint\u00a0\"ckpt_logic_opt\" At each verification checkpoint, the tool automatically generates a checkpoint netlist and the  guide_checkpoint command in the.svf file that is used by the Formality tool during verification."}
{"header": "How do I Ungrouping or Preserving Hierarchies During Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe how you can customize and control the mapping and optimization that is performed during the  initial_map,  logic_opto, and  initial_drc stages of the  compile_fusion command: \u2022 Ungrouping or Preserving Hierarchies During Optimization \u2022 Controlling Boundary Optimization \u2022 Controlling Datapath Optimization \u2022 Controlling MUX Optimization \u2022 Controlling Sequential Mapping \u2022 Controlling Register Replication \u2022 Controlling Register Merging       \u2022 Selectively Removing or Preserving Constant and Unloaded Registers \u2022 Reporting Cross-Probing Information for Optimized Registers \u2022 Controlling High-Fanout-Net Synthesis"}
{"header": "How do I Controlling Boundary Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Ungrouping merges subdesigns of a given level of the hierarchy into the parent cell or design.\n It removes hierarchical boundaries and allows Fusion Compiler to improve timing by reducing the levels of logic and to improve area by sharing logic.\n By default, the compile_fusion command automatically ungroups logical hierarchies that do not have a dont_touch attribute setting.\n During optimization, the  compile_fusion command performs the following types of automatic grouping: \u2022 Area-based automatic ungrouping Before initial mapping, the command estimates the area for unmapped hierarchies and removes small subdesigns.\n Because the command performs automatic ungrouping at an early stage, it has a better optimization context.\n Additionally, datapath extraction is enabled across ungrouped hierarchies.\n These factors improve the area and timing quality of results.\n \u2022 Delay-based automatic ungrouping The command ungroups hierarchies along the critical path and is used essentially for timing optimization.\n For ungrouping of DesignWare and datapath cells, see  Datapath Implementation.\n You can disable automatic ungrouping by setting the  compile.flow.autoungroup application option to  false.\n The default is  true.\n However, doing do can affect the QoR.\n Therefore, it is better to limit ungrouping, rather than disabling it, using the following methods: Controlling the Automatic Ungrouping of Specific Types of Hierarchies To control the automatic ungrouping of specific types of hierarchies, use the set_autoungroup_options command.\n The following example specifies that parent hierarchies of blocks with UPF and SDC constraints should preserved and that automatic ungrouping of other hierarchies should begin from the third level: fc_shell>\u00a0 set_autoungroup_options -keep_parent_hierarchies UPF fc_shell>\u00a0 set_autoungroup_options -keep_parent_hierarchies SDC fc_shell>\u00a0 set_autoungroup_options -start_level 3       The  set_autoungroup_options command is cumulative and the settings are saved in the design library.\n To report information about the hierarchies that are automatically ungrouped or preserved, use the  report_ungroup command.\n Controlling the Automatic Ungrouping of Specific Objects To force or prevent specific cell instances or modules being ungrouped during optimization, use the  set_ungroup command with the  true or  false setting.\n The set_ungroup command sets the  ungroup attribute to the appropriate value for the specified objects.\n If you set the attribute on a module, all cells that reference the module are affected.\n Note: The  set_ungroup command has a higher priority than the set_autoungroup_options command.\n The following example script sets specific modules to be ungrouped and specific cell instances to be preserved during optimization: #\u00a0Set\u00a0modules\u00a0A\u00a0and\u00a0B\u00a0to\u00a0be\u00a0ungrouped set_ungroup\u00a0[get_modules\u00a0{A\u00a0B}]\u00a0true #\u00a0Set\u00a0cells\u00a0u_C\u00a0and\u00a0u_D\u00a0to\u00a0be\u00a0preserved set_ungroup\u00a0[get_cells\u00a0{u_C\u00a0u_D}]\u00a0false #\u00a0Query\u00a0the\u00a0ungroup\u00a0attribute get_attribute\u00a0-name\u00a0ungroup\u00a0-objects\u00a0[get_modules\u00a0{A\u00a0B}] get_attribute\u00a0-name\u00a0ungroup\u00a0-objects\u00a0[get_cells\u00a0{u_C\u00a0u_D}] compile_fusion"}
{"header": "How do I Controlling Datapath Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can control boundary optimization across user-specified logical boundaries and match the interface boundary of a physical block with the RTL module interface.\n Boundary optimization allows you to use RTL floorplanning DEF files during block implementation.\n The following figure shows how constants, equal-opposite logic, logic phase, and unloaded ports are propagated through the logical boundaries without and with boundary optimization.\n       0 Constant propagation 0 Phase inversion Unloaded propagation Equal-opposite logic propagation Disabled Enabled Disabled Disabled Disabled Enabled Enabled Enabled Disabled: without boundary optimization Enabled:  with boundary optimization Global Control By default, all types of boundary optimization are enabled during compile.\n To control boundary optimization globally, use the  compile.flow.boundary_optimization application option.\n When you set the  compile.flow.boundary_optimization application option to  false, \u2022 The tool disables propagation of equal-opposite logic and phase inversion.\n \u2022 Constants and unloaded ports continue to propagate across hierarchies.\n To disable constant propagation and unloaded propagation globally, set the compile.flow.constant_and_unloaded_propagation_with_no_boundary_opt application option to  false.\n The default is  true.\n The setting does not affect object-level specifications.\n Controlling Specific Types of Boundary Optimization To control the level of boundary optimization for hierarchical cell pins, hierarchical cells, or blocks, use the  set_boundary_optimization command.\n The tool uses the following order of precedence to determine the setting to use during optimization: 1.\n Setting applied on pins of hierarchical cell instances 2.\n Setting applied on hierarchical cell instances, which applies to its pins as well 3.\n Setting applied on modules, which applies to all its cells and pins as well       The following table shows the level of boundary optimization you can specify with the set_boundary_optimization command and the types of boundary optimization that are enabled for each level.\n Table 20 Levels of Boundary Optimization and the Corresponding Types of Boundary Optimization Performed Level of boundary optimization Constant propagation Unloaded propagation Equal-opposite logic propagation Phase inversion all     auto     none     You can control the specific types of boundary optimization allowed for an object by using the  -constant_propagation,  -unloaded_propagation, -equal_opposite_propagation, and  -phase_inversion options.\n These options are mutually exclusive with the boundary optimization level specified by using  all,  auto, or none and cannot be used on the same object in a single command invocation.\n If you use the  set_boundary_optimization command multiple times on the same object, the effect is additive.\n Based on the types of boundary optimization you enable or disable, the tool sets the constant_propagation,  unloaded_propagation,  equal_opposite_propagation, and phase_inversion read-only attributes of the specified object to  true or  false.\n If you \u2022 Enable all four types, the tool sets the  boundary_optimization read-only attribute to true \u2022 Disable at least one type, the tool sets the  boundary_optimization read-only attribute to  false To report boundary optimization settings, use the  report_boundary_optimization command.\n To remove them, use the  remove_boundary_optimization command.\n The following example \u2022 Disables all boundary optimization for the U1 cell instance \u2022 Disables equal-opposite logic propagation and phase inversion for the U2 cell instance \u2022 Disables constant propagation and phase inversion for the U3/in1 cell pin fc_shell>\u00a0 set_boundary_optimization [get_cells U1] none fc_shell>\u00a0 set_boundary_optimization [get_cells U2] auto fc_shell>\u00a0 set_boundary_optimization [get_pins U3/in1] \\ -constant_propagation false       fc_shell>\u00a0 set_boundary_optimization [get_pins U3/in1] \\ -phase_inversion false Controlling Phase Inversion To prevent boundary optimization from moving inverters across hierarchical boundaries, set the  compile.optimization.enable_hierarchical_inverter application option to  false.\n By default, the application option is set to  true to allow phase inversion.\n This application option is only effective when boundary optimization is enabled."}
{"header": "How do I Datapath Extraction", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Datapath design is commonly used in applications that contain extensive data manipulation, such as 3-D, multimedia, and digital signal processing (DSP).\n By default, when you run the  compile_fusion command, datapath optimization is enabled and both standard and DesignWare Foundation libraries are automatically linked.\n During datapath optimization, the tool performs the following tasks: \u2022 Shares (or reverses the sharing) of datapath operators \u2022 Uses the carry-save arithmetic technique \u2022 Extracts the data path \u2022 Performs high-level arithmetic optimization on the extracted data path \u2022 Explores better solutions that might involve a different resource-sharing configuration \u2022 Makes tradeoffs between resource sharing and datapath optimization Topics in this section \u2022 Datapath Extraction Transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks.\n \u2022 Datapath Implementation Uses a datapath generator to generate the best implementations for the extracted components.\n \u2022 Optimizing Datapaths"}
{"header": "How do I Datapath Implementation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Datapath extraction transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks to be implemented by a datapath generator.\n This transformation improves the quality of results (QoR) by using carry-save arithmetic.\n       Carry-save arithmetic does not fully propagate carries but stores results in an intermediate form.\n The carry-save adders are faster than the conventional carry-propagate adders because the carry-save adder delay is independent of bit-width.\n These adders use significantly less area than carry-propagate adders because they do not use full adders for the carry.\n The following example shows the code for the a * b + c + d = z expression.\n As shown in Figure\u00a030, the conventional implementation of the expression use three carry-propagate adders, whereas the carry-save arithmetic requires only one carry-propagate adder and two carry-save adders.\n The figure also shows the timing and area numbers for both implementations.\n module\u00a0dp\u00a0(a,\u00a0b,\u00a0c,\u00a0d,\u00a0e);\u00a0\u00a0\u00a0input\u00a0\u00a0[15:0]\u00a0a,\u00a0b; input\u00a0\u00a0[31:0]\u00a0c,\u00a0d; output\u00a0[31:0]\u00a0Z; assign\u00a0Z\u00a0=\u00a0(a\u00a0*\u00a0b)\u00a0+\u00a0c\u00a0+\u00a0d; endmodule Figure 30 Conventional Carry-Propagate Adder Versus Carry-Save Adder       The tool supports extraction of the following components: \u2022 Arithmetic operators that can be merged into one carry-save arithmetic tree \u2022 Operators extracted as part of a datapath: *, +, -, >, <, <=, >=, ==,!=, and MUXes \u2022 Variable shift operators (<<, >>, <<<, >>> for Verilog and sll, srl, sla, sra, rol, ror for VHDL) \u2022 Operations with bit truncation The datapath flow can extract these components only if they are directly connected to each other, that is, no nonarithmetic logic between components.\n Keep the following points in mind: \u2022 Extraction of mixed signed and unsigned operators is allowed only for adder trees \u2022 Instantiated DesignWare components cannot be extracted"}
{"header": "How do I Optimizing Datapaths", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "All the extracted datapath elements and the synthetic operators are implemented by the DesignWare datapath generator in Fusion Compiler.\n The DesignWare datapath generator uses the smart generation technology to perform the following tasks: \u2022 Implement datapath blocks using context-driven optimizations \u2022 Revisit high-level optimization decisions for a given timing context \u2022 Consider logic library characteristics Use these commands and application option for datapath implementation: \u2022 set_datapath_architecture_options This command controls the strategies used to generate the datapath cells for arithmetic and shift operators.\n The following example specifies to use Booth-encoded architectures to generate multiplexers: fc_shell>\u00a0 set_datapath_architecture_options -booth_encoding true \u2022 set_implementation This command specifies the implementation to use for dividers and synthetic library cell instances with a specified name.\n The following example specifies to use the cla3 implementation for the instantiated DesignWare cell U1.\n fc_shell>\u00a0 set_implementation cla3 U1 \u2022 set_synlib_dont_use       This command prevents using specific implementation.\n The following example specifies not to use the rpl implementation.\n fc_shell>\u00a0 set_synlib_dont_use \\ {dw_foundation/DW_div/cla standard/DW_div/rpl} \u2022 compile.datapath.ungroup By default, all DesignWare cells and datapath blocks are ungrouped during timing optimization.\n To disable the ungrouping, set the  compile.datapath.ungroup application option to  false, changing from its default of  true.\n For example, fc_shell>\u00a0 set_app_options \\ -name compile.datapath.ungroup -value false"}
{"header": "How do I Controlling MUX Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Th following script disables the ungrouping of the DP_OP cell with datapath gating element add_3: #\u00a0Disable\u00a0ungrouping\u00a0of\u00a0DP_OP\u00a0with\u00a0datapath\u00a0gating set_datapath_gating_options\u00a0-ungroup\u00a0false\u00a0[get_cells\u00a0add_3] Analyzing Datapath Extraction To get the best QoR results from datapath optimization, ensure that the biggest possible datapath blocks are extracted from the RTL code during compile.\n To examine how the datapath blocks will be extracted from your RTL before compile, use the analyze_datapath_extraction command.\n The command analyzes the arithmetic contents of the design and provides feedback, so you can improve the RTL code as needed.\n The following example shows a datapath report: Cell\u00a0:\u00a0DP_OP_123_2304_10297_J1 -------------------------------- Current\u00a0Implementation\u00a0:\u00a0\u00a0str(area,speed) Contained\u00a0Operations\u00a0\u00a0:\u00a0\u00a0add_30(test.v:30)\u00a0add_30_2(test.v:30) mult_36(test.v:36) Multiplier\u00a0Arch\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0benc_radix4  Data Var\u00a0\u00a0\u00a0\u00a0\u00a0Type\u00a0\u00a0Class\u00a0\u00a0\u00a0\u00a0\u00a0Width\u00a0\u00a0Expression ------------------------------------------------------------------------- PI_0\u00a0\u00a0\u00a0\u00a0PI\u00a0\u00a0\u00a0\u00a0Unsigned\u00a0\u00a0\u00a0\u00a0\u00a0\u00a06 PI_1\u00a0\u00a0\u00a0\u00a0PI\u00a0\u00a0\u00a0\u00a0Unsigned\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 PI_2\u00a0\u00a0\u00a0\u00a0PI\u00a0\u00a0\u00a0\u00a0Unsigned\u00a0\u00a0\u00a0\u00a0\u00a024 T16\u00a0\u00a0\u00a0\u00a0\u00a0IFO\u00a0\u00a0\u00a0Unsigned\u00a0\u00a0\u00a0\u00a0\u00a0\u00a07\u00a0\u00a0PI_0\u00a0+\u00a0PI_1\u00a0\u00a0(test.v:30) PO_0\u00a0\u00a0\u00a0\u00a0PO\u00a0\u00a0\u00a0\u00a0Unsigned\u00a0\u00a0\u00a0\u00a0\u00a030\u00a0\u00a0PI_2\u00a0*\u00a0T16\u00a0(test.v:36)       To report the resources and datapath blocks used in the design, use the report_resources command.\n To report the implementation overview, specify the -summary with the  report_resources command.\n For example, fc_shell>\u00a0 report_resources -hierarchy Controlling Datapath Gating The following figure shows signal transitions of the inputs of a DP_OP cell that is generated during datapath gating optimization.\n To control datapath gating, use the set_datapath_gating_options command.\n The following script disables datapath gating on the datapath element add_3: #\u00a0Disable\u00a0datapath\u00a0gating\u00a0on\u00a0particular\u00a0operator set_datapath_gating_options\u00a0-enable\u00a0false\u00a0[get_cells\u00a0add_3]"}
{"header": "How do I Selecting and Multiplexing Logic", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can map combinational logic representing multiplexers in the HDL code directly to a single multiplexer (MUX) or a tree of multiplexer cells from the target logic library.\n Multiplexers are commonly modeled with if and case statements.\n To implement the mutliplexer logic, the HDL Compiler uses SELECT_OP cells, which the Fusion Compiler tool map to combinational logic or multiplexers in the logic library.\n       User-specified Tool evaluated Implemented using MUX gates Implemented using MUX or non MUX gates based on area costing analyze elaborate Infers Select_OP cells compile_fusion"}
{"header": "How do I Library Requirements", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool infers SELECT_OP cells for logic that selects data signals based on control signals.\n SELECT_OP cells are mapped to combinational logic.\n The following topics describe SELECT_OP inferences: \u2022 Inferring SELECT_OPs Inferring SELECT_OPs HDL Compiler uses SELECT_OP components to implement conditional operations implied by if and case statements.\n An example of a SELECT_OP cell implementation for an 8-bit data signal is shown in  Figure\u00a031.\n       Figure 31 SELECT_OP Implementation for an 8-bit Data Signal Figure 32 Verilog Output\u2014SELECT_OP and Selection Logic       Depending on the design constraints, Fusion Compiler implements the SELECT_OP with either combinational logic or multiplexer cells from the logic library.\n For more information on SELECT_OP inference, see the HDL Compiler documentation."}
{"header": "How do I Controlling Sequential Mapping", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You need to have multiplexer cells in the logic library and also require to use multiplexing logic from the cell library.\n The following section describes library requirements to implement multiplexer cells for multiplexer optimization or to implement multiplexing logic from the cell library to control MUX mapping: \u2022 Understanding Library Cell Requirements for Multiplexer Optimization \u2022 Implementing Multiplexing Logic From Cell Library Understanding Library Cell Requirements for Multiplexer Optimization The multiplexer optimization requires the presence of at least a 2:1 multiplexer cell in the logic library.\n The inputs or outputs of this cell can be inverted.\n If a 2:1 multiplexer primitive cell does not exist in the library, you see the following warning message: Warning:\u00a0Target\u00a0library\u00a0does\u00a0not\u00a0contain\u00a0any\u00a02-1\u00a0multiplexer.\n (OPT-853) An implementation of the MUX_OP cell from the target library is created, but it might not be the best implementation possible.\n All multiplexer cells in the target library can be used to construct the implementation of the MUX_OP cell except \u2022 Enabled multiplexer cells \u2022 Bused output multiplexer \u2022 Multiplexers larger than 32 : 1 For Fusion Compiler to make the best use of the multiplexer cells available in your logic library, recompile the library or obtain a library compiled with version V3.4a or later from your ASIC vendor.\n Implementing Multiplexing Logic From Cell Library During logic synthesis, the tool implements multiplexing logic from the cell library using one of the following methods: \u2022 AND, OR, and INV gates \u2022 MUX gates The tool evaluates the area effect of both methods and selects the solution with the smallest area.\n       You can specify that the tool uses MUX gates to implement specific multiplexing logic by applying the  map_to_mux attribute on the corresponding SELECT_OP WVGTECH cells in the block, as shown in  Example\u00a016.\n Example 16 Using map_to_mux attribute to implement specific multiplexing logic #\u00a0Apply\u00a0the\u00a0map_to_mux\u00a0attribute\u00a0on\u00a0the\u00a0SELECT_OP\u00a0cell\u00a0named\u00a0C10 set_attribute\u00a0-objects\u00a0[get_cells\u00a0C10]\u00a0-name\u00a0map_to_mux\u00a0-value\u00a0true  #\u00a0Query\u00a0if\u00a0the\u00a0attribute\u00a0is\u00a0set\u00a0as\u00a0required\u00a0on\u00a0C10 get_attribute\u00a0-objects\u00a0[get_cells\u00a0C10]\u00a0-name\u00a0map_to_mux  #Run\u00a0the\u00a0compile\u00a0step compile_fusion  #Identify\u00a0the\u00a0cell\u00a0created\u00a0using\u00a0the\u00a0map_to_mux\u00a0attribute get_cells\u00a0-hier\u00a0-filter\u00a0\"map_to_mux==true\u00a0&&\u00a0!infer_mux_override\""}
{"header": "How do I Mapping Sequential Elements Exactly as Described in RTL", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The sequential mapping phase consists of two steps: register inferencing and technology mapping.\n The term register refers to both edge-triggered registers and level-sensitive latches.\n Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN.\n SEQGENs are created during elaboration and are usually mapped to flip-flops during compile.\n Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library.\n Both of these steps are performed by the  compile_fusion command.\n       Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable Q QN SEQGEN This table lists the pins of a SEQGEN cell.\n Only a subset of these pins is used depending on the type of cell that is inferred.\n Unused pins are tied to zero.\n Direction Name Description Cell type                                          Direction Name Description Cell type    During technology mapping, the tool uses the SEQGEN as the starting point for mapping.\n The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register.\n Topics in this section \u2022 Mapping Sequential Elements Exactly as Described in RTL \u2022 Mapping of Scan Cells \u2022 Mapping of Synchronous Reset or Preset Registers \u2022 Specifying Synchronous Input Types for Library Cell Pins \u2022 Controlling Sequential Output Inversion \u2022 Preventing Connections to Register QN Pins \u2022 Mapping of Synchronous Enable Logic to a MUX \u2022 Identification of Shift Registers"}
{"header": "How do I Mapping of Scan Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify that the tool maps sequential elements exactly as described in the RTL, set the compile.seqmap.exact_map application option to  true.\n When this feature is enabled, the tool disables mapping to sequential library cells with inverted outputs or unused ports."}
{"header": "How do I Mapping of Synchronous Reset or Preset Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During test-ready compile, the tool replaces regular flip-flops with flip-flops that contain logic for testability.\n The following figure shows an example of how a D flip-flop is replaced with a scan register during test-ready compile.\n This type of architecture, a multiplexed flip- flop, incorporates a 2-input MUX at the input of the D flip-flop.\n The select line of the MUX enables two modes\u2014functional mode (normal data input) and test mode (scanned data input).\n In this example, the scan-in pin is si, the scan-enable pin is se, and the scan-out pin, so, is shared with the functional output pin, Q.\n       D si D Clk se 1 0 Q/so When you run the  compile_fusion command, \u2022 The tool maps all sequential cells directly to scan registers in your library \u2022 The scan pins, such as scan enable and scan out, are unconnected \u2022 The scan output pin of a scan register is used for scan connections Use the  seqmap.bind_scan_pins application option to hold the scan enable pin inactive If the library contains no scan registers, the tool uses nonscan cells for mapping and issues a warning.\n Set the  dont_use attribute on all scan registers in the library to map to nonscan cells"}
{"header": "How do I Specifying Synchronous Input Types for Library Cell Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default.\n To infer registers with synchronous reset or preset pins, use the  sync_set_reset Synopsys compiler directive in the RTL.\n HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible.\n To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: \u2022 The  sync_set_reset directive Specify the  //synopsys\u00a0sync_set_reset directive in the RTL.\n \u2022 The  hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to  true.\n The default is  false.\n       During compile, the tool performs the following mapping based on the registers in your library: \u2022 The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin.\n \u2022 The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin.\n The tool also attempts to map the logic as close as possible to the data pin.\n This figure shows examples of mapping to registers with and without a synchronous reset pin.\n D Q ___ RST D Using a reset pin D Q ___ RST D Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the  sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible.\n To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to  true.\n Note: Synchronous reset and preset signals are not inferred for level-sensitive latches.\n A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins.\n Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must \u2022 Describe the registers correctly in the RTL \u2022 Ensure the library contain the corresponding cells \u2022 Ensure the  hdlin.elaborate.ff_infer_async_set_reset application option is set to  true (the default)       If the library does not contain this type of registers, the tool leaves the cells unmapped."}
{"header": "How do I Controlling Sequential Output Inversion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When mapping sequential cells, the tool uses the  nextstate_type attribute of a library cell pin to identify its synchronous pin type.\n The valid values for this attribute are  data, preset,  clear,  load,  scan_in, and  scan_enable.\n If this attribute is not specified or is incorrectly specified in the logic library, you can manually specify it by using the  set_attribute command, as shown in the following example: fc_shell>\u00a0 set_attribute [get_lib_pins my_lib/dffsrst/RN] \\ nextstate_type clear"}
{"header": "How do I Preventing Connections to Register QN Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  compile_fusion command can map a register to a sequential library cell with an output that is opposite to that of the register, if it improves QoR.\n This is known as sequential output inversion.\n Sequential output inversion is also useful when mapping to a target library with sequential cells that have only one type of asynchronous inputs (either set or reset).\n In this case, the only way to map a register that uses the missing asynchronous inputs is to use a library cell with the opposite type of asynchronous input and invert the output of that cell, as shown in the following figure.\n This figure shows an example of sequential output inversion during mapping.\n Q ___ SET D Q D ___ RST QN D ___ RST       Note: Information about inverted registers is written to the verification guidance (.svf) file.\n You must include the.svf file in the Formality tool when verifying blocks with sequential output inversion.\n To control sequential output inversion for \u2022 The entire block, use the  compile.seqmap.enable_output_inversion application option.\n The default is  true.\n \u2022 Specific hierarchical or leaf cells, use the  set_register_output_inversion command.\n An instance-specific sequential output inversion setting specified with the set_register_output_inversion command overrides a block-specific setting specified with the  compile.seqmap.enable_output_inversion application option.\n The  compile_fusion command allows the mapping of sequential elements in the design to sequential library cells whose output phase is inverted.\n In certain cases, the tool might infer a register that has one type of asynchronous control, but your library has the opposite type of pin.\n In such cases, the tool maps to the opposite type of register and inverts all the data inputs and outputs."}
{"header": "How do I Mapping of Synchronous Enable Logic to a MUX", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During sequential mapping, the tool can map registers to library cells that have both Q and QN pins, if doing so improves the QoR.\n However, you can prevent the tool from using the QN pin of such registers by setting the  compile.seqmap.disable_qn_usage application option to  true."}
{"header": "How do I Identification of Shift Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When the RTL contains synchronous enable logic, the  compile_fusion command maps the enable logic to library cells with a synchronous enable pin.\n When the library cells with a synchronous enable pin are not available, the  compile_fusion command maps the pushed-out synchronous logic to a MUX, as shown in this figure.\n       To enable the mapping to MUXs, set the  map_sync_enable_to_mux attribute on the SEQGEN cells before compile.\n For example, fc_shell>\u00a0 set_attribute \"A1/B/reg[30] mid/sub1/Q_reg[0]\" \\ -name map_sync_enable_to_mux -value true fc_shell>\u00a0 set_attribute \"mid3/apbif_reg/Q_reg[4]\" \\ -name map_sync_enable_to_mux -value true fc_shell>\u00a0 compile_fusion"}
{"header": "How do I Controlling Register Replication", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During compile, the tool can automatically identify shift registers in the design.\n The compile_fusion\u00a0-to\u00a0initial_opto command maps the first register to a scan cell and the other cells to nonscan cells, as shown in this figure.\n Q D ___ RST D SI SE CLK Q Q D Q D Q SO This capability improves the sequential design area and reduces congestion because of fewer scan-signals for routing.\n To disable this capability, set the compile.seqmap.identify_shift_registers application option to  false.\n The default is true."}
{"header": "How do I Controlling Register Merging", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can perform logic optimization by running the  compile_fusion\u00a0-to\u00a0logic_opto command.\n To identify registers that you want the tool to replicate during logic optimization, use the  set_register_replication command.\n This command sets the register_replication attribute on the specified registers and improves the timing by balancing fanout.\n During logic optimization, the specified registers are replicated and the loads of the original registers are evenly distributed among the new replicated registers when the  -num_copies option is used.\n When you use the  -max_fanout option, the tool computes the number of copies and attempts to distribute loads evenly without violating the maximum fanout constraints.\n You can control the number of copies that are created by using one of the following methods: \u2022 Specify the total number of registers after replication, including the original, by using the  -num_copies option.\n \u2022 Specify the maximum fanout of the replicated registers by using the  -max_fanout option.\n If you specify both options, the  -max_fanout option is ignored.\n The following example specifies that the tool should replicate the regA and regB registers by creating one additional copy of each register: fc_shell>\u00a0 set_register_replication -num_copies 2 regA fc_shell>\u00a0 set_register_replication -num_copies 2 regB Figure\u00a033 shows the regA and regB registers before and after optimization.\n Figure 33 Before and After Register Replication r1 r2 r3 Out1  Out2 r1 r2 r3 RegB regA RegA regB regA regB Out2 Out1       You can include logic in the fanin or fanout of the specified register by using the -include_fanin_logic or  -include_fanout_logic option.\n You can specify any startpoint in the fanin or endpoint in the fanout of the register.\n The following example specifies that the tool should replicate the A_reg register and the logic in the path from this register to the U1 cell: fc_shell>\u00a0 set_register_replication -num_copies 2 A_reg \\ -include_fanout_logic U1 To specify endpoint registers or primary output ports that must be driven by the original register after replication, as shown in  Figure\u00a034, use the -driven_by_original_register option.\n The following example specifies that after replication, the r0 register must drive the r1, r2, and r3 registers: fc_shell>\u00a0 set_register_replication -num_copies 3  r0 \\ -driven_by_original_register {r1 r2 r3} Figure 34 Using the -driven_by_original_register Option r0 r1 r2 r3 Out1  Out2  Out3 r0 r1 r2 r3 Out1  Out2  Out2 r0_rep1 r0_rep2"}
{"header": "How do I Selectively Removing or Preserving Constant and Unloaded", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool performs register merging during optimization.\n To disable register merging, set the  compile.seqmap.enable_register_merging application option to false.\n The default is  true.\n Information about which registers are being merged is stored in the.svf file, and the output log file shows information messages about register merging.\n       You can also control register merging based on the attribute setting by using the set_register_merging command.\n To enable register merging during optimization, specify a  true value to set the register merging attribute on the specified object list.\n To disable register merging, specifies a  false value for the specified object list.\n The objects can include leaf cells, hierarchical cells, and modules.\n This example specifies not to merge registers that have the u1/count_reg string in the instance names: fc_shell>\u00a0 set_register_merging \"u1/count_reg*\" false This example specifies not to merge all flip-flops of u1 instance name: fc_shell>\u00a0 set_register_merging \"u1\" false"}
{"header": "How do I Reporting Cross-Probing Information for Optimized Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To optimize the design by reducing area, the tool can automatically detect and remove constant registers and unloaded registers.\n You can control this behavior as described in the following topics: Removing Constant Registers Certain registers in a design might never change state because they have constant values on one or more input pins.\n These constant values can either be directly at the input or result from the optimization of fanin logic that eventually leads to a constant input of the register.\n Eliminating such registers can improve area significantly.\n By default, the  compile_fusion command removes constant registers and prints an information message in the compile log file.\n This table lists cases in which a sequential element can be eliminated.\n Type of register Data Preset Reset                          Type of register Data Preset Reset           To disable constant register removal for the entire block you are synthesizing, set the compile.seqmap.remove_constant_registers application option to  false, changing it from its default of  true.\n To control constant register removal for a specific cell or module, use the  set_constant_register_removal command.\n For example, the following settings prevent the tool from removing the constant register named reg11: fc_shell>\u00a0 set_constant_register_removal reg11 false The following settings globally disables constant register removal for the entire block except for the module named sub5 : fc_shell>\u00a0 set_app_option -name compile.seqmap.remove_constant_registers -value false  fc_shell>\u00a0 set_constant_register_removal [get_module sub5] true Information about removed constant registers is written to the verification guidance.svf file and the compile log file.\n To report the constant registers removed during compile, use the report_constant_registers command.\n Removing Unloaded Registers During optimization, the tool deletes registers with outputs that do not drive any load.\n The combinational logic cone associated with the input of the register can also be deleted if the cell is not used in the design.\n Register outputs can become unloaded because of redundancy in the circuit or as a result of constant propagation.\n In some designs where the registers have been instantiated, the outputs might already be unloaded.\n By default, the  compile_fusion command removes unloaded registers in the design and prints an information message in the compile log file.\n To disable this capability for the block you are synthesizing, set the  compile.seqmap.remove_unloaded_registers application option to  false, changing it from its default of  true.\n To control unloaded register removal for a specific cell or module, use the  set_unloaded_register_removal command.\n       For example, the following settings prevent the tool from removing the unloaded register named reg22: fc_shell>\u00a0 set_unloaded_register_removal reg22 false The following settings globally disables unloaded register removal for the entire block except for the module named sub5 : fc_shell>\u00a0 set_app_option -name compile.seqmap.remove_unloaded_registers -value false  fc_shell>\u00a0 set_unloaded_register_removal [get_module sub5] true To report the unloaded registers that were removed during compile, use the report_unloaded_registers command."}
{"header": "How do I Controlling High-Fanout-Net Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  compile_fusion command mergers registers and removes constant and unloaded registers during register optimization.\n To print the RTL file name and line number of these optimized register in the  compile_fusion command log file and in the  report_transformed_registers command output, set the compile.seqmap.print_cross_probing_info_for_removed_registers application option to  true.\n The following table shows the messages printed out during the different types of register optimization.\n Table 21 Cross-Probing Information Messages Printed During Register Optimization Register Optimization Information Message  Information:\u00a0The\u00a0register\u00a0'a/b_reg {\u00a0{/user/test/design.v:49}\u00a0}'\u00a0is\u00a0removed\u00a0as constant\u00a00\u00a0(SQM-4100)  Information:\u00a0The\u00a0register 'a/c_reg{\u00a0{/user/test/design.v:193}\u00a0}'\u00a0is\u00a0removed because\u00a0it\u00a0is\u00a0unloaded.\n (SQM-4101)  Information:\u00a0The\u00a0register\u00a0'a_reg[1] {\u00a0{/user/testcases/top.v:113}\u00a0}'\u00a0is\u00a0removed\u00a0because it\u00a0is\u00a0merged\u00a0to\u00a0'a_reg[0]'.\n (SQM-4102)       The following example output shows the cross probing information that is reported by the report_transformed_registers command: Legend: c0r\u00a0-\u00a0Constant\u00a00\u00a0Register\u00a0Removed c1r\u00a0-\u00a0Constant\u00a01\u00a0Register\u00a0Removed ul\u00a0\u00a0-\u00a0Unloaded\u00a0Removed inv\u00a0-\u00a0Inverted rep\u00a0-\u00a0Replicated mrg\u00a0-\u00a0Merged\u00a0register mb\u00a0\u00a0-\u00a0Mutibit mbd\u00a0-\u00a0Mutibit\u00a0debanked Register\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Transformation\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Filename: Line\u00a0number ------------------------------------------------------------------------- ------- mega_shift_reg\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0c0r {{a/b/test1.v:112}} Carry_Flag_reg\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ul {{a/b/test2.v:117}} mega_shift_reg[10]\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0mrg\u00a0(mega_shift_reg[31]) {{a/b/test3.v:121\u00a0}}"}
{"header": "How do I Performing Multibit Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool performs high-fanout-net synthesis during the  initial_drc stage of the compile-fusion command.\n To use globally routed nets to determine the topology for the buffers inserted during high-fanout synthesis, set the compile.initial_drc.global_route_based application option to  true.\n After high- fanout synthesis, which is performed during the DRC fixing stage of the  compile_fusion command, the global routes are deleted.\n Global-route-based buffering benefits designs with high congestion in routing channels such as the channels between banks of macros.\n This feature increases the runtime of the compile_fusion command.\n Therefore, you should enable it only for designs with highly congested routing channels."}
{"header": "How do I Performing Integrated Multibit-Register Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can combine (bank) single-bit registers or smaller multibit registers and replace them with equivalent larger multibit registers.\n For example, the tool can combine eight 1-bit registers or four 2-bit register banks and replace them with one 8-bit register bank or two 4-bit register banks.\n The tool merges single-bit registers only if they have the same timing constraints, and it copies the timing constraints to the resulting multibit register.\n       Figure 35 Replacing Multiple Single-Bit Register Cells With a Multibit Register Cell Two 1-bit register cells One 2-bit register cell Replace with D Q D Q 2 2 D Q SI SE SI SE SI SE Replacing single-bit registers with multibit registers reduces \u2022 Area due to shared transistors and optimized transistor-level layout \u2022 The total clock tree net length \u2022 The number of clock tree buffers and clock tree power The tool can also split (debank) large multibit registers into smaller multibit registers or single-bit registers, if it improves the total negative slack.\n Some logic libraries have mixed-drive-strength multibit registers where some bits have a higher drive strength than others.\n For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit."}
{"header": "How do I Creating a Multibit Register Bank From Specific Single-Bit", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform integrated multibit register optimization during the  compile_fusion command, 1.\n Enable multibit register optimization by setting the  compile.flow.enable_multibit application option to  true.\n When you do so, by default, the tool performs the following multibit optimizations during different stages of the  compile_fusion command: \u25e6 Combines single registers or smaller register banks at the RTL level to create larger register banks during the  initial_map stage To disable this feature, set the  compile.flow.enable_rtl_multibit_banking application option to  false.\n \u25e6 Splits multibit register banks created at the RTL level if the register bank includes registers on critical timing paths during the  logic_opto stage To disable this feature, set the  compile.flow.enable_rtl_multibit_debanking application option to  false.\n \u25e6 Creates multibit register banks considering placement during the  initial_opto stage To disable this feature, set the compile.flow.enable_physical_multibit_banking application option to  false.\n You can enable placement-based multibit banking during the  final_place stage of the  compile_fusion command, instead of the  initial_opto stage, by setting the  compile.flow.enable_second_pass_multibit_banking application option to  true and the  compile.flow.enable_physical_multibit_banking application option to  false.\n You should enable placement-based multibit banking either during the initial_opto stage or the  final_place stage; not both.\n \u25e6 Splits multibit register banks, if it improves total negative slack (TNS), during the initial_opto and  final_opto stages To disable this feature, set the  compile.flow.enable_multibit_debanking application option to  false.\n 2.\n (Optional).\n       3.\n Specify settings for multibit register banking by using the  set_multibit_options command.\n For example, the following command excludes the reg[1] cell from multibit optimization during the RTL-banking stage: fc_shell>\u00a0 set_multibit_options -exclude [get_cells \"reg[1]\"] \\ -stage rtl The following command specifies that during the physical-banking stage, the tool banks only registers that are connected to the same bus: fc_shell>\u00a0 set_multibit_options  -bus_registers_only \\ -stage physical 4.\n (Optional) Control multibit register optimization using application options as shown in the following table.\n Table 22 General Application Options for Controlling Multibit Register Optimization To do this Set this application option   multibit.banking.enable_strict_scan_check  true    multibit.banking.lcs_consider_multi_si_cells  true        multibit.banking.across_equivalent_icg true    dont_touch legalize_only size_only  mv.cells.enable_multibit_pm_cells true size_only   multibit.common.exclude_size_only_cells  false  compile_fusion  compile.flow.enable_multibit_rewiring true       To do this Set this application option   logic_opto  compile.flow.enable_toggle_aware_rtl_multibit_ reordering true      initial_opto\u00a0(compile_fusion) final_place final_opto (compile_fusion/place_opt)   logic_opto compile_fusion  opt.common.enable_multibit_feature true 5.\n (Optional) Create a multibit register bank from specific single-bit registers as described in  Creating a Multibit Register Bank From Specific Single-Bit Registers.\n 6.\n (Optional) Control the naming style used for multibit banking as described in  Specifying Naming Styles for Multibit Registers.\n 7.\n Perform optimization by using the  compile_fusion command.\n 8.\n (Optional) Report multibit information.\n To report the multibit register banks inferred by the tool, use the report_transformed_registers\u00a0-multibit command, as described in  Reporting Multibit Registers.\n To report multibit statistics such as the total number of single-bit and multibit registers, the multibit banking ratio, and so on, use the  report_multibit command.\n For more information about how to determine why multibit register banking is not performed for specific cells, see  Identifying Why Multibit Banking Is Not Performed.\n 9.\n (Optional) Analyze the multibit banking components in the GUI as described in  Viewing Multibit Components in the GUI."}
{"header": "How do I Specifying Naming Styles for Multibit Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  compile_fusion command on an RTL design, you can create a multibit bus consisting of specific unmapped single-bit registers by using the create_multibit command.\n Then, when you run the  compile_fusion command,       during the  initial_map stage, the tool maps the single-bit cells of the bus created by the create_multibit command into a multibit register bank.\n The single-bit registers you specify with the  create_multibit\u00a0-sort command must \u2022 Be unmapped \u2022 Be of the same type \u2022 Be in the same logical hierarchy \u2022 Not be part of an existing bus In the following example, the single-bit cells are combined in alphanumeric descending order, which is reg4, reg3, reg2, and reg1: fc_shell>\u00a0 set_app_option -name compile.flow.enable_multibit -value true fc_shell>\u00a0 create_multibit {reg2 reg4 reg1 reg3} -sort descending fc_shell>\u00a0 compile_fusion In the following example the single-bit cells are combined in alphanumeric ascending order, which is reg1, reg2, reg3, and reg4: fc_shell>\u00a0 set_app_option -name compile.flow.enable_multibit -value true fc_shell>\u00a0 create_multibit {reg2 reg4 reg1 reg3} -sort ascending fc_shell>\u00a0 compile_fusion In the following example, the single-bit cells are combined in the specified order, which is reg2, reg4, reg1, and reg3: fc_shell>\u00a0 set_app_option -name compile.flow.enable_multibit -value true fc_shell>\u00a0 create_multibit {reg2 reg4 reg1 reg3} -sort none fc_shell>\u00a0 compile_fusion Note: You must set the  compile.flow.enable_multibit application option to true before you run the  create_multibit command on unmapped single bit registers.\n If not, the tool issues the following error message: Error:\u00a0create_multibit\u00a0command\u00a0failed:\u00a0multibit\u00a0flow\u00a0is disabled.\n (MBIT-068)"}
{"header": "How do I Reporting Multibit Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Fusion Compiler allows you to customize the naming styles for multibit registers.\n You can use the application options described in this topic to modify the default naming styles to match the requirements of your design flow or a third-party tool.\n       Specifying a Name Separator When creating the name for a multibit register, the tool concatenates the names of the single-bit registers and uses the _ character as the name separator.\n For example, when the tool combines the single-bit registers named reg1 and reg2, the multibit register is named reg1 _ reg2.\n To change the default name separator, use the multibit.naming.multiple_name_separator_style application option.\n Specifying a Name Prefix To specify a prefix for the multibit register name, use the  multibit.naming.name_prefix application option.\n Compacting Hierarchical Names When combining single-bit registers with hierarchical names, the tool uses the full hierarchical names of the single-bit registers for the concatenated multibit register name.\n For example, when the tool combines the single-bit registers named A/B/P/reg1 and A/B/ Q/reg2, the multibit register is named A/B/P/reg1_A/B/Q/reg2.\n To make the multibit register name more compact, specify that common hierarchical names should not be repeated by setting the multibit.naming.compact_hierarchical_name application option to  true.\n If you do so, when the tool combines the single-bit registers named A/B/P/reg1 and A/B/Q/reg2, the multibit register is named A/B/P/reg1_Q/reg2.\n Specifying a Range Separator for Contiguous Bits of a Bused Register When combining contiguous bits of a bused register, the tool uses the : character as the range separator.\n For example, when the tool combines single-bit bused registers named regA[0], regA[1], and regA[2], the multibit register is named regA[2:0].\n To change the range separator, use the  multibit.naming.range_separator_style application option.\n Specifying an Element Separator for Noncontiguous Bits of a Bused Register When combining noncontiguous bits of a bused register, the tool uses the, character as the element separator.\n For example, when the tool combines the single-bit bused registers named regA[1] and regA[3], the multibit register is named regA[3,1].\n To change the element separator, use the  multibit.naming.element_separator_style application option.\n       Specifying the Expanded Naming Styles When Combining Elements of a Multidimensional Register Array To specify the expanded naming styles for the multibit registers created by combining elements of a multidimensional register array, use the multibit.naming.expanded_name_style application option.\n For more information on this application option, see the man page."}
{"header": "How do I Identifying Why Multibit Banking Is Not Performed", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you run the  compile_fusion command, you can report the registers that are transformed due to multibit banking and debanking by using the report_transformed_registers\u00a0-multibit command.\n The following example shows a portion of a report generated by the report_transformed_registers\u00a0-multibit command.\n fc_shell>\u00a0 report_transformed_registers -multibit...\n **************************************** Attributes: mb\u00a0\u00a0-\u00a0multibit mbd\u00a0-\u00a0multibit\u00a0debanked...\n Register\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Optimization ----------------------------------- MB_2_MB_1\u00a0\u00a0\u00a0\u00a0\u00a0mb\u00a0(source:MB_2,\u00a0MB_1) MB_0_MB_3\u00a0\u00a0\u00a0\u00a0\u00a0mb\u00a0(source:MB_0,\u00a0MB_3) MB_5,\u00a0MB_6\u00a0\u00a0\u00a0\u00a0mbd\u00a0(source:\u00a0MB_5_MB_6)"}
{"header": "How do I Improving the Banking Ratio", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report a summary of the multibit banking ratio, a list of reasons for not banking or debanking cells, and the number of cells for each reason, use the  report_multibit command, as shown in the following example: fc_shell>\u00a0 report_multibit **************************************** Report\u00a0:\u00a0report_multibit...\n...\n  ****************************************  Total\u00a0number\u00a0of\u00a0sequential\u00a0cells:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04020 Number\u00a0of\u00a0single-bit\u00a0flip-flops:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03149 Number\u00a0of\u00a0single-bit\u00a0latches:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a029 Number\u00a0of\u00a0multi-bit\u00a0flip-flops:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0842 Number\u00a0of\u00a0multi-bit\u00a0latches:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00        Total\u00a0number\u00a0of\u00a0single-bit\u00a0equivalent\u00a0cells:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0853 (A)\u00a0\u00a0\u00a0Single-bit\u00a0flip-flops:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03149 (B)\u00a0\u00a0\u00a0Single-bit\u00a0latches:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a029 (C)\u00a0\u00a0\u00a0Multi-bit\u00a0flip-flops:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a05352 (D)\u00a0\u00a0\u00a0Multi-bit\u00a0latches:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00  Sequential\u00a0cells\u00a0banking\u00a0ratio\u00a0((C+D)/(A+B+C+D)):\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a062.74% Flip-flop\u00a0cells\u00a0banking\u00a0ratio\u00a0((C)/(A+C)):\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a062.96% BitsPerflop:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02.13  Reasons\u00a0for\u00a0sequential\u00a0cells\u00a0not\u00a0mapping\u00a0to\u00a0multibit\u00a0during\u00a0RTL\u00a0Banking:  Explanations: r12:\u00a0Cell\u00a0is\u00a0single\u00a0bit\u00a0because\u00a0its\u00a0parent\u00a0multibit\u00a0cell\u00a0was\u00a0debanked due\u00a0to\u00a0improve\u00a0timing\u00a0(Number\u00a0of\u00a0cells:\u00a091) r31:\u00a0Cell\u00a0cannot\u00a0be\u00a0banked\u00a0to\u00a0multibit\u00a0because\u00a0it\u00a0is\u00a0assigned\u00a0to\u00a0use single-bit\u00a0lib\u00a0cell\u00a0(Number\u00a0of\u00a0cells:\u00a063)   Reasons\u00a0for\u00a0multibit\u00a0sequential\u00a0cells\u00a0not\u00a0debanking\u00a0to\u00a0single\u00a0bit\u00a0cells during\u00a0RTL\u00a0Debanking:  Explanations:: r45:\u00a0Multibit\u00a0cell\u00a0cannot\u00a0be\u00a0debanked\u00a0because\u00a0it\u00a0is\u00a0not\u00a0critical enough\u00a0(Number\u00a0of\u00a0cells:\u00a0478) To report all the cells that are ignored during banking and debanking, use the -ignored_cells option with the  report_multibit command.\n To report the compatible multibit and single-bit library cells that can be used for banking and debanking, use the  check_multibit_library command.\n The following example generates a compatible library cell report for RTL banking and debanking: fc_shell>\u00a0 check_multibit_library -stage RTL \\ -banking -debanking **************************************** Report\u00a0:\u00a0check_multibit_library Flow\u00a0\u00a0\u00a0:\u00a0RTL\u00a0BANKING **************************************** ---------------------------------------------------------------- Single\u00a0bit\u00a0Lib\u00a0cell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Compatibility\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Multi\u00a0bit\u00a0Lib\u00a0cell ---------------------------------------------------------------- SB_reg1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0PIN\u00a0ORDER\u00a0MISMATCH\u00a0\u00a0MB_reg1 SB_reg2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0COMPATIBLE\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0MB_reg2 ---------------------------------------------------------------- Singlebit\u00a0with\u00a0NO\u00a0Multibit\u00a0Equivalents ---------------------------------------------------------------- SB_reg3        **************************************** Report\u00a0:\u00a0check_multibit_library Flow\u00a0\u00a0\u00a0:\u00a0RTL\u00a0DEBANKING **************************************** ---------------------------------------------------------------- Multi\u00a0bit\u00a0Lib\u00a0cell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Compatibility\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Single\u00a0bit\u00a0Lib\u00a0cell ---------------------------------------------------------------- MB_reg2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0COMPATIBLE\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SB_reg2 MB_reg1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0PIN\u00a0ORDER\u00a0MISMATCH\u00a0\u00a0SB_reg1 ---------------------------------------------------------------- Multibit\u00a0with\u00a0NO\u00a0Singlebit\u00a0Equivalents ---------------------------------------------------------------- MB_reg3"}
{"header": "How do I Viewing Multibit Components in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the  initial_mapping stage, the tool can prioritize the use of sequential library cells that have functionally equivalent multibit library cells.\n After you run the  compile_fusion command, if the  report_multibit -ignored_cells command indicates that many cells were not banked due to a lack of multibit cells in the library, you can enable this feature by setting the compile.seqmap.prefer_registers_with_multibit_equivalent application option to true and rerunning the  compile_fusion command.\n However, enabling this feature might degrade the design QoR."}
{"header": "How do I Mapping Combinational Multibit Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Fusion Compiler uses the WordView infrastructure to map multibit components.\n To view multibit components in the GUI, you must complete the following requirements: \u2022 Ensure the library contains multibit components in.ndm format.\n \u2022 Enable multibit component mapping by setting the  compile.flow.enable_multibit application option as follows: fc_shell>\u00a0 set_app_options -name compile.flow.enable_multibit \\ -value true Follow these steps to view multibit components in WordView: 1.\n Read the RTL by using the  analyze and  elaborate commands.\n 2.\n Run the  compile_fusion\u00a0-to\u00a0initial_opto command.\n The tool maps the bused registers to multibit components during compile.\n 3.\n (Optional) Check the multibit component mapping information by using the report_cells command.\n For example, The RTL contains the reg_state bused register.\n       module\u00a0top\u00a0(...); output\u00a0[2:0]\u00a0reg_state; always\u00a0@(posedge\u00a0clk) reg_state\u00a0<=\u00a0next_reg_state; endmodule The report shows that the reg_state bus register is mapped to the MB_DFF multibit component.\n fc_shell>\u00a0 report_cells [get_cells *reg_state_reg* -hierarchical]...\n Cell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Reference\u00a0\u00a0\u00a0\u00a0\u00a0Library\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Attributes --------------------------------------------------------------- reg_state_reg[2:0]\u00a0\u00a0\u00a0MB_DFF\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0my_mb_lib\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0n"}
{"header": "How do I Running Concurrent Clock and Data Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Combinational multibit cells are library cells, where a single cell implements multiple logic functions.\n The Fusion Compiler tool: \u2022 Banks single-bit combinational cells to multibit combinational cells.\n \u2022 Debanks multibit combinational cells as needed to improve QoR.\n Figure 36 Combinational Multibit Library Cells To enable combinational multibit mapping during the  initial_opto and  final_opto stages, use the  opt.common.enable_multibit_combinational_cells application option with the  set_app_options command: fc_shell>\u00a0 set_app_options -name opt.common.enable_multibit_combinational_cells -value true       Note: By default, the tool debanks the multibit combinational cells.\n Figure 37 Combinational Multibit Library Cell Flow To print the combinational multibit cells created for each library reference, use the -combinational option with the  report_multibit command, as shown in the following example: fc_shell>\u00a0 report_multibit -combinational --------------------------------------------------------------------- #Outputs\u00a0\u00a0Reference\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Number\u00a0of\u00a0instances\u00a0\u00a0\u00a0Single-bit Equivalent --------------------------------------------------------------------- 2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0combo_mbit_lib_cell1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0257\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0514 4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0combo_mbit_lib_cell2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a057\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0228 --------------------------------------------------------------------- To check the compatible single-bit equivalent cell of combinational multibit library cells, use the  -combinational option with the  check_multibit_library command, as shown in the following example: fc_shell>\u00a0 check_multibit_library -combinational ------------------------------------------------------------------------ Combinational\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Compatibility\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Equivalent\u00a0Singlebit Multibit\u00a0LibCell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0LibCell ------------------------------------------------------------------------ combo_mbit_lib_cell1\u00a0\u00a0\u00a0\u00a0Compatible\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0combo_sbit_lib_cell1 Don't\u00a0use\u00a0Mismatch\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0combo_sbit_lib_cell2       combo_mbit_lib_cell2\u00a0\u00a0\u00a0\u00a0PVT\u00a0mismatch\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0combo_sbit_lib_cell3 ------------------------------------------------------------------------"}
{"header": "How do I Useful Skew", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Changing clock latencies can balance the slack in successive timing path stages to optimize clock and data paths.\n This capability is called concurrent clock and data (CCD) optimization, which can reduce total negative slacks (TNS), worst negative slacks (WNS), area, and leakage power.\n In addition, it can improve correlation between physical synthesis and place-and-route."}
{"header": "How do I Controlling Concurrent Clock and Data Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "This figure shows how concurrent clock and data optimization allows for clock skew to remove negative slack and potential area and leakage recovery."}
{"header": "How do I Controlling Clock Latencies, Path Groups, and Boundary Paths", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool performs concurrent clock and data optimization during the compile_fusion command.\n You can disable it by setting the  compile.flow.enable_ccd application option to  false.\n The default is  true.\n During concurrent clock and data optimization, \u2022 The tool uses ideal clock tree, and it updates clock latencies and balance points for all active scenarios.\n \u2022 The tool adjusts the register latencies within the delayed and advanced latency settings for the most critical sequential elements in the design.\n By default, the maximum delayed latency is 100 ps, and the maximum advanced latency is 300 ps.\n \u2022 All path groups are considered for useful skew computation.\n \u2022 All boundary timing paths are considered during concurrent clock and data optimization.\n Note: In an incremental compile, enabling concurrent clock and data optimization has no effect.\n For best results, you should also do the following: \u2022 Enable the hold scenario even during compile to reduce hold violations that are caused by clock latency insertions during concurrent clock and data optimization.\n The tool considers the hold scenario only for concurrent clock and data optimization, but not for other optimization steps.\n \u2022 Enable concurrent clock and data optimization for the  clock_opt command."}
{"header": "How do I Reducing Dynamic Voltage Drop", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify a maximum delayed latency for useful skew computation, set the ccd.max_postpone application option to a specific value, as shown in the following example: fc_shell>\u00a0 set_app_options \\ ccd.max_postpone 50       To specify a maximum advanced latency for useful skew computation, set the ccd.max_prepone application option to a specific value, as shown in the following example: fc_shell>\u00a0 set_app_options \\ ccd.max_prepone 100 To omit useful skew computation for specific path groups, specify one or more path groups with the  ccd.skip_path_groups application option as follows: fc_shell>\u00a0 set_app_options ccd.skip_path_groups  path_group_list To disable concurrent clock and data optimization for boundary timing paths, set the ccd.optimize_boundary_timing application to  false, changing it from its default of  true.\n All optimization on I/O paths and latencies for boundary registers will not be adjusted to improve register to register timing.\n fc_shell>\u00a0 set_app_options ccd.optimize_boundary_timing false"}
{"header": "How do I Specifying Optimization Targets at the Preroute Stage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When running the  compile_fusion command, you can reduce dynamic voltage drop across a block by enabling dynamic power shaping optimization by setting the compile.flow.enable_dps application option to  true.\n The tool performs dynamic power shaping optimization during the  final_opto stage of the  compile_fusion command.\n When you enable this feature, the tool performs power analysis and uses useful skew techniques to reduce dynamic voltage drop.\n Optionally, you can customize the power analysis performed during dynamic power shaping optimization by using the ccd.dps.use_case application option."}
{"header": "How do I Transferring to Back End", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When performing concurrent clock and data optimization using the  compile_fusion command, you can give a higher priority to the WNS optimization of \u2022 Certain path groups by specifying them by using the  ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell>\u00a0 set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2} If a path group you specify with this application option is also specified as a path group to skip with the  ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization.\n       \u2022 Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell>\u00a0 set_app_options \\ -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified path groups.\n \u2022 The worst 300 timing paths by setting the  ccd.enable_top_wns_optimization application option to  true"}
{"header": "How do I Performing Test Insertion and Scan Synthesis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To transfer the clock latencies and balance points from the front-end tool to the back-end tool, use the  write_ascii_files command.\n The command writes the  design.MCMM directory, which contains timing contexts in Tcl files for.\n For example, The  design.MCMM/scenario_ scenario.tcl file contains the following clock latency settings: set_clock_latency\u00a0-clock\u00a0[get_clocks\u00a0{CLK}]\u00a0-0.3\u00a0[get_pins\u00a0{d_reg[4]/CP}] set_clock_latency\u00a0-clock\u00a0[get_clocks\u00a0{CLK}]\u00a00.1\u00a0[get_pins\u00a0{d_reg[7]/CP}] The  design.MCMM/mode_ mode.tcl file contains the following balance points: set_clock_balance_points\u00a0-clock\u00a0[get_clocks\u00a0{CLK}]\u00a0\\ -balance_points\u00a0[get_pins\u00a0{d_reg[4]/CP}]\u00a0\\ -consider_for_balancing\u00a0true\u00a0\\ -rise\u00a0-delay\u00a00.3\u00a0-corners\u00a0[get_corners\u00a0{default}] set_clock_balance_points\u00a0-clock\u00a0[get_clocks\u00a0{CLK}]\u00a0\\ -balance_points\u00a0[get_pins\u00a0{d_reg[7]/CP}]\u00a0\\ -consider_for_balancing\u00a0true -rise\u00a0-delay\u00a0-0.1\u00a0-corners\u00a0[get_corners\u00a0{default}]"}
{"header": "How do I Scan Synthesis Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Fusion Compiler test synthesis solution enables transparent implementation of DFT capabilities into the Synopsys synthesis flow without interfering with functional, timing, signal integrity, or power requirements.\n The test solution for Fusion Compiler consists of two stages: \u2022 Scan Synthesis Flow \u2022 Minimizing Glitches on Asynchronous Set and Reset Lines of Scan Registers       Benefits of two-stage test insertion include \u2022 Better timing, area, power, and congestion QoR for logic and DFT synthesis at the same time \u2022 Better integration of power intent and DFT logic \u2022 Improved congestion optimization that considers the placement for compressor and decompressor (codec) test logic \u2022 Eliminating the incremental compile step to synthesize and place the DFT logic"}
{"header": "How do I Minimizing Glitches on Asynchronous Set and Reset Lines of", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Specifying synthesis constraints specific to DFT insertion for certain registers must be mapped to non-scan versions and the core wrapper reuse threshold.\n To specify the DFT configurations: 1.\n Execute  compile_fusion\u00a0-from\u00a0initial_map\u00a0-to\u00a0logic_opto.\n 2.\n Specify the DFT configurations such as DFT signals, chain counts, test modes, and so on.\n 3.\n Complete the DFT insertion.\n For more information about DFT insertion, see the TestMAX DFT User Guide.\n 4.\n Execute  compile_fusion\u00a0-from\u00a0initial_place.\n Note: You must create scan test and scan in and scan out ports before importing floorplan information.\n In addition, the floorplan must contain the physical locations of the test and scan ports.\n Scan-Only Script Example #\u00a0Set\u00a0up\u00a0the\u00a0library...\n #\u00a0Read\u00a0the\u00a0design...\n #\u00a0Specify\u00a0any\u00a0registers\u00a0that\u00a0should\u00a0not\u00a0be\u00a0mapped\u00a0to\u00a0scan\u00a0equivalent,\u00a0and also\u00a0to\u00a0be\u00a0excluded\u00a0from\u00a0any\u00a0scan\u00a0chains set_scan_element\u00a0false\u00a0<registers\u00a0that\u00a0should\u00a0not\u00a0be\u00a0mapped\u00a0to\u00a0scan equivalent> #\u00a0Run\u00a0compile_fusion\u00a0to\u00a0logic_opto\u00a0step compile_fusion\u00a0-to\u00a0logic_opto #\u00a0DFT\u00a0Specifications: #\u00a0Scan\u00a0chain\u00a0setup set_scan_configuration\u00a0-chain_count\u00a0sc #\u00a0DFT\u00a0signals #\u00a0Clocks\u00a0and\u00a0asynchronous\u00a0resets       set_dft_signal\u00a0-view\u00a0existing\u00a0-type\u00a0ScanClock\u00a0\\ -port\u00a0clk\u00a0-timing\u00a0[list\u00a045\u00a055] set_dft_signal\u00a0-view\u00a0existing\u00a0-type\u00a0Reset\u00a0\\ -port\u00a0reset_n\u00a0-active_state0 #\u00a0Scan\u00a0in,\u00a0scan\u00a0out,\u00a0scan\u00a0enable set_dft_signal\u00a0-view\u00a0spec\u00a0-type\u00a0ScanDataIn\u00a0-port\u00a0SI set_dft_signal\u00a0-view\u00a0spec\u00a0-type\u00a0ScanDataOut\u00a0-port\u00a0SO set_dft_signal\u00a0-view\u00a0spec\u00a0-type\u00a0ScanEnable\u00a0-port\u00a0SE #\u00a0Scan\u00a0Synthesis\u00a0steps create_test_protocol dft_drc preview_dft insert_dft #\u00a0Continue\u00a0from\u00a0initial_place\u00a0step compile_fusion\u00a0-from\u00a0initial_place\u00a0-to\u00a0initial_opto #\u00a0Perform\u00a0post\u00a0dft_drc dft_drc\u00a0-test_mode\u00a0Internal_scan #\u00a0Generate\u00a0post\u00a0dft_drc\u00a0verbose\u00a0report report_dft_drc_violations\u00a0-test_mode\u00a0Internal_scan\u00a0-rule\u00a0all #\u00a0Write\u00a0out\u00a0Scandef write_scan_def\u00a0 design.scan.def #\u00a0Write\u00a0out\u00a0test\u00a0model write_test_model\u00a0-output\u00a0 design.ctl #\u00a0Save\u00a0output\u00a0for\u00a0TetraMAX write_test_protocol\u00a0-output\u00a0 design.scan.spf \\ -test_mode\u00a0Internal_scan write_verilog\u00a0-hierarchy\u00a0all\u00a0 design.v"}
{"header": "How do I Specifying Settings for Performance, Power, and Area", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When a design switches between the functional and scan modes, glitches might occur on asynchronous set and reset lines of scan registers, which can reset the state of these registers.\n The tool can prevent this by adding gating logic to the asynchronous set and reset lines.\n To enable this feature, you must specify a top-level port to control the gating logic by using the  set_register_async_gating_pin\u00a0-port command.\n This control port must be a predefined port in the RTL that is not connected to any other net.\n To get information about such gated scan registers, run the  report_async_gated_registers command after physical synthesis.\n The added gating logic can be an AND or OR gate, depending on the polarity of the asynchronous pins on the scan registers.\n When gating logic is added, the Formality tool requires additional information to verify the design and the Fusion Compiler tool generates an appropriate.svf file that disables the gating logic in the functional mode.\n Note: This feature is supported only for the in-compile DFT flow."}
{"header": "How do I Enabling High-Effort Timing Mode", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics provide information settings you can use to improve performance, power, and area (PPA) of a design: \u2022 Enabling High-Effort Timing Mode \u2022 Enabling Enhanced Delay Optimization to Improve Total Negative Slack \u2022 Enabling High-Effort Area Mode \u2022 Enabling the Embedded Area Optimization Flow"}
{"header": "How do I Enabling Enhanced Delay Optimization to Improve Total Negative", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In most cases, you can achieve better timing QoR by enabling high-effort timing mode for compile.\n To enable this mode, set the  compile.flow.high_effort_timing application option to  1.\n Running high-effort timing mode during compile can increase runtime because the tool performs multiple passes of placement and optimization to obtain optimal timing results."}
{"header": "How do I Enabling High-Effort Area Mode", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can improve the total negative slack of a block by using path groups to focus the tool on fixing more violating paths during optimization.\n However,using this technique can increase the runtime and degrade the area and power QoR.\n To enable enhanced delay optimization techniques that improve total negative slack, set the  compile.flow.enhanced_delay_opto_for_pg application option to  1.\n This feature has better runtime and better area and power QoR, as compared to the extensive use of path groups to improve total negative slack."}
{"header": "How do I Enabling the Embedded Area Optimization Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "On designs that need further reduction of area, set the  compile.flow.high_effort_area application option to  true.\n Running high-effort area mode during compile might increase runtime because the tool performs multiple passes of placement and optimization to obtain optimal area results."}
{"header": "How do I Performing Design Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the  logic_opto stage of the  compile_fusion command, as an initial step, the tool performs timing optimization and DesignWare reselection and ungrouping.\n After this initial step, the tool can perform an optional embedded area optimization flow before moving on to other optimization techniques performed during the  logic_opto stage.\n The embedded area optimization flow consists of dedicated ungrouping, fast area- driven logic restructuring, and light timing optimization.\n To enable this feature, set the compile.flow.areaResynthesis application option to  true.\n This feature can reduce the area of blocks with many DesignWare hierarchies."}
{"header": "How do I Reporting Commands and Examples", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the reports generated by Fusion Compiler to analyze and debug your design.\n You can generate reports before and after you compile your design.\n Generate reports before compile to check that you have set attributes, constraints, and design rules properly.\n Generate reports after compile to analyze the results and debug your design.\n This section includes the following topics: \u2022 Reporting Commands and Examples \u2022 Measuring Quality of Results \u2022 Comparing QoR Data \u2022 Reporting Logic Levels in Batch Mode \u2022 Querying Specific Message IDs"}
{"header": "How do I Measuring Quality of Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "This table shows some reporting commands to report QoR, timing, area, and so on.\n Use this command To do this report_area    report_qor   report_timing        Use this command To do this report_power   report_clock_gating  report_logic_levels  report_area Example fc_shell>\u00a0 report_area -designware -hierarchy -physical **************************************** Report\u00a0:\u00a0area Design\u00a0:\u00a0test...\n **************************************** Information:\u00a0Base\u00a0Cell\u00a0(com):\u00a0cell\u00a0XNOR2ELL,\u00a0w=3300,\u00a0h=6270\u00a0(npin=3) Information:\u00a0Base\u00a0Cell\u00a0(seq):\u00a0cell\u00a0LPSDFE2,\u00a0w=10560,\u00a0h=6270\u00a0(npin=5) Number\u00a0of\u00a0cells:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a08 Number\u00a0of\u00a0combinational\u00a0cells:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04 Number\u00a0of\u00a0sequential\u00a0cells:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04 Number\u00a0of\u00a0macros/black\u00a0boxes:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Number\u00a0of\u00a0buf/inv\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Number\u00a0of\u00a0references\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 Combinational\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a049.66 Buf/Inv\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.00 Noncombinational\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0231.74 Macro/Black\u00a0box\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.00 Total\u00a0cell\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0281.40 ____________________________________________________________________  Hierarchical\u00a0area\u00a0distribution ------------------------------ Global\u00a0cell\u00a0area\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Local\u00a0cell\u00a0area --------------------------------------------- Hierarchical\u00a0cell\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Absolute\u00a0\u00a0Percent\u00a0\u00a0Combi-\u00a0\u00a0\u00a0Noncombi-\u00a0\u00a0Black- Total\u00a0\u00a0\u00a0\u00a0\u00a0Total\u00a0\u00a0\u00a0\u00a0national\u00a0national\u00a0\u00a0\u00a0boxes Design -------------------------------------------------------------------- test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0281.40\u00a0\u00a0\u00a0\u00a0100.0\u00a0\u00a0\u00a0\u00a037.24\u00a0\u00a0\u00a0\u00a0231.74\u00a0\u00a0\u00a0\u00a0\u00a00.00 test mult_10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a012.41\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04.4\u00a0\u00a0\u00a0\u00a012.41\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.00\u00a0\u00a0\u00a0\u00a0\u00a00.00 DW_mult_uns_J1_H3_D1 -------------------------------------------------------------------- Total\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a049.66\u00a0\u00a0\u00a0\u00a0231.74\u00a0\u00a0\u00a0\u00a0\u00a00.00  Area\u00a0of\u00a0detected\u00a0synthetic\u00a0parts ---------------------------------- Perc.of Module\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Implem.\n \u00a0\u00a0Count\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Area\u00a0\u00a0\u00a0cell\u00a0area       ---------------------------------------------------- DW_mult_uns\u00a0\u00a0pparch\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a012.41\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04.4% ---------------------------------------------------- Total:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a012.41\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04.4%  Estimated\u00a0area\u00a0of\u00a0ungrouped\u00a0synthetic\u00a0parts ------------------------------------------- Estimated\u00a0\u00a0\u00a0Perc.\n of Module\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Implem.\n \u00a0\u00a0Count\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0area\u00a0\u00a0cell\u00a0area ---------------------------------------------------- DW_mult_uns\u00a0\u00a0pparch\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048.28\u00a0\u00a0\u00a0\u00a0\u00a0\u00a017.2% ---------------------------------------------------- Total:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048.28\u00a0\u00a0\u00a0\u00a0\u00a0\u00a017.2%  Total\u00a0synthetic\u00a0cell\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a060.69\u00a0\u00a0\u00a021.6%\u00a0(estimated) ____________________________________________________________  Core\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01767 Aspect\u00a0Ratio:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01.0902 Utilization\u00a0Ratio:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.1593  The\u00a0above\u00a0information\u00a0was\u00a0from\u00a0the\u00a0logic\u00a0library.\n The\u00a0following\u00a0information\u00a0was\u00a0from\u00a0the\u00a0physical\u00a0library:  Total\u00a0moveable\u00a0cell\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0281.4 Total\u00a0fixed\u00a0cell\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.0 Total\u00a0physical\u00a0cell\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0281.4 Core\u00a0area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.000,\u00a00.000,\u00a040.260,\u00a043.890 report_qor Example fc_shell>\u00a0 report_qor *********************************************** Report\u00a0:\u00a0qor Design\u00a0:\u00a0top...\n *********************************************** Scenario\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0'SC1' Timing\u00a0Path\u00a0Group\u00a0\u00a0\u00a0\u00a0\u00a0'clk' ----------------------------------------------- Levels\u00a0of\u00a0Logic:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a06 Critical\u00a0Path\u00a0Length:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.28 Critical\u00a0Path\u00a0Slack:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.19 Critical\u00a0Path\u00a0Clk\u00a0Period:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.30 Total\u00a0Negative\u00a0Slack:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.80 No.\n of\u00a0Violating\u00a0Paths:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a011 Worst\u00a0Hold\u00a0Violation:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.07 Total\u00a0Hold\u00a0Violation:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.13 No.\n of\u00a0Hold\u00a0Violations:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a032.00 -----------------------------------------------  Cell\u00a0Count -----------------------------------------------       Hierarchical\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 Hierarchical\u00a0Port\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a024 Leaf\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0287 Buf/Inv\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a045 Buf\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04 Inv\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a041 CT\u00a0Buf/Inv\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Combinational\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0208 Sequential\u00a0Cell\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a079 Macro\u00a0Count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 -----------------------------------------------  Area ----------------------------------------------- Combinational\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0419.34 Noncombinational\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0736.26 Buf/Inv\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a067.60 Total\u00a0Buffer\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a09.66 Total\u00a0Inverter\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a057.94 Macro/Black\u00a0Box\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02337.90 Net\u00a0Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Net\u00a0XLength:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Net\u00a0YLength:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 ----------------------------------------------- Cell\u00a0Area\u00a0(netlist):\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03493.49 Cell\u00a0Area\u00a0(netlist\u00a0and\u00a0physical\u00a0only):\u00a03493.49 Net\u00a0Length:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00  Design\u00a0Rules ----------------------------------------------- Total\u00a0Number\u00a0of\u00a0Nets:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0363 Nets\u00a0With\u00a0Violations:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Max\u00a0Trans\u00a0Violations:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Max\u00a0Cap\u00a0Violations:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 ----------------------------------------------- report_transformed_registers Example The  report_transformed_registers command reports the following information about registers that are modified or removed during compile: \u2022 Sequential output ports inversion \u2022 Constant registers that are removed and the constant values \u2022 Constant registers that are preserved by users \u2022 Unloaded registers that are removed \u2022 Unloaded registers that are preserved by users \u2022 Register merging       \u2022 Register replication \u2022 Shift registers \u2022 Multibit registers \u2022 Summary of register optimizations Use the  report_transformed_registers command only on a mapped design generated by compile or incremental compile.\n If you run the command on an unmapped design, the report_transformed_registers command reports no information.\n The information of transformed or optimized registers is stored in the design library, so you can query the same information by using the  report_transformed_registers command in different sessions.\n For example, fc_shell>\u00a0 report_transformed_registers **************************************** Report:\u00a0report_transformed_registers Version:\u00a0...\n Date:\u00a0...\n **************************************** Legend: C0p\u00a0-\u00a0constant\u00a00\u00a0register\u00a0preserved C1p\u00a0-\u00a0constant\u00a01\u00a0register\u00a0preserved C0r\u00a0-\u00a0constant\u00a00\u00a0register\u00a0removed C1r\u00a0-\u00a0constant\u00a01\u00a0register\u00a0removed ulp\u00a0-\u00a0preserved\u00a0unloaded\u00a0register ulr\u00a0-\u00a0removed\u00a0unloaded\u00a0register mrg\u00a0-\u00a0merged\u00a0register srh\u00a0-\u00a0shift\u00a0register\u00a0head srf\u00a0-\u00a0shift\u00a0register\u00a0flop mb\u00a0\u00a0-\u00a0multibit rep\u00a0-\u00a0replicated inv\u00a0-\u00a0inverted   Register\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Optimization ---------------------------------------------------------\u00a0------------ I_RISC_CORE/I_DATA_PATH/PSWL_Carry_reg\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0C0r I_RISC_CORE/I_STACK_TOP/I3_STACK_MEM/Stack_Mem_reg[0][0]\u00a0\u00a0C0r I_RISC_CORE/I_STACK_TOP/I3_STACK_MEM/Stack_Mem_reg[1][0]\u00a0\u00a0C0r To report the count of each type of register transformation, specify the  -summary option as shown in the following example: fc_shell>\u00a0 report_transformed_registers -summary **************************************** Report:\u00a0report_transformed_registers Version:\u00a0...\n Date:\u00a0...\n       **************************************** Legend: C0p\u00a0-\u00a0constant\u00a00\u00a0register\u00a0preserved C1p\u00a0-\u00a0constant\u00a01\u00a0register\u00a0preserved C0r\u00a0-\u00a0constant\u00a00\u00a0register\u00a0removed C1r\u00a0-\u00a0constant\u00a01\u00a0register\u00a0removed ulp\u00a0-\u00a0preserved\u00a0unloaded\u00a0register ulr\u00a0-\u00a0removed\u00a0unloaded\u00a0register mrg\u00a0-\u00a0merged\u00a0register srh\u00a0-\u00a0shift\u00a0register\u00a0head"}
{"header": "How do I Measuring Quality of Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "srf\u00a0-\u00a0shift\u00a0register\u00a0flop mb\u00a0\u00a0-\u00a0multibit rep\u00a0-\u00a0replicated inv\u00a0-\u00a0inverted  Register\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Count ---------------------------------------------------------------------- Constant\u00a0Registers\u00a0Deleted\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a012 Constant\u00a0Registers\u00a0Preserved\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 Unloaded\u00a0Registers\u00a0Deleted\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0101 Unloaded\u00a0Registers\u00a0Preserved\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a038 Shift\u00a0Registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0170 Merged\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a012 Multibit\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a010 Inverted\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a015 Replicated\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04"}
{"header": "How do I Comparing QoR Data", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To measure the quality of results (QoR) of the design in the current state and store the quality information in a set of report files, use the  create_qor_snapshot command.\n You can capture the QoR information using different optimization strategies or at different stages of the design and compare the quality of results.\n The  create_qor_snapshot command measures and reports the quality of the design in terms of timing, design rules, area, power, congestion, and so on.\n It stores the quality information into a set of snapshot files in a directory named snapshot under the current working directory.\n To store the quality information in a different directory, use the time.snapshot_storage_location application option.\n The following example generates a QoR snapshot named r1 using zero wire load for timing paths in the snapshot directory: fc_shell>\u00a0 create_qor_snapshot -name r1 -zero_wire_load...\n No.\n of\u00a0scenario\u00a0=\u00a04 s1\u00a0=\u00a0function s2\u00a0=\u00a0function_min s3\u00a0=\u00a0test s4\u00a0=\u00a0test_min       ------------------------------------------------------------------------ --- WNS\u00a0of\u00a0each\u00a0timing\u00a0group:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0s1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0s2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0s3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0s4 ------------------------------------------------------------------------- REGIN\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.34\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- fref_clk0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02.34\u00a0\u00a0\u00a0\u00a0\u00a03.25\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- pld_clk\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.65\u00a0\u00a0\u00a0\u00a0\u00a01.65\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- pll_fixed_clk_central\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.61\u00a0\u00a0\u00a0\u00a0\u00a01.65\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- REGOUT\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.39\u00a0\u00a0\u00a0\u00a0\u00a00.44\u00a0\u00a0\u00a0\u00a0\u00a01.18\u00a0\u00a0\u00a0\u00a0\u00a01.72...\n ------------------------------------------------------------------------- Setup\u00a0WNS:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.34\u00a0\u00a0\u00a0\u00a0\u00a00.44\u00a0\u00a0\u00a0\u00a0\u00a01.02\u00a0\u00a0\u00a0\u00a0\u00a01.10\u00a0\u00a0\u00a0\u00a0\u00a0-0.34 Setup\u00a0TNS:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-130.82\u00a0\u00a0\u00a0\u00a0\u00a00.00\u00a0\u00a0\u00a0\u00a0\u00a00.00\u00a0\u00a0\u00a0\u00a0\u00a00.00\u00a0\u00a0\u00a0-130.82 Number\u00a0of\u00a0setup\u00a0violations:\u00a0\u00a0\u00a01152\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01152 Hold\u00a0WNS:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0-0.55\u00a0\u00a0\u00a0\u00a0-0.78\u00a0\u00a0\u00a0\u00a0-0.30\u00a0\u00a0\u00a0\u00a0-1.28\u00a0\u00a0\u00a0\u00a0\u00a0-1.28...\n ------------------------------------------------------------------------- Area:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01200539.606 Cell\u00a0count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0562504 Buf/inv\u00a0cell\u00a0count:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0145920 Std\u00a0cell\u00a0utilization:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.24...\n Querying QoR Snapshots To retrieve and report the snapshots created by the  create_qor_snapshot command, use the  query_qor_snapshot command.\n The  query_qor_snapshot command analyzes the QoR timing reports previously generated and displays the results in HTML format according to the specified filters.\n In this example, the  query_qor_snapshot command analyzes the placeopt snapshot that is stored in the snapshot directory and then reports the timing paths with worst negative slack values between -2.0 ns and -1.0 ns: fc_shell>\u00a0 create_qor_snapshot -name placeopt fc_shell>\u00a0 query_qor_snapshot -name placeopt -filters \"-wns -2.0,-1.0\" Reporting QoR Snapshots To display QoR information and statistics for the current design, use the  report_qor command.\n For example, the following command displays the r1 QoR snapshot that is stored in the snapshot directory: fc_shell>\u00a0 report_qor_snapshot -name r1 -display Removing QoR Snapshots To remove an existing QoR snapshot from the directory specified by the time.snapshot_storage_location application option, use the  remove_qor_snapshot       command.\n For example, the following command removes the preroute QoR snapshot that is stored in the snapshot directory: fc_shell>\u00a0 remove_qor_snapshot -name preroute"}
{"header": "How do I Setting Your Baseline Run", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can generate a web-based report to view and compare your QoR data with a QORsum report by performing the following steps: 1.\n (Optional) Configure the QoR data, which is captured and displayed in the subsequent steps, by using the  set_qor_data_options command.\n \u25e6 To specify the most critical power scenarios in your design, use the -leakage_scenario and  -dynamic_scenario options.\n The tool uses the power scenarios you specify to generate the high-level summary of the power QoR in the QORsum report.\n If you do not specify these options, it uses the active power scenario with the highest total power for both the leakage and dynamic scenario for the power QoR summary.\n These settings are only used for the power QoR summary.\n The tool uses the power information of all active power scenarios to capture and report the detailed power information in the QORsum report.\n \u25e6 To specify the most critical clock name and clock scenario, use the  -clock_name and  -clock_scenario options.\n The tool uses the clock name and scenario you specify to generate the high-level summary of the clock QoR in the QORsum report.\n If you do not specify these options, the tool identifies the most critical clock and uses it for the clock QoR summary.\n These settings are only used for the clock QoR summary.\n The tool uses all clocks to generate the detailed clock QoR information in the QORsum report.\n \u25e6 To specify a name to identify the run in the QORsum report, use the  -run_name option.\n By default, the tool names each run with a number, such as Run1, Run2, and so on.\n You can use this option to give a more meaningful name to each run.\n You can also specify the run name by using the  -run_names option when you generate the QORsum report by using the  compare_qor_data command in step  3.\n If you do so, the tool ignores the run name specify by the  set_qor_data_options\u00a0-run_name command.\n       The following example specifies the leakage-power scenario, dynamic-power scenario, clock scenario, and the clock to use for the corresponding summary in the QORsum report: fc_shell>\u00a0 set_qor_data_options \\ -leakage_scenario S1 -dynamic_scenario S2 \\ -clock_scenario S3 -clock_name sys_clk 2.\n Collect the QoR data for your report by using the  write_qor_data command.\n The write_qor_data command captures QoR data related to timing, power, runtime, and other metrics.\n You can run the  write_qor_data command multiple times, at each stage of the design flow at which you want to capture QoR data.\n Use the  -label and specify a value to indicate at which stage of the flow you are capturing the data.\n By default, the  write_qor_data command captures data relevant to a placed and optimized design.\n You can specify the  -report_group option with any of the five supported value ( unmapped,  mapped,  placed,  cts,  routed ) to tune the set of reports being captured, based on the state of the flow where you are capturing the data.\n For finer-grain control, use the  -report_list option to explicitly specify each report you want to generate.\n The  write_qor_data command captures a standard set of QoR data to disk from most of the common tool reports like the  report_qor and  report_power.\n If there is additional custom data to capture that is not part of the command collection, use the  capture_qor_data command to capture fully custom QoR data or GUI layout images to include in the web-based QORsum report.\n This can be used to supplement the standard QoR data captured by the  write_qor_data command, or to create fully custom QORsum reports.\n Related commands include  define_qor_data_panel, that lets you create a new panel in the QORsum report for viewing QoR data, and set_qor_data_metric_properties, that lets you customize the properties of any metric column in any QORsum report panel, so you can control things like the style of coloring, or the thresholds for coloring when comparing data.\n 3.\n Generate the QORsum report by using the  compare_qor_data command.\n This command takes the data captured by one or more runs of the  write_qor_data command and creates a web-based report for viewing and comparing those results.\n You must specify the location of the output of each of the  write_qor_data runs from the previous step by using  -run_locations option.\n Each path location corresponds to the run result that you want to compare.\n You can assign a specific name to identify the run in the QORsum report by using the -run_names option.\n If you do so, the tool ignores the run name specify by using the set_qor_data_options\u00a0-run_name command.\n By default, the tool names each run by a number, such as run1, run2, and so on.\n       You can specify the output directory by using the  -output option.\n By default, the tool writes the report to a directory named compare_qor_data.\n To overwrite exiting output data, use the  -force option.\n By default, the tool does not overwrite existing output data.\n 4.\n View the generated QORsum report by using the  view_qor_data command.\n Figure 38 QORsum Report For more information about exploring the comparison data, see the following topics: \u2022 Setting Your Baseline Run \u2022 Changing the QoR Display Style \u2022 Sorting and Filtering the Data \u2022 Exploring the Detailed Comparison Data"}
{"header": "How do I Changing the QoR Display Style", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the first row of data is your baseline run against which all other runs are compared.\n The name of the baseline run is highlighted in gold to mark it as the \u201cgolden,\u201d or baseline, result.\n       The shading of non-baseline cells indicates the direction and degree by which the data differs from the baseline: \u2022 Red indicates a degradation compared to the baseline; green indicates an improvement compared to the baseline \u2022 Lighter shading represents a smaller difference compared to the baseline; darker shading represents a larger difference compared to the baseline To view the delta thresholds corresponding to each shade, hover the cursor over the column headers: To change your baseline run, click the Runs button and select a new run as the baseline from the Baseline Run column, as shown in the following figure:       See Also \u2022 Changing the QoR Display Style \u2022 Sorting and Filtering the Data \u2022 Exploring the Detailed Comparison Data"}
{"header": "How do I Sorting and Filtering the Data", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the comparison tables show the QoR values for all runs.\n For example, the NVE number for the following run is 2374: To cycle through different display styles of the data, right-click anywhere in the table.\n You can view the data \u2022 as a percentage delta against the baseline \u2022 as an absolute delta against the baseline (shown in  italic ) For example, as a percentage delta, the NVE number shows 2.7% fewer failing endpoints than the baseline: As an absolute delta, the NVE number shows 65 fewer failing endpoints than the baseline: See Also \u2022 Sorting and Filtering the Data \u2022 Exploring the Detailed Comparison Data"}
{"header": "How do I Exploring the Detailed Comparison Data", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further.\n To sort and filter the data, see the following topics: \u2022 Sorting the Data \u2022 Filtering Metrics \u2022 Filtering Runs \u2022 Example Analysis See Also \u2022 Exploring the Detailed Comparison Data       Sorting the Data Click any column header to sort the data using that metric.\n The first click performs an ascending sort, while the second click performs a descending sort.\n For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom:       Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly.\n For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in  Figure\u00a039.\n Figure 39 Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column.\n For example, to display only the first four runs in a table, select the runs as shown in Figure\u00a040.\n Figure 40 Choose Baseline and Visible Runs Dialog Box       Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further.\n Suppose you open the comparison report shown in  Figure\u00a041 and set the util60_aspect1%1_layerM9 run as the base run.\n Figure 41 Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer.\n This suggests that restricting the metal layers significantly impacts timing.\n       You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs.\n You could restrict your analysis to your lower-utilization runs by turning off the       visibility of your higher-utilization runs as shown in  Figure\u00a042, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals.\n Figure 42 Displaying Lower-Utilization Runs"}
{"header": "How do I Reporting Logic Levels in Batch Mode", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you launch the QORsum report, the application opens the QOR Summary table, which summarizes high-level timing, power, and congestion metrics for each of your runs.\n This and other summary views help you sort and filter the data to pinpoint the runs you want to explore further.\n Detailed table panels provide deeper insight into your data than can be found on the summary tables.\n For example, a summary table might give a high-level overview of design timing (WNS, TNS, NVE) at each major stage in the flow.\n A detailed table might show more in-depth path-group based timing information, showing the timing numbers for each separate scenario and path group in the design.\n This is only one example.\n There are many detailed table panels in the QORsum report, that shows information like statistics about each library cell instantiated in the design (number of instances, type of cell, total, area), or information about how much wirelength is on each routed metal layer.\n A detailed table lets you view this information for up to six different datasets at once.\n A dataset is a set of data captured for a specific run and stage/label in the flow.\n For example, you might view the  route_opt command results for three different runs at once.\n Or you might view one run, but looking at the progression of results across different stages in the design flow (place_opt, clock_opt, route_opt), as shown in the following figure.\n       Figure 43 Path Group Details The flows are shown side by side as columns under each metric.\n For example, the WNS column group (and the column group of each metric) shows the same six columns labeled 1, 2, 5, 6, 9, 10.\n These columns represent the results of each flow, and are given a flow ID number, rather than showing the full flow name, to prevent the columns from being too wide.\n The first column under each metric is the baseline, and the other five are the test flows being compared to that baseline.\n A legend is shown above the table with the flow ID number in a gold box (for the baseline) or a blue box (for the test flows), followed by the flow name.\n You can expand or collapse the legend by clicking the Legend button.\n You can also see the flow ID numbers in the \u201cChoose Baseline and Visible Runs\u201d dialog box, which is opened by clicking the Runs button.\n The detailed table views can display up to six runs at one time (your baseline run, plus the first five other runs selected in the Choose Baseline and Visible Runs dialog box).\n To change the runs that are displayed, 1.\n Click the Runs button to open the Choose Baseline and Visible Runs dialog box.\n 2.\n From the Visible Runs (Summary) column, select or deselect the runs accordingly.\n This selects and deselects those runs from the Visible flows (Detailed) column.\n Because a detailed table may show hundreds or even thousands of lines of data, it is not possible to view more than six datasets at a time.\n But if you want to see more details about these metrics across all runs and all flow stages/labels loaded into the QORsum report, there is an alternate view that shows this.\n This is called the Focused View.\n It can be accessed either by clicking the Focused View toggle button at the top of the report (see Figure 1), or by clicking on the frozen columns on the left side of the detailed table.\n In the focused view, you can see the results for all runs and all flow stages for a specific row of data from a detailed table.\n For example, in a path-group based timing detailed table, you might want to focus on the information only for path_group1 in scenarioA.\n To see this, click on the row in the detailed table for that path group and scenario.\n The Focused View for it opens.\n       Using the same path-group timing example, the focused view shows one path group at a time.\n You can change the focus to a different path group by selecting a different scenario or path group name in the drop-down menus at the top of the report.\n See  Figure\u00a044 Figure 44 Focused View Drop-down Menu Filtering the Detailed Data Detailed views offer filters to focus on specific data.\n Some views have default filters that are shown automatically.\n For example, the following detailed views have default scenario and path group filters: Path Type Details, Path Group Details, and Logic Level Details.\n You can modify the default filters by \u2022 Removing the filter by clicking the X symbol before the filter name \u2022 Changing the filter value \u2022 Enable and disable the filter by clicking anywhere on the filter but the X symbol or value field You can also apply custom filters to the detailed data.\n To create a custom filter, 1.\n Click the Filter button to display the Add Filter fields, which are shown in the following figure: 2.\n Define the filter by defining the filter criteria and selecting the datasets to include in the results.\n       To define the filter, select the column and comparison type, and then specify the comparison value.\n \u25e6 To perform a numeric comparison, select one of the following comparison types:  =,!=,  <,  <=,  >, or  >= and specify a numeric value in the Value field.\n \u25e6 To perform a string comparison, select the  contains comparison type and specify a string value in the Value field.\n \u25e6 To perform a regular expression comparison, select the  regexp comparison type and specify a regular expression in the Value field.\n \u25e6 To filter based on the available values of the selected column, select the  enum comparison type, which populates the Value field with a drop-down menu that contains the available values, and then enable one or more of the displayed values.\n When a value is enabled, a check mark is displayed before the value.\n To enable or disable a value, highlight the value by clicking it or navigating to it by using the Up and Down arrows, and then press Enter, which toggles the value status.\n You can also type a string in the Value field to filter the available values in the drop-down menu.\n To dismiss selected values, click the X symbol.\n 3.\n Apply the filter by clicking the green check mark.\n For example, to filter the Path Group Details view by displaying the path groups in the func@cworst scenario, define the filter as shown in the following figure:"}
{"header": "How do I Querying Specific Message IDs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "As an alternative to displaying logic-level histograms in the GUI, you can report logic levels by using the  report_logic_levels command on the command line or in a script (batch mode).\n Note: You must have a mapped design to run logic-level reporting.\n You can use the command to report logic levels of \u2022 The entire design or a selected path group \u2022 All types of paths, including same-clock paths, cross-clock paths, infeasible paths, and multicycle paths in all scenarios The report contains logic distribution and timing information in the summary, logic-level distribution, and logic-level path report sections.\n By default, buffers and inverters are not reported.\n       To report logic levels, 1.\n (Optional) Set a specific logic-level threshold other than the default by using the set_analyze_rtl_logic_level_threshold command.\n By default, the tool derives the logic-level threshold based on the delay values required for the paths.\n \u25e6 To set a logic-level threshold for the entire design, enter fc_shell>\u00a0 set_analyze_rtl_logic_level_threshold  threshold_value \u25e6 To set a logic-level threshold for a specific path group, enter fc_shell>\u00a0 set_analyze_rtl_logic_level_threshold \\ -group  path_group threshold_value The path group setting overrides the global threshold of the entire design.\n \u25e6 To reset all threshold values, enter fc_shell>\u00a0 set_analyze_rtl_logic_level_threshold -reset \u25e6 To reset a specific group setting, enter fc_shell>\u00a0 set_analyze_rtl_logic_level_threshold \\ -group  path_group  -reset 2.\n (Optional) Specify the fields in the summary section of the report by setting the shell.synthesis.logic_level_report_summary_format application option.\n The default contains five fields:  \"group\u00a0period\u00a0wns\u00a0num_paths\u00a0max_level\".\n You can specify up to eight fields.\n For example, fc_shell>\u00a0 set_app_options \\ -name shell.synthesis.logic_level_report_summary_format \\ -value \"group num_paths max_level min_level avg_level\"...\n 3.\n (Optional) Specify the fields in the path group section of the report by setting the shell.synthesis.logic_level_report_group_format application option.\n The default contains five fields:  \"slack\u00a0ll\u00a0llthreshold\u00a0startpoint\u00a0endpoint\".\n You can specify up to ten fields.\n For example, fc_shell>\u00a0 set_app_options \\ -name shell.synthesis.logic_level_report_group_format \\ -value \"slack ll ll_buf_inv clockcycles startclk endclk \"...\n 4.\n Report logic levels by using the  report_logic_levels command.\n The following example generates a logic-level report of the clk_i path group: fc_shell>\u00a0 report_logic_levels -group clk_i"}
{"header": "How do I 4", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "To query specific information, warning, or error message IDs that occurred during the previous command step, you can use the  check_error command.\n Follow these steps to set up and query the message IDs: 1.\n Specify the message IDs to query by using the global scope application option, shell.common.check_error_list.\n fc_shell>\u00a0 set_app_options -name shell.common.check_error_list \\ -value {DES-001 CMD-005} shell.common.check_error_list\u00a0{DES-001\u00a0CMD-005} 2.\n Use the  link command as an example for the previous command step.\n fc_shell>\u00a0 link Error:\u00a0Current\u00a0block\u00a0is\u00a0not\u00a0defined.\n (DES-001) 3.\n Query the specified message IDs that were issued during the  link command step by using the  check_error command.\n fc_shell>\u00a0 check_error -verbose {DES-001} 1 The result shows that the DES-001 message ID was issued during the  link command step.\n If none of the specified message IDs was issued, the  check_error command returns 0."}
{"header": "How do I Introduction to Clock Gating", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "RTL clock gating is a power optimization feature provided by the Fusion Compiler tool.\n This is a high-level optimization technique that can save a significant amount of power by adding clock gates to registers that are not always enabled and have synchronous load- enable or explicit feedback loops.\n The tool gates flip-flops by extracting common enable signals shared by the flip-flops either in the same hierarchy or across hierarchies.\n This technique greatly reduces dynamic power consumption by reducing the switching activity on the clock inputs to registers and eliminating the multiplexers.\n It can also result in a smaller chip area.\n Clock gating occurs by default during the  compile_fusion command using specified clock-gating settings.\n If you do not specify any clock-gating constraints, the default constraints are used.\n While you cannot disable clock gating, you can use the clock-gating commands in this section to prevent insertion of clock gates in specific blocks or the whole design.\n The tool identifies preexisting clock-gating cells during the  analyze and  elaborate commands.\n The tool inserts one more level of clock-gating cells at the leaf level.\n For more information, see the following topics: \u2022 Introduction to Clock Gating \u2022 Clock-Gating Prerequisite Conditions \u2022 Setting Up Clock Gating \u2022 Clock Gating Flows \u2022 Replacing Clock Gates \u2022 Controlling Clock-Gate Latencies \u2022 Controlling the Number of Clock-Gate Levels \u2022 Merging Clock Gates \u2022 Setting Clock Gating Transformations \u2022 Setting Routing Rules for Clock Gates \u2022 Clock Gating and Multibit Registers       \u2022 Placement-Aware Clock Gating \u2022 Fanin-Based Sequential Clock Gating \u2022 Reporting Clock-Gating Results \u2022 Reporting Clock-Gate Enable Signals \u2022 Clock Gate Efficiency Reporting \u2022 Self-Gating Optimization \u2022 Special Naming and Querying for DFT Wrapper Clock Gates"}
{"header": "How do I Naming Convention for Tool-Inserted Clock Gates", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Clock gating applies to synchronous load-enable registers, which are flip-flops that share the same clock and synchronous control signals.\n Synchronous control signals include synchronous load-enable, synchronous set, synchronous reset, and synchronous toggle.\n Synchronous load-enable registers are represented by a register with a feedback loop that maintains the same logic value through multiple cycles.\n Clock gating applied to synchronous load enable registers reduces the power needed when reloading the register banks.\n Figure\u00a045 shows a simple register bank implementation using a multiplexer and feedback loop.\n Figure 45 Synchronous Load-Enable Register With Multiplexer Flip Flop Mux Control Logic Register Bank EN CLK DATA IN 0 1 DATA OUT When the synchronous load enable signal (EN) is at logic state 0, the register bank is disabled.\n In this state, the circuit uses the multiplexer to feed the Q output of each storage element in the register bank back to the D input.\n When the EN signal is at logic state 1, the register is enabled, allowing new values to load at the D input.\n       These feedback loops can unnecessarily use power.\n For example, if the same value is reloaded in the register throughout multiple clock cycles (EN equals 0), the register bank and its clock net consume power while values in the register bank do not change.\n The multiplexer also consumes power.\n Clock gating eliminates the feedback net and multiplexer shown in  Figure\u00a045 by inserting a gate in the clock net of the register.\n Note: While applying the clock-gating techniques, the tool considers generated clocks similar to defined clocks.\n The clock-gating cell selectively prevents clock edges, thus preventing the gated-clock signal from clocking the gated register.\n Figure\u00a046 shows a latch-based clock-gating cell and the waveforms of the signals are shown with respect to the clock signal, CLK.\n Figure 46 Latch-Based Clock Gating Flip Flop Control Logic Register Bank D Q G Latch CLK ENCLK ENL EN CLK DATA IN DATA OUT CLK CLK EN ENL ENCLK The clock input to the register bank, ENCLK, is gated on or off by the AND gate.\n ENL is the enabling signal that controls the gating; it derives from the EN signal on the multiplexer shown in  Figure\u00a045.\n The register bank is triggered by the rising edge of the ENCLK signal.\n The latch prevents glitches on the EN signal from propagating to the register\u2019s clock pin.\n When the CLK input of the 2-input AND gate is at logic state 1, any glitching of the EN signal could, without the latch, propagate and corrupt the register clock signal.\n The latch eliminates this possibility because it blocks signal changes when the clock is at logic 1.\n       In latch-based clock gating, the AND gate blocks unnecessary clock pulses by maintaining the clock signal\u2019s value after the trailing edge.\n For example, for flip-flops inferred by HDL constructs of rising-edge clocks, the clock gate forces the gated clock to 0 after the falling edge of the clock.\n By controlling the clock signal for the register bank, you can eliminate the need for reloading the same value in the register through multiple clock cycles.\n Clock gating inserts clock-gating circuitry into the register bank\u2019s clock network, creating the control to eliminate unnecessary register activity.\n Clock gating does the following: \u2022 Reduces clock network power dissipation \u2022 Relaxes datapath timing \u2022 Reduces congestion by eliminating feedback multiplexer loops For designs that have large register banks, clock gating can save power and area by reducing the number of gates in the design.\n However, for smaller register banks, the overhead of adding logic to the clock tree might not compare favorably to the power saved by eliminating a few feedback nets and multiplexers."}
{"header": "How do I Clock Gating in the Compile Log File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs.\n The naming convention is as follows: prefix_base-name[_index] \u2022 The prefix is  clock_gate by default.\n To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option.\n \u2022 The base name is the most frequent instance name among the registers gated by the clock gate.\n The base name does not include bus bit indexes.\n \u2022 If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0.\n For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg.\n If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0.\n However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register."}
{"header": "How do I Clock-Gate Levels and Stages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The compile log file contains information about clock gating, which can help you debug simple setup issues.\n By default, the clock-gating information is displayed after \u2022 Clock-gate insertion n the  initial_map stage \u2022 Clock-gate restructuring in the  logic_opto stage \u2022 Clock-gate restructuring in the  initial_opto stage \u2022 Self-gating insertion in the  initial_opto stage, if enabled The reported information includes the following: \u2022 The number of preexisting clock gates that have a  dont_touch attribute, which prevents optimization and might lead to unsatistactory results \u2022 The number of clock-gating library cells that have a CTS purpose, which is required for insertion \u2022 Clock-gating metrics such as the number of elements and the number of gated registers \u2022 A summary of reasons for registers that could not be gated If the self-gating or fanin-based sequential clock gating features are enabled, their metrics are displayed separately.\n An example of the compile log for a run that includes self-gating is as follows: Number\u00a0of\u00a0Pre-Exsting\u00a0Clock\u00a0Gates\u00a0with\u00a0dont_touch\u00a0Attribute:\u00a00 Number\u00a0of\u00a0ICG\u00a0library\u00a0cells\u00a0with\u00a0CTS\u00a0purpose:\u00a012 --------------------------------------------------------------------------- Tool\u00a0Gated\u00a0Register\u00a0Summary --------------------------------------------------------------------------- Clock\u00a0Gating\u00a0Type\u00a0\u00a0\u00a0\u00a0|\u00a0Number\u00a0of\u00a0Clock\u00a0Gates\u00a0\u00a0|\u00a0Register\u00a0Count\u00a0|\u00a0Bitwidth |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Equivalent --------------------------------------------------------------------------- Regular\u00a0Clock\u00a0Gating\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 Self\u00a0Gating\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 --------------------------------------------------------------------------- --------------------------------------------------------------------------- Regular\u00a0Clock\u00a0Gating\u00a0Ungated\u00a0Register\u00a0Summary --------------------------------------------------------------------------- Ungated\u00a0Reason\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0Count\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Bitwidth --------------------------------------------------------------------------- Enable\u00a0is\u00a0Constant\u00a0One\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 ---------------------------------------------------------------------------       --------------------------------------------------------------------------- Self\u00a0Gating\u00a0Ungated\u00a0Register\u00a0Summary --------------------------------------------------------------------------- Ungated\u00a0Reason\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0Count\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Bitwidth --------------------------------------------------------------------------- Register\u00a0is\u00a0clock\u00a0gated,\u00a0and\u00a0ineraction\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| is\u00a0set\u00a0to\u00a0none\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 The\u00a0tool\u00a0as\u00a0not\u00a0able\u00a0to\u00a0find\u00a0enough\u00a0registers\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| that\u00a0are\u00a0compatible\u00a0to\u00a0this\u00a0register\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| in\u00a0order\u00a0to\u00a0be\u00a0gated.\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 ---------------------------------------------------------------------------"}
{"header": "How do I Clock-Gating Prerequisite Conditions", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool uses the following definitions for clock-gate levels and stages in clock-gating commands and options: \u2022 The clock-gate level is related to the fanin of a clock gate.\n \u25e6 Level 0 refers to a clock source.\n \u25e6 Level 1 refers to the first clock gate downstream from the clock source.\n \u25e6 Level 2 refers to a clock gate driven by a clock gate of level 1.\n \u25e6 Level N refers to a clock gate driven by a clock gate of level N-1.\n \u2022 The clock-gate stage is related to the fanout of a clock gate.\n \u25e6 Stage 0 refers to a register driven by a clock gate.\n \u25e6 Stage 1 refers to a clock gate that only drives registers directly or across buffers, inverters, or hierarchical transitions.\n In addition, stage 1 is assigned to clock gates whose stage cannot be determined, such as unloaded clock gates.\n \u25e6 Stage N refers to a clock gate that drives at least one clock gate of stage N-1, either directly or across buffers, inverters, or hierarchical transitions.\n The tool keeps a separate count of levels and stages for all clock gates and for tool- inserted clock gates.\n Figure\u00a047 shows a simple circuit with two preexisting clock gates (P1 and P2) and three tool-inserted clock gates (T1, T2, and T3).\n  Table\u00a023  lists the levels and stages for each of the clock gates.\n       Figure 47 Design With Multiple Clock Gates Table 23 Clock-Gate Levels and Stages Object Type Level (all clock gates) Level (tool-inserted clock gates) Stage (all clock gates) Stage (tool-inserted clock gates)"}
{"header": "How do I Clock-Gating Enable Condition", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before gating the clock signal of a register, the Fusion Compiler tool checks to see if certain clock-gating conditions are satisfied.\n The tool inserts a clock gate only if all the clock-gating conditions are met: \u2022 The circuit demonstrates synchronous load-enable functionality.\n \u2022 The circuit satisfies the setup condition.\n \u2022 The register bank or group of register banks satisfies the minimum number of bits you specify with the  set_clock_gating_options -minimum_bitwidth command.\n The default minimum bitwidth is 3.\n After clock gating is complete, the status of clock-gating conditions for gated and ungated register banks appears in the clock-gating report.\n For information about the clock-gating report, see  Reporting Clock-Gating Results.\n Clock-Gating Conditions The register must satisfy the following conditions for the tool to gate the clock signal of the registers: \u2022 Enable condition If the register bank\u2019s synchronous load-enable signal is a constant logic 1, reducible to logic 1, or logic 0, the condition is  false and the circuit is not gated.\n If the synchronous load-enable signal is not a constant logic 1 or 0, the condition is  true and the setup condition is checked.\n The enable condition is the first condition that the tool checks.\n For more information, see  Clock-Gating Enable Condition.\n \u2022 Setup condition This condition applies to latch-free clock gating only.\n The enable signal must come from a register that uses the same clock as the register being gated.\n The setup condition is checked only if the register satisfies the enable condition.\n For more information, see  Clock-Gating Setup Condition.\n \u2022 Width condition The width condition is the minimum number of bits for gating registers or groups of registers with equivalent enable signals.\n The default is 3.\n You can set the width condition by using the  -minimum_bitwidth option of the  set_clock_gating_options command.\n The width condition is checked only if the register satisfies the enable condition and the setup condition."}
{"header": "How do I Clock-Gating Setup Condition", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The enable condition of a register or clock gate is a combinational function of nets in the design.\n The enable condition of a register represents the states for which a clock signal must be passed to the register.\n The enable condition of a clock gate corresponds to the states for which a clock is passed to the registers in the fanout of the clock gate.\n The tool uses the enable condition of the registers for clock-gate insertion.\n Enable conditions are represented by Boolean expressions for nets.\n For example: module\u00a0TEST\u00a0(en1,\u00a0en2,\u00a0en3,\u00a0in,\u00a0clk,\u00a0dataout); input\u00a0en1,\u00a0en2,\u00a0en3,\u00a0clk; input\u00a0[5:0]\u00a0in; output\u00a0[5.0]\u00a0dataout; reg\u00a0[5.0]\u00a0dataout; wire\u00a0enable; assign\u00a0enable\u00a0=\u00a0(en1\u00a0|\u00a0en3)\u00a0&\u00a0en2; always\u00a0@(\u00a0posedge\u00a0clk\u00a0)\u00a0begin if(\u00a0enable\u00a0) dataout\u00a0<=\u00a0in; else dataout\u00a0<=\u00a0dataout; end endmodule In this example, the enable condition for the register bank dataout_reg* can be expressed as en1 en2 + en3 en2."}
{"header": "How do I Setting Up Clock Gating", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform clock gating, the tool requires that the enable signal of the register bank is synchronous with its clock.\n This is the setup condition.\n For latch-based or integrated clock gating, the tool can insert clock gating irrespective of the enable signal\u2019s and the clock\u2019s clock domains.\n If the enable signal and the register bank reside in different clock domains, you must ensure that the two clock domains are synchronous and that the setup and hold times for the clock-gating cell meet the timing requirements.\n An exception exists for primary input ports that use a clock specified with the set_input_delay command.\n In this case, the input port is synchronous with the clock and the setup condition is true."}
{"header": "How do I Setting the Clock-Gating Style", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The clock gating feature only supports latch-based integrated clock-gating cells.\n Tool- inserted clock-gating cells do not have a wrapper hierarchy.\n       Clock-gating optimization uses the following defaults: \u2022 The maximum fanout is infinite.\n \u2022 The minimum bitwidth is three.\n \u2022 A latch-based precontrol cell for both positive-edge and negative-edge triggered flip- flops is used as a clock-gating cell.\n If only positive-edge or negative-edge clock-gating cells are available, the tool inserts inverters on both sides of the clock-gating cell.\n You must load a design and libraries before you can set up clock-gating constraints.\n To set up clock gating, follow these steps: 1.\n Load the design and libraries 2.\n Set the style by using the  set_clock_gate_style command 3.\n Set the options by using the  set_clock_gating_options command 4.\n Specify objects to be included or excluded from clock gating by using the set_clock_gating_objects command 5.\n Allow other clock-gating cell types for optimization by using the following command: fc_shell>\u00a0 set_lib_cell_purpose -include cts [get_lib_cells...] For more information, see the following topics: \u2022 Setting the Clock-Gating Style \u2022 Setting Clock-Gating Options \u2022 Enabling or Disabling Clock Gating on Design Objects \u2022 Clock-Gating Enable Source Selection \u2022 User-Driven Enable Exclusion \u2022 Report Clock Gating Options"}
{"header": "How do I Setting Clock-Gating Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  set_clock_gate_style command to select the type of integrated clock-gating cell you want to use.\n The following options are available: Option Description -test_point  none before after       Option Description -observation_output  true  false -target  pos_edge_flip_flop  neg_edge_flip_flop -objects"}
{"header": "How do I Enabling or Disabling Clock Gating on Design Objects", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  set_clock_gating_options command to define the netlist structure of the inserted clock-gating cells.\n The following options are available: Option Description -minimum_bitwidth   -max_fanout   -objects"}
{"header": "How do I Clock-Gating Enable Source Selection", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can enable or disable clock gating on certain design objects by overriding all necessary conditions set by the clock-gating style.\n The  set_clock_gating_objects command specifies the design objects on which clock gating should be enabled or disabled during the  compile_fusion command.\n The following example excludes all registers in the subdesign ADDER, except the out1_reg bank.\n The out1_reg bank is clock gated according to the specified clock-gating style: fc_shell>\u00a0 set_clock_gating_objects -exclude ADDER \\ -include ADDER/out1_reg[*]       The following example sets and then removes the inclusion and exclusion criteria specified by the  -include,  -exclude, and  -clear options: fc_shell>\u00a0 set_clock_gating_objects -include ADDER/out1_reg[*] \\ -exclude ADDER/out2_reg[*] fc_shell>\u00a0 set_clock_gating_objects \\ -clear {ADDER/out1_reg[*] ADDER/out2_reg[*]}"}
{"header": "How do I User-Driven Enable Exclusion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool extracts the clock-gating enable condition from one of these sources: \u2022 Signals connected directly to the synchronous enable pin of the sequential element, as shown in  Figure\u00a048 Figure 48 Directly Connected Enable Signal \u2022 The enable condition on the feedback loops of the input and output data pins of the sequential element, as shown in  Figure\u00a049 Figure 49 Enable Signal in a Feedback Loop When using clock gating, you can specify the signal source of the enable logic.\n The set_clock_gating_objects\u00a0-enable_source option applies to all objects specified with the  -force or  -include options in the same command.\n If you use the  -enable_source option, you cannot use the  -clear,  -reset, or  -exclude options.\n       The  -enable_source option can be one of the following: \u2022 none \u2022 enable_pin_only \u2022 feedback_loop_only \u2022 both (default) \u2022 prefer_enable_pin \u2022 prefer_feedback_loop For example, the following command inserts an always-enabled clock-gating cell: set_clock_gating_objects\u00a0-force\u00a0[get_cells\u00a0u_dfx/input_b_reg*]\u00a0\\ -enable_source\u00a0none The following command uses the enable signal from the synchronous enable pin, if there is one.\n Otherwise, the tool uses the enable on the feedback loop of the register.\n set_clock_gating_objects\u00a0-include\u00a0[get_cells\u00a0u_dfx/input_c_reg*]\u00a0\\ -enable_source\u00a0prefer_enable_pin"}
{"header": "How do I Report Clock Gating Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  set_clock_gating_enable command provides an interface to specify signals to be excluded from clock-gating enable.\n The  report_clock_gating\u00a0-ungated command reports a new reason for registers that are not gated due to enable exclusion.\n The options and syntax of the  set_clock_gating_enable command are identical to the corresponding Design Compiler command.\n Use this command to control the signals to enable clock gating during clock-gate insertion.\n This command provides a mechanism to specify why a given signal should not be used as an enable condition for clock gating.\n The syntax of the  set_clock_gating_enable command is as follows: status\u00a0set_clock_gating_enable [-exclude\u00a0objects_to_exclude] [-undo\u00a0objects_to_remove_exclusion]       The following figure shows a circuit before enable exclusion: In this step, a forward traversal is performed from all user-specified exclusion signals until endpoints (primary output ports, input ports of sequential cells, including clock gating cells, black boxes, and so on) are reached.\n If the endpoint is a clock-gate-enable pin, then all pins on the path are marked with a temporary design attribute for use in subsequent steps.\n       The following figure shows a circuit after enable exclusion:"}
{"header": "How do I Clock Gating Flows", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  report_clock_gating_options command reports the clock gating settings used for the current design.\n The command output includes a table that reports minimum bitwidth and maximum fanout for each relevant object.\n A parameter to print options set up only for certain objects is also available.\n The available parameters for the command are as follows: \u2022 No split: By default, long names are split in multiple lines for easier human reading.\n Enabling this option makes names print in a single line.\n \u2022 Objects: A list of hierarchical objects to query.\n Ignores the rest of the objects in the design, and displays an error for each non-hierarchical cell passed with  CGT-2500 and CGT-2501 warning messages.\n       The output of the  report_clock_gating_options command is shown in  Figure\u00a050 : Figure 50 Output of the report_clock_gating_options Command When no gating options have been set, or when the design has been set only with specific options, the table displays the assigned options in a single row, alongside any other objects that might have been passed through the -objects parameter.\n Figure\u00a051 shows the  report_clock_gating_options command output when no options are set to specific objects.\n Figure 51 Command Output With no Options set to Specific Objects Figure\u00a052 shows the  report_clock_gating_options command output when no options are set to specific objects, but both the design and  b0 have been passed as parameters for objects.\n       Figure 52 Command Output With no Specific Object Options but Passed as Parameters When multiple objects are set using the same options, they appear in a single row, with the name column being divided into multiple lines if the  -nosplit parameter is not used.\n Otherwise, everything occupies a single line.\n report_clock_gating_options\u00a0-objects\u00a0{design,\u00a0obj1,\u00a0obj2,\u00a0obj3,\u00a0obj4} Figure 53 Command Output With the Same Option set to Multiple Objects Figure\u00a054 shows the same scenario as  Figure\u00a053, but with the  -nosplit parameter: report_clock_gating_options\u00a0-objects\u00a0{design,\u00a0obj1,\u00a0obj2,\u00a0obj3,\u00a0obj4} -nosplit Figure 54"}
{"header": "How do I Inserting Clock Gates in Multivoltage Designs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool inserts clock-gating cells during the  compile_fusion command.\n The following topics describe clock-gating flows: \u2022 Inserting Clock Gates in Multivoltage Designs \u2022 Inserting Clock Gates in an RTL Design"}
{"header": "How do I Inserting Clock Gates in an RTL Design", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In a multivoltage design, the different hierarchies of the design might have different operating conditions and use different target library subsets.\n When inserting clock-gating cells in a multivoltage design, the tool chooses the appropriate library cells based on the specified clock-gating style as well as the operating conditions that match the operating conditions of the hierarchical cell of the design.\n If you do not specify a clock-gating style, the tool uses a default style where the test point is  before and the observation output is false.\n If the tool does not find a library cell that suits the clock-gating style and the operating conditions, the tool issues a warning message and does not insert a clock-gating cell.\n To check whether there are integrated clock-gate cells available for clock-gate insertion, use the  check_clock_gate_library_cell_availability command."}
{"header": "How do I Replacing Clock Gates", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert clock gating logic in an RTL design and to synthesize the design with the clock- gating logic, follow these steps: 1.\n Read the RTL design.\n 2.\n (Optional) Use the  insert_dft command to insert test cells into the design.\n 3.\n Use the  compile_fusion command to compile the design.\n During the compile process, the tool inserts clock gates on the registers qualified for clock-gating.\n By default, during clock-gate insertion, the  compile_fusion command uses the clock gating default settings and also honors the setup, hold, and other constraints specified in the logic libraries.\n To override the setup and hold values specified in the library, use the  set_clock_gating_check command before compiling the design.\n The default settings are suitable for most designs.\n The  compile_fusion command automatically connects the scan enable and test ports or pins of the integrated clock-gating cells, as needed.\n 4.\n Use the  report_clock_gating command to report the registers and the clock-gating cells in the design.\n Use the  report_power command to get information about the dynamic power used by the design after clock-gate insertion.\n The following example illustrates a typical command sequence for clock using default settings: fc_shell>\u00a0 read_verilog design.v fc_shell>\u00a0 create_clock -period 10 -name CLK fc_shell>\u00a0 compile_fusion fc_shell>\u00a0 insert_dft       fc_shell>\u00a0 report_clock_gating fc_shell>\u00a0 report_power"}
{"header": "How do I Controlling Clock-Gate Latencies", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you want to replace all the technology-independent clock gates in your RTL with integrated clock-gating cells from the libraries, use the  replace_clock_gates command before executing the  compile_fusion command.\n The  replace_clock_gates command identifies combinational elements in the clock network acting as clock gates and replaces them.\n When you use the  replace_clock_gates command, the tool honors the constraints specified by the  set_clock_gate_style,  set_lib_cell_purpose, and set_target_ligrary_subset commands when it selects a library cell.\n When the tool identifies combinational elements, these elements must have only two input pins (the clock pin and the enable signal pin) and only one output pin.\n If the cell does not meet these criteria, the cell is not a candidate for replacement.\n The following table lists the WVGTECH instances and their replacement cells.\n Combinational Cell in RTL Integrated Clock Gate Replacement           The new clock-gating cell is inferred with the following name: rep_clock_gate_+<instance_name_of_combinational_cell> The tool reports replaced clock gates as tool-inserted clock gates."}
{"header": "How do I Integrated Clock-Gate Latency Estimation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During synthesis, the Fusion Compiler tool assumes that clocks are ideal.\n An ideal clock incurs no delay through the clock network.\n This assumption is made because real clock- network delays are not known until after clock tree synthesis.\n In reality, clocks are not ideal and there is a nonzero delay through the clock network.\n For designs with clock gating, the clock-network delay at the registers is different from the clock-network delay at the clock-       gating cell.\n This difference in the clock-network delay at the registers and at the clock- gating cell results in tighter constraints for the setup condition at the enable input of the clock-gating cell.\n The tool can obtain clock-gate latencies in the following ways: \u2022 Integrated latency estimation By default, the tool estimates and updates clock-gate latencies throughout the flow.\n Estimated clock latencies are more accurate than user-specified clock latencies.\n \u2022 User-specified latency You can disable integrated latency estimation for specific instances and specify latency values manually."}
{"header": "How do I User-Specified Clock-Gate Latency", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool estimates and updates clock-gate latencies throughout the compile_fusion command flow.\n This ensures that the tool uses accurate clock-gate latencies during datapath optimization and useful-skew optimization performed before clock tree synthesis, when clocks are ideal.\n If you plan to perform structural multisource clock tree synthesis for your design, ensure that the tool estimates clock-gate latencies that are appropriate for structural multisource clock subtrees by setting the opt.clock_latency_estimation.estimate_smscts_subtrees application option to true.\n To improve the accuracy of the estimated clock-gate latencies, specify clock tree synthesis settings before you run the  compile_fusion command.\n Such settings include the clock tree buffer library cell list, the clock tree inverter library cell list, and clock nondefault routing rules.\n Estimated clock latencies are more accurate than user-specified clock latencies.\n In addition, the tool updates the estimated clock latencies after steps such as placement and multibit banking, while user-specified latencies are static values.\n To prevent the tool from estimating the latency for a specific clock gate, set the dont_estimate_clock_latency attribute on its clock pin by using the  set_attribute command, as shown in the following example: fc_shell>\u00a0 set_attribute \\ [get_pins {ICG21/CK}] dont_estimate_clock_latency true       For best results, do not use the following features with integrated clock-gate latency estimation: \u2022 Trial clock tree synthesis To disable this feature, set the  compile.flow.trial_clock_tree application option to false.\n \u2022 Clock-gate optimization To disable this feature, set the  compile.flow.optimize_icgs application option to false.\n \u2022 Placement-aware clock gating The tool automatically disables this feature when clock-gate latency estimation is enabled regardless of the  compile.clockgate.physically_aware application option setting.\n \u2022 User-specified latencies User-specified latencies are set by the  set_clock_latency, set_clock_gate_latency,  set_clock_gating_check\u00a0-setup, or  set_path_margin -setup commands.\n The tool does not modify any  set_clock_latency constraints that you specify on clock- gating cells.\n Tool-estimated clock-gate latency values are stored as offsets from the user- specified values.\n You can see the offset values by using the  write_script\u00a0-format icc2 command and checking for the  set_clock_latency\u00a0-offset commands in the generated output.\n If you do not set any latency values, the reported offsets are equal to the estimated latency values.\n The estimated latency offset values are not captured in an SDC file generated by the write_sdc command.\n Latency estimates are most accurate if the relative locations of the clock gates and their gated registers do not change during clock tree synthesis.\n To preserve the placement of integrated clock gates, enable the automatic relocation of clock network cells by setting the  cts.compile.enable_cell_relocation application option to  auto before clock tree synthesis."}
{"header": "How do I Controlling the Number of Clock-Gate Levels", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You cannot disable general integrated clock-gate latency estimation.\n However, you can disable the feature for specific clock gates by setting a  dont_estimate_clock_latency attribute on their clock pins.\n This topic describes how to manually specify latency values on those clock gates.\n       Specify the clock network latency by using either the  set_clock_latency or set_clock_gate_latency command.\n The  set_clock_gate_latency command can be used for both gate-level and RTL designs.\n The clock latency specified using the  set_clock_gate_latency command is annotated on the registers during the  compile_fusion command when the clock-gating cells are inserted.\n However, if you modify the latency values on the clock gates after the compilation, you must manually apply the latency values on the existing clock-gating cells using the  apply_clock_gate_latency command.\n Note: After you modify the clock-gate latency using the  set_clock_gate_latency command, if you compile your design using the  compile_fusion command, it is not necessary to use the  apply_clock_gate_latency command to apply the latency values.\n The tool annotates the specified value during compilation.\n To remove clock latency information previously set on clock-gating cells with the set_clock_gate_latency or  apply_clock_gate_latency commands, use the reset_clock_gate_latency command.\n This command removes the clock latency values on the specified clocks.\n If you do not specify the clock, the clock latency values on all the clock-gating cells are removed.\n The set_clock_latency Command Use the  set_clock_latency command to specify clock network latency for specific clock- gating cells.\n In  Figure\u00a055,  lat_cgtoreg is the estimated delay from the clock pin of the clock-gating cell to the clock pin of the gated register and  lat_reg is the estimated clock-network latency to the clock pins of the registers without clock gating.\n Figure 55 Clock Latency With Clock-Gating Design Clock- Gating Cell Register Clock tree delay Clock tree delay lat_reg lat_cgtoreg For all clock pins of registers (gated or ungated) in the design that are driven by a specific clock, use the  lat_reg value for the  set_clock_latency command.\n For clock pins of all the clock-gating cells, use the difference between the  lat_reg and  lat_cgtoreg       values for the  set_clock_latency command.\n Because the purpose of setting the latency values is to account for the different clock-network delays between the registers and the clock-gating cell, it is important to get a reasonably accurate value of the difference ( lat_cgtoreg ).\n The absolute values used are less important unless you are using these values to account for clock-network delay issues not related to clock gating.\n The set_clock_gate_latency Command When you use the  compile_fusion command, clock gates are inserted during the compilation process.\n To specify the clock network latency before the clock-gating cells are inserted by the tool, use the  set_clock_gate_latency command.\n This command lets you specify the clock network latency for the clock-gating cells as a function of the clock domain, clock-gating stage, and the fanout of the clock-gating cell.\n The latency that you specify is annotated on the clock-gating cells when they are inserted by the compile_fusion command.\n You can manually annotate the latency values on the existing clock-gating cells in your design using the  apply_clock_gate_latency command.\n The  set_clock_gate_latency command takes the following arguments: \u2022 -clock\u00a0 clock_list \u2022 -stage\u00a0 clock_gate_stage \u2022 -fanout_latency\u00a0 fanout_list The  fanout_list is a list of tuples specifying a fanout range and a delay decrement.\n In the following example, three fanout ranges are created: 1 to 5 with a latency value of 0.5, 6-15 with a latency value of 0.8, and 16 to infinity with a latency value of 0.6.\n set_clock_gate_latency\u00a0-stage\u00a01\u00a0\\ -fanout_latency\u00a0{{1-5\u00a00.5}\u00a0{6-15\u00a00.8}\u00a0{16-inf\u00a00.6}} To specify a clock latency value for clock-gated registers, use the  -stage option with a value of 0.\n Because you are specifying the latency value for the clock-gated registers, the value for the  -fanout_latency option should be  1-inf (1 to infinity) and the latency is the absolute clock latency value for the registers, as shown in the following example: set_clock_gate_latency\u00a0-clock\u00a0CLK\u00a0-stage\u00a00\\ -fanout_latency\u00a0{1-inf\u00a01.0} If the  -clock option is not specified, the setting applies to all clocks in the design.\n Clock latencies using the  set_clock_latency command have higher precedence and are not overwritten.\n Figure\u00a056 shows an example of clock-gate stages and fanout.\n       Figure 56 Clock-Gating Stages and Latency Calculations The following commands set the latency values for  Figure\u00a056 : set_clock_gate_latency\u00a0-stage\u00a00\u00a0-fanout_latency\u00a0{{1-inf\u00a01.0}} set_clock_gate_latency\u00a0-stage\u00a01\u00a0-fanout_latency\u00a0{{1-inf\u00a00.3}} set_clock_gate_latency\u00a0-stage\u00a02\u00a0-fanout_latency\u00a0{{1-inf\u00a00.2}} set_clock_gate_latency\u00a0-stage\u00a03\u00a0-fanout_latency\u00a0{{1-inf\u00a00.1}} Figure\u00a057 shows another example of fanout and latency calculations.\n       Figure 57 Latency Calculations With Varying Fanout The following commands specify the latency and fanout for  Figure\u00a057.\n set_clock_gate_latency\u00a0-stage\u00a00\u00a0\\ -fanout_latency\u00a0{{1-inf\u00a01.6}} set_clock_gate_latency\u00a0-stage\u00a01\u00a0\\ -fanout_latency\u00a0{{1-20\u00a00.6}\u00a0{21-inf\u00a00.8}} set_clock_gate_latency\u00a0-stage\u00a02\u00a0\\ -fanout_latency\u00a0{{1-20\u00a00.2}\u00a0{21-inf\u00a00.3}} set_clock_gate_latency\u00a0-stage\u00a03\u00a0\\ -fanout_latency\u00a0{{1-30\u00a00.1}\u00a0{31-65\u00a00.8}\u00a0{66-inf\u00a00.18}} set_clock_latency\u00a0\"0.4\"\u00a0{uicg_a/CK} Note that for the clock gate uicg_a, the latency value of 0.4 is assigned using the set_clock_latency command, which cannot be overwritten."}
{"header": "How do I Clock-Gate Multilevel Expansion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The number of clock-gate levels is the count of clock gates between a clock source and a register.\n Standard clock-gate insertion provides one level of clock-gate insertion.\n However, designs often contain preexisting clock gates, in which case the design might contain multiple levels of clock gates.\n       You can modify the default clock-gate insertion operation by allowing additional levels of clock gating, by limiting the number of clock-gate levels, or both."}
{"header": "How do I Clock-Gate Collapsing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "It is difficult to determine the optimum number of clock-gate levels manually.\n The Fusion Compiler tool can analyze all clock gates and insert additional clock gates to take advantage of shared enable signals.\n Inserting additional clock gates might improve power, area, or other metrics, depending on the design.\n If six or more clock gates share an enable signal, the tool inserts an additional level of clock gates.\n The new clock gates are then considered for further level expansion.\n As a result, the tool might insert multiple levels of clock gates during this operation.\n To allow the tool to expand the number of clock-gate levels, set the compile.clockgate.enable_level_expansion application option to  true (the default is  false ) and set the  compile.clockgate.max_number_of_levels application option to a nonzero value (the default is 0).\n In this case, the tool adds clock gates until either of the following conditions is met: \u2022 All common enable signals are identified and used for multilevel clock-gate expansion.\n \u2022 The user-specified maximum number of clock-gate levels is reached.\n The tool names a newly-inserted clock gate as follows, based on the status of the set of clock gates whose enable functions are modified by the new clock gate: \u2022 If at least one of the clock gates is a tool-inserted clock gate, the base name is clock_gate_ml.\n The name is appended with the register base name, similar to the naming convention for other tool-inserted clock gates.\n \u2022 If all of the clock gates are preexisting clock gates, the tool uses the name of the preexisting clock gate with the largest fanout and appends  _ml_pe.\n The  compile.clockgate.max_number_of_levels application option specifies the maximum number of allowed clock-gate levels.\n The default is 0, which allows an infinite number of levels.\n However, to use the clock-gate level expansion capability, you must set this application option to a nonzero value (in addition to setting the compile.clockgate.enable_level_expansion application option to  true ).\n If you specify clock-gate level expansion, but the maximum number of allowed levels is low, the expansion operation cannot take full advantage of the tool's ability to analyze common enable signals.\n To enable or disable clock-gate level expansion for specific clock gates, use the set_clock_gate_transformations\u00a0-expand_levels command.\n       The following usage notes apply: \u2022 New clock gates inherit the constraints set by the  set_clock_gate_transformations, set_clock_gate_style,  set_dont_touch,  set_size_only,  set_lib_cell_purpose, and  set_boundary_optimization commands.\n \u2022 Clock-gate latency estimations are updated after the insertion operation.\n \u2022 When the insertion operation modifies the enable signal of a clock gate, the gate retains its original designation of being either preexisting or tool-inserted.\n \u2022 Self-gating is restricted from adding another clock-gate level if the maximum number of levels is already reached.\n \u2022 Integrated clock gates inside multibit cells are counted as part of the clock-gate level count.\n However, they are not candidates for clock-gate level expansion.\n \u2022 New clock gates do not inherit timing exceptions."}
{"header": "How do I Controlling Tool-Inserted Clock-Gate Levels", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The default of the  compile.clockgate.max_number_of_levels application option is 0, which allows an infinite number of levels.\n You can set the  compile.clockgate.max_number_of_levels application option without enabling clock-gate level expansion.\n In this case, the tool collapses clock-gate levels if the specified limit is less than the number of clock-gate levels that exist after the  initial_map stage.\n The tool collapses clock-gate levels as follows: \u2022 The tool first tries to collapse clock gates at levels higher than the specified maximum level, starting from the clock gates at the highest level (closest to the registers).\n \u2022 If a specific clock gate cannot be collapsed, the tool tries to collapse upstream clock gates until it reaches the lowest level (closest to the source).\n The collapse can occur across hierarchies.\n The tool tries to preserve the parent (upstream) clock gate.\n \u2022 The tool removes all remaining clock gates that do not meet the maximum number of levels."}
{"header": "How do I Activity-Based Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify the maximum number of clock-gate levels that the tool should use for either all clock gates or only tool-inserted clock gates.\n If you specify a value for all clock gates, you must know how many clock-gate levels already exist in the RTL design.\n Alternatively, you can specify a value only for tool-inserted clock gates.\n For details about how the Fusion Compiler tool counts clock-gate levels, see  Clock-Gate Levels and Stages.\n       To specify the maximum number of clock-gate levels, use the set_clock_gating_tree_options command with one of the following mutually exclusive options: \u2022 The  -max_total_levels option specifies the maximum number of levels for all clock gates.\n The argument is an integer greater than or equal to 1.\n \u2022 The  -max_tool_inserted_levels option specifies the maximum number of levels for tool-inserted clock gates.\n The argument is an integer greater than or equal to 1.\n To restrict the clock-level control to specific clock sources, use the the  -clocks option of the  set_clock_gating_tree_options command, which takes a list of clocks as an argument.\n To allow clock-gate removal (also known as ungating) if some clock gates are not collapsible when the tool attempts to meet the maximum clock level constraint, use the -ungate_if_not_collapsible option."}
{"header": "How do I Merging Clock Gates", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you load a SAIF file, the Fusion Compiler tool analyzes the switching activity to evaluate whether to expand a tool-inserted clock gate.\n This analysis prevents the insertion of unnecessary clock gates.\n For example, in  Figure\u00a058, clock gates A1 and A2 are each common to two paths and are therefore candidates for multilevel expansion.\n Figure 58 Before Clock-Gate Level Expansion       However, if clock gate A2 is always enabled, it has a toggle rate of 0 and a static probability of 1.\n Adding another clock-gate level does not provide any benefit in this case.\n The final configuration is shown in  Figure\u00a059.\n Figure 59 After Clock-Gate Level Expansion If clock-gate level expansion is enabled, the Fusion Compiler tool performs activity- driven analysis by default.\n If a SAIF file is not available, disable this feature by setting the compile.clockgate.enable_activity_drivel_level_expansion application option to false (the default is  true ).\n If clock-gate level expansion is disabled, the tool ignores the compile.clockgate.enable_activity_driven_level_expansion application option."}
{"header": "How do I Setting Clock Gating Transformations", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage.\n The tool looks for clock-gating cells that share a common clock and enable signal.\n This feature is on by default.\n The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching.\n Note that the the tool also checks clock-gating style and multivoltage constraints.\n Clock-gating cells with the  dont_touch or  size_only constraints are not optimized.\n To disable this feature, use the  set_clock_gate_transformations command."}
{"header": "How do I Setting Routing Rules for Clock Gates", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, clock gating optimization occurs automatically when you synthesize fhs design.\n You can, however, define settings to allow or prevent clock gating optimization on specific objects.\n The tool makes no distinction among clock gates.\n Every clock gate is subject to optimization, whether it is a preexisting or tool-inserted clock gate.\n The simplest way to restrict clock gating optimization is by using the  set_dont_touch and  set_size_only commands.\n These commands restrict all clock gating optimization by preventing removal, merging, and splitting of all clock gates.\n For a more refined approach, use the  set_clock_gate_transformations command.\n With this command, you can set specific constraints on each integrated clock gate and control which operations can be performed on the clock gate.\n The  set_clock_gate_transformations command provides the following options: \u2022 -split_fanout Setting this option to  false prevents fanout splitting even if the fanout is larger than the maximum allowed.\n This setting also prevents any splitting performed by placement- aware clock gating.\n \u2022 -merge_equivalents Setting this option to  true allows a clock gate to be merged with an equivalent clock gate.\n \u2022 -collapse_levels Setting this option to  false prevents redundant clock gates from being collapsed \u2022 -ungate_fanout Setting this option to  true specifies that the clock gate fanout remain ungated \u2022 -reset Resets all clock gate settings for the whole design If the  size_only or  dont_touch attributes are set on a clock-gating instance or clock- gating library cell, these attributes take precedence over any of the constraints specified by the  set_clock_gate_transformations command.\n       Example Using Clock Gating Transformations For the example in  Figure\u00a060, suppose you set the following restrictions: set_clock_gating_options\u00a0-minimum_bitwidth\u00a06 set_clock_gate_transformations\u00a0[get_cells\u00a0uicg_b*]\u00a0true\u00a0\\ -ungate_fanout\u00a0false set_clock_gate_transformations\u00a0[get_cells\u00a0uicg_c*]\u00a0false Figure 60 Example of Clock Gating Restrictions During optimization, the tool removes the uicg_a clock gate because of a minimum bitwidth violation (minimum bitwidth is 6).\n The uicg_b1 and uicg_b2 clock gates are merged (assuming they have an equivalent enable signal).\n Even though the minimum bitwidth is not met, ungating is not allowed, so the registers remain gated.\n The uicg_c1 and uicg_c2 clock gates do not allow any transformations, therefore no optimizations are performed for these clock gates."}
{"header": "How do I Clock Gating and Multibit Registers", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you set constraints for physical implementation, you can set nondefault routing rules to define stricter (wider) wire width and spacing requirements for specific nets to improve timing and reduce crosstalk.\n To specify nondefault routing rules, use the create_routing_rule and  set_routing_rule commands.\n       However, the  set_routing_rule command does not allow annotation on the output nets of tool-inserted clock gates, because these nets do not exist until after the execution of the compile_fusion command.\n To specify nondefault routing rules that are applied automatically on nets connected to the output pins of tool-inserted clock gates, use the  set_clock_gate_routing_rule command.\n These rules are applied on clock gates after the  compile_fusion command.\n For example, create_routing_rule\u00a0cg_rule...\n set_clock_gate_routing_rule\u00a0-rule\u00a0cg_rule...\n compile_fusion...\n report_routing_rules"}
{"header": "How do I Placement-Aware Clock Gating", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the Fusion Compiler flow, clock gating works in conjunction with multibit register mapping.\n The multibit packing ratio has a higher precedence than clock gating.\n The following command enables multibit mapping: fc_shell>\u00a0 set_app_options -name compile.flow.enable_multibit -value true Clock-gating cells are not inserted to gate preinstantiated multibit registers.\n For more information on clock gating reports, see  Reporting Clock-Gating Results."}
{"header": "How do I Fanin-Based Sequential Clock Gating", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you enable placement-aware clock gating, the tool performs the following optimizations: \u2022 Replication of clock gates with timing-critical enables \u2022 Adjustment of clock gates so they are placed closer to their gated registers \u2022 Automatic clock network latency annotation for clock-gate cells To enable this feature, set the  compile.clockgate.physically_aware application option to  true.\n (The default is  false.) The example in  Figure\u00a061 shows the difference between using and not using physically- aware clock gating.\n In this layout view, you can see that the integrated clock gates (shown in red) are physically closer to their gated registers.\n       Figure 61 Placement-Aware Clock Gating Clock gate cells are shown in  red Gated clock nets are shown in  blue Placement-Aware Clock Gating Disabled Placement-Aware Clock Gating Enabled"}
{"header": "How do I Setting Sequential Clock Gating Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Sequential clock gating is the process of extracting and propagating enable conditions from upstream or downstream sequential elements in the data path for the purpose of enabling clock gate insertion for additional registers.\n The Fusion Compiler tool supports fanin-based sequential clock gating, in which a register can be gated during a given clock cycle if all the registers in the transitive fanin did not change state in the previous clock cycle.\n To enable this feature, set the  comple.clockgate.fanin_sequential application option to  true (the default is  false ).\n This feature requires the FC-New-Tech-Power license.\n Figure\u00a062 and  Figure\u00a063 illustrate the general concept of fanin-based sequential clock gating.\n The circuit in  Figure\u00a062 has a register bank R1 whose transitive fanin consists       of register bank R0.\n All registers in bank R0 share the same enable condition EN0 and all registers in both register banks are clocked by clock CLK.\n If in one clock cycle the registers in bank R0 are disabled (in other words, enable signal EN0 is 0), those registers do not change their values.\n Therefore, in the next clock cycle, the registers in bank R1 do not change their values and consequently they are candidates for clock gating.\n Figure 62 Before Clock Gating Figure\u00a063 shows the clock-gate implementation.\n Clock gate CG1 is first inserted for register bank R0.\n The tool creates a new register RD1 to generate a delayed version of enable signal EN0.\n The delayed signal drives sequential clock gate SEQCG1 for register bank R1.\n Figure 63 After Clock Gating The Fusion Compiler tool implements several different clock-gating strategies as needed, based on analyzing the circuit.\n For example, if the fanin registers do not all have the same enable signals, the tool looks for common signals upstream from the enable signals and uses those signals as inputs to the inserted delay register.\n Sequential clock gates are inserted by the  compile_fusion command.\n During the initial_map stage, the tool analyzes the local hierarchy of the registers and inserts clock gates as needed.\n During the  logic_opto stage, the tool performs analysis across hierarchical boundaries and inserts additional clock gates as needed.\n The name of a clock gate inserted as a result of fanin-based sequential clock gating begins with the prefix  seq_clock_gate_fi_.\n The rest of the name follows standard clock-       gate naming conventions.\n If the tool inserts a delay register as a result of this feature, the register name begins with the prefix  reg_seqcg_ followed by standard clock-gate naming conventions (in other words, the most common base name among the gated registers)."}
{"header": "How do I Reporting Sequential Clock Gates", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Sequential clock gates inserted by the tool honor the settings in the set_clock_gating_style command, which applies to all clock gates.\n However, the following commands are specific to fanin-based sequential clock gates: \u2022 The  set_fanin_sequential_clock_gating_options command This command specifies the minimum bitwidth and maximum fanout that a fanin-based sequential clock gate is allowed to gate.\n The default minimum bitwidth is 3 and the default maximum fanout is unlimited.\n You can specify a list of designs, power domains, and hierarchical instances to which the settings apply.\n \u2022 The  report_fanin_sequential_clock_gating_options command This command lists the settings for design objects.\n \u2022 The  set_fanin_sequential_clock_gating_objects command This command allows you to specify registers, hierarchical cells, power domains, or modules to be included in or excluded from fanin-based sequential clock gate insertion.\n \u2022 The  report_fanin_sequential_clock_gating_objects command This command lists the settings explicitly set with the set_fanin_sequential_clock_gating_objects command.\n Regardless of any settings made with the set_fanin_sequential_clock_gating_options and set_fanin_sequential_clock_gating_objects commands, the following conditions prevent fanin-based sequential clock-gate insertion: \u2022 A register has asynchronous state changes.\n \u2022 A register contains objects other than edge-triggered flip-flops in its transitive fanin.\n Disallowed objects include ports, latches, and registers with asynchronous state changes.\n \u2022 The enable signal extracted from registers in the transitive fanin depends on their output pins.\n \u2022 The toggle rate of a register's clock signal is so low that clock gating provides no benefit.\n       \u2022 Registers in the transitive fanin are controlled by a different base clock or triggered by the opposite clock edge.\n \u2022 At least one of the registers in the transitve fanin is always enabled.\n \u2022 The next state function of the register under analysis or of the registers in its transitive fanin depends on logic that contains a  dont_care condition in the RTL.\n \u2022 The register under analysis is multibit and its slices do not share the same enable signal."}
{"header": "How do I Reporting Clock-Gating Results", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "If sequential clock gating is enabled, the  report_clock_gating command automatically displays a summary table, similar to the following: Sequential\u00a0Clock\u00a0Gating\u00a0Summary ------------------------------------------------------------------------------ |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0Bitwidth\u00a0\u00a0\u00a0| ------------------------------------------------------------------------------ |No\u00a0of\u00a0sequential\u00a0clock\u00a0gates\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |No\u00a0of\u00a0fanin-based\u00a0sequential\u00a0clock\u00a0gates\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a02\u00a0(100.0%)\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |No\u00a0of\u00a0sequentially-gated\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a07\u00a0(21.2%)\u00a0\u00a0|\u00a0\u00a0\u00a07\u00a0(21.2%)\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |No\u00a0of\u00a0fanin-based\u00a0sequentially-gated\u00a0regs\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a07\u00a0(21.2%)\u00a0\u00a0|\u00a0\u00a0\u00a07\u00a0(21.2%)\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |No\u00a0of\u00a0registers\u00a0not\u00a0sequentially\u00a0gated\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a026\u00a0(78.8%)\u00a0\u00a0|\u00a0\u00a026\u00a0(78.8%)\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |Total\u00a0number\u00a0of\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a033\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a033\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| ------------------------------------------------------------------------------ Use the  report_clock_gating\u00a0-ungated command to report the reasons why sequential clock gating is not implemented.\n The report is similar to the following: fc_shell>\u00a0 report_clock_gating -ungated  -------------------------------------------------------------------------- Not\u00a0fanin-based\u00a0sequentially\u00a0gated\u00a0registers -------------------------------------------------------------------------- Register\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0Reason\u00a0for\u00a0not\u00a0gating\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0What's\u00a0next?\n -------------------------------------------------------------------------- q2_reg[0]\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Register\u00a0contains\u00a0object\u00a0different\u00a0than\u00a0edge-triggered flip-flops\u00a0in\u00a0its\u00a0transitive\u00a0fanin\u00a0\u00a0|\u00a0Check\u00a0the\u00a0register transitive\u00a0fanin q2_reg[4]\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Register\u00a0contains\u00a0object\u00a0different\u00a0than\u00a0edge-triggered flip-flops\u00a0in\u00a0its\u00a0transitive\u00a0fanin\u00a0\u00a0|\u00a0Check\u00a0the\u00a0register transitive\u00a0fanin u/reg1_reg[2]\u00a0|\u00a0Register\u00a0enable\u00a0function\u00a0is\u00a0not\u00a0a\u00a0cover\u00a0of\u00a0the\u00a0transitive fanin\u00a0enable\u00a0function\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0Check\u00a0the\u00a0register enable\u00a0condition -------------------------------------------------------------------------- Total\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a07"}
{"header": "How do I Reporting Clock-Gate Enable Signals", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After compiling your design, you can check the results using the  report_clock_gating command.\n An example is shown in  Figure\u00a064.\n Figure 64 Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics.\n The term \"pre-existing clock gates\" refers to user-instantiated clock gates.\n The preexisting category also includes registers that are gated by a tool-inserted clock gate.\n This includes registers that are gated by both preexisting and tool-inserted clock-gating cells.\n By default, the tool reports multilevel statistics.\n This includes the maximum level of clock- gating cells in the design.\n Clock-gate levels are counted from the clock source toward the register.\n If multibit flip-flops are found in the design, multibit composition is automatically reported.\n       Figure 65 Example of a Multibit Composition Report To report the details on ungated registers, use the  -ungated option for report_clock_gating.\n For details on the gated registers, use the  -gated option."}
{"header": "How do I Clock Gate Efficiency Reporting", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "A clock gate often has an enable signal that is a Boolean expression comprising of one or more of the following reference (or invariant) points: \u2022 Hierarchical ports \u2022 Sequential output pins \u2022 Black box output pins To report the clock gate enable signal as a Boolean function, use the report_clock_gating_enable_condition command.\n You must specify a collection of clock gates to be reported."}
{"header": "How do I Self-Gating Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The clock gate efficiency reporting feature calculates the efficiency of clock-gates by considering toggle rate.\n This computation based on toggle rate has a direct dependency on power saving which can be used to improve gating efficiency.\n The  report_clock_gating_efficiency command reports the overall clock gating efficiency of the user specified clock gates for each clock tree.\n The syntax of the command is as follows: -\u00a0report_clock_gating_efficiency [-by_register] [-by_clock_gate] [-bin_size] [-type\u00a0clock_gate\u00a0|\u00a0self_gate\u00a0|\u00a0fanin_seqcg] [-origin\u00a0tool_inserted\u00a0|\u00a0pre_existing] [-sortby\u00a0name\u00a0|\u00a0stage\u00a0|\u00a0gating_efficiency]       The following figure shows the  report_clock_gating_efficiency command report: The columns of this report include the following parameters: \u2022 Toggle Savings Distribution : A histogram of registers efficiency with a bin size of 5 (the bin size can be modified) \u2022 Number of Registers : The number of registers in each histogram bin \u2022 Accumulated Percentage : The cumulative percentage of registers encountered so far \u2022 Number of Bitwidth : The bitwise equivalent for the number of registers in each bin \u2022 Accumulated Percentage (of the bitwidth): The cumulative bitwise register equivalent percentage encountered so far       The reports can be refined to report efficiency with respect to the following: \u2022 Bin size using the following command: report_clock_gating_efficiency\u00a0-bin_size\u00a0#numberofbin \u2022 Registers using the following command: report_clock_gating_efficiency\u00a0-by_register       The columns of this report include the following parameters: \u25e6 Register : The name of the register under consideration \u25e6 Bitwidth : Bitwidth of the register \u25e6 Local Clock Toggle Rate : Toggle rate at the clock pin of the register after gating \u25e6 D Toggle Rate : Toggle rage at the D-pin of the register \u25e6 Q Toggle Rate : Toggle rage at the Q-pin of the register \u25e6 D/Clk Toggle Rate : D toggle rate per local clock toggle rate \u25e6 Q/Clk Toggle Rate : Q toggle rate per local clock toggle rate \u25e6 Current Gating Efficiency : Efficiency of the register computed as 1 (local clock toggle by root clock toggle) \u2022 Clock gates using the following command: report_clock_gating_efficiency\u00a0-by_clock_gate The columns of this report include the following parameters: \u25e6 Clock : The root clock of the clock gate \u25e6 Clock Gating Stage : Stage of the clock gate \u25e6 Gating Element \u25e6 Number of Fanout Registers : The number of registers the clock gate is directly driving \u25e6 Number of Fanout Bitwidth : The bitwidth equivalent for the number of registers the clock gate is directly driving       \u25e6 Toggle Savings : Toggle saving of the clock-gate \u25e6 Clock Gating Efficiency : The efficiency of the clock gate \u25e6 Receiver Clock Gate : The name of clock-gate directly driven by the clock-gate under consideration The output can also be sorted based on name, efficiency, or stage of clock gates in ascending order using the following command: report_clock_gating_efficiency\u00a0-sort_by\u00a0[name\u00a0|\u00a0stage\u00a0| gating_efficiency] \u2022 name : Alphabetically \u2022 stage : By clock gate stage \u2022 gating_efficiency : By clock gate or register gating efficiency       The following figure shows an example report:"}
{"header": "How do I Self-Gating Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool supports self-gating optimization, which occurs at the  compile_fusion command.\n This feature reduces dynamic power consumption by turning off the clock signal of certain registers during clock cycles when the data remains unchanged.\n       Figure 66 Example of a Self-Gating Cell CLK D Q Registers with an enable condition that cannot be inferred from the existing logic can only be gated using the self-gating technique.\n They cannot be gated using traditional clock gating.\n By default, the tool supports self-gating only on registers that are not gated.\n You can use the  set_self_gating_options command to allow self-gating on these registers.\n However, the time duration that the clock signal is turned off might increase for these registers,.\n To ensure QoR improvements, the self-gating algorithm takes timing and power into consideration.\n A self-gating cell is inserted for the registers if \u2022 There is enough timing slack available in the register's data pin.\n For designs with multiple scenarios, the algorithm considers the timing of the worst case among active scenarios enabled for setup.\n \u2022 Internal dynamic power of the circuit is reduced.\n For designs with mutiple scenarios, the algorithm uses the average internal dynamic power among active scenarios enabled for dynamic power.\n To minimize the area and power overhead, a self-gating cell can be shared across a few registers by creating a combined enable condition with a tree of comparator cells.\n If the self-gated registers are driven by synchronous set or synchronous clear signals, these signals are also included in the construction of the enable signal so that the circuit remains functionally unchanged.\n  Figure\u00a067  is an example of a self-gating cell that is shared across two registers (4 bits).\n Note that one of the self-gated registers is a multibit register and the other register is a single-bit register.\n The tool can also self-gate a group of multibit registers or a group of single-bit registers.\n       Figure 67 Self-Gating Tree CLK D0 Q0 D2 Q2 D1 Q1 D Q EN The tool does not support the following types of sequential cells for self-gate insertion: \u2022 Level-sensitive sequential cells \u2022 Level-sensitive scan design registers \u2022 Master-slave flip-flops \u2022 Retention registers \u2022 Single-bit and multibit registers that belong to shift registers \u2022 Multibit registers with multiple clock paths For more information, see the following topics: \u2022 Self-Gating Flow \u2022 Library Requirements for Self-Gating \u2022 Setting Up for Self-Gating \u2022 Reporting and Querying Self-Gating Cells"}
{"header": "How do I Library Requirements for Self-Gating", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Figure\u00a068 illustrates the Fusion Compiler flow for inserting self-gates by using the compile_fusion command.\n       Figure 68 General Self-Gating Flow Fusion Compiler read_saif\u00a0in.saif or set_switching_activity compile_fusion SAIF RTL/netlist Libraries Reports set_app_options\u00a0-name compile.clockgate.self_gating\u00a0-value\u00a0true"}
{"header": "How do I Setting Up for Self-Gating", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform self-gating, the logic library should contain AND and OR gates to build the self- gating tree.\n The library should also contain XOR, NAND, and OR gates for the comparator gate.\n The integrated clock-gating cells in the library must have the following settings: \u2022 Sequential cell: latch \u2022 Control point: before \u2022 Control signal: scan_enable \u2022 Observation point: none If the library does not contain cells with these configurations for the corresponding operating conditions, the tool does not insert self-gating cells.\n If an integrated clock gate compatible with self-gating is specified by the  set_clock_gate_style command, the self- gating feature uses the same integrated clock gate or the clock gate that is most similar to the one specified."}
{"header": "How do I Setting Self-Gating Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set up the block for self-gating, perform the following steps before you run the compile_fusion command: 1.\n Enable self-gating by setting the  compile.clockgate.self_gating application option to  true.\n fc_shell>\u00a0 set_app_options -name compile.clockgate.self_gating \\ -value true 2.\n Apply switching activity by using the  read_saif or  set_switching_activity command.\n 3.\n (Optional) Specify self-gating settings using the  set_self_gating_options command.\n For more information, see  Setting Self-Gating Options.\n 4.\n (Optional) Override the tool's default behavior of selecting self-gating objects by using the  set_self_gating_objects command.\n For more information, see  Controlling the Selection of Self-Gating Objects."}
{"header": "How do I Controlling the Selection of Self-Gating Objects", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify self-gating settings, use the  set_self_gating_options command with the following options: \u2022 -min_bitwidth bitwidth Controls the minimum size for self-gating banks.\n The default is 4.\n \u2022 -max_bitwidth bitwidth Controls the maximum size for self-gating banks.\n The default is 8.\n \u2022 -interaction_with_clock_gating\u00a0 interaction_type Registers gated by user-instantiated clock-gating cells are candidates for self-gating.\n Valid arguments are  none (skip registers gated by tool-inserted clock gates),  insert (the default; insert self-gates on gated registers), and  collapse (collapse tool-inserted clock gates if they are in the same hierarchy).\n \u2022 -objects\u00a0 object_list Specifies that the options should be applied to the listed objects.\n Supported objects are hierarchical instances, power domains, and designs.\n By default, the settings apply to the entire design.\n \u2022 -tree_type\u00a0 combinational_logic_type Uses the specified logic type to build the gated enable tree.\n Valid arguments are  xor, nand,  or, and  auto (the default).\n       To report self-gating options, use the  report_self_gating_options command."}
{"header": "How do I Reporting and Querying Self-Gating Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To override the default behavior of selecting self-gating objects, use the set_self_gating_objects command with the following options: \u2022 -force\u00a0 object_list Directs the tool to perform self-gating on the listed objects, even if the objects do not pass internal checks.\n \u2022 -exclude\u00a0 object_list Prevents the tool from self-gating the listed objects, even if they pass the internal checks.\n \u2022 -include\u00a0 object_list Specifies that the listed objects should be self-gated according to the insertion rules set by the  set_clock_gating_options command.\n This is the default setting for all registers in the design.\n \u2022 -clear\u00a0 object_list Removes all inclusion, exclusion, and forced criteria on the listed objects.\n \u2022 -reset Removes all configurations previously set by the  set_self_gating_objects command.\n \u2022 -tree_type\u00a0 combinational_logic_type Specifies the type of combinational cells to use.\n Valid arguments are  xor (the default), or,  nand, and  auto.\n When  auto is specified, the tool automatically decides which comparison logic to use based on switching activity information.\n This might help to reduce the area while optimizing power.\n You must use this option with the  -include or -force options.\n To report self-gating objects, use the  report_self_gating_objects command."}
{"header": "How do I Special Naming and Querying for DFT Wrapper Clock Gates", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  report_clock_gating command automatically detects the presence of self-gates in the design and displays the corresponding information at the bottom of the report, as shown in the following example report.\n       Clock\u00a0Gating\u00a0Summary ------------------------------------------------------------------ |\u00a0\u00a0Number\u00a0of\u00a0Clock\u00a0gating\u00a0elements\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a05\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Tool-Inserted\u00a0Clock\u00a0gates\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a05\u00a0(100.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Pre-Existing\u00a0Clock\u00a0gates\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0(0.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Gated\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048\u00a0(100.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Tool-Inserted\u00a0Gated\u00a0registers\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048\u00a0(100.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Pre-Existing\u00a0Gated\u00a0registers\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0(0.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Ungated\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0\u00a0\u00a0(0.00%)\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Total\u00a0number\u00a0of\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Max\u00a0number\u00a0of\u00a0Clock\u00a0Gate\u00a0Levels\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0Number\u00a0of\u00a0Multi\u00a0Level\u00a0Clock\u00a0Gates\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| ------------------------------------------------------------------ Self\u00a0Gating\u00a0Summary --------------------------------------------------------- |\u00a0\u00a0\u00a0\u00a0Number\u00a0of\u00a0self-gating\u00a0cells\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0Number\u00a0of\u00a0self\u00a0gated\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a020\u00a0\u00a0(41.67%)\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0Number\u00a0of\u00a0registers\u00a0not\u00a0self-gated\u00a0|\u00a0\u00a028\u00a0\u00a0(58.33%)\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| |\u00a0\u00a0\u00a0\u00a0Total\u00a0number\u00a0of\u00a0registers\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a048\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| ---------------------------------------------------------- Self-gating cells are also counted as clock gates in the clock gating summary table.\n In this example, there are two clock gates and three self-gates, for a total of five clock-gating elements.\n You can find all the self-gates in a design by using the  get_clock_gates command.\n This command returns a collection of clock-gating or self-gating cells.\n For example, the following command returns the self-gating cells that gate registers clock by CLK: fc_shell>\u00a0 get_clock_gates -clock CLK -type self-gate"}
{"header": "How do I 5", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "DFT wrapper clock gates refer to those clock gates that drive only DFT wrapper cells.\n The clock gating engine prefixes  dft_wrapper_ to the names of all DFT wrapper clock gates       clock gates irrespective of their origin.\n This helps to identify specific clock gates driving wrapper cells during automatic test pattern generation (ATPG).\n Table 24 Commands and their expected return values Command Expected Return Value get_clock_gates\u00a0-gating_wrapper_cells_only  dft_wrapper_ICG  dft_wrapper_clock_gate_reg get_clock_gates\u00a0-gating_wrapper_cells_only -origin\u00a0tool_inserted   dft_wrapper_clock_gate_reg  get_clock_gates\u00a0-gating_wrapper_cells_only -origin\u00a0pre_existing   dft_wrapper_ICG  get_clock_gates\u00a0{ICG\u00a0clock_gate_reg} -gating_wrapper_cells_only   get_clock_gates\u00a0{ICG dft_wrapper_clock_gate_reg} -gating_wrapper_cells_only    dft_wrapper_clock_gate_reg get_clock_gates\u00a0{*clock_gate_reg} -gating_wrapper_cells_only    dft_wrapper_clock_gate_reg This feature works only when you enable clock gate support for DFT wrapper cells.\n To enable clock gate support for DFT wrapper cells, set the following variable to  true : compile.clockgate.enable_dft_wrapper_cell_support       The following figures show how a clock gate can be split so that different clock gates can gate internal cells and wrapper cells separately: Figure 69 Splitting a Clock Gate to Internal Cells and Wrapper Cells Figure 70 Gating Internal Cells and Wrapper Cells Separately       Note: The clock gates cloned to gate wrapper cells alone, inherit their names from parent clock gates and have  dft_wrapper_ appended to their names.\n This is not applicable to the names of self-gates that drive wrapper cells only.\n Table\u00a025 shows how different types of clock gates are renamed.\n Table 25 How different clock gate types are renamed Clock Gate Type Name New Name  clock_gate_reg dft_wrapper_clock_gate_reg  icg_0 dft_wrapper_icg_0 Use the  -gating_wrapper_cells_only option with the  get_clock_gates command to return all clock gates (except self-gates) that drive wrapper cells only.\n This option can be used in conjunction with the already existing options.\n Use the  compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option to restrict the renaming of pre-existing clock gates (driving wrapper cells only).\n This option accepts a list of strings as values.\n The clock gates matching any of the substrings provided in the application option are not renamed.\n Note: The compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option does not have any effect on the -gating_wrapper_cells_only querying option.\n Consider the following example: set_app_options\u00a0-name compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs\u00a0-value {clk_gate_ctl\u00a0clk_gate_snps} This prevents the renaming of any pre-existing clock gates that have the  clk_gate_ctl or clk_gate_snps pattern in their name but can still be queried using the  get_clock_gates -gating_wrapper_cells_only command."}
{"header": "How do I Prerequisites for Clock Tree Synthesis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To learn how to perform clock tree synthesis in the Fusion Compiler tool, see the following topics: \u2022 Prerequisites for Clock Tree Synthesis \u2022 Defining the Clock Trees \u2022 Verifying the Clock Trees \u2022 Setting Clock Tree Design Rule Constraints \u2022 Specifying the Clock Tree Synthesis Settings \u2022 Implementing Clock Trees and Performing Post-CTS Optimization \u2022 Implementing Multisource Clock Trees \u2022 Analyzing the Clock Tree Results"}
{"header": "How do I Defining the Clock Trees", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "This topic details the prerequisites required before running the clock tree synthesis.\n Before you run clock tree synthesis on a block, it should meet the following requirements: \u2022 The clock sources are identified with the  create_clock or  create_generated_clock commands.\n \u2022 The block is placed and optimized.\n Use the  check_legality\u00a0-verbose command to verify that the placement is legal.\n Running clock tree synthesis on a block that does not have a legal placement might result in long runtimes and reduced QoR.\n The estimated QoR for the block should meet your requirements before you start clock tree synthesis.\n This includes acceptable results for \u25e6 Congestion If congestion issues are not resolved before clock tree synthesis, the addition of clock trees can increase congestion.\n If the block is congested, you can rerun the       create_placement command with the  -congestion and  -congestion_effort high options, but the runtime can be long.\n \u25e6 Timing \u25e6 Maximum capacitance \u25e6 Maximum transition time \u2022 The power and ground nets are prerouted.\n \u2022 High-fanout nets, such as scan enables, are synthesized with buffers.\n \u2022 The active scenarios are defined.\n By default, the Fusion Compiler tool synthesizes and optimizes all clocks in all active scenarios that are enabled for setup or hold analysis."}
{"header": "How do I Deriving the Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "This section details the information required to analyze and define each clock tree before running clock tree synthesis.\n Before you run clock tree synthesis, analyze each clock tree in the block and determine \u2022 What the clock root is \u2022 What the required clock sinks and clock tree exceptions are \u2022 Whether the clock tree contains preexisting cells, such as clock-gating cells \u2022 Whether the clock tree converges, either with itself (a convergent clock path, definedclockconvergent convergent clock path) or with another clock tree (an overlaping clock path, definedclockoverlaping overlapping clock path) \u2022 Whether the clock tree has timing relationships with other clock trees in the block, such as interclock skew requirements Use this information to define the clock trees and validate that the tool has the correct clock tree definitions.\n The Fusion Compiler tool derives the clock trees based on the clocks defined in the block.\n If the derived clock trees do not meet your requirements, you can define clock trees as described in the following topics: \u2022 Deriving the Clock Trees \u2022 Defining Clock Tree Exceptions \u2022 Restricting Optimization on the Clock Network \u2022 Copying Clock Tree Exceptions Across Modes       \u2022 Deriving Clock Tree Exceptions From Ideal Clock Latencies \u2022 Handling Endpoints With Balancing Conflicts"}
{"header": "How do I Identifying the Clock Roots", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool derives the clock trees by tracing through the transitive fanout from the clock roots to the clock endpoints.\n In general, the tracing terminates when it finds a clock pin of a sequential cell or macro; however, the tool traces through sequential cells if they are integrated clock-gating (ICG) cells or their fanout drives a generated clock.\n If the clock-gating logic uses a non-unate cell, such as an XOR or XNOR gate, the tool uses both the positive-unate timing arc and the negative-unate timing arc when tracing the clock path.\n If this does not correspond to the functional mode of the block, use the set_case_analysis command to hold all nonclock inputs of the cell at a constant value, which forces the cell into the required functional mode for clock tree synthesis.\n For example, suppose a block has the gating logic shown in  Figure\u00a071.\n Figure 71 Non-Unate Gated Clock To force the XOR gate (U0) into functional mode for timing analysis, use the following command: fc_shell>\u00a0 set_case_analysis 0 U0/B"}
{"header": "How do I Identifying the Clock Endpoints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool uses the clock sources defined by the  create_clock command, which can be either input ports or internal hierarchical pins, as the clock roots.\n For nested clock trees with generated clocks, which are defined by the create_generated_clock command, the tool considers the master-clock source to be the clock root, and the clock endpoints of the nested clock tree are considered endpoints of the master-clock source.\n For example, for the netlist shown in  Figure\u00a072, the tool considers the CLK port to be the clock root for the genclk1 generated clock.\n       Figure 72 Nested Clock Tree With a Generated Clock D Q CLK QN clk1 genclk1 If the block contains generated clocks, ensure that the master-clock sources are correctly defined, as incorrect definitions can result in poor skew and timing QoR.\n In particular, \u2022 If the tool cannot trace back to the master-clock source, it cannot balance the sink pins of the generated clock with the sink pins of its source.\n \u2022 If the master-clock source is not a clock source defined by the  create_clock or create_generated_clock command, the tool cannot synthesize a clock tree for the generated clock or its source.\n Use the  check_clock_trees command to verify that your master-clock sources are correctly defined, as described in  Verifying the Clock Trees.\n Specifying the Clock Root Timing Characteristics To get realistic clock tree synthesis results, you must ensure that the timing characteristics of the clock roots are correctly modeled.\n \u2022 If the clock root is an input port without an I/O pad cell, you must accurately specify the driving cell of the input port.\n If you specify a weak driving cell, the tool might insert extra buffers to try to meet the clock tree design rule constraints, such as maximum transition time and maximum capacitance.\n If you do not specify a driving cell (or drive strength), the tool assumes that the port has infinite drive strength.\n For example, if the CLK1 port is the root of the CLK1 clock tree, use the following command to set its driving cell as the CLKBUF cell in the mylib cell library: fc_shell>\u00a0 set_driving_cell -lib_cell mylib/CLKBUF [get_ports CLK1] \u2022 If the clock root is an input port with an I/O pad cell, you must accurately specify the input transition time of the input port.\n       For example, if the CLK1 port is the root of the CLK1 clock tree and the I/O pad cell has already been inserted, use the following commands to set its input transition time to 0.3 for rising delays and 0.2 for falling delays: fc_shell>\u00a0 set_input_transition -rise 0.3 [get_ports CLK1] fc_shell>\u00a0 set_input_transition -fall 0.2 [get_ports CLK1]"}
{"header": "How do I Defining Clock Tree Exceptions", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When deriving the clock trees, the tool identifies two types of clock endpoints: \u2022 Sink pins clock tre synthesistop pindefinedexceptions for clock tre synthesistop pinsclock tre exceptionstop pinclock tre sinksdefining Sink pins are the clock endpoints that are used for delay balancing.\n The tool assigns an insertion delay of zero to all sink pins and uses this delay during delay balancing.\n During clock tree synthesis, the tool uses sink pins in calculations and optimizations for both design rule constraints and clock tree timing (skew and insertion delay).\n Sink pins are also referred to as balancing pins.\n \u2022 Ignore pins clock tre synthesisexclude pindefinedexceptions for clock tre synthesisexclude pinsclock tre exceptionsexclude pin Ignore pins are clock endpoints that are excluded from clock tree timing calculations and optimizations.\n The tool uses ignore pins only in calculations and optimizations for design rule constraints.\n During clock tree synthesis, the tool isolates ignore pins from the clock tree by inserting a guide buffer before the pin.\n Beyond the ignore pin, the tool never performs skew or insertion delay optimization, but does perform design rule fixing.\n The tool identifies the following clock endpoints as sink pins: \u2022 A clock pin on a sequential cell (a latch or flip-flip), unless that cell drives a generated clock \u2022 A clock pin on a macro cell       The tool identifies the following clock endpoints as clock tre synthesisimplicitexclude pin ignore pins: \u2022 Source pins of clock trees in the fanout of another clock For example, in  Figure\u00a073, the source pin of the driven clock (clk2) is an ignore pin of the driving clock (clk1).\n Sinks of the driven clock are not considered sinks of the driving clock.\n Figure 73 Cascaded Clock With Two Source Clocks CLK clk1 clk2 \u2022 Nonclock input pins of sequential cells \u2022 Three-state enable pins \u2022 Output ports \u2022 Incorrectly defined clock pins (for example, the clock pin does not have trigger edge information or does not have a timing arc to the output pin) \u2022 Buffer or inverter input pins that are held constant by using the  set_case_analysis command Note: The tool does not synthesize a clock tree if its source is held constant by using the  set_case_analysis command.\n \u2022 Input pins of combinational cells or integrated clock-gating cells that do not have any fanout or that do not have any enabled timing arcs To verify that the tool has correctly identified the sink pins and ignore pins, examine the clock trees in the GUI, as described in  Analyzing Clock Trees in the GUI.\n If the default sink and ignore pins are correct, you are done with the clock tree definition.\n Otherwise, first identify any timing settings, such as disabled timing arcs and case analysis settings, that affect the clock tree traversal.\n To identify disabled timing arcs in the block, use the  report_disable_timing command.\n To identify case analysis settings in the block, use the  report_case_analysis command.\n Remove any timing settings that cause an incorrect clock tree definition.\n       If necessary, you can override the default balancing and ignore pin settings by using the set_clock_balance_points command, as described in  Defining Clock Tree Exceptions.\n The implicit ignore on an intermediate pin can be inferred by any of the following reasons: \u2022 All the register pins in the fanout are EXPLICIT IGNORE \u2022 Disabled path on a MUX input is caused by the  set_case_analysis command \u2022 Disabled timing arc on a downstream pin is set by the  set_disable_timing, set_false_path commands, disable timing due to conditional arcs.\n \u2022 set_sense\u00a0-stop_propogation constraint on a downstream pin \u2022 Dangling pin in the downstream path \u2022 Downstream path goes to a data pin of a register or a subblock \u2022 Downstream path has an unconstrained output port without any set_clock_balance_point\u00a0-consider_for_balancing\u00a0true setting \u2022 Downstream path has a constrained  set_output_delay output port \u2022 Pins on the path to cascaded  create_clock definition Note: This implicit or explicit ignore does not essentially mean that the clock endpoints are excluded from clock tree calculations.\n Explicit ignore means, the endpoints are not considered for skew balancing with other endpoints of the clock, but the portion is considered for DRC fixing in clock tree."}
{"header": "How do I Defining Sink Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Clock tree exceptions are user-defined changes to the default endpoints (balancing and ignore pins) derived by the tool for a specific clock.\n The Fusion Compiler tool supports the following types of clock tree exceptions: \u2022 User-defined sink pins These exceptions define sink pins in addition to those derived by the tool for a clock tree.\n For example, you might define a tool-derived ignore pin as a clock sink.\n For information about defining sink pins, see  Defining Sink Pins.\n \u2022 User-defined insertion delay requirements These exceptions specify special insertion delay requirements for a sink pin (either derived or user-specified).\n       For information about defining insertion delay requirements, see  Defining Insertion Delay Requirements.\n \u2022 User-defined ignore pins These exceptions exclude clock endpoints that were derived as sink pins by the tool.\n For example, you might define an ignore pin to exclude all branches of the clock tree that fan out from some combinational logic or to exclude a tool-derived sink pin.\n For information about defining ignore pins, see  Defining Ignore Pins."}
{"header": "How do I Defining Insertion Delay Requirements", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define one or more pins as sink pins, use the following syntax: set_clock_balance_points -clock\u00a0 clock -consider_for_balancing\u00a0true -balance_points\u00a0 pins [-corners\u00a0 corners ] The  -clock option is not required.\n If you do not use it, the sink pin applies to all clocks.\n By default, the insertion delay for the user-specified sink pins is 0.\n For information about overriding the default insertion delay, see  Defining Insertion Delay Requirements.\n When you define sink pins, by default, they apply to all corners.\n To apply the definition to specific corners, use the  -corners option.\n For example, to specify pin U2/A as a sink pin for the CLK clock in the current corner, use the following command: fc_shell>\u00a0 set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing true -balance_points [get_pins U2/A] To report the user-defined sink pins, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins report_clock_balance_points command.\n This command reports both the user-defined sink pins and the user-defined ignore pins.\n To remove the sink pin definition from a pin, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins remove_clock_balance_points command.\n For example, to remove the sink pin definition from the U2/A pin for the CLK clock, use the following command: fc_shell>\u00a0 remove_clock_balance_points -clock [get_clocks CLK] \\ -balance_points [get_pins U2/A]"}
{"header": "How do I Defining Ignore Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To override the default phase delay of zero for sink pins (derived or user-specified), use the  -delay option with the  set_clock_balance_points command to specify the       insertion delay requirements.\n The tool adds the specified delay (positive or negative) to the calculated insertion delay up to the specified sink pin.\n The syntax to define the insertion delay requirement for one or more sink pins is set_clock_balance_points [-clock\u00a0 clock ] -delay\u00a0 delay [-rise]\u00a0[-fall]\u00a0[-early]\u00a0[-late] -balance_points\u00a0 pins [-corners\u00a0 corners ] The  -clock option is not required.\n If you do not use it, the insertion delay requirement applies to all clocks.\n Clock tree synthesis uses the specified delay value for the path delay calculations used to build the clock tree.\n By default, the specified delay value is used for both longest-path and shortest-path calculations for both rising-edge and falling-edge paths.\n To control when the specified delay value is used, use the  -rise,  -fall,  -early, and  -late options.\n When you define insertion delay requirements, by default, they apply to all corners.\n To apply the definition to specific corners, use the  -corners option.\n For example, to specify that clock tree synthesis should use an insertion delay of 2.0 ns for rising-edge shortest-path calculations for the U2/CLK pin for the CLK clock in the current corner, use the following command: fc_shell>\u00a0 set_clock_balance_points -clock [get_clocks CLK] \\ -rise -early -delay 2.0 -balance_points [get_pins U2/CLK] To report the user-defined insertion delay for sink pins, use the report_clock_balance_points command.\n This command reports the user-defined sink pins, the derived sink pins with user-specified insertion delay, and the user-defined ignore pins."}
{"header": "How do I Ensuring Clock Tree Exceptions are Valid", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define one or more pins as ignore pins, use the following syntax: set_clock_balance_points [-clock\u00a0 clock ] -consider_for_balancing\u00a0false -balance_points\u00a0 pins The  -clock option is not required.\n If you do not use it, all user-defined ignore pins apply to all clocks.\n       For the CLK clock tree shown in  Figure\u00a074, assume that you want to ignore all branches of the clock tree beyond the U2 cell.\n To do so, you would use the following command: fc_shell>\u00a0 set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins U2/A] Figure 74 User-Defined Ignore Pin CLK A B U2 To report the user-defined ignore pins, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins report_clock_balance_points command.\n This command reports both the user-defined sink pins and the user-defined ignore pins.\n During clock tree synthesis, the tool adds guide buffers and isolates ignore pins from the rest of the clock network.\n During subsequent data path optimization, the tool fixes any existing DRC violations beyond the guide buffers.\n To remove the ignore pin definition from a pin, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins remove_clock_balance_points command.\n For example, to remove the ignore pin definition from pin U2/CLK for the CLK clock, use the following command: fc_shell>\u00a0 remove_clock_balance_points -clock [get_clocks CLK] \\ -balance_points [get_pins U2/CLK]"}
{"header": "How do I Restricting Optimization on the Clock Network", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To identify pins on the clock network, the tool checks if the  is_clock_is_used_as_clock pin attribute is  true during clock tree synthesis.\n If you use the set_clock_balance_points command to specify a clock tree exception on a pin for which the  is_clock_is_used_as_clock attribute is  false, the tool accepts the exception, but ignores it during clock tree synthesis.\n       Consider the clock network in the following figure.\n Figure 75 Specifying Exceptions on Pins Beyond the Clock Network CLK A B U2 D FF3 Y n5 By default, the tool sets \u2022 The  is_clock_is_used_as_clock attribute of the U2/A, U2/Y, and FF3/D pins to false and considers the network beyond the U2/A pin as part of the data network \u2022 The U2/A pin as an ignore pin and excludes the network beyond this from clock tree synthesis During clock tree synthesis, the tool adds a guide buffer and isolates the U2/A pin from the rest of the clock network.\n During subsequent data path optimization, the tool can fix any existing DRC violations beyond the guide buffer.\n Assume you want clock tree synthesis to fix DRC violations up to the FF3/D pin using clock tree constraints.\n To do so, you must 1.\n Specify the FF3/D pin as an explicit ignore pin as follows: fc_shell>\u00a0 set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins FF3/D]       2.\n Force clock tree synthesis to consider the FF3/D pin as a pin on the clock network by using the  set_sense\u00a0-clock_leaf command as follows: fc_shell>\u00a0 set_sense -clock_leaf [get_pins FF3/D] The  set_sense\u00a0-clock_leaf command sets \u25e6 The  is_clock_used_as_clock attribute to  true for all the pins of the clock branches that fanin to the pin specified as the clock leaf \u25e6 The  is_clock_used_as_clock attribute to  false for all the pins in the fanout from the pin specified as the clock leaf, and the tool does not propagate the clock beyond this pin To check the value of the  is_clock_used_as_clock pin attribute, use the get_attribute command, as shown in the following example: fc_shell>\u00a0 get_attribute [get_pins FF3/D] is_clock_used_as_clock"}
{"header": "How do I Setting Don\u2019t Touch Settings", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can restrict the optimization on portions of the clock network by specifying \u2022 Don\u2019t touch settings These settings identify parts of the clock tree on which clock tree synthesis and optimization is not performed.\n You can use don\u2019t touch settings to prevent the modification of a clock network beyond a specific pin, the buffering of specific nets, or the sizing of specific cells.\n For information about defining don\u2019t touch settings, see  Setting Don\u2019t Touch Settings.\n \u2022 Size-only settings These settings identify clock tree cells for which the tool can perform only cell sizing.\n Note that these cells can be moved, unless they have a placement status of fixed.\n For information about defining size-only settings, see  Setting Size-Only Settings."}
{"header": "How do I Setting Size-Only Settings", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set a don't touch setting on a clock tree, use the  set_dont_touch_network command.\n fc_shell>\u00a0 set_dont_touch_network -clock_only [get_pins  pin_name ] The  -clock_only option sets the don't touch setting only on the clock network.\n If you do not specify the  -clock_only option, the don't touch setting is set on both the data path and the clock path.\n       To remove the don't touch setting from a clock tree, use the  -clear option with the set_dont_touch_network command.\n fc_shell>\u00a0 set_dont_touch_network -clock_only [get_pins  pin_name ] -clear You can also set don't touch settings on specific objects in the clock network by using the set_dont_touch command.\n The following commands set a don't touch setting on a cell and a net: fc_shell>\u00a0 set_dont_touch [get_cells  cell_name ] true fc_shell>\u00a0 set_dont_touch [get_nets -segments  net_name ] true To report all the don't touch settings set on the current block, use the  report_dont_touch command.\n fc_shell>\u00a0 report_dont_touch -all Note: If a cell has a placement status of fixed, it is treated like a don\u2019t touch cell during clock tree synthesis."}
{"header": "How do I Copying Clock Tree Exceptions Across Modes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set a size-only setting on a cell, use the  set_size_only command.\n The following command sets a size-only setting on a cell: fc_shell>\u00a0 set_size_only [get_cells  cell_name ] true To report all the size-only settings set on the current block, use the  report_size_only command.\n fc_shell>\u00a0 report_size_only -all"}
{"header": "How do I Deriving Clock Tree Exceptions From Ideal Clock Latencies", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify that the tool copies clock tree exceptions from one mode to one or more equivalent modes by using the  set_clock_tree_options command with the -copy_exceptions_across_modes,  -from_mode, and  -to_mode options.\n The following example specifies that during clock tree synthesis the clock tree exceptions in the mode name M1 should be copied to the modes name M2 and M3: fc_shell>\u00a0 set_clock_tree_options -copy_exceptions_across_modes \\ -from_mode M1 -to_mode {M2 M3}"}
{"header": "How do I Handling Endpoints With Balancing Conflicts", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you have set ideal clock latencies for specific sinks in your design, you can use the derive_clock_balance_points command to convert these ideal latency settings to clock tree exceptions.\n The  derive_clock_balance_points command converts ideal latencies specified with the  set_clock_latency command on clock sink pins to  set_clock_balance_points commands.\n Use the  derive_clock_balance_points command before clock tree synthesis, when the design has ideal clocks.\n By default, the  derive_clock_balance_points command \u2022 Generates balance point constraints for all ideal primary clocks of all active scenarios that are enabled for setup analysis, hold analysis, or both.\n It does not generate balance points for generated clocks.\n To generate the balance points for \u25e6 Specific primary clocks, use the  -clocks option.\n \u25e6 All active scenarios of specific corners, use the  -corners option.\n \u2022 Calculates a reference latency for each primary ideal clock, which is the sum of the ideal source and network latency specified on the clock with the  set_clock_latency command.\n To specify a different reference latency value, use the  -reference_latency option.\n \u2022 Applies the derived clock balance point constraints to the design.\n To generate an output file containing  set_clock_balance_points commands, instead applying it to the design, use the  -output option.\n Balance points that the tool derives are clock and corner specific.\n Ensure that appropriate set_clock_latency constraints are set for all clocks for all modes used for clock tree synthesis in at least the worst corner.\n The tool uses the following formula to derive the delay values for the corresponding set_clock_balance_points commands: (Clock balance point delay value at the sink) = (Reference latency of the clock) - (Total ideal clock latency at the sink) The total ideal clock latency at the sink is the sum of the source latency of the clock and the ideal network latency for the sink.\n       For example, assume you have the following timing constraint settings: fc_shell>\u00a0 set_clock_latency -source 0.5 [get_clocks clk] fc_shell>\u00a0 set_clock_latency 1.0 [get_clocks clk] fc_shell>\u00a0 set_clock_latency 1.5 [get_pins reg1/CK] fc_shell>\u00a0 set_clock_latency 0.5 [get_pins reg2/CK] If you run the  derive_clock_balance_points command, the tool derives the following clock balance point constraints: fc_shell>\u00a0 set_clock_balance_points -delay -0.5 \\ -balance_points [get_pins reg1/CK] -clock clk -corners worst fc_shell>\u00a0 set_clock_balance_points -delay 0.5 \\ -balance_points [get_pins reg2/CK] -clock clk -corners worst To avoid conflicts, do not manually apply any clock balance points for a clock that you derive balance points with the  derive_clock_balance_points command."}
{"header": "How do I Verifying the Clock Trees", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In some blocks, the clocks have endpoints that are structurally impossible to balance.\n The Fusion Compiler tool can automatically detect endpoints with balancing conflicts and derive an ignore pin to resolve the conflict.\n This capability is enabled by default for the synthesize_clock_trees and  clock_opt commands.\n To disable this capability, set the cts.common.enable_auto_exceptions application option to  false.\n       With this capability, the tool detects and fixes the following types of balancing conflicts: \u2022 Internal sink pins of modules that have a combinational clock path If a module contains both internal sink pins and combinational clock paths, it is impossible to balance the internal sink pins.\n To resolve the balancing conflict, the tool defines the internal sink pins as ignore pins.\n For example, assume that you have a module that contains a combinational path in the clock network, as shown in figure (a) in  Figure\u00a076, which is represented by the extracted timing model (ETM) shown in figure (b).\n Figure 76 Module With Combinational Clock Path Q Clk_out D Clk (a) Netlist (b) ETM with check pin Clk D Q Clk_out Clk_check_pin_1 Combinational delay In this case, the internal check pin inside the ETM has delays coming from the ETM timing library; these delays are considered by clock tree synthesis as sinks and are balanced with other sinks at the top level.\n If the path to the check pin is the shortest path, top-level clock tree synthesis cannot insert buffers on the shortest path and therefore leaves a large skew at the top level.\n Setting the internal check pin as an ignore pin resolves the skew issue coming from the ETM.\n \u2022 Sink pins that cannot be balanced simultaneously If a block contains two clocks that drive common sinks, one of which is a clock pin that is the parent of another sink, due to a generated clock, it is impossible to simultaneously balance the parent and child clock pins with another common sink.\n To resolve the balancing conflict, the tool defines the parent clock pin as an ignore pin.\n For example, in  Figure\u00a077, FF_gen/CLK and FF0_1-10/CLK are sinks of clkb, FF1_1-10/CLK and FF0_1-10/CLK are sinks of clka, and FF_gen/CLK is the parent of       FF1_1-10/CLK.\n In this case, the tool defines FF_gen/CLK as an ignore pin for clkb to resolve the balancing conflict.\n Figure 77 Clock Pins That Cannot Be Balanced Simultaneously"}
{"header": "How do I Setting Clock Tree Design Rule Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you synthesize the clock trees, use the check_clock_tre comandcomandscheck_clock_tre check_clock_trees command to verify that the clock trees are properly defined.\n For example, to verify that the CLK clock tree is properly defined, use the following command: fc_shell>\u00a0 check_clock_trees -clocks [get_clocks CLK] If you do not specify the  -clock option, the tool checks all clocks in the current block.\n The  check_clock_trees command checks for the following issues: \u2022 Clock (master or generated) with no sinks \u2022 Loops in the clock network \u2022 Multiple clocks reach the same register because of overlapping clocks, but multiple- clocks-per-register propagation is not enabled \u2022 Ignored clock tree exceptions \u2022 Stop pin or float pin defined on an output pin \u2022 Buffers with multiple timing arcs used in clock tree references \u2022 Situations that cause an empty buffer list       \u2022 Generated clock without a valid master clock source A generated clock does not have a valid master-clock source in the following situations: \u25e6 The master clock specified in  create_generated_clock does not exist \u25e6 The master clock specified in  create_generated_clock does not drive the source pin of the generated clock \u25e6 The source pin of the generated clock is driven by multiple clocks, and some of the master clocks are not specified with  create_generated_clock.\n For example, in  Figure\u00a078, the GEN_REG/Q pin is driven by both CLKA and CLKB.\n If only CLKA is specified as a master clock in a  create_generated_clock command, GEN_CLK does not have a valid master clock source.\n Figure 78 Generated Clock With Invalid Master Clock Source D Q 0 1 REG1 REG2 D Q D Q GEN_REG CLKA CLKB GEN_CLK For multicorner-multimode designs, the  check_clock_trees command checks all active scenarios for the following issues: \u2022 Conflicting per-clock exception settings \u2022 Conflicting balancing settings Before you implement the clock trees, you should manually fix the reported issues.\n Each message generated by the  check_clock_trees command has a detailed man page that describes how to fix the identified issue.\n You can improve the clock tree and timing QoR by fixing all the issues identified by the  check_clock_trees command."}
{"header": "How do I Specifying the Clock Tree Synthesis Settings", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis: \u2022 clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the  set_max_capacitance command.\n If you do not specify this constraint, the clock tree synthesis default is 0.6 pF.\n \u2022 clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the  set_max_transition command.\n If you do not specify this constraint, the clock tree synthesis default is 0.5 ns.\n By default, these constraints apply to all corners associated with the current mode.\n To set the constraint for a specific mode, use the  -mode option with the  get_clocks command to identify the clocks.\n To set the constraint for specific corners associated with the specified mode, use the  -corners option with the constraint command.\n Be careful to apply the correct constraints across all the modes and their associated corners.\n For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell>\u00a0 set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the  -mode option with the  get_clocks command to specify the mode and use the  -corners option to specify the corner.\n For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell>\u00a0 set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell>\u00a0 set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell>\u00a0 set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]]"}
{"header": "How do I Specifying the Clock Tree References", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The clock tree synthesis options guide the implementation of the clock trees.\n The following topics describe how to set these options: \u2022 Specifying the Clock Tree References \u2022 Setting Skew and Latency Targets \u2022 Enabling Local Skew Optimization \u2022 Specifying the Primary Corner for Clock Tree Synthesis \u2022 Preventing Specific Clocks From Being Synthesized \u2022 Preserving Preexisting Clock Trees \u2022 Enabling Clock Tree Power Reduction Techniques \u2022 Enabling Wire Length Aware Power-Driven Relocation \u2022 Reducing Electromigration \u2022 Handling Inaccurate Constraints During Clock Tree Synthesis \u2022 Defining Clock Cell Spacing Rules \u2022 Creating Skew Groups \u2022 Defining a Name Prefix for Clock Cells \u2022 Using the Global Router During Initial Clock Tree Synthesis \u2022 Specifying Constraints for Clock Nets \u2022 Constructing Faster Clock Tree to Specific Endpoints \u2022 Improving Latency-Driven Clock-Gate Splitting \u2022 Improving the Repeater Levels in Clock Tree \u2022 Reducing Signal Integrity Effects on Clock Nets \u2022 Specifying Settings for Clock Latency Adjustments \u2022 Timing Driven Sink Transition Target \u2022 Reporting the Clock Tree Settings"}
{"header": "How do I Deriving Clock Tree References for Preexisting Gates", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The buffer and inverter cells that can be used to build a clock tree and the reference cells of the preexisting gates of the clock tree are referred to as  clock tree references.\n To specify the clock tree references, use the  set_lib_cell_purpose\u00a0-include\u00a0cts command.\n Ensure that the list of cells you specify as clock tree references meets the following criteria: \u2022 The list contains at least one buffer or one inverter \u2022 The list contains the library cells of the preexisting gates If they are not included in the list, the tool is unable to resize these preexisting gates during clock tree synthesis and optimization.\n You can automatically derive equivalent cells for all the preexisting clock tree cells that are not buffers or inverters and specify them as clock references by using the  derive_clock_cell_references command, as described in  Deriving Clock Tree References for Preexisting Gates.\n \u2022 For multivoltage designs with always-on buffering requirements, the list contains always-on cells \u2022 The library cells in the reference list do not have a  dont_touch attribute If library cells have the  dont_touch attribute set on them, they are not used by clock tree synthesis even if you specify them as clock tree references.\n To ensure that clock tree synthesis uses only the specified set of cells and that these cells are not used by any optimization step other than clock tree synthesis, run the following commands: fc_shell>\u00a0 set cts_cells  list_of_cells fc_shell>\u00a0 set_lib_cell_purpose -exclude cts [get_lib_cells] fc_shell>\u00a0 set_lib_cell_purpose -include none [get_lib_cells $cts_cells] fc_shell>\u00a0 set_lib_cell_purpose -include cts [get_lib_cells $cts_cells]"}
{"header": "How do I Restricting the Target Libraries Used", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To ensure that the tool resize preexisting gates in the clock network during clock tree synthesis and optimization, you must specify equivalent cells as clock references.\n Not specifying a complete list of equivalent cells for preexisting gates can affect clock tree QoR.\n You can automatically derive equivalent cells for all the preexisting clock tree cells and specify them as clock references by using the  derive_clock_cell_references command.\n       When you run this command, the tool sets the  valid_purpose attribute to  true on equivalent library cells of the preexisting clock tree cells that are not buffers or inverters.\n This command does not derive equivalent library cells for preexisting buffers and inverters, Therefore, you must manually specify the buffers and inverters to use for clock tree synthesis, as shown in the following example: fc_shell>\u00a0 set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell>\u00a0 derive_clock_cell_references fc_shell>\u00a0 synthesize_clock_trees Instead of automatically specifying the equivalent library cells of the preexisting clock tree cells as clock tree references, you can generate a Tcl script that specifies the equivalent library cells of the preexisting clock tree cells as clock tree references.\n To do so, use the -output option.\n fc_shell>\u00a0 derive_clock_cell_references -output cts_leq_cells.tcl You can edit the output file, source it, and then run clock tree synthesis, as shown in the following example: fc_shell>\u00a0 set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell>\u00a0 source cts_leq_cells.tcl fc_shell>\u00a0 synthesize_clock_trees"}
{"header": "How do I Setting Skew and Latency Targets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can restrict the libraries used during clock tree synthesis for the top level or a lower level of the logical hierarchy of a design by using the  set_target_library_subset -clock command.\n To enable the use of the target library subset, you must set the opt.common.enable_target_library_subset_opt application option to  1.\n The following example specifies the buf1 and buf2 cells from the HVT_lib and LVT_lib libraries as clock tree references.\n However, it restricts the lower-level block named TSK_BLK to use only the cells from the LVT_lib library for its clock nets.\n Therefore, only buf1 and buf2 cells from the LVT_lib library are used as clock references for that block.\n fc_shell>\u00a0 set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} fc_shell>\u00a0 set_target_library_subset -clock {LVT_lib} \\ -objects [TOP/TSK_BLK] fc_shell>\u00a0 set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1"}
{"header": "How do I Enabling Local Skew Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, clock tree synthesis tries to achieve the best skew and latency for all clocks.\n However, this can lead to area, power, and runtime overhead for low frequency clocks, which have relaxed skew and latency targets.\n \u2022 To specify a skew target, use the  -target_skew option with the set_clock_tree_options command.\n \u2022 To specify a latency target, use the  -target_latency option with the set_clock_tree_options command.\n By default, when you define skew and latency targets, they apply to all clocks in all corners.\n To define targets for specific clocks, use the  -clocks option.\n To define targets for specific corners, use the  -corners option.\n To report the user-defined skew and latency targets, use the report_clock_tree_options command.\n To remove user-defined skew or latency targets, use the  remove_clock_tree_options command.\n To remove all skew and latency targets, use the  -all option; otherwise, use the appropriate  -target_skew,  -target_latency,  -clocks, and  -corners options to remove the specific targets."}
{"header": "How do I Specifying the Primary Corner for Clock Tree Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths.\n If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design.\n However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design.\n During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths.\n To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the  synthesize_clock_trees and  clock_opt commands, set the cts.compile.enable_local_skew and  cts.optimize.enable_local_skew application options to  true.\n fc_shell>\u00a0 set_app_options -list {cts.compile.enable_local_skew true} fc_shell>\u00a0 set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you       specify with the  set_clock_tree_options\u00a0-target_skew command.\n To prevent the tool from deriving skew targets, use the following application option setting: fc_shell>\u00a0 set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}
{"header": "How do I Preventing Specific Clocks From Being Synthesized", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During initial clock tree synthesis, by default, the tool identifies the corner with the worst clock delays and inserts buffers to balance the clock delays in all modes of this corner.\n To identify a specific corner as the primary corner for initial clock tree synthesis, use the cts.compile.primary_corner application option."}
{"header": "How do I Preserving Preexisting Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool synthesizes all clocks defined with the  create_clock and create_generated_clock commands.\n To prevent the tool from synthesizing a specific clock, specify it by using the  cts.common.skip_cts_clocks application option.\n fc_shell>\u00a0 set_app_options \\ -name cts.common.skip_cts_clocks -value CK_B"}
{"header": "How do I Enabling Clock Tree Power Reduction Techniques", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you perform clock tree synthesis, by default, the tool removes all preexisting clock buffers and inverters.\n You can prevent this by setting the cts.compile.remove_existing_clock_trees application option to  false.\n To preserve specific preexisting clock buffers or inverters, apply a don\u2019t touch or size-only exception on them."}
{"header": "How do I Enabling Wire Length Aware Power-Driven Relocation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can enable clock tree power reduction techniques by using the cts.compile.power_opt_mode application option as shown in the following table.\n Table 26 Settings for the cts.compile.power_opt_mode Application Option To do this Use this setting   gate_relocation  low_power_targets       Table 26 Settings for the cts.compile.power_opt_mode Application Option (Continued) To do this Use this setting   all"}
{"header": "How do I Reducing Electromigration", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports improved activity driven clock gate relocation by controlling the amount of wire length degradation and considering the power impact before performing the clock gate relocation.\n To enable activity driven clock gate relocation, set the cts.compile.power_opt_mode application option to  all or  gate_relocation.\n The clock gates are not relocated or moved if: \u2022 Relocating an integrated clock gate (ICG) has a minor power benefit or degrades power while degrading wire length.\n \u2022 Moving the clock gate has a significant wire length impact for a less power benefit."}
{"header": "How do I Handling Inaccurate Constraints During Clock Tree Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Clock cells consume more power than cells that are not in the clock network.\n Clock cells that are clustered together in a small area increase the current densities for the power and ground rails, which increases the potential for electromigration problems.\n One way to avoid the problem is to set spacing requirements between clock cells to prevent local clumping of the clock cells along a standard cell power rail between the perpendicular straps.\n To use this method to reduce electromigration in the block, 1.\n Define clock cell spacing rules for the inverters, buffers, and integrated clock-gating cells in the clock network by using the  set_clock_cell_spacing command, as described in  Defining Clock Cell Spacing Rules.\n 2.\n Perform clock tree synthesis by using the  synthesize_clock_trees command, as described in  Performing Standalone Clock Trees Synthesis, or the  clock_opt command, as described in  Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command.\n Note: The clock cell spacing rules are also honored by the balance_clock_groups command.\n For information about using this command, see  Balancing Skew Between Different Clock Trees.\n       3.\n Check clock cell spacing rule violations by using the  check_legality\u00a0-verbose command.\n You should not see any violations if you set the appropriate clock cell spacing constraints."}
{"header": "How do I Defining Clock Cell Spacing Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the early stages of the implementation of a design, the constraints can be inaccurate or too restrictive.\n Running clock tree synthesis on such a design can lead to long runtime or poor clock tree QoR.\n You can run clock tree synthesis on such a design, but still get usable results in a reasonable runtime.\n To do so, set the following application variable before you begin clock tree synthesis: fc_shell>\u00a0 set_app_options \\ -name cts.common.enable_dirty_design_mode -value true When you use this application option setting, the tool \u2022 Ignores  dont_touch and  dont_touch_network attribute settings on clock nets.\n \u2022 Removes maximum transition and maximum capacitance constraints if they are too tight.\n \u2022 Removes the maximum net length constraint if it is less than 50 microns.\n \u2022 Ignores clock cell spacing rules if the horizontal spacing requirement is more than three times the site height and the vertical spacing requirement is more than twenty times the site height.\n \u2022 Ignores nondefault routing rules if the width plus the spacing requirement of the routing rule is more than ten times the default width plus the default spacing.\n \u2022 Reports balance point delay values that are large enough to cause an increase in clock insertion delay."}
{"header": "How do I Creating Skew Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define clock cell spacing rules, use the  set_clock_cell_spacing command.\n At a minimum, you must specify the minimum spacing in the x-direction or the y-direction; typically you would specify the minimum spacing in both directions.\n To specify the minimum spacing in microns in the \u2022 X-direction, set the  -x_spacing option to a nonzero value This value is usually dependent on the library cell\u2019s drive strength and clock frequency.\n       \u2022 Y-direction, set the  -y_spacing option to a nonzero value This value is usually less than half a row height.\n Note: Using a large spacing value increases the skew because the cells are spaced further away from the intended clusters of sinks.\n By default, the specified cell spacing requirements apply to all clock cells.\n To restrict the clock cell spacing rules to specific \u2022 Library cells, use the  -lib_cells option \u2022 Clocks, use the  -clocks option If adjoining clock cells both have cell spacing rules for a given direction, the sum of the spacing values applies.\n For example, if two adjoining clock cells both have a minimum cell spacing of 5 microns in the x-direction, they are placed at least 10 microns apart in the x-direction.\n You can relax the adjoining cell spacing rule by setting the cts.placement.cell_spacing_rule_style application option to  maximum, in which case the tool uses the larger of the spacing settings between two adjoining cells instead of the sum of the spacing settings.\n For example, the clock cells in the previous example are placed at least 5 microns apart in the x-direction, instead of 10 microns.\n The clock cell spacing rules defined by the  set_clock_cell_spacing command are honored by the  synthesize_clock_trees,  balance_clock_groups, and  clock_opt commands.\n To report clock cell spacing rules, use the  report_clock_cell_spacings command.\n To remove clock cell spacing rules, use the  remove_clock_cell_spacings command.\n By default, this command removes all clock cell spacing rules.\n To remove specific clock cell spacing rules, use the  -lib_cells option."}
{"header": "How do I Defining a Name Prefix for Clock Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During clock tree synthesis, you might want to balance a group of sinks only among each other, and not the rest of the sinks.\n To do so, define a skew group by using the create_clock_skew_group command.\n When you use this command, specify the sinks you want to group, by using the  -objects option.\n Optionally, you can specify the following: \u2022 A clock or generated clock for which to create the skew group by using the  -clock option.\n \u2022 A mode for which to create the skew group by using the  -mode option.\n       By default, the tool creates the skew group for the current mode.\n \u2022 A name for the skew group by using the  -name option.\n The following example creates a skew group named sg1 consisting of sinks reg1/CP, reg2/ CP, and reg3/CP: fc_shell>\u00a0 create_clock_skew_group -name sg1 \\ -objects {reg1/CP reg2/CP reg3/CP} To report skew groups, use the  report_clock_skew_groups command.\n To remove skew groups, use the  remove_clock_skew_groups command."}
{"header": "How do I Using the Global Router During Initial Clock Tree Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify a name prefix for the cells added on the clock network during clock tree synthesis by using the  cts.common.user_instance_name_prefix application option.\n The following example specifies CTS_ as the name prefix for the cells added on the clock network during clock tree synthesis: fc_shell>\u00a0 set_app_options \\ -name cts.common.user_instance_name_prefix -value \"CTS_\" To specify a name prefix for the cells added on the data nets during optimization, including during the  clock_opt command, use the  opt.common.user_instance_name_prefix application option, as described in  Specifying a Cell Name Prefix for Optimization."}
{"header": "How do I Specifying Constraints for Clock Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, initial clock tree synthesis uses the virtual router to build the clock trees.\n For designs with complex floorplans, this can introduce congestion hotspots and degrade clock QoR after clock routing.\n The tool can use the global router during the initial clock tree synthesis stage of the synthesize_clock_trees and  clock_opt commands.\n To enable this feature, set the cts.compile.global_route_aware_buffering application option to  true."}
{"header": "How do I Constructing Faster Clock Tree to Specific Endpoints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the Fusion Compiler tool uses the default routing rule and any available routing layers to route the clock trees.\n You can specify the minimum and maximum routing layers for clock nets as described in Specifying the Routing Resources.\n These routing layer constraints are used during RC estimation, congestion analysis, and routing.\n       To reduce the wire delays in the clock trees, you can use wide wires and higher metal layers instead.\n routing rulenondefault, defined Wide wires are represented by nondefault routing rules.\n To use nondefault routing rules on the clock nets, you must first define the routing rules and assign them to the clock nets as described in  Using Nondefault Routing Rules."}
{"header": "How do I Improving Latency-Driven Clock-Gate Splitting", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool enables you to construct a faster clock tree to specified endpoints without any additional detouring or delay balancing.\n This improves clock latency to the specified endpoints.\n To achieve a faster clock tree to specific endpoints, you must create a user skew group for the required endpoints.\n To create a skew group for a specific endpoint, use the following command before running the  synthesize_clock_tree or the build_clock stage of the  clock_opt command: fc_shell>\u00a0 create_clock_skew_group -objects  <endpoints> Note: \u2022 If there is a balancing requirement between the fast endpoints, you must put them in the same skew group.\n \u2022 If there is no balancing requirement between the endpoints, you must create separate skew groups for each endpoint.\n The upstream clock logic of the required skew group endpoints is shared with the endpoints of the default group or other user skew groups.\n This leads to detouring for balancing among the endpoints of the default group or other user skew group.\n       Figure 79 Faster Clock Tree to Specific Endpoints If a gate drives both skew group and non-skew group endpoints, the skew group endpoints might be delayed due to the balancing requirements of the non-skew group endpoints.\n In such cases, in addition to creating skew groups, you must also completely isolate the skew group endpoints from the rest of the clock tree by cloning the gates along the path to these endpoints.\n To create a separate clock path from the clock source to the required endpoints, use the -to option with the  split_clock_cells command before clock tree synthesis, that is, before using the  synthesize_clock_trees or the  build_clock stage of the  clock_opt command.\n fc_shell>\u00a0 split_clock_cells -to $endpoints The Fusion Compiler tool enables you to construct a faster clock tree by identifying the optimal cloning solution to achieve the best latency for the group of specified sinks.\n To achieve a fast clock tree to certain endpoints, use the  split_clock_cells\u00a0-to\u00a0< $sinks>\u00a0-latency_driven command.\n The endpoints must also be created as part of the user skew group using the  create_clock_skew_group command."}
{"header": "How do I Improving the Repeater Levels in Clock Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The latency-driven clock-gate (CG) splitting now automatically identifies and evaluates different CG cloning moves.\n This improves clock insertion delay to meet the maximum level constraint.\n To enable level driven CG splitting, set the  cts.icg.latency_driven_cloning application option to  true.\n Figure 80 Latency Driven Clock-Gate Splitting"}
{"header": "How do I Reducing Signal Integrity Effects on Clock Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool supports clock level improvement which ensures considering level improvement as a metric while building the clock trees and also considers buffering solutions which helps to improve the repeater levels.\n With lesser buffer trees chosen the level improvement takes place locally which further helps to improve the metric for overall clock tree.\n Figure 81 Improving the Repeater Levels in Clock Tree To enable clock level improvement, set the cts.buffering.reduce_clock_level_effort application option to  high before the build_clock stage of the  clock_opt command."}
{"header": "How do I Specifying Settings for Clock Latency Adjustments", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The timing of a design can be improved by reducing signal integrity issues on clock nets.\n To do so, the tool can derive nondefault routing rules with larger spacing requirements and assign them to the clock nets in regions without routing congestion.\n       To enable this feature, use the following application option setting: fc_shell>\u00a0 set_app_options \\ -name cts.optimize.enable_congestion_aware_ndr_promotion -value true When the tool derives a new nondefault routing rule for a clock net, the new spacing requirement is dependent on the spacing requirement of the existing routing rule of that net.\n If the existing routing rule is \u2022 A nondefault routing rule with a spacing requirement of less than or equal to two times the default spacing, the spacing requirement is doubled The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n \u2022 A nondefault routing rule with a spacing requirement of more than two times the default spacing, the spacing requirement is increased by one default spacing The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n \u2022 The default routing rule, the spacing requirement is doubled The name of this new nondefault rule is default_rule_equivalent_ndr_double_spacing."}
{"header": "How do I Timing Driven Sink Transition Target", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "I/O ports are usually constrained using real or virtual clocks.\n After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate.\n When you run clock tree synthesis with the  clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports.\n You can control these latency adjustments by using the set_latency_adjustment_options command.\n The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell>\u00a0 set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the  synthesize_clock_trees command, the tool does not automatically update the clock latencies.\n To do so, use the compute_clock_latency command after clock tree synthesis.\n This command honors the settings you specify with the  set_latency_adjustment_options command."}
{"header": "How do I Reporting the Clock Tree Settings", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool supports the setup and hold timing on critical endpoints by achieving a sharper transition on the critical launch and capture clock pins.\n The tool populates the ideal timing information from the and uses it to identify the critical endpoints.\n A transition target tighter than the user specified  max_transition is applied for the clock pins of timing critical endpoints and the clock tree is built considering the tightened transition which helps to improve the timing.\n To enable timing driven sink transition target, set the cts.compile.timing_driven_sink_transition application option to  true before the compile_fusion stage."}
{"header": "How do I Implementing Clock Trees and Performing Post-CTS Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the settings that are used by clock tree synthesis, use the report_clock_settings command.\n By default, the commands reports the clock tree configuration, including the design rule constraints, target skew, and target latency; the clock tree references; the clock cell spacing rules; and the nondefault routing rules for all clocks in the current block.\n To report the settings for specific clocks, use the  -clock option to specify the clocks of interest.\n To report specific information, use the  -type option with the appropriate keyword.\n \u2022 To report the clock tree design rule constraints, target skew, and target latency, use -type\u00a0configurations.\n \u2022 To report the clock tree references, use  -type\u00a0references.\n \u2022 To report the clock cell spacing rules, use  -type\u00a0spacing_rules.\n \u2022 To report the nondefault routing rule used for the clock nets, use  -type routing_rules."}
{"header": "How do I Performing Standalone Clock Trees Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you perform clock tree synthesis, you should save the block.\n This allows you to refine the clock tree synthesis goals and rerun clock tree synthesis with the same starting point, if necessary.\n The following topics describe the different methods available for implementing clock trees: \u2022 Performing Standalone Clock Trees Synthesis \u2022 Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command \u2022 Controlling Concurrent Clock and Data Optimization       \u2022 Splitting Clock Cells \u2022 Balancing Skew Between Different Clock Trees \u2022 Performing Global-Route-Based Optimization Using Machine Learning Data \u2022 Routing Clock Trees \u2022 Inserting Via Ladders During Clock Tree Synthesis, Optimization, and Clock Routing \u2022 Marking Clocks as Propagated After Clock Tree Synthesis \u2022 Performing Postroute Clock Tree Optimization \u2022 Performing Voltage Optimization \u2022 Marking Clock Trees as Synthesized \u2022 Removing Clock Trees"}
{"header": "How do I Synthesizing, Optimizing, and Routing Clock Trees With the", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform standalone clock tree synthesis, use the  synthesize_clock_trees command, as shown in the following example: fc_shell>\u00a0 synthesize_clock_trees When you use this command, the tool performs the following tasks: 1.\n Clock tree synthesis Before clock tree synthesis, the tool performs virtual routing of the clock nets and uses RC estimation to determine the clock net timing.\n 2.\n Clock tree optimization Before clock tree optimization, the tool performs global routing on the clock nets and uses RC extraction to determine the clock net timing.\n During clock tree optimization, the tool performs incremental global routing on clock nets modified during optimization.\n Note: This command does not detail route the clock trees.\n By default, this command works on all clocks in all active scenarios that are enabled for setup or hold analysis.\n You can specify the clocks to be built by using the  -clock option.\n For example, to build only the CLK clock tree, use the following command: fc_shell>\u00a0 synthesize_clock_trees -clocks [get_clocks CLK] After clock tree synthesis, the tool sets the clocks in all modes of all active scenarios as propagated."}
{"header": "How do I Considering Voltage Drop Information During Clock Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To synthesize the clock trees, route the clock nets, and further optimize the design by using a single command, use the  clock_opt command.\n The  clock_opt command consist of the following stages: 1.\n The  build_clock stage, during which the tool synthesizes and optimizes the clock trees for all clocks in all modes of all active scenarios.\n After clock tree synthesis, the tool sets the synthesized clocks as propagated.\n 2.\n The  route_clock stage, during which the tool detail routes the synthesized clock nets.\n 3.\n The  final_opto stage, during which the tool performs further optimization, timing- driven placement, and legalization.\n It then global routes the block and performs extensive global-route-based optimization, which includes incremental legalization and route patching.\n You can limit the  clock_opt command to one or more contiguous stages by using the -from option to specify the stage from which you want to begin and the  -to option to specify the stage after which you want to end.\n If you do not specify the  -from option, the tool begins from the  build_clock stage.\n Similarly, if you do not specify the  -to option, the tool continues until the  final_opto stage is completed.\n For example, to synthesize and optimize the clock trees and detail route the clock nets only, limit the execution to the  build_clock and  route_clock stages by use the following command: fc_shell>\u00a0 clock_opt -to route_clock Because the tool performs global routing during the  final_opto stage, you should specify all router related settings, such as routing rules, route guides, application option settings required for the technology node, and so on, before you run the  clock_opt command.\n You should run the  final_opto only one time for each block.\n After this stage is completed, all the signal routes in the block are global routed.\n Therefore, when subsequently run any routing command, such as the  route_auto, route_global, or route_group command, the tool skips global routing.\n To avoid errors during subsequent track assignment and detail routing, do not change any global route shapes after you run the  clock_opt command."}
{"header": "How do I Using Nondefault Routing Rules for Critical Nets During", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  clock_opt command does not consider voltage drop information when inserting clock buffers.\n Therefore, the tool might place clock buffers in locations with high PG resistance, which increases the voltage drop.\n To prevent this, you can use the       RedHawk Fusion feature to analyze the PG network and use this information with the clock_opt command, as shown in the following flow: 1.\n Use the RedHawk Fusion feature to analyze the PG network by using the analyze_rail\u00a0-min_path_resistance command.\n 2.\n Load the RedHawk Fusion results by using the  open_rail_result command.\n 3.\n Enable voltage-drop-aware clock tree synthesis by setting the clock_opt.flow.enable_voltage_drop_aware application option to  true.\n 4.\n Run the  clock_opt command."}
{"header": "How do I Performing Concurrent Clock and Data Optimization During the", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve timing QoR, the tool can use nondefault routing rules on timing critical nets during preroute optimization.\n In addition, the tool can guide the router to honor these nondefault rule assignments as soft constraints.\n To enable this capability for the  clock_opt command, set the clock_opt.flow.optimize_ndr application option to  true.\n fc_shell>\u00a0 set_app_options -name clock_opt.flow.optimize_ndr \\ -value true"}
{"header": "How do I Controlling Multibit Optimization Performed During the clock_opt", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Applying useful skew techniques during datapath optimization to improve the timing QoR by taking advantage of the positive slack and adjusting the clock arrival times of registers is referred to as concurrent clock and data (CCD) optimization.\n By default, the tool performs concurrent clock and data optimization during the  clock_opt command.\n To disable concurrent clock and data optimization for the  clock_opt command, set the clock_opt.flow.enable_ccd application option to  false.\n You can change the default behavior of concurrent clock and data optimization during the clock_opt command by performing any of the following optional steps: 1.\n (Optional) Limit the latency adjustment values for concurrent clock and data optimization as described in  Limiting the Latency Adjustment Values.\n 2.\n (Optional) Control the latency adjustment of boundary registers for concurrent clock and data optimization as described in  Excluding Boundary Paths.\n 3.\n (Optional) Ignore specific path groups during concurrent clock and data optimization as described in  Excluding Specific Path Groups.\n       4.\n (Optional) Ignore specific scenarios during concurrent clock and data optimization as described in  Excluding Specific Scenarios.\n 5.\n (Optional) Ignore specific sinks during concurrent clock and data optimization as described in  Excluding Specific Sinks.\n 6.\n (Optional) Control the effort of timing optimization performed during concurrent clock and data optimization as described in  Controlling Timing Optimization Effort.\n 7.\n (Optional) Control the effort of hold timing optimization performed during concurrent clock and data optimization as described in  Controlling Hold Time Optimization Effort.\n 8.\n (Optional) Control the adjustment of I/O clock latencies performed during concurrent clock and data optimization as described in  Controlling the Adjustment of I/O Clock Latencies.\n 9.\n (Optional) Analyze the effects of concurrent clock and data optimization as described in Reporting Concurrent Clock and Data Timing."}
{"header": "How do I Performing Power or Area Recovery on the Clock Network", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe how you can control the multibit optimization performed during the  clock_opt command: \u2022 Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells \u2022 Enabling Post-Clock-Tree-Synthesis Multibit Debanking Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Some logic libraries have mixed-drive-strength multibit cells where some bits have a higher drive strength than others.\n For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit.\n To enable this feature for the  clock_opt command, set the  clock_opt.flow.enable_multibit_rewiring application option to  true.\n Enabling Post-Clock-Tree-Synthesis Multibit Debanking To improve the timing QoR, the  clock_opt command can debank multibit registers during the  final_opt stage, if doing so does not introduce hold timing violations.\n To enable this feature, set the  clock_opt.flow.enable_multibit_debanking application option to true before you run the  final_opt stage of the  clock_opt command."}
{"header": "How do I Performing IR-Drop-Aware Placement During the clock_opt", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you enable concurrent clock and data optimization for the  clock_opt command, the tool performs clock power recovery on clock cells and registers during the  final_opt stage.\n       If you do not enable concurrent clock and data optimization, you can enable clock power recovery by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name clock_opt.flow.enable_clock_power_recovery \\ -value power Before you perform power recovery using this technique, you must 1.\n Enable scenarios for dynamic, leakage, or total power optimization by using the -dynamic_power and - leakage_power options of the  set_scenario_status command 2.\n (Optional) Provide a switching activity by using the  read_saif command If you do not provide switching activity, the tool uses default switching activity for dynamic power recovery.\n Instead of power recovery, you can enable area recovery on the clock cells and registers during the  final_opt stage  clock_opt command by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name clock_opt.flow.enable_clock_power_recovery \\ -value area"}
{"header": "How do I Controlling Concurrent Clock and Data Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During placement, the tool can use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values, which reduces the power density of such areas.\n To perform IR-drop-aware placement during the  clock_opt command, use the following steps: 1.\n Run the  clock_opt command through the route-clock stage by using the  clock_opt -to\u00a0route_clock command.\n 2.\n Set up for RedHawk Fusion and perform static or dynamic voltage drop analysis by using the  analyze_rail\u00a0-voltage_drop command as shown in the following example: fc_shell>\u00a0 source redhawk_setup.tcl fc_shell>\u00a0 analyze_rail -voltage_drop static -nets {VDD VSS} For more information, see  Performing Voltage Drop Analysis.\n 3.\n Enable IR-drop-aware placement by setting the  place.coarse.ir_drop_aware application option to  true.\n       4.\n (Optional) Specify additional settings for IR-drop-aware placement, as described in Controlling IR-Drop-Aware Placement.\n 5.\n Run the final optimization stage of the  clock_opt command by using the  clock_opt -from\u00a0final_opto command."}
{"header": "How do I Limiting the Latency Adjustment Values", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Applying useful skew techniques during datapath optimization to improve the timing QoR by taking advantage of the positive slack and adjusting the clock arrival times of registers is referred to as concurrent clock and data (CCD) optimization.\n Concurrent clock and data optimization is enabled by default for the  compile_fusion and  clock_opt commands.\n To enabled it for the  route_opt command, set the route_opt.flow.enable_ccd application option to  true.\n You can change the default behavior of concurrent clock and data optimization by \u2022 Limiting the Latency Adjustment Values \u2022 Excluding Boundary Paths \u2022 Excluding Specific Path Groups \u2022 Excluding Specific Scenarios \u2022 Excluding Specific Sinks \u2022 Controlling Timing Optimization Effort \u2022 Controlling Hold Time Optimization Effort \u2022 Controlling the Adjustment of I/O Clock Latencies \u2022 Performing Dynamic-Voltage-Drop-Driven Concurrent Clock and Data Optimization During the route_opt Command \u2022 Specifying Optimization Targets at the Preroute Stage \u2022 Specifying Optimization Targets at the Postroute Stage \u2022 Enabling Buffer Removal at the Postroute Stage \u2022 Reporting Concurrent Clock and Data Timing \u2022 Scaling CCD Offsets to New Scenarios for Reporting Timing \u2022 Skewing Latch and Discrete Clock Gates"}
{"header": "How do I Excluding Boundary Paths", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can limit the latency adjustment values for concurrent clock and data optimization performed during the  place_opt,  clock_opt, and  route_opt commands as follows: \u2022 Limit the amount that the clock latencies are advanced by using the  ccd.max_prepone application option.\n \u2022 Limit the amount that the clock latencies are delayed by using the  ccd.max_postpone application option.\n There is no default for these application options.\n Specify these values in the library timing units.\n The following example sets a limit of 0.2 for advancing and 0.1 for delaying clock latencies: fc_shell>\u00a0 set_app_options -list {ccd.max_prepone 0.2} fc_shell>\u00a0 set_app_options -list {ccd.max_postpone 0.1}"}
{"header": "How do I Excluding Specific Path Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool performs concurrent clock and data optimization on all paths in a block.\n However, you might want to exclude paths that are connected to boundary registers, which are registers in the transitive fanout of input ports and transitive fanin of output ports.\n To exclude boundary paths from concurrent clock and data optimization, set the ccd.optimize_boundary_timing application option to  false.\n When you do so, you can selectively ignore the boundary paths of some ports during boundary path exclusion by using the ccd.ignore_ports_for_boundary_identification application option.\n The following example disables concurrent clock and data optimization for all boundary paths except for those connected to the ports named IN_A and OUT_A: fc_shell>\u00a0 set_app_options -name ccd.optimize_boundary_timing \\ -value false fc_shell>\u00a0 set_app_options \\ -name ccd.ignore_ports_for_boundary_identification \\ -value {IN_A OUT_A} Even when you disable concurrent clock and data optimization on boundary registers, the tool can still optimize the clock tree fanin cone of these boundary registers, when doing so improves the timing QoR of other internal registers that share the same clock paths.\n To prevent the clock tree fanin of boundary registers from changing, set the ccd.optimize_boundary_timing_upstream application option to  false.\n However, doing so heavily restricts the scope of concurrent clock and data optimization.\n These application option settings affect concurrent clock and data optimization performed during the  place_opt,  clock_opt, and  route_opt commands."}
{"header": "How do I Excluding Specific Scenarios", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To exclude a specific path group from concurrent clock and data optimization, use the ccd.skip_path_groups application option and specify the name of the path group you want ignored.\n You can ignore a path group for all scenarios or a specific scenario.\n For example, to ignore the path group named CLK1 for all scenarios and CLK2 for the scenario named scnA, use the following command: fc_shell>\u00a0 set_app_options -name ccd.skip_path_groups \\ -value {CLK1 {CLK2 scnA}} This setting affects concurrent clock and data optimization performed during the place_opt,  clock_opt, and  route_opt commands."}
{"header": "How do I Excluding Specific Sinks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To exclude a specific scenarios from concurrent clock and data optimization, use the ccd.ignore_scenarios application option and specify the name of the scenarios you want to ignore.\n For example, to ignore the scenario named scnB, use the following command: fc_shell>\u00a0 set_app_options -name ccd.ignore_scenarios \\ -value {scnB}} This setting affects concurrent clock and data optimization performed during the place_opt,  clock_opt, and  route_opt commands."}
{"header": "How do I Controlling Timing Optimization Effort", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To exclude a specific sink from concurrent clock and data optimization, 1.\n Apply a  cts_fixed_balance_pin attribute on the sink pin by using the set_attribute command as shown in the following example: fc_shell>\u00a0 set_attribute -objects reg21/CK \\ -name cts_fixed_balance_pin -value true 2.\n Set the  ccd.respect_cts_fixed_balance_pins application option to  true.\n These setting prevents the tool from adjusting the latencies of the sinks that have a cts_fixed_balance_pin attribute set to  true.\n However, changes in the clock tree due to concurrent clock and data optimization performed on other sinks can change the latencies of the sinks that have a  cts_fixed_balance_pin attribute set to  true.\n To prevent the tool from making any changes to the clock paths between the sinks that have a  cts_fixed_balance_pin attribute set to  true and the clock root, set the       ccd.respect_cts_fixed_balance_pins application option to  upstream instead of true.\n This application option setting affects concurrent clock and data optimization performed during the  place_opt,  clock_opt, and  route_opt commands."}
{"header": "How do I Controlling Hold Time Optimization Effort", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool focuses on improving the timing and power QoR during concurrent clock and data optimization.\n You can change the effort level for timing optimization by setting the  ccd.timing_effort application option to  low or  high.\n The default is  medium.\n This setting affects concurrent clock and data optimization performed during the final_opt stage of the  clock_opt command and the  route_opt command."}
{"header": "How do I Controlling the Adjustment of I/O Clock Latencies", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool focuses on fixing setup violations during concurrent clock and data optimization.\n However, if your design has hold violations that are difficult to fix, you can increase the effort for hold fixing by setting the  ccd.hold_control_effort application option to  medium,  high, or  ultra.\n The default is  low.\n Increasing the priority of hold violations reduces the number of setup violations that are fixed.\n Therefore, the hold priority should be increased only if the hold timing is critical.\n This setting affects concurrent clock and data optimization performed during the  final_opt stage of the  clock_opt command and the  route_opt command."}
{"header": "How do I Performing Dynamic-Voltage-Drop-Driven Concurrent Clock and", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool adjusts the latencies of the I/O clocks, which are the clocks that constrain the boundary ports, when it performs concurrent clock and data optimization during the  clock_opt command.\n The tool also uses concurrent clock and data optimization techniques to adjust the I/O clock latencies when you subsequently run the compute_clock_latency command.\n The tool does not update the I/O clock latencies \u2022 For the entire block when you disable this feature by setting the ccd.adjust_io_clock_latency to  false or when you disable concurrent clock and data optimization for boundary paths by setting the  ccd.optimize_boundary_timing application option to  false \u2022 For specific I/O paths when you exclude the corresponding path groups from concurrent clock and data optimization by using the  ccd.skip_path_groups application option \u2022 For specific I/O clocks when you disable latency adjustment those I/O clocks by using the  set_latency_adjustment_options\u00a0-exclude_clocks command"}
{"header": "How do I Specifying Optimization Targets at the Preroute Stage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The concurrent clock and data optimization performed during the  route_opt command can reduce the peak dynamic voltage drop without affecting the timing QoR.\n To enable this feature, set the  route_opt.flow.enable_voltage_drop_opt_ccd application option to true.\n When you enable this feature, during the  route_opt command, the tool uses the RedHawk Fusion feature to identify dynamic-voltage-drop hotspots and cells rows where the cells from the hotspots can be relocated.\n Then, during optimization, the tool relocates or downsizes the cells in the hotspots to reduce the peak dynamic voltage drop without hurting the timing QoR.\n You can specify one of the following thresholds for selecting cells for optimization: \u2022 A threshold for the cell voltage drop, as a percentage of the supply voltage, by using the  ccd.voltage_drop_voltage_threshold application option.\n Any cell with a voltage drop that exceeds this threshold is selected for optimization.\n \u2022 A threshold for the number of cells, as a percentage of the total number of cells, by using the  ccd.voltage_drop_population_threshold application option.\n Cells are selected starting with the worst violator.\n During postroute optimization, the tool can perform RedHawk dynamic voltage drop analysis to identify cells involved in voltage drop violations, and then use optimization techniques on those cells to improve the dynamic voltage drop.\n You can further improve the dynamic voltage drop by enabling IR-driven sizing, which uses the RedHawk dynamic voltage drop analysis results to identify cells involved in voltage drop violations, and then tries to replace those cells with cells having smaller leakage current.\n To enable this feature, set the route_opt.flow.enable_irdrivenopt application option to  true, in addition to setting the  route_opt.flow.enable_voltage_drop_opt_ccd application option to  true."}
{"header": "How do I Specifying Optimization Targets at the Postroute Stage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When performing concurrent clock and data optimization using the  place_opt or clock_opt command, you can give a higher priority to the WNS optimization of \u2022 Certain path groups by specifying them by using the  ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell>\u00a0 set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2}       If a path group you specify with this application option is also specified as a path group to skip with the  ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization.\n \u2022 Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell>\u00a0 set_app_options -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified paths groups.\n \u2022 The worst 300 timing paths by setting the  ccd.enable_top_wns_optimization application option to  true"}
{"header": "How do I Enabling Buffer Removal at the Postroute Stage", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "At the final stages of your design flow, you can use the  route_opt command to perform concurrent clock and data optimization on specific critical path groups or endpoints by using the following steps: 1.\n Enable targeted concurrent clock and data optimization for the  route_opt command by setting the  route_opt.flow.enable_targeted_ccd_wns_optimization application option to  true.\n 2.\n Specify the optimization target by using one or both of the following settings: \u25e6 Specify the path groups to optimize by using the  ccd.targeted_ccd_path_groups application option Note: If a path group you specify with this application option is also specified as a path group to skip by using the  ccd.skip_path_groups application option, the path group is skipped during targeted concurrent clock and data optimization.\n \u25e6 Specify the endpoints to optimize by using the ccd.targeted_ccd_end_points_file application option You must specify at least one of these settings.\n If you specify both, the tool optimizes the specified endpoints of the specified paths groups.\n 3.\n (Optional) Specify the type of optimization to perform by using the ccd.targeted_ccd_select_optimization_moves application option.\n The valid values are       \u25e6 auto, the default, which enables all optimization types, including buffering \u25e6 size_only, which enables sizing only \u25e6 equal_or_smaller_sizing, which enables sizing only to cells that are the same size or smaller \u25e6 footprint_sizing, which enables sizing only to cells with the same footprint 4.\n (Optional) Specify an optimization effort by using the ccd.targeted_ccd_wns_optimization_effort application option.\n The valid values are  high (default),  medium, and  low.\n The higher the effort, the more timing QoR improvement you will see in the targeted paths, but at the expense of the timing QoR of other paths.\n 5.\n (Optional) Specify a threshold beyond which the slack for the path groups that are not targeted can be degraded by using the ccd.targeted_ccd_threshold_for_nontargeted_path_groups application option.\n By default, if the path groups that are not targeted have positive slack, the tool can degrade this slack until it reaches zero.\n For the  route_opt command, you can enable both regular concurrent clock and data optimization by using the  route_opt.flow.enable_ccd application option and targeted concurrent clock and data optimization by using the route_opt.flow.enable_targeted_ccd_wns_optimization application option.\n If you enable both, the tool performs regular concurrent clock and data optimization first, followed by targeted concurrent clock and data optimization.\n The following script performs targeted concurrent clock and data optimization on a block that has already undergone routing and postroute optimization: open_lib\u00a0design1 open_block\u00a0blk.post_route  #Disable\u00a0regular\u00a0CCD\u00a0optimization,\u00a0which\u00a0was\u00a0previously\u00a0performed set_app_options\u00a0\\ -name\u00a0route_opt.flow.enable_ccd\u00a0-value\u00a0false  #Enable\u00a0targeted\u00a0CCD\u00a0optimization set_app_options\u00a0\\ -name\u00a0route_opt.flow.enable_targeted_ccd_wns_optimization\u00a0\\ -value\u00a0true  #Specify\u00a0the\u00a0path\u00a0group\u00a0and\u00a0endpoints\u00a0to\u00a0target set_app_options\u00a0-name\u00a0ccd.targeted_ccd_path_groups\u00a0-value\u00a0clkA set_app_options\u00a0-name\u00a0ccd.targeted_ccd_end_points_file\u00a0\\ -value\u00a0clkA_ep.txt        #Specify\u00a0the\u00a0optimization\u00a0type\u00a0and\u00a0effort set_app_options\u00a0\\ -name\u00a0ccd.targeted_ccd_select_optimization_moves\u00a0-value\u00a0size_only set_app_options\u00a0-name\u00a0ccd.targeted_ccd_wns_optimization_effort\u00a0\\ -value\u00a0medium  #\u00a0Perform\u00a0the\u00a0targeted\u00a0CCD\u00a0optimization route_opt"}
{"header": "How do I Reporting Concurrent Clock and Data Timing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve QoR by removing buffers or pairs of inverters when concurrent clock and data optimization is performed during  route_opt command, set the ccd.post_route_buffer_removal application option to  true, as shown in the following example: fc_shell>\u00a0 set_app_options -name route_opt.flow.enable_ccd \\ -value true fc_shell>\u00a0 set_app_options -name ccd.post_route_buffer_removal \\ -value true fc_shell>\u00a0 route_opt"}
{"header": "How do I Scaling CCD Offsets to New Scenarios for Reporting Timing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You analyze the timing effects of concurrent clock and data optimization by using the report_ccd_timing command.\n By default, it reports the setup and hold slack of the worst capture (D-slack) and launch (Q-slack) paths of the five most critical endpoint registers in the block, as shown in the following example report: fc_shell>\u00a0 report_ccd_timing...\n...\n ---------------------------------------------------------------- Setup\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Hold ---------------------------------------------------------------- D-slack\u00a0\u00a0\u00a0\u00a0Q-slack\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0D-slack\u00a0\u00a0\u00a0\u00a0Q-slack\u00a0\u00a0\u00a0\u00a0\u00a0Pin ---------------------------------------------------------------- -0.567710\u00a0\u00a0-0.173974\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.524202\u00a0\u00a0\u00a00.167434\u00a0\u00a0\u00a0\u00a0sink2/CP -0.175268\u00a0\u00a0\u00a00.125309\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.168582\u00a0\u00a0\u00a00.077625\u00a0\u00a0\u00a0\u00a0sink3e/CP -0.173974\u00a0\u00a0\u00a00.126836\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.167434\u00a0\u00a0\u00a00.076277\u00a0\u00a0\u00a0\u00a0sink3a/CP -0.033271\u00a0\u00a0-0.175268\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00.068856\u00a0\u00a0\u00a00.168582\u00a0\u00a0\u00a0\u00a0sink3d/CP 0.017364\u00a0\u00a0-0.033271\u00a0\u00a0\u00a0\u00a0\u00a0-0.022138\u00a0\u00a0\u00a00.068856\u00a0\u00a0\u00a0\u00a0sink3c/CP       To control the type of report generated, use the  -type option as follows: \u2022 To report information for the paths in the fanin or fanout of the most critical endpoints, use the  -type\u00a0fanin or  -type\u00a0fanout option.\n \u2022 To report information for the previous, current, and next path stages of the most critical endpoints, use the  -type\u00a0stage option.\n \u2022 To report information for all the previous, current, and next path stages of the most critical endpoints, use the  -type\u00a0chain option.\n  Figure\u00a082 shows the previous, current, and next stages for an endpoint register.\n Figure 82 Previous, Current, and Next Path Stages By default, the command reports setup slacks at D and Q pins of registers.\n To report the hold slacks at these pins, use the  -hold option.\n By default, the command analyzes timing paths across all active scenarios and reports the worst D and Q slacks across scenarios.\n To analyze and report the slack for specific scenarios use the  -scenarios option.\n To report the information for specific path endpoints, specify the corresponding clock pins by using the  -pins option.\n You can analyze the effects latency adjustments performed during concurrent clock and data optimization by increasing or decreasing the clock arrival of a specific endpoint using the  -prepone or  -postpone option with the  -pins option as shown in the following example: fc_shell>\u00a0 report_ccd_timing -pins Reg11/clk -postpone 0.02 You can also see the effects of changing specific cell and net delay values by using the -annotate_cell_delay and  -annotate_net_delay options, as shown in the following example: fc_shell>\u00a0 report_ccd_timing -annotate_cell_delay {{U1/a U1/y 0.2}} \\ -pin I2/d -type stage The delay values you specify with these options are used only for analyzing and reporting the concurrent clock and data timing.\n They are not saved and used during subsequent concurrent clock and data optimization."}
{"header": "How do I Skewing Latch and Discrete Clock Gates", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To copy concurrent clock and data (CCD) offsets to the new scenarios for consistent timing or QoR reports, use the  copy_useful_skew command.\n During CCD, when a pin's CTS balance point offsets are derived in only a subset of the active scenarios, use this command to copy the offsets to the in-active scenarios and active scenarios that do not have the CCD offsets.\n The  copy_useful_skew command also ensures that the corresponding constraints of the  set_clock_latency command are set on all the pins and scenarios, where a new offset value is computed.\n The average value of the offset is computed across all scenarios, where a balance point offset is defined.\n The average value is then scaled back in each active scenario using the scaling factor of the scenario corner."}
{"header": "How do I Splitting Clock Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To skew latches and discrete clock gates together, set the ccd.skew_opt_merge_dcg_cells_by_driver application option to  true before compile_fusion or  place_opt\u00a0final_opto.\n By default, the application option is set to false.\n Setting the  ccd.skew_opt_merge_dcg_cells_by_driver application option to true enhances the concurrent clock and data optimization to skew latches and gating element by the same offset.\n This ensures the latch and gate are at the same level and improves hold timing of discrete clock gates.\n fc_shell>\u00a0 set_attribute -name ccd.skew_opt_merge_dcg_cells_by_driver -value true"}
{"header": "How do I Balancing Skew Between Different Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can manually split clock cells that have DRC violations by using the split_clock_cells\u00a0-cells command, as shown in the following example: fc_shell>\u00a0 split_clock_cells -cells [get_cells U1/ICG*] The tool does not split the specified cells if \u2022 They do not have DRC violations \u2022 They have don\u2019t-touch, size-only, or fixed-placement attribute settings \u2022 It is necessary to punch ports on the boundaries of power domains or blocks that have been identified with the  set_freeze_ports command After splitting a cell, the tool \u2022 Names the new cells using the <original_cell_name>_split_<integer> naming convention \u2022 Copies all the settings and constraints from the original cell to the newly created cells       Instead of specifying the cells to split, you can specify one or more collection of loads that are driven by the same driver by using the  -loads option, as shown in the following example: fc_shell>\u00a0 set loads1 [get_pins I1/reg*/CK] fc_shell>\u00a0 set loads2 [get_pins I2/reg*/CK] fc_shell>\u00a0 split_clock_cells -loads [list $load1 $load2] After splitting, each set of loads is driven by a newly created driver."}
{"header": "How do I Defining the Interclock Delay Balancing Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can automatically balance the skew between a group of clocks.\n The set of clocks considered during delay balancing is referred to as a  clock balance group.\n You can define multiple clock balance groups.\n For each clock balance group, you can define a delay offset between the clocks.\n Together, the clock balance groups and their delay offset settings are referred to as  interclock delay balancing constraints.\n Note: The tool cannot balance skew between a generated clock and other clocks.\n To balance multiple clocks, perform the following steps: 1.\n Generate the interclock delay balancing constraints either by Manually defining the clock balance groups and their delay offsets, as described in Defining the Interclock Delay Balancing Constraints Having the tool generate them as described in  Generating Interclock Delay Balancing Constraints Automatically 2.\n Balance the interclock delays as described in  Running Interclock Delay Balancing."}
{"header": "How do I Generating Interclock Delay Balancing Constraints Automatically", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define interclock delay balancing constraints, use the  create_clock_balance_group command.\n At a minimum, you must specify a name for the clock balance group and the clocks in the group.\n \u2022 To specify a name for the clock balance group, use the  -name option.\n \u2022 To specify the clock trees in the group, use the  -objects option with the  get_clocks command.\n By default, the clock balance group is defined for the clocks in the current mode.\n To define a clock balance group for the clocks of a specific mode, use the -objects option with the  get_clocks\u00a0-mode command.\n       For example, to define a clock balance group named group1 that contains the clocks named clk1 and clk2 in the current mode, use the following command: fc_shell>\u00a0 create_clock_balance_group -name group1 \\ -objects [get_clocks {clk1 clk2}] To define a clock balance group named group2 that contains all the clocks in the mode named m2, use the following command: fc_shell>\u00a0 create_clock_balance_group -name group2 \\ -objects [get_clocks -mode m2] By default, the tool has a goal of zero delay offset between clocks.\n All clocks are balanced with the same insertion delay which usually is the longest insertion delay among the clocks.\n To specify a delay offset between clocks in the group, use the  -offset_latencies option.\n By default, the delay offset applies to the current corner.\n To apply the delay offset to a specific corner, use the  -corner option.\n For example, assume the design has three clocks named clk1, clk2, and clk3.\n If you want the insertion delay of clk1 and clk2 to be the same and the insertion delay of clk3 to be 100 less than that of clk1 and clk2, use the following command: fc_shell>\u00a0 create_clock_balance_group -name group3 \\ -objects [get_clocks {clk1 clk2 clk3}] \\ -offset_latencies {0 0 -100} Reporting Clock Balance Groups To report clock balance groups, use the  report_clock_balance_groups command.\n The report lists the clock balance groups for all modes in all active scenarios.\n Removing Clock Balance Groups To remove clock balance groups, use the  remove_clock_balance_groups command.\n You can either remove specific clock balance groups by specifying the clock balance groups or all clock balance groups by using the  -all option.\n If you specify the clock balance groups to remove, they are removed from the current mode.\n However, if a specified group does not exist in the current mode, but does exist in another mode, it is removed from that mode.\n If you use the  -all option, the clock balance groups are removed from all modes.\n For example, to remove a previously defined clock balance group named group1 from the current mode, use the following command: fc_shell>\u00a0 remove_clock_balance_groups group1 To remove all clock balance groups from all modes, use the following command: fc_shell>\u00a0 remove_clock_balance_groups -all"}
{"header": "How do I Running Interclock Delay Balancing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can automatically generate the interclock delay balancing constraints based on the timing relationships between the clocks.\n To automatically generate the interclock delay balancing constraints, use the following command: fc_shell>\u00a0 derive_clock_balance_constraints This command identifies clocks that have interclock timing paths and places them in the same balance group.\n After running this command, use the report_clock_balance_groups command to report the generated interclock delay balancing constraints, as described in  Reporting Clock Balance Groups.\n If necessary, you can modify the clock balance groups as described in  Defining the Interclock Delay Balancing Constraints.\n By default, the tool considers all timing paths when identifying the timing relationships between the clocks.\n To consider only those timing paths with slack less than a specified value, use the  -slack_less_than option with the  derive_clock_balance_constraints command.\n For example, to generate interclock balancing constraints only for paths with slack less than -0.2 ns, use the following command: fc_shell>\u00a0 derive_clock_balance_constraints -slack_less_than -0.2 Assume you run this command on a block for which clock A has a timing relationship only with clock B and the worst negative slack (WNS) of this group of timing paths is -0.1 ns and clock C has a timing relationship only to clock D and the WNS of this group of timing paths is -0.3 ns.\n The command considers only those timing paths with slack less than -0.2 ns, so it defines a single balance group that contains clocks C and D.\n Clocks A and B are not constrained because the timing paths between them have slack greater than -0.2 ns."}
{"header": "How do I Performing Global-Route-Based Optimization Using Machine", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you perform interclock delay balancing, you must generate the interclock delay balancing constraints as described in  Defining the Interclock Delay Balancing Constraints.\n interclock delay balancingruning To perform interclock delay balancing, use the balance_inter_clock_delay comandcomandsbalance_inter_clock_delay balance_clock_groups command.\n For multicorner-multimode designs, the tool performs interclock delay balancing on all active scenarios.\n fc_shell>\u00a0 balance_clock_groups"}
{"header": "How do I Routing Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For designs with poor timing correlation between the preroute and postroute stages, you can improve the correlation by performing optimization after clock tree synthesis using machine learning (ML) data derived after detail routing.\n The machine learning concept uses the following terminology: \u2022 Labels, which are the outputs you are trying to predict \u2022 Features, which are the inputs that affect the outputs \u2022 Model, which is the relationship between the features (inputs) and the labels (outputs) \u2022 Training, which is the process of learning the relationship between the features (inputs) and the labels (outputs), based on the data collected To perform global-route-based optimization using machine learning (ML) data derived from the postroute stage, 1.\n Collect machine learning features and labels, and train the model by performing the following steps in a specific iteration, iteration N: a.\n Perform clock tree synthesis and clock routing by completing the  build_clock and route_clock stages of the  clock_opt command.\n b.\n Specify the output directory for the machine learning data by using the new est_delay.ml_delay_opto_dir application option.\n fc_shell>\u00a0 set_application_option \\ -name est_delay.ml_delay_opto_dir -value./ML c.\n Enable integrated feature extraction by setting the new est_delay.ml_delay_gre_mode application option to  feature.\n fc_shell>\u00a0 set_application_option \\ -name est_delay.ml_delay_gre_mode -value feature d.\n Perform global-route-based optimization by using the  clock_opt\u00a0-from final_opt command.\n e.\n Perform detail routing.\n f.\n Collect labels associated with the features that were previously collected during the  clock_opt\u00a0-from\u00a0final_opt command by using the  estimate_delay -training_labels command, as shown in the following example: fc_shell>\u00a0 estimate_delay -training_labels \"label_1\" \\ -output_dir./ML       The labels must be collected after detail routing, but before postroute optimization.\n g.\n Train the machine learning model for the collected features and label by using the estimate_delay\u00a0-train_model command as shown in the following example: fc_shell>\u00a0 estimate_delay -train_model \"features_1 label_1\" \\ -output_dir./ML h.\n Continue with postroute optimization and the rest of the steps in the implementation flow.\n 2.\n Use the machine learning data to improve correlation by performing the following steps in the subsequent iteration, iteration N+1: a.\n Perform clock tree synthesis and clock routing by completing the  build_clock and route_clock stages of the  clock_opt command.\n b.\n Specify the output directory for the machine learning data by using the new est_delay.ml_delay_opto_dir application option.\n fc_shell>\u00a0 set_application_option \\ -name est_delay.ml_delay_opto_dir -value./ML c.\n Enable the machine learning model, which was derived in the previous iteration, by setting the new  est_delay.ml_delay_gre_mode application option to  enable.\n fc_shell>\u00a0 set_application_option \\ -name est_delay.ml_delay_gre_mode -value enable d.\n Perform global-route-based optimization with the machine learning data by using the  clock_opt\u00a0-from\u00a0final_opto command.\n e.\n Perform detail routing.\n f.\n Disable the machine learning model after you complete all the detail routing steps by using the  estimate_delay\u00a0-disable_model command, as shown in the following example: fc_shell>\u00a0 estimate_delay -disable_model -output_dir./ML g.\n Continue with postroute optimization and the rest of the steps in the implementation flow.\n When using this feature, ensure that \u2022 The same scenarios are active at each step and each iteration of the flow \u2022 The machine learning model is re-created if there are changes to the design, its environment, or the flow"}
{"header": "How do I Inserting Via Ladders During Clock Tree Synthesis, Optimization,", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After synthesizing and optimizing the clocks, you can detail route the clock nets by using the  route_group command, as shown in the following example: fc_shell>\u00a0 route_group -all_clock_nets -reuse_existing_global_route true When you set the  -reuse_existing_global_route option of the  route_group command to  true, the detail router uses the existing clock global routes, which ensures better correlation.\n Alternatively, you can detail route the clock nets by using the  clock_opt command, as shown in the following example: fc_shell>\u00a0 clock_opt -from route_clock -to route_clock"}
{"header": "How do I Marking Clocks as Propagated After Clock Tree Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A via ladder is a stacked via that starts from the pin layer and extends into an upper layer where the router connects to it.\n Via ladders reduce the via resistance, which can improve performance and electromigration robustness.\n The via ladder insertion flow during clock tree synthesis, optimization, and clock routing consists of the following steps: 1.\n Ensure that the via ladder rules are defined as described in  Defining Via Ladder Rules.\n 2.\n Specify the via ladders that can be used for specific library pins by using the set_via_ladder_candidate command, as described in  Specifying Via Ladder Candidates for Library Pins.\n 3.\n Define the via ladder constraints by using the  set_via_ladder_rules command, as described in  Defining Via Ladder Constraints.\n 4.\n Enable high-performance and electromigration via ladder insertion for critical paths during the  clock_opt command by setting the opt.common.enable_via_ladder_insertion application option to  true.\n 5.\n Perform clock tree synthesis and optimization by using the  clock_opt\u00a0-to build_clock command.\n 6.\n Insert the via ladders by using the  insert_via_ladders command, as described in Inserting Via Ladders.\n 7.\n Route the clock nets by using the  clock_opt\u00a0-from\u00a0route_clock command."}
{"header": "How do I Performing Postroute Clock Tree Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you run the  synthesize_clock_trees or  clock_opt command, after clock tree synthesis, the tool removes the ideal setting from all the synthesized clocks of all active scenarios and sets all the corresponding register clock pins as propagated.\n If your block has scenarios that were not set as active before clock tree synthesis, set these scenarios as active by using the  set_scenario_status\u00a0-active\u00a0true command and mark all clocks as propagated by using the  synthesize_clock_trees -propagate_only command, as shown in the following example: fc_shell>\u00a0 set_scenario_status -active true [all_scenarios] fc_shell>\u00a0 synthesize_clock_trees -propagate_only The  synthesize_clock_trees\u00a0-propagate_only command removes the ideal setting from the clocks; it does not perform clock tree synthesis."}
{"header": "How do I Performing Voltage Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you detail route the clock nets of a block, its clock tree QoR can degrade due to the differences between the clock global routes used during clock tree synthesis and the clock detail routes.\n Clock tree QoR can further degrade when you detail route the signal nets due to coupling capacitance and crosstalk effects.\n You can perform clock tree optimization on a postroute design by using the synthesize_clock_trees\u00a0-postroute command.\n When you do so, you should specify the type of routing performed on the design by using the  -routed_clock_stage option.\n For example, to perform clock tree optimization on a design that has completed clock routing, use the following command: fc_shell>\u00a0 synthesize_clock_trees -postroute \\ -routed_clock_stage detail To perform clock tree optimization on a design that has completed both clock and signal routing, use the following command: fc_shell>\u00a0 synthesize_clock_trees -postroute \\ -routed_clock_stage detail_with_signal_routes Note: When you enable concurrent clock and data optimization, including power or area recovery that uses this technique, the tool does not optimize the clock latency or skew during postroute clock tree optimization; it only fixes the logical DRC violations on the clock network."}
{"header": "How do I Marking Clock Trees as Synthesized", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The voltage level of a design is determined by the technology node (at device level) and the performance requirement.\n The Fusion Compiler tool can perform voltage optimization, which tries to achieve better performance, power, and area (PPA) at a lower voltage level.\n To perform voltage optimization, you need \u2022 Scaled library panes Voltage optimization works on the fundamental principle of scaling the voltage, Therefore, scaled library panes with different voltages are required.\n \u2022 A signoff methodology with a scaled library setup The voltage optimization flow consists of the following high-level steps: 1.\n Perform physical synthesis at the original design voltage using the  compile_fusion command.\n 2.\n Perform clock tree synthesis and optimization at the original design voltage by using the  clock_opt command.\n 3.\n Associate a set of related library panes to form a scaling group by using the define_scaling_lib_group command.\n 4.\n Specify voltage ranges for specific corners by using the  set_vopt_range command, as shown in the following example: fc_shell>\u00a0 set_vopt_range -corner C1 \\ -low_voltage 0.81 -high_voltage 1.0 fc_shell>\u00a0 set_vopt_range -corner C2 \\ -low_voltage 0.81 -high_voltage 1.0 5.\n Specify a total negative slack (TNS) and power target and tolerance for voltage optimization by using the  set_vopt_target command.\n The following example specifies a total negative slack target for voltage optimization and specifies that I/O paths should be excluded from the total negative slack costing: fc_shell>\u00a0 set_vopt_target -tns -1.0 -excludeIO 6.\n Perform voltage optimization by using the  voltage_opt command.\n 7.\n Perform routing at the optimized voltage by using the  route_auto command.\n 8.\n Perform postroute optimization at the optimized voltage by using the  route_opt command."}
{"header": "How do I Removing Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To prevent the Fusion Compiler tool from modifying them, you can mark existing clock trees in your design as synthesized clock tree by using the  mark_clock_trees command as shown in  Table\u00a027.\n Table 27 Using the mark_clock_trees Command To do this Use this option   create_clock create_generated_clock  -clocks\u00a0 clock_list   -synthesized   -clear dont_touch   -dont_touch dont_touch   -clear -dont_touch  set_clock_routing_rules  -routing_rules  set_clock_cell_spacing  -clock_cell_spacing  -fix_sinks  -freeze_routing The tool traverses the clock trees and marks the clock trees as specified.\n Clock tree traversal continues until it finds an exception pin or a default sink pin."}
{"header": "How do I Implementing Multisource Clock Trees", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove the buffers and inverters on a clock tree, use the remove_clock_tre comandcomandsremove_clock_tre remove_clock_trees command.\n The  remove_clock_trees commands traverses the clock tree from its root to its sinks and removes all buffers and inverters, except those with  dont_touch or size_only attributes.\n Cells beyond clock tree exceptions are considered part of the clock tree, but cells beyond a clock-to-data pin are considered part of the data path and are       not removed.\n In addition to removing the buffers and inverters, the  remove_clock_trees command resets the attributes related to clock tree synthesis.\n Note: The  remove_clock_trees command does not support clock mesh nets.\n By default, this command removes the buffers and inverters from all clock trees in all modes.\n To remove the buffers and inverters from specific clock trees, use the  -clocks option to specify the clock trees.\n By default, when you use the  -clocks option, the clocks are selected from the current mode.\n To select clocks from a specific mode, use the get_clocks\u00a0-mode command to select the clocks.\n For example, to remove only the clock tree in the current mode named my_clk, use the following command: fc_shell>\u00a0 remove_clock_trees -clocks [get_clocks my_clk] Table\u00a028 shows how clock tree removal is affected by the structure of the clock tree.\n Table 28 Clock Tree Removal Behavior Object Impact on clock tree removal                                 Table 28 Clock Tree Removal Behavior (Continued) Object Impact on clock tree removal       By default, the  remove_clock_trees command removes the detail route shapes of the clock nets it removes.\n However, you can preserve the route shapes of the clock nets by setting the  shape_use attribute of the clock nets to  user_route."}
{"header": "How do I Introduction to Multisource Clock Trees Structures", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics introduce the different types of multisource clock trees and provides detailed information about the different multisource clock tree implementation flows and steps: \u2022 Introduction to Multisource Clock Trees Structures \u2022 Implementing a Regular Multisource Clock Tree \u2022 Implementing a Regular Multisource Clock Tree Using Integrated Tap Assignment \u2022 Implementing a Regular Multisource Clock Tree With an H-Tree-Only Global Clock Tree Structure \u2022 Implementing MSCTS Multiple H-Tree \u2022 Implementing Power Aware Flexible H-Tree \u2022 Implementing a Structural Multisource Clock Tree \u2022 Implementing a Structural Multisource Clock Tree Using Integrated Subtree Synthesis \u2022 Improving the Correlation Between the SMSCTS and CCD \u2022 Inserting Clock Drivers \u2022 Synthesizing the Global Clock Trees \u2022 Creating Clock Straps \u2022 Routing to Clock Straps \u2022 Analyzing the Clock Mesh       \u2022 Performing Automated Tap Insertion and H-Tree Synthesis \u2022 Specifying Tap Assignment Options and Settings \u2022 Building the Local Clock Subtree Structures"}
{"header": "How do I Implementing a Regular Multisource Clock Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A multisource clock tree is a custom clock structure that has more tolerance to on-chip variation and has better performance across corners than traditional clock tree structures.\n These custom clock trees consist of \u2022 A global clock structure, which includes \u25e6 The clock root \u25e6 A global clock tree, which is usually an H-tree structure \u25e6 Clock mesh drivers \u25e6 A clock mesh \u2022 Local subtrees that can be driven \u25e6 By a predefined set of drivers, called tap drivers, that are connected to the clock mesh, as shown in  Figure\u00a083.\n Because the subtrees are built using regular clock tree synthesis commands such as the  synthesize_clock_trees or  clock_opt command, such a structure is called a regular multisource clock tree.\n \u25e6 Directly from multiple points of the clock mesh, as shown in  Figure\u00a084.\n Because the subtrees are built preserving the user-defined structure and optimized by merging and splitting the clock cells, such a structure is called a structural multisource clock tree.\n       Figure 83 Regular Multisource Clock Tree Clock root  Global clock tree  Clock mesh  Mesh drivers  Clock gates Tap drivers  and sinks Global clock structure Local subtrees Figure 84 Structural Multisource Clock Tree Clock root  Global clock tree  Clock mesh  Mesh drivers  Clock gates and sinks Global clock structure Local subtrees"}
{"header": "How do I Implementing a Regular Multisource Clock Tree Using Integrated", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To implement a regular multisource clock tree, use the following steps: 1.\n Specify your clock tree constraints and settings.\n 2.\n Perform the following steps for multivoltage designs: a.\n Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to  true.\n b.\n Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to  true.\n c.\n Run the  check_mv_design command and fix all multivoltage issues.\n 3.\n Enable cell electromigration fixing by setting the  cts.multisource.cell_em_aware application option to  true.\n 4.\n Insert the tap drivers by using the  create_clock_drivers command, as described in Inserting Clock Drivers.\n 5.\n Create the clock mesh by using the  create_clock_straps command, as described in Creating Clock Straps.\n 6.\n Insert the mesh drivers by using the  create_clock_drivers command, as described in  Inserting Clock Drivers.\n 7.\n Build the global clock tree structure by using the synthesize_multisource_global_clock_trees command, as described in Synthesizing the Global Clock Trees.\n 8.\n Route the connections between the clock mesh and the tap drivers by using the route_clock_straps command, as described in  Routing to Clock Straps.\n 9.\n Analyze the clock mesh by using the  analyze_subcircuit command, as described in Analyzing the Clock Mesh.\n 10.\n Specify options and settings for tap assignment as described in  Specifying Tap Assignment Options and Settings.\n       11.\n Perform tap assignment by using the  synthesize_multisource_clock_taps command, which \u25e6 Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks \u25e6 Assigns endpoints to the closest tap driver and split cells along the path honoring any sink groups defined \u25e6 Copies the UPF and SDC constraints and the user-specified attributes onto the newly created cells across the active scenarios 12.\n Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell>\u00a0 clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers.\n It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n For more information about the  clock_opt command, see  Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command.\n 13.\n Analyze the clock tree results as described in  Analyzing the Clock Tree Results."}
{"header": "How do I Implementing a Regular Multisource Clock Tree With an", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A regular multisource clock tree has tap drivers that are driven by a clock mesh and drive clock-gating cells and sinks.\n If you insert these tap drivers before you run the compile_fusion command, the tool can assign sinks to these drivers such that it improves the overall timing QoR of the block.\n It also allows the tool to improve the timing of clock-gating paths.\n To perform regular multisource clock tree synthesis integrated with placement and optimization, use the following steps: 1.\n Specify the placement and optimization constraints and settings.\n 2.\n Specify the clock tree constraints and settings.\n       3.\n Perform the following steps for multivoltage designs: a.\n Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to  true.\n b.\n Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to  true.\n c.\n Run the  check_mv_design command and fix all multivoltage issues.\n 4.\n Enable cell electromigration fixing by setting the  cts.multisource.cell_em_aware application option to  true.\n 5.\n Insert the tap drivers by using the  create_clock_drivers command, as described in Inserting Clock Drivers.\n 6.\n Create the clock mesh by using the  create_clock_straps command, as described in Creating Clock Straps.\n 7.\n Insert the mesh drivers by using the  create_clock_drivers command, as described in  Inserting Clock Drivers.\n 8.\n Build the global clock tree structure by using the synthesize_multisource_global_clock_trees command, as described in Synthesizing the Global Clock Trees.\n 9.\n Route the connections between the clock mesh and the tap drivers by using the route_clock_straps command, as described in  Routing to Clock Straps.\n 10.\n Analyze the clock mesh by using the  analyze_subcircuit command, as described in Analyzing the Clock Mesh.\n 11.\n Specify options and settings for tap assignment as described in  Specifying Tap Assignment Options and Settings.\n 12.\n Enable integrated tap assignment by setting the compile.flow.enable_multisource_clock_trees application option to  true and run the  compile_fusion\u00a0-from\u00a0initial_place command.\n fc_shell>\u00a0 set_app_options \\ -name compile_flow.flow.enable_multisource_clock_trees -value true fc_shell>\u00a0 compile_fusion -initial_place 13.\n Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell>\u00a0 clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers.\n It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n       For more information about the  clock_opt command, see  Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command.\n 14.\n Analyze the clock tree results as described in  Analyzing the Clock Tree Results."}
{"header": "How do I Implementing MSCTS Multiple H-Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n Figure 85 Regular Multisource Clock Tree With an H-Tree-Only Global Clock Structure To implement a regular multisource clock tree structure with an H-tree-only global clock tree structure, 1.\n Specify your clock tree constraints and settings.\n 2.\n Perform the following steps for multivoltage designs: a.\n Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to  true.\n b.\n Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to  true.\n c.\n Run the  check_mv_design command and fix all multivoltage issues.\n 3.\n Enable cell electromigration fixing by setting the  cts.multisource.cell_em_aware application option to  true.\n 4.\n Specify the required settings by using the set_regular_multisource_clock_tree_options command and       perform tap insertion and global clock tree (H-tree) synthesis by using the synthesize_regular_multisource_clock_trees command, as described in Performing Automated Tap Insertion and H-Tree Synthesis.\n 5.\n Specify options and settings for tap assignment, as described in  Specifying Tap Assignment Options and Settings.\n 6.\n Perform tap assignment by using the  synthesize_multisource_clock_taps command, which \u25e6 Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks \u25e6 Assigns endpoints to the closest tap driver and splits cells along the path honoring any sink groups defined \u25e6 Copies the UPF and SDC constraints and the user-specified attributes onto the newly created cells across the active scenarios 7.\n Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell>\u00a0 clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers.\n It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n For more information about the  clock_opt command, see  Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command.\n 8.\n Analyze the clock tree results, as described in  Analyzing the Clock Tree Results."}
{"header": "How do I Implementing Power Aware Flexible H-Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve clock QoR, latency, and skew, you can build multiple global trees in different sections of the floorplan by using the  -htree_sections option with the set_regular_multisource_clock_tree_options command.\n The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n       Figure 86 MSCTS Multiple H-Tree You can define the different sections in the floorplan by using a symmetric configuration of tap drivers or only tap locations by coordinates, as shown in the following example: set_regular_multisource_clock_tree_options\u00a0-\u00a0htree_sections\u00a0[\u00a0list\u00a0\\ [list\u00a0-section_name\u00a0\u201csectionA_name\u201d\u00a0-tap_boundary\u00a0{{315.8800\u00a01275.8000} {1750.0400\u00a02187.1000}}\u00a0-prefix\u00a0\u201csectionA\u201d\u00a0-tap_boxes\u00a0{4\u00a04}]\u00a0\\ [list\u00a0-section_name\u00a0\u201csectionB_name\u201d\u00a0-tap_locations\u00a0{{700472}\u00a0{1350\u00a0472}} -prefix\u00a0\u201csection\u201d]] Figure 87 MSCTS Multiple H-Tree"}
{"header": "How do I Implementing a Structural Multisource Clock Tree", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool derives tap driver configurations by adding power awareness in the flexible H-Tree synthesis flow, which is optimal in terms of total clock power and overall clock latency.\n       This requires at least one of the dynamic power scenarios to be defined and active during H-tree Synthesis.\n In case of multiple scenarios, the worst active scenario is considered for power costing.\n The initial tap configurations are generated based on floorplan shape, size, sink distribution, placement, routing constraints, and or each tap configuration.\n This helps to estimate the latency and power for each subtree, and then tabulates and compares the results of different tap configurations to determine the best solution for power aware flexible H-Tree synthesis.\n To enable power aware flexible H-tree synthesis, set the cts.multisource.power_aware_flexible_htree_synthesis application option to true."}
{"header": "How do I Implementing a Structural Multisource Clock Tree Using", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In a structural multisource clock tree, the subtrees are driven directly by the clock mesh or through predefined drivers.\n These drivers are in turn driven by global clock distribution structure such as a clock mesh and H-tree.\n The local subtrees of a structural multisource clock tree are optimized by clock cell merging, splitting, sizing, and relocation, while preserving the levels of the user-defined clock tree structure.\n To implement a structural multisource clock tree, perform the following steps: 1.\n Specify your clock tree constraints and settings.\n 2.\n For multivoltage designs, \u25e6 Enable multivoltage support by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name cts.multisource.enable_full_mv_support -value true \u25e6 Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name opt.common.allow_physical_feedthrough -value true \u25e6 Run the  check_mv_design command and fix all multivoltage issues 3.\n Enable cell electromigration fixing by setting the  cts.multisource.cell_em_aware application option to  true.\n 4.\n Create the clock mesh by using the  create_clock_straps command, as described in Creating Clock Straps.\n 5.\n Insert the mesh drivers by using the  create_clock_drivers command, as described in  Inserting Clock Drivers.\n       6.\n Build the global clock tree structure by using the synthesize_multisource_global_clock_trees command, as described in Synthesizing the Global Clock Trees.\n 7.\n Model the delays of the mesh nets using  set_annotated_delay and set_annotated_transition commands.\n The loads of the clock mesh are not finalized until the local subtrees are synthesized in step 6 and routed to the mesh in step 7.\n Therefore the clock mesh can only be analyzed after you complete those steps.\n However, to prevent the tool from seeing a very large delay through the clock mesh when synthesizing the local subtrees, annotate a realistic delay and transition value on the clock mesh net.\n 8.\n Build the local subtrees by using the  synthesize_multisource_clock_subtrees command, as described in  Building the Local Clock Subtree Structures.\n 9.\n Route the connections between the clock mesh and the local subtrees by using the route_clock_straps command, as described in  Routing to Clock Straps.\n 10.\n Analyze the clock mesh by using the  analyze_subcircuit command, as described in Analyzing the Clock Mesh.\n 11.\n Synthesize the entire clock tree, from the clock root, by using the  clock_opt\u00a0-from build_clock\u00a0-to\u00a0route_clock command.\n During this step, the tool fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n 12.\n Analyze the clock tree results as described in  Analyzing the Clock Tree Results."}
{"header": "How do I Improving the Correlation Between the SMSCTS and CCD", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In a structural multisource clock tree, the subtrees are driven directly by the clock mesh or through predefined drivers.\n These drivers are, in turn, driven by a global clock distribution structure such as a clock mesh or an H-tree.\n By using the  compile_fusion command to synthesize and optimize the local subtrees of a structural multisource clock tree, you can improve the timing QoR of the design.\n       To implement a structural multisource clock tree using the integrated subtree synthesis capabilities, perform the following steps: 1.\n Specify your clock tree constraints and settings.\n 2.\n For multivoltage designs, \u25e6 Enable multivoltage support by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name cts.multisource.enable_full_mv_support -value true \u25e6 Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by using the following application option setting: fc_shell>\u00a0 set_app_options \\ -name opt.common.allow_physical_feedthrough -value true \u25e6 Run the  check_mv_design command and fix all multivoltage issues 3.\n Enable multicorner optimization by setting the cts.multisource.enable_multi_corner_support application option to  true.\n The default is  false.\n By default, the tool uses the worst corner associated with the mode in which the subtree options are defined.\n When you enable this feature, the tool considers all corners associated with the mode in which the subtree options are defined.\n 4.\n Enable cell electromigration fixing by setting the  cts.multisource.cell_em_aware application option to  true.\n 5.\n Create the clock mesh by using the  create_clock_straps command, as described in Creating Clock Straps.\n 6.\n Insert the mesh drivers by using the  create_clock_drivers command, as described in  Inserting Clock Drivers.\n 7.\n Build the global clock tree structure by using the synthesize_multisource_global_clock_trees command, as described in Synthesizing the Global Clock Trees.\n 8.\n Model the delays of the mesh nets by using the  set_annotated_delay and set_annotated_transition commands.\n 9.\n Specify settings for local subtree synthesis by using the set_multisource_clock_subtree_options command.\n       You must specify \u25e6 The clock for synthesizing the subtrees by using the  -clock option \u25e6 The drivers of the subtrees to be synthesized by using the  -driver_objects option Optionally you can \u25e6 Prevent the tool from merging specific clock tree cells by using the -dont_merge_cells option \u25e6 Balance the levels of the local subtree by using the  -balance_levels\u00a0true option and specify a target number of levels, which applies to all sinks of the local subtree, by using the  -target_level option Optionally, you can apply a different target number of levels to specific sink pins and clock balance points by using the set_multisource_clock_subtree_constraints command with the  -pins and -target_level options.\n \u25e6 Specify a maximum total wire delay from any subtree driver to any of its sinks by using the  -max_total_wire_delay option and the corner it applies to by using the -corner option \u25e6 Enable the reordering of clock-gating cells by using the  -enable_icg_reordering true option When you enable this feature, the tool swaps the position of a clock-gating cell with the buffer that is driving the clock-gating cell.\n Then, the buffer is gated by the clock- gating cell, thereby reducing the dynamic power consumption.\n To perform reordering, you must \u25aa Enable the scenarios used for structural multisource clock tree synthesis \u25aa Annotate the switching activity for the enable pins of the clock-gating cells You can prevent specific clock-gating cells from being reordered by using the set_multisource_clock_subtree_constraints command with the  -cells and -ignore_for_icg_reordering options.\n To report the settings you specified, use the report_multisource_clock_subtree_options command.\n To remove the settings you specified, use the  remove_multisource_clock_subtree_options command.\n 10.\n Enable integrated structural multisource clock tree synthesis by setting the compile.flow.enable_multisource_clock_trees application option to  true, and build the local subtree by running the  compile_fusion\u00a0-from\u00a0initial_place command.\n       fc_shell>\u00a0 set_app_options \\ -name compile_flow.flow.enable_multisource_clock_trees -value true fc_shell>\u00a0 compile_fusion -from initial_place 11.\n Route the connections between the clock mesh and the local subtrees by using the route_clock_straps command, as described in  Routing to Clock Straps.\n 12.\n Analyze the clock mesh by using the  analyze_subcircuit command, as described in Analyzing the Clock Mesh.\n 13.\n Enable integrated structural multisource clock tree synthesis by setting the clock_opt.flow.enable_multisource_clock_trees application option to  true, and synthesize the entire clock tree from the clock root by using the  clock_opt\u00a0-from build_clock\u00a0-to\u00a0route_clock command.\n fc_shell>\u00a0 set_app_options \\ -name clock_opt.flow.enable_multisource_clock_trees -value true fc_shell>\u00a0 clock_opt -from build_clock -to route_clock During this step, the tool incrementally optimizes the existing subtrees.\n 14.\n Analyze the clock tree results as described in  Analyzing the Clock Tree Results."}
{"header": "How do I Inserting Clock Drivers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To improve the correlation between the structural multisource clock tree synthesis (SMSCTS) and concurrent clock and data (CCD), the Fusion Compiler tool supports the enhanced CCD engine with more SMSCTS specific offsets.\n This improves the CCD balance point implementation and timing after the SMSCTS step in the  clock_opt command.\n To enable the improved correlation between the SMSCTS and CCD in the compile_fusion command and  build_clock stage of the  clock_opt command, set the cts.multisource.enable_subtree_synthesis_aware_ccd application option to  true.\n The improved correlation between the SMSCTS and CCD: \u2022 Improves the overall latency implementation after SMSCTS in the  clock_opt command.\n \u2022 Reduces long and short path violations.\n \u2022 Improves timing after the  clock_opt command with CCD offsets."}
{"header": "How do I Inserting Clock Drivers for Designs With Multiple Levels of", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you insert clock drivers, \u2022 Specify all clock tree synthesis settings, including clock routing rules \u2022 Specify that the inserted clock drivers should be aligned with the clock straps of the mesh structure by setting the  cts.multisource.enable_clock_driver_snapping application option to  true During multisource clock tree synthesis, you can use the  create_clock_drivers command for the following: \u2022 Insert mesh drivers for both regular or structural multisource clock trees.\n \u2022 Tap drivers for regular multisource clock trees.\n When you insert mesh or tap drivers, \u2022 Specify the loads to drive by using the  -loads option.\n The load can be a net or a set of pins or ports connected to the same net.\n \u2022 Specify where to add the clock drivers as exact locations by using the  -location option.\n Alternatively, you can add the clock drivers in an X by Y grid pattern over the entire core area by using the  -boxes option.\n You can limit the X by Y grid pattern to a specific area by using the  -boundary option with the  -boxes option.\n \u2022 Specify a list of cells that can be used as clock drivers by using the  -lib_cells option.\n You can specify both single-rail and dual-rail library cells.\n Alternatively, you can select the existing driver of the load net as a template for the clock drivers by using the  -template option.\n If the template cell you specify is a buffer or inverter, you can also specify different versions of this buffer or inverter as clock drivers by using the  -lib_cells option with the  -template option.\n When you insert mesh drivers, to specify that the outputs of all the clock drivers must be connected together to drive the mesh net, use the  -short_outputs option.\n The following example creates a grid of eight by eight mesh drivers, places them in a regular pattern that covers the full core area, shorts the outputs of the clock drivers and connects to the net named clk_mesh, and transfers preexisting routing shapes and vias from the net named clk to this net: fc_shell>\u00a0 create_clock_drivers -loads [get_nets clk1_mesh] \\ -boxes {8 8} -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -short_outputs -output_net_name clk_mesh \\ -transfer_wires_from [get_nets clk]       The following example creates a grid of five by five tap drivers that are placed within the rectangle bounded at the lower-left by (200, 200) and upper right by (1000, 1000).\n fc_shell>\u00a0 create_clock_drivers -loads [get_nets clkA] \\ -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -boxes {5 5} -boundary [list {{200 200} {1000 1000}} ] In this example, one of the tap drivers drives all the loads of the original clock net named clkA.\n To distribute the loads among all the clock drivers, you must subsequently perform automated multisource tap assignment by using the synthesize_multisource_clock_taps command, as described in  Specifying Tap Assignment Options and Settings.\n You can use the  create_clock_drivers to add multiple levels of clock drivers by using the  -configuration option and specifying the configuration of drivers at each level.\n The following example inserts three levels of clock drivers.\n The first level consists of one buffer, the second level consists of four inverters in a 2x2 grid, and the third level consists of 16 inverters in a 4x4 grid.\n fc_shell>\u00a0 create_clock_drivers -loads [get_nets clk] \\ -configuration [list \\ [list -level 1  -boxes {1 1} -lib_cells buf32x ] \\ [list -level 2  -boxes {2 2} -lib_cells inv16x ] \\ [list -level 3  -boxes {4 4} -lib_cells inv8x ]] For this example, because there is no bounding box specified at any level, the drivers at each level are evenly distributed in the core area.\n The buffer in the first level is placed at the center of the core area, the four buffers in the next level are placed at the center of the four quadrants of the core area, and so on, resulting in an evenly placed clock drivers that can be routed to form an H-tree structure as shown in  Figure\u00a088 Figure 88 Clock Drivers Placed in an H-Tree Structure After it inserts the clock drivers, the tool marks the clock drivers that it inserts as fixed and don\u2019t touched.\n The tool avoids overlapping the clock drivers with other fixed cells, blockages, and macros.\n However, the clock drivers can overlap with cells that are not       fixed.\n The  create_clock_drivers command does not legalize the design.\n To do so, run the  legalize_placement command.\n If you run the  create_clock_drivers command multiple times, to reduce runtime, run the  legalize_placement command one time, after you complete all the  create_clock_drivers command runs.\n When routing the H-trees, the tool uses the highest routing layers available, based on the routing rules specified for the clock nets.\n These same layers can contain prerouted nets such as power and ground nets.\n To prevent placing clock drivers under these preroutes, which can cause pin accessibility issues, the  create_clock_drivers command creates temporary placement blockages for the preroutes on the same layers it uses for routing.\n After it completes routing, it removes these temporary placement blockages, as shown in the following example output.\n...\n Net:\u00a0clk;\u00a0Rule:\u00a0htree_ndr;\u00a0Min\u00a0Layer:\u00a0M8;\u00a0Max\u00a0Layer:\u00a0M9...\n Information:\u00a0Using\u00a0routing\u00a0H/V\u00a0layer\u00a0pair\u00a0'M9'/'M8'\u00a0for\u00a0net\u00a0'clk'.\n (CTS-659)...\n Converting\u00a0metal\u00a0shapes\u00a0in\u00a0horizontal\u00a0layer\u00a0M9\u00a0and\u00a0vertical\u00a0layer\u00a0M8\u00a0into placement\u00a0blockages.\n In\u00a0total\u00a0703\u00a0placement\u00a0blockages\u00a0created.\n...\n Successfully\u00a0deleted\u00a0all\u00a0temporary\u00a0placement\u00a0blockages\u00a0and\u00a0the\u00a0cell\u00a0map.\n If you specify multirow-height cells with the  -lib_cell option of the create_clock_drivers command, the tool might not be able to place them due to the temporary placement blockages it creates for the preroutes.\n If so, you can prevent the tool from creating the temporary placement blockages by setting the cts.multisource.enable_pin_accessibility_for_global_clock_trees application option to  false.\n To remove clock drivers inserted by the  create_clock_drivers command, use the remove_clock_drivers command."}
{"header": "How do I Synthesizing the Global Clock Trees", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert clock drivers from the top level of a design with multiple levels of physical hierarchy, 1.\n Enable the lower-level physical blocks for editing by using the  set_editability command.\n 2.\n Enable clock driver insertion for multiple levels of physical hierarchy by setting the cts.multisource.enable_mlph_flow application option to  true.\n       3.\n Insert clock drivers by using the  create_clock_drivers command.\n 4.\n Route the inserted clock drivers by using the synthesize_multisource_global_clock_trees\u00a0-roots\u00a0-leaves -use_zroute_for_pin_connections command.\n When inserting clock drivers to lower-level blocks, the tool reuses existing clock ports.\n If there are no existing clock ports, the tool creates new ports, if it is allowed.\n You can allow new ports to be added to a block by using use the  set_freeze_ports command."}
{"header": "How do I Inserting Clock Drivers for Designs With Multiple Levels of", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you insert clock drivers, ensure that all clock tree synthesis settings, including clock routing rules, are specified.\n To perform clock tree synthesis and detail routing to build an H-tree style global clock tree, use the  synthesize_multisource_global_clock_trees command.\n When building the H-tree, the tool tries to minimize the skew between the endpoints, which is essential for multisource clock tree synthesis.\n When you use this command to synthesize and detail route a global clock tree, you must specify \u2022 The clock net to synthesize by using the  -nets option.\n \u2022 The library cells to use by using the  -lib_cells option.\n You can specify both single- rail and dual-rail library cells.\n By default, the tool uses the Custom Router to route the H-tree structure and connect to the pins of the clock tree cells.\n If the Custom Router is unable to resolve all routing DRC violation when making pin connections, use the Zroute to make the pin connections by using the  -use_zroute_for_pin_connections options.\n To stop the routes at the highest available metal layer close to the pin shape, use the  -skip_pin_connections option.\n The following example synthesizes and detail routes a global clock tree for the clock net named clkA.\n fc_shell>\u00a0 synthesize_multisource_global_clock_trees \\ -nets [get_nets clkA] -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -use_zroute_for_pin_connections You can also use the  synthesize_multisource_global_clock_trees command to only perform clock detail routing for an H-tree style clock structure that has already been synthesized.\n       When doing so, you must specify \u2022 The startpoint of the global clock structure, by using the  -roots option.\n \u2022 The endpoints of the global clock structure by using the  -leaves option.\n The following example detail routes an existing H-tree style clock structure.\n The startpoint is the port named clk1 and the endpoints are the inputs of a group of mesh drivers.\n fc_shell>\u00a0 synthesize_multisource_global_clock_trees \\ -roots [get_ports clk1] -leaves [get_pins mesh_buf*/A] \\ -use_zroute_for_pin_connections When routing the H-trees, the tool uses the highest routing layers available, based on the routing rules specified for the clock nets.\n These same layers can contain prerouted nets such as power and ground nets.\n To prevent placing clock drivers under these preroutes, which can cause pin accessibility issues, the synthesize_multisource_global_clock_trees command creates temporary placement blockages for the preroutes on the same layers it uses for routing.\n After it completes routing, it removes these temporary placement blockages, as shown in the following example output.\n...\n Net:\u00a0clk;\u00a0Rule:\u00a0htree_ndr;\u00a0Min\u00a0Layer:\u00a0M8;\u00a0Max\u00a0Layer:\u00a0M9...\n Information:\u00a0Using\u00a0routing\u00a0H/V\u00a0layer\u00a0pair\u00a0'M9'/'M8'\u00a0for\u00a0net\u00a0'clk'.\n (CTS-659)...\n Converting\u00a0metal\u00a0shapes\u00a0in\u00a0horizontal\u00a0layer\u00a0M9\u00a0and\u00a0vertical\u00a0layer\u00a0M8\u00a0into placement\u00a0blockages.\n In\u00a0total\u00a0703\u00a0placement\u00a0blockages\u00a0created.\n...\n Successfully\u00a0deleted\u00a0all\u00a0temporary\u00a0placement\u00a0blockages\u00a0and\u00a0the\u00a0cell\u00a0map.\n If you specify multirow-height cells with the  -lib_cell option of the synthesize_multisource_global_clock_trees command, the tool might not be able to place them due to the temporary placement blockages it creates for the preroutes.\n If so, you can prevent the tool from creating the temporary placement blockages by setting the cts.multisource.enable_pin_accessibility_for_global_clock_trees application option to  false.\n To remove a clock structure created by the synthesize_multisource_global_clock_trees command, use the remove_multisource_global_clock_trees command."}
{"header": "How do I Creating Clock Straps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert clock drivers from the top level of a design with multiple levels of physical hierarchy, 1.\n Enable the lower-level physical blocks for editing by using the  set_editability command.\n 2.\n Enable clock driver insertion for multiple levels of physical hierarchy by setting the cts.multisource.enable_mlph_flow application option to  true.\n 3.\n Insert clock drivers by using the  create_clock_drivers command.\n When inserting clock drivers to lower-level blocks, the tool reuses existing clock ports.\n If there are no existing clock ports, the tool creates new ports, if it is allowed.\n You can allow new ports to be added to a block by using use the  set_freeze_ports command."}
{"header": "How do I Routing to Clock Straps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create clock straps, which are straight metal shapes in a single routing layer, by using the  create_clock_straps command.\n You can use this command to implement \u2022 A clock mesh, which is a two-dimensional grid in a horizontal and a vertical layer, where the straps are connected by vias at the intersection points, as shown in Figure\u00a089.\n \u2022 A clock spine, which can be either a one- or two-dimensional structures.\n One-dimensional spines are straps in a single direction.\n Two-dimensional spines consists of one-dimensional spines connected to multiple stripes in the orthogonal direction.\n Stripes connected to one spine do not connect to stripes of a different spine and the minimum distance between the stripes of different spines is called the backoff, as shown in  Figure\u00a090       Figure 89 Clock Mesh Structure Boundary of clock mesh Start distance for Incremental step for subsequent straps (0,0) Start distance for Incremental step for subsequent straps first vertical strap first horizontal strap End distance for last vertical strap End distance for last horizontal strap       Figure 90 Clock Spine Structure Boundary of clock spine (0,0) Backoff Stripes Spine The horizontal and vertical  start, end, and step distances are applicable for  clock spine structures too.\n When you use the  create_clock_straps command, \u2022 To specify the clock net for which to create the structure, use the  -net option.\n \u2022 To specify the bounding box to confine the structure, use the  -boundary option.\n \u2022 To specify keepouts, use the  -keepouts option.\n If part of a strap is over a keepout, by default, the tool splits the strap and creates the portions that are outsides the keepouts.\n However, you can disable splitting and specify that the tool not create a strap if it is over a keepout by using the  -allow_splitting false option.\n \u2022 To specify the layers on which create the straps, use the  -layers option.\n The tool determines the direction of the straps based on the metal layer you specify.\n To create straps in both directions, specify a layer for each direction.\n \u2022 To specify the width of the straps, use the  -width option.\n       \u2022 To specify where to create the straps, use the  -grid option as follows: \u25e6 To create a single horizontal or vertical strap, specify the distance from the x- or y- axis.\n \u25e6 To create a multiple straps in a single direction, specify an iterator list consisting of the start distance to the first strap, the end distance to the last strap, and the incremental distance between straps.\n \u25e6 To create a multiple straps in a both the horizontal and vertical directions, specify an iterator list for each direction, starting with the horizontal direction.\n Use the  -grid option to create multiple straps for both the clock mesh and clock spine structures.\n \u2022 To specify a margin within which the tool can move a strap from the position it derives based on the  -grid option settings, use the  -margins option.\n If the tool cannot create a strap within the specified margin, due to obstructions or keepouts, it does not create the strap.\n By default, the tool uses a margin of zero and only creates the strap if it can do so at the exact position it derives.\n \u2022 To create straps on the boundary specified with the -boundary option, use the -create_ends option.\n \u2022 To allow straps that are unconnected to orthogonal straps, use the  -allow_floating true option.\n By default, the tool does not allow orthogonal straps that are unconnected.\n \u2022 To specify the type of straps to create, use the  -type option and specify  user_route, stripe, or  detect.\n When you create straps in both direction, specify a list of two values starting with the type for the horizontal direction.\n You can specify  detect as the type only when you are creating a clock spine structure and want the tool to detect and use existing spines.\n When you do so, you must specify a list consisting of the type for the orthogonal stripes and  detect, with the type for the horizontal direction specified first in the list.\n In addition, when the tool detects existing spine, you can specify a minimum length for the spine, by using the  -detect_length option.\n \u2022 To specify the maximum length of the orthogonal stripes, when creating a clock spine structure, use the  -length option.\n \u2022 To specify the backoff distance between stripes of different spines, when creating a clock spine structure, use the  -backoff option.\n       \u2022 To specify the direction of the spines, when creating a clock spine structure and the tool is not detecting and using existing spines, use the  -spine_direction option.\n \u2022 To shield the straps with power and ground nets, use the  -bias option.\n \u2022 To shield the straps with specific nets, use the  -bias_to_nets with the list of nets.\n \u2022 To specify the distance from the shielding nets, use the  -bias_margins option.\n \u2022 To remove the straps of a specific clock net, use the  -clear option.\n For example, the following command creates a clock mesh for the net named clk1_mesh that is bounded by coordinates (0,0) and (1200, 980).\n The straps are on layers M7 and M8 with a width of 2.4 units and of type stripe.\n The horizontal straps on layer M7 start at a distance of 20 units from the x-axis and repeat every 100 units, until they reach 1200 units from the x-axis.\n The vertical straps on layer M8 start at a distance of 60 units from the y- axis and repeat every 150 units, until they reach 980 units from the x-axis.\n fc_shell>\u00a0 create_clock_straps -nets [get_nets clk1_mesh] \\ -layers {M7 M8} -widths {2.4 2.4} -types {stripe stripe} \\ -grids {{20 1200 100} {60 980 150}}-boundary {{0 0} {1200 980}} The following example creates a two-dimensional spine structure that has spines on the vertical layer M8 with a width of 3.6 units and of type  user_route and stripes on the horizontal layer M7 with a width of 2.4 units and of type  stripe.\n The vertical spines on layer M8 start at a distance of 60 units from the y-axis and repeat every 150 units, until they reach 980 units from the x-axis.\n The horizontal stripes on layer M7 have a length of 120 units and they start at a distance of 20 units from the x-axis and repeat every 100 units, until they reach 1200 units from the x-axis.\n The minimum distance (backoff) between stripes of different spines is 5 units.\n fc_shell>\u00a0 create_clock_straps -nets [get_nets clk1_mesh] \\ -layers {M7 M8} -widths {2.4 3.6} -types {stripe user_route} \\ -grids {{20 1200 100} {60 980 150}} -length 120 -backoff 5"}
{"header": "How do I Analyzing the Clock Mesh", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you create clock straps for a clock net by using the  create_clock_straps command, you can route the drivers and loads of the clock net to the clock straps by using the  route_clock_straps command and specify the clock net name by using the  -nets option.\n The tool connects the drivers and the loads only to clock straps with the  shape_use attribute setting of  stripe.\n It does not connect to clock straps with the  shape_use attribute setting of  user_route.\n       To specify a topology for connecting the clock drivers and sinks to the clock straps, use the -topology option as follows: \u2022 To create a fishbone routing topology, the default topology, use the  -topology fishbone option.\n In a fishbone topology, each driver pin is individually connected to the nearest stripe.\n To minimize wire length, multiple load pins are connected using comb routing to a single finger, which is connected to the stripe, as shown in  Figure\u00a091.\n Figure 91 Fishbone Topology Fanout Clock mesh strap ( shape_use  =  user_route ) Clock mesh strap ( shape_use  =  stripe ) Comb route  Driver pins Load pins Finger route If you are using a fishbone topology, you can specify \u25e6 A maximum fanout for the loads of a finger, as shown in  Figure\u00a092, by using -fishbone_fanout option.\n Figure 92 Fanout of a Finger of the Fishbone Topology Finger Fanout \u25e6 A maximum span between any two loads connected to a finger, as shown in Figure\u00a093, by using  -fishbone_span option.\n       The span is measured orthogonal to the direction of the finger.\n Figure 93 Span and Subspan of the Fishbone Topology Subspan  Span Subfinger Finger \u25e6 A maximum subspan between any two loads connected to a subfinger, as shown in Figure\u00a093, by using  -fishbone_sub_span option.\n The subspan is measured orthogonal to the direction of the subfinger.\n \u25e6 The layers to use for routing the fingers and subfingers by using the -fishbone_layers option.\n \u2022 To create a comb routing topology, use the  -topology\u00a0comb option.\n In a comb topology, each driver and load pin is directly routed to the nearest stripe.\n However, if the Manhattan distance from a pin to the nearest stripe is more than the comb distance, the tool routes the pin to the nearest net shape using a Steiner topology, as shown in  Figure\u00a094.\n The default comb distance is two global routing cells.\n To change the comb distance, use the  route.common.comb_distance application option.\n       Figure 94 Comb Topology Load pins Driver pins  Clock mesh strap ( shape_use  =  stripe ) Clock mesh strap ( shape_use  =  user_route ) Comb route Pin that is further than the comb distance Comb routing is suitable when there are a large number of driver and load pins directly under the clock-mesh stripes.\n The tool uses stacked vias to connect the pins to the stripes, which are usually in the higher routing layers.\n However, this can contribute to physical DRC violations due to many adjacent stacked vias, as shown in  Figure\u00a095.\n Figure 95 Vias in the Comb Topology Driver and load pins Clock mesh strap on Stacked vias  higher routing layer \u2022 To create a substrap routing topology, use the  -topology\u00a0sub_strap option.\n In a substrap topology, additional straps that are parallel to the stripes are created on intermediate routing layers.\n This reduces the number of stacked vias, as compared to the comb topology.\n       Figure 96 Vias in the Substrap Topology Driver and load pins Clock mesh stripe on Substrap on intermediate  higher routing layer routing layers For the substrap topology, you \u25e6 Must specify the layers in which to create the substrap by using the -sub_strap_layers option \u25e6 Can specify the maximum RC delay allowed for the substrap by using the -sub_strap_max_delay option The default is 2 ps.\n This delay constrains the length and the number of loads connected to the substrap."}
{"header": "How do I Performing Automated Tap Insertion and H-Tree Synthesis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To reduce skew variation, clock mesh structures require higher timing accuracy than traditional clock structures.\n Therefore, to analyze a clock mesh structures, use the analyze_subcircuit command, which performs transistor level circuit simulation for the clock mesh and back-annotates accurate timing information.\n Before you run the  analyze_subcircuit command, you must \u2022 Detail route the clock mesh net.\n \u2022 Have a circuit-level model for each of the gates in your clock tree and a transistor model for each of the transistors in the circuit-level models.\n \u2022 Have access to a SPICE simulator such, as NanoSim, FineSim, or HSPICE.\n       For the  analyze_subcircuit command, you must specify \u2022 The clock mesh net you want to simulate by using the  -net option.\n Alternatively, you can specify the sinks of the mesh net by using the  -to option.\n If multiple clocks reach the net or the sinks you specify, use the  -clock option to distinguish the clock you want to analyze.\n \u2022 A name by using the  -name option.\n This name is used to construct the circuit elements.\n It is also used in the name of the output files and the directory where the output is stored.\n Optionally you can specify an annotated transition on the clock port or the start point of your clock mesh.\n If you do so, the clock must be specified as propagated by using the set_propagated_clock command.\n When you run the  analyze_subcircuit command, the tool performs the following steps: 1.\n Performs RC extraction and generates parasitic files.\n You can run extraction as a standalone step by using the  -extraction option.\n 2.\n Generates SPICE files for simulating the clock mesh, using the parasitic files from the previous step as input.\n You can generate the SPICE files as a standalone step by using the -create_spice_deck option.\n When you do so, you can use parasitic files generated by a different extraction tool.\n If these parasitic files have a different naming convention, you can specify the appropriate file suffix by using the  -spef_input_file_suffix and -rc_include_file_suffix options.\n 3.\n Runs SPICE simulation, using the SPICE files generated in the previous step as input.\n By default, the tool uses the NanoSim simulator.\n You can use the FineSim or HSPICE simulators by using the  finesim or  hspice setting with the  -simulator option.\n You must specify the location of the circuit-level and transistor-level models by using the  -driver_subckt_files and  -spice_header_files options.\n You customize these settings by specifying different files for the maximum and minimum conditions within each scenario by using the  -configuration option.\n You can run simulation as a standalone step by using the  -run_simulation option.\n 4.\n Generates timing annotation files containing  set_disable_timing, set_annotated_delay, and  set_annotated_transition commands, using the simulation results as input.\n       For clock mesh nets, which have multiple drivers, the  set_disable_timing command is used to disable all except one of the drivers, which is called the anchor driver.\n The annotated net delay arcs are defined from the anchor driver.\n You can generate the timing annotation files as a standalone step by using the -write_annotation option.\n 5.\n Applies the annotation files generated in the previous step.\n You can apply the annotation files as a standalone step by using the -apply_annotation option.\n If you want to run some of the steps of the mesh analysis flow, such as extraction or SPICE simulation, using other tools, you can do so and run the rest of the steps of the flow using the standalone options of the  analyze_subcircuit command, following the same sequence.\n The following example analyzes the clock mesh net named clk_mesh using the HSPICE simulator.\n It customizes the simulation by using different files for the minimum and maximum conditions of each scenario.\n fc_shell>\u00a0 analyze_subcircuit -net clk_mesh \\ -driver_subckt_files max_spice_model \\ -spice_header_files header_file \\ -configuration { \\ {-scenario_name scenario1 \\ -max_driver_subckt_files max_file1 \\ -max_spice_header_files header_max1 \\ -min_driver_subckt_files min_file1 \\ -min_spice_header_files header_min1} \\ {-scenario_name scenario2 \\ -max_driver_subckt_files max_file2 \\ -max_spice_header_files header_max2 \\ -min_driver_subckt_files min_file2 \\ -min_spice_header_files header_min2}} -simulator hspice \\ -name clk_mesh_analysis"}
{"header": "How do I Specifying Tap Assignment Options and Settings", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform this task, you must 1.\n Specify the required settings by using the set_regular_multisource_clock_tree_options command as follows: \u25e6 The clock name by using the  -clock option \u25e6 The topology for the global clock tree by using the  -topology\u00a0htree_only option       \u25e6 The number of rows and columns of tap cells to insert by using the  -tap_boxes option \u25e6 A list of library cells to use as tap drivers by using the  -tap_lib_cells option The library cells you specify must be enabled for clock tree synthesis by using the set_lib_cell_purpose\u00a0-include\u00a0cts command.\n \u25e6 A list of library cells to use for synthesizing the global clock tree (H-tree) by using the  -htree_lib_cells option The library cells you specify must be enabled for clock tree synthesis by using the set_lib_cell_purpose\u00a0-include\u00a0cts command.\n By default, the tool uses \u25e6 The net connected to the clock root to insert the tap drivers and build the clock structure You can specify a different net of the clock network by using the  -net option.\n \u25e6 The locations of the sinks to determine the boundary within which to insert the tap cells You can control this boundary by using the  -tap_boundary option.\n You can also specify keepout areas within which tap cells should not be inserted by using the -keepouts option.\n \u25e6 The layers and routing rules specified by the clock tree synthesis settings to route the H-tree You can specify the layers and routing rules for the H-tree by using the -htree_layers and  -htree_routing_rule options.\n You can report the options you specified by using the report_regular_multisource_clock_tree_options command, and remove them by using the  remove_regular_multisource_clock_tree_options command.\n 2.\n (Optional) Enable flexible H-tree synthesis by setting the cts.multisource.flexible_htree_synthesis application option to  true.\n When you enable this feature, the tool identifies the best count, configuration, and placement of tap drivers for minimum clock tree insertion delay.\n To specify that the tool derives a symmetric configuration of tap drivers, set the cts.multisource.tap_selection application option to  symmetric.\n The default is  user, and by default the tool uses the configuration specified by the  -tap_boxes option of the  set_regular_multisource_clock_tree_options command for the tap drivers.\n       3.\n Insert the tap drivers and build the H-tree by using the synthesize_regular_multisource_clock_trees command, which consists of the following two stages: \u25e6 tap_synthesis, during which the tool inserts the tap drivers \u25e6 htree_synthesis, during which the tool builds the H-tree that drives the tap drivers By default, the tool performs both stages.\n You can perform only one of these stages by using the  -to or  -from option.\n The following example script inserts tap drivers in four columns and two rows and builds the H-tree: ##\u00a0Include\u00a0only\u00a0tap\u00a0driver\u00a0and\u00a0H-tree\u00a0library\u00a0cell\u00a0for\u00a0CTS set\u00a0cts_references\u00a0[get_lib_cells\u00a0-filter\u00a0valid_purposes=~*cts*] set_lib_cell_purpose\u00a0-exclude\u00a0cts\u00a0[get_lib_cells\u00a0$cts_references] set_lib_cell_purpose\u00a0-include\u00a0cts\u00a0{\u00a0LIB1/BUF1\u00a0LIB1/BUF2}  ##\u00a0Set\u00a0up\u00a0and\u00a0insert\u00a0tap\u00a0drivers\u00a0and\u00a0build\u00a0H-tree set_regular_multisource_clock_tree_options\u00a0\\ -clock\u00a0clk\u00a0-topology\u00a0htree_only\u00a0-tap_boxes\u00a0{4\u00a02}\u00a0\\ -tap_lib_cells\u00a0[get_lib_cells\u00a0*/CKBUF*]\u00a0\\ -htree_lib_cells\u00a0[get_lib_cells\u00a0*/CKINV*]\u00a0\\ -htree_layers\u00a0\"m9\u00a0m10\"\u00a0-htree_routing_rule\u00a0\"htree_ndr\" synthesize_regular_multisource_clock_trees  ##\u00a0Reapply\u00a0CTS\u00a0library\u00a0cell\u00a0list\u00a0as\u00a0required\u00a0for\u00a0the\u00a0subsequent\u00a0steps set_lib_cell_purpose\u00a0-include\u00a0cts\u00a0[get_lib_cells\u00a0$cts_references]"}
{"header": "How do I Building the Local Clock Subtree Structures", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you can perform automated tap assignment by using the synthesize_multisource_clock_taps command, you must perform the following steps: 1.\n Remove  dont_touch,  size_only,  fixed, and  locked attributes setting on the clock cells that are not required.\n These settings prevent the tool from merging or splitting clock cells during tap assignment, if necessary.\n 2.\n Specify settings for automated tap assignment by using the set_multisource_clock_tap_options command.\n You must specify \u25e6 The clock for tap assignment by using the  -clock option.\n All the sinks reachable from the given clock are considered for redistribution.\n \u25e6 The tap drivers among which the sinks are redistributed by using the -driver_objects option.\n       \u25e6 The number of taps that the sinks are redistributed among by using the  -num_taps option.\n Currently, the number of taps specified with this option must be equal to the number of drivers specified with the  -driver_objects option.\n To prevent the tool from merging specific clock tree cells, specify the instance names using the  -dont_merge_cells option.\n To report the settings you specify for automated tap assignment, use the  report_multisource_clock_tap_options command.\n To remove the settings you specify for automated tap assignment, use the remove_multisource_clock_tap_options command.\n 3.\n (Optional) Create multisource sink groups for tap assignment by using the create_multisource_clock_sink_group command.\n Skew groups defined for the clock can be distributed among different taps.\n To retain the objects of a skew group under the same tap, create a corresponding multisource sink group.\n Use the following commands to remove, report, or manipulate multisource sink groups: \u25e6 remove_multisource_clock_sink_groups \u25e6 report_multisource_clock_sink_groups \u25e6 get_multisource_clock_sink_groups \u25e6 add_to_multisource_clock_sink_group \u25e6 remove_from_multisource_clock_sink_group 4.\n (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during tap assignment by using the following application options: \u25e6 cts.multisource.subtree_merge_cell_name_prefix \u25e6 cts.multisource.subtree_merge_cell_name_suffix \u25e6 cts.multisource.subtree_split_cell_name_prefix \u25e6 cts.multisource.subtree_split_cell_name_suffix \u25e6 cts.multisource.subtree_split_net_name_prefix \u25e6 cts.multisource.subtree_split_net_name_suffix"}
{"header": "How do I Analyzing the Clock Tree Results", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In a structural multisource clock tree, the local subtrees are directly driven by the clock mesh.\n You can synthesize these local subtrees by using the synthesize_multisource_clock_subtrees command.\n Before you synthesize the local subtrees, you must 1.\n Build the global clock distribution structure.\n 2.\n Model the clock mesh net with a realistic annotated delay and transition values using the  set_annotated_delay and  set_annotated_transition commands.\n 3.\n Remove  dont_touch,  size_only,  fixed, and  locked attributes setting on the clock cells that are not required.\n These settings prevent the synthesize_multisource_clock_subtrees command from merging or splitting clock cells, if necessary.\n 4.\n Specify settings for local subtree synthesis by using the set_multisource_clock_subtree_options command.\n You must specify \u25e6 The clock for synthesizing the subtrees by using the  -clock option.\n \u25e6 The drivers of the subtrees to be synthesized by using the  -driver_objects option.\n The clock specified with the  -clock option should pass through each drivers specified with the  -driver_objects option.\n Optionally you can \u25e6 Prevent the tool from merging specific clock tree cells by using the -dont_merge_cells option.\n \u25e6 Balance the levels of the local subtree by using the  -balance_levels\u00a0true option and specify a target number of levels, which applies to all sinks of the local subtree, by using the  -target_level option.\n Optionally, you can apply a different target number of levels to specific sink pins and clock balance points by using the set_multisource_clock_subtree_constraints command with the  -pins and -target_level options.\n \u25e6 Specify a maximum total wire delay from any subtree driver to any of its sinks by using the  -max_total_wire_delay option and the corner it applies to by using the -corner option.\n       \u25e6 Enable the reordering of clock-gating cells by using the  -enable_icg_reordering true option.\n When you enable this feature, the tool swaps the position of a clock-gating cell with the buffer that is driving the clock-gating cell.\n Then, the buffer is gated by the clock- gating cell, thereby reducing the dynamic power consumption.\n To perform reordering, you must \u25aa Enable scenarios used for structural multisource clock tree synthesis for dynamic power optimization \u25aa Annotate switching activity for the enable pins of the clock-gating cells You can prevent specific clock-gating cells from being reordered by using the set_multisource_clock_subtree_constraints command with the  -cells and -ignore_for_icg_reordering options.\n To report the settings you specified, use the report_multisource_clock_subtree_options command.\n To remove the settings you specified, use the  remove_multisource_clock_subtree_options command.\n 5.\n (Optional) Enable multicorner optimization by setting the cts.multisource.enable_multi_corner_support application option to  true.\n The default is  false.\n By default, the tool uses the worst corner associated with the mode in which the subtree options are defined.\n When you enable this feature, the tool considers all corners associated with the mode in which the subtree options are defined.\n 6.\n (Optional) Ignore the maximum capacitance, maximum fanout, or both constraints of the clock drivers by using the  cts.multisource.ignore_drc_on_subtree_driver application option.\n When you synthesize multisource clock subtrees, by default, the tool considers the maximum transition, capacitance, and fanout constraints of the clock drivers you specify.\n However, the clock drivers typically have relaxed or no maximum capacitance or maximum fanout constraint, which can affect the multisource clock tree QoR.\n The following example ignores both the maximum capacitance and maximum fanout constraints of the clock drivers: fc_shell>\u00a0 set_app_options \\ -name cts.multisource.ignore_drc_on_subtree_driver \\ -value \"max_fanout max_capacitance\" 7.\n (Optional) Enable fishbone routing for the subtree clock nets by using the cts.multisource.subtree_routing_mode application option.\n       fc_shell>\u00a0 set_app_options \\ -name cts.multisource.subtree_routing_mode -value fishbone 8.\n (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during local subtree synthesis by using the following application options: \u25e6 cts.multisource.subtree_merge_cell_name_prefix \u25e6 cts.multisource.subtree_merge_cell_name_suffix \u25e6 cts.multisource.subtree_split_cell_name_prefix \u25e6 cts.multisource.subtree_split_cell_name_suffix \u25e6 cts.multisource.subtree_split_net_name_prefix \u25e6 cts.multisource.subtree_split_net_name_suffix When you run the  synthesize_multisource_clock_subtrees command the tool performs the following steps: 1.\n Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks.\n 2.\n Optimizes the subtree by splitting, sizing, and relocating the clock cells, and snaps the first level of clock cells to the clock straps.\n 3.\n Routes the clock nets.\n By default, it global routes the nets.\n However, if you enable fishbone routing by using the  cts.multisource.subtree_routing_mode application option, the tool creates a mix of detail routed fishbone trunks and fingers, and global comb routes to connect the net loads to the fishbone fingers, as shown in  Figure\u00a097.\n You can control the fishbone routing by using the following application options: \u25e6 cts.routing.fishbone_max_tie_distance \u25e6 cts.routing.fishbone_max_sub_tie_distance \u25e6 cts.routing.fishbone_bias_threshold \u25e6 cts.routing.fishbone_bias_window \u25e6 cts.routing.fishbone_horizontal_bias_spacing \u25e6 cts.routing.fishbone_vertical_bias_spacing 4.\n Refines the clock trees by sizing and relocating cells based on the routing.\n       Figure 97 Detail Fishbone Routes and Global Comb Routes Global comb route Fishbone trunk Fishbone finger You can run specific steps of the  synthesize_multisource_clock_subtrees command by using the  -from and  -to options and specifying  merge,  optimize,  route_clock, or refine.\n Structural subtrees that you build by using the synthesize_multisource_clock_subtrees command are not changed or removed when you subsequently run any clock tree synthesis command."}
{"header": "How do I Generating Clock Tree QoR Reports", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After synthesizing the clock trees, analyze the results to verify that they meet your requirements.\n Typically the analysis process consists of the following tasks: \u2022 Analyzing the clock tree QoR (as described in  Generating Clock Tree QoR Reports ) \u2022 Analyzing the clock tree timing (as described in  Analyzing Clock Timing ) \u2022 Verifying the placement of the clock instances, using the GUI (as described in Analyzing Clock Trees in the GUI )"}
{"header": "How do I Reporting Clock Tree Power", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To generate clock tree QoR reports, use the  report_clock_qor command.\n The  report_clock_qor command can generate the following types of reports: \u2022 Summary By default, this command reports a summary of the clock tree QoR, which includes the latency, skew, DRC violations, area, and buffer count.\n \u2022 Latency       To report the longest and shortest path for each clock, use the  -type\u00a0latency option.\n \u2022 DRC violators To report the maximum transition and capacitance constraint violators, use the  -type drc_violators option.\n \u2022 Robustness To report the robustness of each sink, use the  -type\u00a0robustness option.\n The robustness of a sink is the ratio between its latency for the corner for which the report is being generated and its latency for the corner specified by the  -robustness_corner option.\n The mode use for both latency values is the mode for which the report is being generated.\n When you use the -type\u00a0robustness option, you must specify a corresponding robustness corner by using the  -robustness_corner option.\n \u2022 Clock-balance groups QoR To report a clock QoR summary for each clock-balance group, use the  -type balance_groups option.\n It also reports the clock latency offset values specified with the  -offset_latencies option of the  create_clock_balance_group command and the actual latency offset values.\n \u2022 Local skew To report the QoR summary and the worst local skew for each clock or skew group, use the  -type\u00a0local_skew option.\n It also reports the five largest and five smallest local skew values and the corresponding endpoints.\n \u2022 Clock tree power To report a summary of the leakage, internal, sink, net switching, dynamic, and total power per clock per scenario, use the  -type\u00a0power option.\n If the power.clock_network_include_clock_sink_pin_power application option is set to off, the sink power is not reported.\n When you use the  -type option, you can generate the output as a comma separated values (CSV) file by using the  -csv option and specifying the output file name using the -output option.\n The  report_clock_qor command can also generate the following types of histograms: \u2022 Latency histogram To report the latency of each sink in a histogram format, use the  -histogram_type latency option.\n \u2022 Transition histogram       To report the transition time of each sink in a histogram format, use the -histogram_type\u00a0transition option.\n \u2022 Capacitance histogram To report the capacitance of each sink in a histogram format, use the -histogram_type\u00a0capacitance option.\n \u2022 Local skew histogram To report the local skew in a histogram, use the  -histogram_type\u00a0local_skew option.\n \u2022 Robustness histogram To report the robustness of each sink, with respect to a robustness corner specified by using the  -robustness_corner option, in a histogram format, use the -histogram_type\u00a0robustness option.\n \u2022 Wire delay fraction histogram To report the ratio between the wire delay and the total delay for each logic stage of the clock tree in a histogram format, use the  -histogram_type\u00a0wire_delay_fraction option.\n By default, the tool generates a report for all clock trees in all active modes and corners in all active scenarios.\n You can limit the report to specific \u2022 Portions of a clock network by using the  -from,  -to, and - through options \u2022 Clock trees by using the  -clock option \u2022 Skew groups by using the  -skew_group option \u2022 Modes by using the  -mode option \u2022 Corners by using the  -corner option \u2022 Scenarios by using the  -scenario option If you use the  -scenario option, you cannot use the  -mode and  -corner options."}
{"header": "How do I Creating Collections of Clock Network Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the power of a clock tree, use the  report_clock_power command.\n By default, it reports the power for all clock trees in all modes and corners of all active scenarios.\n To report the power \u2022 Only for specific clocks, use the  -clocks option \u2022 Only for specific modes, use the  -modes option \u2022 Only for specific corners, use the  -corners option \u2022 Only for specific scenarios, use the  -scenario option \u2022 On a per-segment or per-subtree basis, use the  -type\u00a0per_segment or  -type per_subtree option \u25e6 A segment is the clock buffer tree from one integrated-clock-gating (ICG) cell to the next ICG cells or sinks in its fanout For example, in the following figure, the buffer tree from the output of the ICG1 cell to the inputs of the ICG2, ICG3, and ff2 cells is considered a segment.\n \u25e6 A subtree is a clock tree from an ICG cell all the way to the sinks in its fanout.\n For example, in the following figure, the clock tree from the output of the ICG1 cell to the inputs of the ff1, ff2, and ff3 cells is considered a subtree.\n Figure 98 Segments and Subtrees of a Clock Tree"}
{"header": "How do I Analyzing Clock Timing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create a collection of the pins on a clock network by using the get_clock_tree_pins command.\n By default, this command returns all the pins on all the clock networks of all scenarios.\n You can limit the selection by using one of the following methods \u2022 Limit it to specific clock by using the  -clocks option.\n \u2022 Limit it to specific scenario, scenarios of modes, or scenarios of corners by using the -scenarios,  -modes, or  -corners option.\n You can further limit the selection by \u2022 Considering only the clock paths that go from, through, and to specific pins by using the  -from,  -through, and  -to options.\n \u2022 Filtering the pins based on their attributes by using the  -filter option.\n For more information about all the available options and all the supported pin attributes, see the man page for the  get_clock_tree_pins command.\n The following example creates a collection named clk1_icg_pins, which consists of the pins of integrated-clock-gating cells that are on the clock network of the clock named clk1: fc_shell>\u00a0 set clk1_icg_pin \\ [get_clock_tree_pins -filter is_on_ICG -clocks clk1]"}
{"header": "How do I Analyzing Clock Trees in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The timing characteristics of the clock network are important in any high-performance design.\n To obtain detailed information about the clock networks in the current block, use the report_clock_timing comandcomandsreport_clock_timing report_clock_timing command.\n You must use the  -type option to specify the type of report to generate.\n The report_clock_timing command can generate the following types of reports: \u2022 Single-clock local skew To generate a single-clock local skew report, use the  -type\u00a0skew option.\n \u2022 Interclock skew To generate an interclock skew report, use the  -type\u00a0interclock_skew option.\n \u2022 Latency To generate a latency report, use the  -type\u00a0latency option.\n       \u2022 Transition To generate a transition time report, use the  -type\u00a0transition option."}
{"header": "How do I 6", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "The Fusion Compiler GUI provides the Clock Tree Visual Mode to help you visualize and analyze the clock trees in your design.\n In this mode, you can overlay the clock tree information to the layout view, or view the clock tree structure in the schematic view.\n For more information about analyzing clock tree information in the GUI, see the  Using Map and Visual Modes topic in the  Fusion Compiler Graphical User Interface User Guide."}
{"header": "How do I Introduction to Zroute", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "This topic describes the routing capabilities of Zroute, which is the router for the Fusion Compiler tool.\n Zroute is architected for multicore hardware and efficiently handles advanced design rules for 45 nm and below technologies and design-for-manufacturing (DFM) tasks.\n It also describes the postroute optimization features supported by the Fusion Compiler tool.\n To learn about routing and postroute optimization, see the following topics: \u2022 Introduction to Zroute \u2022 Basic Zroute Flow \u2022 Prerequisites for Routing \u2022 Defining Vias \u2022 Inserting Via Ladders \u2022 Checking Routability \u2022 Routing Constraints \u2022 Routing Application Options \u2022 Routing Clock Nets \u2022 Routing Critical Nets \u2022 Routing Secondary Power and Ground Pins \u2022 Routing Signal Nets \u2022 Shielding Nets \u2022 Performing Postroute Optimization \u2022 Analyzing and Fixing Signal Electromigration Violations \u2022 Performing ECO Routing \u2022 Routing Nets in the GUI \u2022 Cleaning Up Routed Nets       \u2022 Analyzing the Routing Results \u2022 Saving Route Information \u2022 Deriving Mask Colors \u2022 Inserting and Removing Cut Metal Shapes"}
{"header": "How do I Basic Zroute Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute has five routing engines: global routing, track assignment, detail routing, ECO routing, and routing verification.\n You can invoke global routing, track assignment, and detail routing by using task-specific commands or by using an automatic routing command.\n You invoke ECO routing and route verification by using task-specific commands.\n Zroute includes the following main features: \u2022 Multithreading on multicore hardware for all routing steps, including global routing, track assignment, and detail routing \u2022 A realistic connectivity model where Zroute recognizes electrical connectivity if the rectangles touch; it does not require the center lines of wires to connect \u2022 A dynamic maze grid that permits Zroute to go off-grid to connect pins, while retaining the speed advantages of gridded routers \u2022 A polygon manager, which allows Zroute to recognize polygons and to understand that design rule checks (DRCs) are aimed at polygons \u2022 Concurrent optimization of design rules, antenna rules, wire optimization, and via optimization during detail routing \u2022 Concurrent redundant via insertion during detail routing \u2022 Support for soft rules built into global routing, track assignment, and detail routing \u2022 Timing- and crosstalk-driven global routing, track assignment, detail routing, and ECO routing \u2022 Intelligent design rule handling, including merging of redundant design rule violations and intelligent convergence \u2022 Net group routing with layer constraints and nondefault routing rules \u2022 Clock routing \u2022 Route verification       \u2022 Optimization for DFM and design-for-yield (DFY) using a soft rule approach \u2022 Support for advanced design rules, such as multiple patterning"}
{"header": "How do I Prerequisites for Routing", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Figure\u00a099 shows the basic Zroute flow, which includes clock routing, signal routing, DFM optimizations, and route verification.\n Figure 99 Basic Zroute Flow"}
{"header": "How do I Defining Vias", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you can run Zroute, you must ensure that the block and physical library meet the following requirements: \u2022 Library requirements Zroute gets all of the design rule information from the technology file; therefore, you must ensure that all design rules are defined in the technology file before you start routing.\n For more information about the technology file and defining routing design rules, see the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 Block requirements Before you perform routing, your block must meet the following conditions: \u25e6 Power and ground nets have been routed after design planning and before placement.\n For more information, see the  Fusion Compiler Design Planning User Guide.\n \u25e6 Clock tree synthesis and optimization have been performed.\n For more information, see  Clock Tree Synthesis.\n \u25e6 Estimated congestion is acceptable.\n \u25e6 Estimated timing is acceptable (about 0 ns of slack).\n \u25e6 Estimated maximum capacitance and transition have no violations.\n To verify that your block meets the last three prerequisites, you can check the routability of its placement as explained in  Checking Routability."}
{"header": "How do I Reading Via Definitions from a LEF File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The router supports the following types of via definitions: \u2022 Simple vias and simple via arrays A simple via is a single-cut via.\n It is specified by a cut layer and the height and width of the rectangular shapes on its cut and metal layers.\n A simple via array is a multiple-cut simple via.\n Simple vias and simple via arrays can be used for the following purposes: \u25e6 Clock or signal routing using nondefault routing rules \u25e6 Redundant via insertion \u25e6 Power and ground routing with advanced via rules \u2022 Custom vias A custom via is a multiple-cut, odd-shaped via that is created from an arbitrary collection of Manhattan polygons.\n Custom vias can be used only for redundant via insertion.\n Via definitions can come from the following sources: \u2022 The  ContactCode sections of the technology file associated with the design library The technology file can contain definitions for simple vias, simple via arrays, and custom vias.\n For information about defining vias in the technology file, see the Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 Via rule  GENERATE statements in a LEF file The via rule GENERATE statements define simple via arrays.\n For information about defining vias in a LEF file, see  Reading Via Definitions from a LEF File.\n \u2022 User-defined via definitions You can define simple vias, simple via arrays, and custom vias.\n For information about creating user-defined via definitions, see  Creating a Via Definition.\n If you want Zroute to use a via definition for signal routing, ensure that is has the following attribute settings: \u2022 is_default attribute is  true \u2022 is_excluded_for_signal_routing attribute is  false In addition, Zroute uses nondefault vias that are explicitly specified in a fat via table in the technology file or in a nondefault routing rule defined by the  create_routing_rule command."}
{"header": "How do I Creating a Via Definition", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To read via definitions specified by via rule  GENERATE statements in a LEF file, use the read_tech_lef command.\n This command supports the following LEF syntax: via_rule_name GENERATE\u00a0[DEFAULT] LAYER\u00a0 lower_layer_name ENCLOSURE\u00a0 lower_overhang1 lower_overhang2 LAYER\u00a0 upper_layer_name ENCLOSURE\u00a0 upper_overhang1 upper_overhang2 LAYER\u00a0 cut_layer_name RECT\u00a0 llx lly urx ury SPACING\u00a0 x_spacing BY\u00a0 y_spacing The WIDTH and RESISTANCE statements are not supported."}
{"header": "How do I Defining Simple Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create a via definition, use the  create_via_def command.\n After it is created, the via definition can be used anywhere in the design, similar to a  ContactCode definition in the technology file.\n The user-specified via definition is stored in the design library, so it can be used only in that design.\n The  create_via_def command can define simple vias, simple via arrays, and custom vias.\n The following topics describe how to define these types of vias.\n \u2022 Defining Simple Vias \u2022 Defining Custom Vias"}
{"header": "How do I Defining Custom Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a simple via or via array, use the following  create_via_def syntax: create_via_def -cut_layer\u00a0 layer -cut_size\u00a0{ width height } -upper_enclosure\u00a0{ width height } -lower_enclosure\u00a0{ width height } [-min_rows\u00a0 number_of_rows ] [-min_columns\u00a0 number_of_columns ] [-min_cut_spacing\u00a0 distance ] [-cut_pattern\u00a0 cut_pattern ] [-is_default] [-force] via_def_name You do not need to specify the enclosure layers; the tool determines them from the technology file by getting the metal layers adjacent to the specified via layer.\n       By default, when you define a simple via, it is a single-cut via.\n To define a via array, specify the minimum number of rows and columns for the array ( -min_rows and  -min_columns options), as well as the minimum cut spacing ( -min_cut_spacing option).\n By default, the cut pattern is a full array of cuts.\n To modify the cut pattern, use the  -cut_pattern option.\n To overwrite an existing via definition, use the  -force option; otherwise, the command fails if the specified via definition already exists.\n For example, to create a single-cut via definition named design_via1_HV for the VIA12 via layer, use the following command: fc_shell>\u00a0 create_via_def design_via1_HV \\ -cut_layer VIA12 -cut_size {0.05 0.05} \\ -lower_enclosure {0.02 0.0} -upper_enclosure {0.0 0.2} \\ To create a via definition with an alternating 2x2 cut pattern in which the lower-left cut is omitted, use the following command: fc_shell>\u00a0 create_via_def design_via12 -cut_pattern \"01 10\" To report information about the user-defined via definitions, use the  report_via_defs command."}
{"header": "How do I Inserting Via Ladders", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a custom via, use the following  create_via_def syntax: create_via_def -shapes\u00a0{\u00a0{ layer { coordinates }\u00a0[ mask_constraint ]}\u00a0...\n } [-lower_mask_pattern\u00a0alternating\u00a0|\u00a0uniform] [-upper_mask_pattern\u00a0alternating\u00a0|\u00a0uniform] [-force] via_def_name In the  -shapes option, you must specify shapes for one via layer and two metal layers, which are the enclosure layers for the via.\n You can specify multiple shapes per layer.\n For example, to create a custom via definition, use a command similar to the following: fc_shell>\u00a0 create_via_def design_H_shape_via \\ -shapes { {VIA12 {0.035 -0.035} {0.100 0.035}} {VIA12 {-0.100 -0.035} {-0.035 0.035}} {METAL1 {-0.130 -0.035} {0.130 0.035}} {METAL2 {-0.100 -0.065} {-0.035 0.065}} {METAL2 {0.035 -0.065} {0.100 0.065}} {METAL2 {-0.100 -0.035} {0.100 0.035}} } To overwrite an existing via definition, use the  -force option; otherwise, the command fails if the specified via definition already exists.\n       If you are using double-patterning technology, you can assign mask constraints to the shapes or the enclosure layers, but not both.\n \u2022 To assign mask constraints to the shapes, use the  mask_one,  mask_two, or mask_three keywords for the  mask_constraint arguments when specifying the -shapes option.\n You would use this method if the mask constraints follow an arbitrary pattern.\n When you create a via with the  create_via command, the via shapes inherit the mask constraints specified in the via definition.\n If the mask constraint you specify for an enclosure layer when you create a via differs from the mask constraint specified for the first shape in the via definition, the specified mask constraint determines the mask-shift used for all shapes on that layer.\n For example, fc_shell>\u00a0 create_via_def VIA12 \\ -shapes { {M1 {-0.037 -0.010} {-0.017 0.01} mask_two} {M1 {0.017 -0.010} {0.037 0.01} mask_one} {VIA1 {-0.037 -0.01} {0.037 0.01} mask_two} {M2 {-0.044 -0.010} {0.044 0.010} mask_one} } fc_shell>\u00a0 create_via -net n1 -via_def VIA12 \\ -origin {100.100 200.320} \u2022 To assign mask constraints to the enclosure layers, use the  -lower_mask_pattern and  -upper_mask_pattern options.\n You can specify either  uniform or  alternating as the mask pattern.\n In either case, you specify the mask constraint for the first shape when you create a via with the  create_via command.\n If you specify  uniform, all shapes on the layer use the specified mask constraint.\n If you specify  alternating, the colors alternate from shape to shape after the first shape.\n For example, fc_shell>\u00a0 create_via_def VIA12 \\ -shapes { {M1 {-0.010 -0.030} {0.027 0.050}} {M1 {0.047 -0.030} {0.084 0.050}} {VIA1 {0.000 0.000} {0.074 0.020}} {M2 {-0.030 0.000} {0.104 0.020}} } \\ -lower_mask_pattern uniform fc_shell>\u00a0 create_via -via_def VIA12 -origin {000.100 200.320} -lower_mask_constraint mask_two To report information about the via definitions, use the  report_via_defs command.\n This command reports the shapes that comprise the via definition but does not report the upper and lower mask patterns."}
{"header": "How do I Defining Via Ladder Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A  via ladder, which is also referred to as a  via pillar, is a stacked via that starts from the pin layer and extends into an upper layer where the router connects to it.\n Via       ladders reduce the via resistance, which can improve performance and electromigration robustness.\n To use via ladders, \u2022 Via ladder rules must be defined in the technology data for the design For information about defining via ladder rules, see  Defining Via Ladder Rules.\n \u2022 You must insert the via ladders before you perform global routing The Fusion Compiler tool provides the following methods for inserting via ladders: \u25e6 Automatic insertion during preroute optimization, as described in  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization \u25e6 Constraint-based insertion by using the  insert_via_ladders command, as described in  Constraint-Based Via Ladder Insertion \u25e6 Manual insertion by using the  create_via_ladder command, as described in Manual Via Ladder Insertion See Also \u2022 Querying Via Ladders \u2022 Removing Via Ladders \u2022 Controlling Via Ladder Connections"}
{"header": "How do I Generating Via Ladder Rules for Electromigration Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A via ladder rule defines the number of rows and the number of cuts in each row for each layer in a via ladder.\n Via ladder rules can be defined in the technology file or by using the create_via_rule command.\n For example, each of the following methods creates an identical via ladder rule: \u2022 Define the rule in the technology file.\n ViaRule\u00a0\"VL1\"\u00a0{ cutLayerNameTblSize\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a02 cutLayerNameTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(VIA1,\u00a0VIA2)\u00a0\u00a0\u00a0#\u00a0via\u00a0layer\u00a0names cutNameTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(CUT1A,\u00a0CUT2A)\u00a0#\u00a0cut\u00a0names numCutRowsTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(2,\u00a02)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0rows\u00a0in\u00a0ladder numCutsPerRowTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(2,\u00a02)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0columns\u00a0in\u00a0ladder upperMetalMinLengthTbl\u00a0\u00a0=\u00a0(L1,\u00a0L2)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0minimum\u00a0length\u00a0rule cutXMinSpacingTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(X1,\u00a0X2)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0X-direction\u00a0spacing cutYMinSpacingTbl\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(Y1,\u00a0Y2)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0Y-direction\u00a0spacing maxNumStaggerTracksTbl\u00a0\u00a0=\u00a0(S1,\u00a0S2)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0maximum\u00a0staggering forHighPerformance\u00a0\u00a0=\u00a00       forElectromigration\u00a0=\u00a01 } For details about defining via ladder rules in the technology file, see the \"Via Ladder Rule\" topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 Define the rule on the command line by using the  create_via_rule command with a detailed specification and then specifying additional details by setting its attributes.\n fc_shell>\u00a0 create_via_rule -name VL1 -cut_layer_names {VIA1 VIA2} \\ -cut_names {CUT1A CUT2A} -cut_rows {2 2} -cuts_per_row {2 2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ upper_metal_min_length_table {L1 L2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_x_min_spacing_table {X1 X2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_y_min_spacing_table {Y1 Y2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ max_num_stagger_tracks_table {S1 S2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ for_high_performance false fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ for_electro_migration true \u2022 Define the rule on the command line by creating an empty via rule with the create_via_rule command and then specifying the details by setting its attributes.\n fc_shell>\u00a0 create_via_rule -name VL1 fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_layer_name_table_size 2 fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_layer_name_table {via1 via2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_name_table {CUT1A CUT2A} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ num_cuts_per_row_table {2 2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] num_cut_rows_table {2 2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ upper_metal_min_length_table {L1 L2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_x_min_spacing_table {X1 X2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ cut_y_min_spacing_table {Y1 Y2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ max_num_stagger_tracks_table {S1 S2} fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ for_high_performance false fc_shell>\u00a0 set_attribute [get_via_rules VL1] \\ for_electro_migration true       The tool treats the via rules the same, regardless of the method used to create them.\n You can perform the following tasks for via rules: \u2022 Create a collection of via rules by using the  get_via_rules command \u2022 Remove via rules by using the  remove_via_rules command \u2022 Display detailed information about the via rules by using the  report_via_rules command \u2022 Set or query via rule attributes To see the attributes supported on via rule objects, use the  list_attributes -application\u00a0-class\u00a0via_rule command.\n \u2022 Save the via rules in a technology file by using the  write_tech_file command See Also \u2022 Generating Via Ladder Rules for Electromigration Via Ladders"}
{"header": "How do I Generating Via Ladder Rules for Performance Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Instead of explicitly defining via ladder rules for electromigration via ladders, you can use the  generate_via_ladder_template command to generate via ladder rules and constraints based on a configuration file.\n The configuration file is an XML file that provides information about the via ladder rules, as well as the association between the via ladder rules and specific pins.\n You must specify the name of the configuration file by using the -config_file option.\n The command generates two script files: \u2022 A script file that defines the via ladder rules, which is called the template script file This script file contains a  create_via_rule command for each template defined in the configuration file, as well as  set_attribute commands to set the appropriate via rule attributes.\n By default, the file is named auto_gen_via_ladder_template.tcl.\n To specify a different file name, use the  -template_file option.\n \u2022 A script file that defines the via ladder constraints, which is called the association script file This script file contains  set_via_ladder_candidate commands for the pins specified in the configuration file, as well as  set_attribute commands to set the is_em_via_ladder_required attribute for the pins to  true.\n By default, the file is named auto_gen_via_ladder_association.tcl.\n To specify a different file name, use the  -association_file option.\n       The configuration file has the following syntax: <EmRule> <!--\u00a0template\u00a0definition\u00a0--> <Template\u00a0name=\" rule_name \"> <Layer\u00a0name=\" layer_name \"\u00a0row_number=\" cuts_per_row \" [max_stagger_tracks=\" count \"] [upper_cut_x_min_spacing=\" x_spacing \"] [upper_cut_y_min_spacing=\" y_spacing \"]\u00a0/>...\n more\u00a0layers </Template> \u2026\u00a0more\u00a0templates  <!--\u00a0Pin\u00a0to\u00a0template\u00a0association\u00a0--> <Pin\u00a0name=\" pin_name \"> <Template\u00a0name=\" rule_name \"/> </Pin>...\n more\u00a0associations </EmRule> Each  Template section specifies the template for a via ladder rule.\n You can specify one or more  Template sections.\n Within a template section, you specify the via ladder structure by specifying the number of cuts per row for each metal layer involved in the via ladder.\n The command uses the information in the configuration file and associated information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file \u2022 The cut layers that connect the specified metal layers \u2022 The cut names \u2022 The minimum required length for each metal layer Note: You must open the block before running the  generate_via_ladder_template command to ensure that the command has access to the technology data for the block.\n Each  Pin section specifies the template associated with a pin, where the pin name can include the asterisk wildcard character (*).\n You can specify one or more  Pin sections.\n The template specified in the  Pin section\u2019s  Template attribute must be one of the templates specified in the  Template sections.\n For example, assume you have a configuration file named vl_config that has the following contents: <EmRule> <Template\u00a0name=\"template_1_3231\"> <Layer\u00a0name=\"M1\"\u00a0row_number=\"3\"/> <Layer\u00a0name=\"M2\"\u00a0row_number=\"2\"/> <Layer\u00a0name=\"M3\"\u00a0row_number=\"3\"/>       <Layer\u00a0name=\"M4\"\u00a0row_number=\"1\"/> </Template> <Pin\u00a0name=\"*/BCELLD5A11*/Z\"> <Template\u00a0name=\"template_1_3231\"/> </Pin> </EmRule> To generate the script files to define the via ladder rules and constraints, use the following command: fc_shell>\u00a0 generate_via_ladder_template -config_file vl_config Example\u00a017 shows the template script file generated by this command.\n  Example\u00a018 shows the association script file generated by this command.\n Example 17 Template Script File create_via_rule\u00a0-name\u00a0template_1_3231\u00a0\\ -cut_layer_names\u00a0{VIA1\u00a0VIA2\u00a0VIA3}\u00a0-cut_names\u00a0{V1S\u00a0V2S\u00a0V3S}\u00a0\\ -cut_rows\u00a0{2\u00a03\u00a01}\u00a0-cuts_per_row\u00a0{3\u00a02\u00a03} set\u00a0viaRule\u00a0[get_via_rules\u00a0template_1_3231] set_attribute\u00a0$viaRule\u00a0upper_metal_min_length_table\u00a0{0.3\u00a00.2\u00a00.4} set_attribute\u00a0$viaRule\u00a0for_electro_migration\u00a0true Example 18 Association Script File foreach_in_collection\u00a0pin\u00a0[get_lib_pins\u00a0-quiet\u00a0*/BCELLD5A11*/Z]\u00a0{ set_attribute\u00a0-quiet\u00a0$pin\u00a0is_em_via_ladder_required\u00a0true set_via_ladder_candidate\u00a0$pin\u00a0-ladder_name\u00a0\"template_1_3231\" } See Also \u2022 Defining Via Ladder Rules \u2022 Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}
{"header": "How do I Via Ladder Rule Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the  setup_performance_via_ladder command to generate the via ladder rules and associations.\n By default, this command \u2022 Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the  -max_layer attribute.\n       The command uses information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file: \u25e6 The cut layers that connect the specified metal layers \u25e6 The cut names \u25e6 The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block.\n The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules.\n For details about these files, see  Via Ladder Rule Files.\n You can also generate these files by using the generate_via_rules_for_performance command.\n \u2022 Associates via ladder rules with the pins of all library cells that do not have a  dont_use attribute To include the pins of library cells that have a  dont_use attribute, use the  -dont_use option.\n To associate via ladder rules only with specific pins, use the  -lib_pins option.\n The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations.\n For details about this file, see  Via Ladder Association File.\n You can also generate this file by using the  associate_performance_via_ladder command.\n \u2022 Runs the generated script files See Also \u2022 Defining Via Ladder Rules \u2022 Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}
{"header": "How do I Via Ladder Association File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The command generates two via ladder rule files: \u2022 An XML file that provides information about the via ladder rules The XML file has the following syntax: <EmRule> <!--\u00a0template\u00a0definition\u00a0--> <Template\u00a0name=\" rule_name \"\u00a0for_electro_migration=\"true\" for_high_performance=\"true\"> <Layer\u00a0name=\" layer_name \"\u00a0row_number=\" cuts_per_row \"...\n more\u00a0layers </Template> \u2026\u00a0more\u00a0templates  </EmRule> Each  Template section specifies the template for a via ladder rule.\n Within a template section, the via ladder structure is specified by specifying the number of cuts per row for each metal layer involved in the via ladder.\n By default, the generated XML file is named auto_perf_via_ladder_rule.xml.\n To specify a different name, use the  -xml_file option.\n \u2022 A script file that defines the via ladder rules The script file contains a  create_via_rule command for each template defined in the XML file, as well as  set_attribute commands to set the appropriate via rule attributes.\n By default, the generated script file is named auto_perf_via_ladder_rule.tcl.\n To specify a different file name, use the  -rule_file option."}
{"header": "How do I Constraint-Based Via Ladder Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The command generates a script file that defines the association between the library cell pins and the via ladder rules.\n This script file contains  set_via_ladder_candidate commands for the library cell pins.\n By default, the generated script file is named auto_perf_via_ladder_association.tcl.\n To specify a different file name, use the  -association_file option."}
{"header": "How do I Defining Via Ladder Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To use the constraint-based method to insert via ladders, 1.\n Ensure that the via ladder rules are defined, as described in  Defining Via Ladder Rules.\n 2.\n Define the via ladder constraints by using the  set_via_ladder_rules command, as described in  Defining Via Ladder Constraints.\n 3.\n Insert the via ladders by using the  insert_via_ladders command, as described in Inserting Via Ladders.\n 4.\n Verify the via ladders by using the  verify_via_ladders command, as described in Verifying Via Ladders."}
{"header": "How do I Defining Global Via Ladder Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The via ladder constraints define the pins on which to insert via ladders and the via ladder templates that can be used for those pins.\n You can define both global and instance- specific via ladder constraints; if the constraints conflict, the instance-specific constraints override the global constraints.\n \u2022 To define global via ladder constraints, which are referred to as via ladder rules, use the  set_via_ladder_rules command, as described in  Defining Global Via Ladder Constraints.\n \u2022 To define instance-specific via ladder constraints, use the set_via_ladder_constraints command, as described in  Defining Instance-Specific Via Ladder Constraints.\n In addition, you can specify via ladder candidates for specific pins by using the set_via_ladder_candidate command.\n This command is used by preroute optimization to insert via ladders on timing-critical paths, as described in  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization.\n To report the via ladder constraints, use the  report_via_ladder_constraints command.\n See Also \u2022 Inserting Via Ladders"}
{"header": "How do I Defining Instance-Specific Via Ladder Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define global via ladder constraints, which are referred to as via ladder rules, use the set_via_ladder_rules command to set via ladder constraints on library cell pins.\n You must specify the mapping between library cell pins and via ladder templates, as well as the pins to which to apply the mapping.\n Use the following options to specify the mapping: \u2022 -master_pin_map or  -master_pin_map_file These options specify the mappings for specific library pins using the following format: {\u00a0{ lib_cell / pin { via_ladder_list }}\u00a0...}       To specify the mapping on the command line, use the  -master_pin_map option.\n To specify the mapping in an external file, use the  -master_pin_map_file option to specify the mapping file name.\n \u2022 -default_ladders This option specifies the via ladder templates to use for all library pins not explicitly specified in the mapping.\n Use the following options to specify the pins to which to apply the mapping: \u2022 -all_instances_of This option explicitly specifies library cell pins to which to apply the mapping.\n \u2022 -all_clock_outputs Set this option to  true to apply the mapping to all clock output pins.\n \u2022 -all_clock_inputs Set this option to  true to apply the mapping to all clock input pins.\n \u2022 -all_pins_driving This option applies the mapping to all pins that drive one of the specified ports.\n To report the via ladder rules, use the  report_via_ladder_rules command.\n To remove via ladder rules, use the  remove_via_ladder_rules command."}
{"header": "How do I Inserting Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define instance-specific via ladder constraints, use the  set_via_ladder_constraints command.\n You must specify the instance pins and the via ladder templates that can be used for those pins.\n For example, to enable the use of the VL1, VL2, and VL3 via ladder templates for the u1/i1 and u2/i2 pins, use the following command: fc_shell>\u00a0 set_via_ladder_constraints -pins {u1/i1 u2/i2} \\ {VL1 VL2 VL3} To report the via ladder constraints, use the  report_via_ladder_constraints command.\n To remove via ladder constraints, use the  remove_via_ladder_constraints command."}
{"header": "How do I Protecting Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert via ladders, use the  insert_via_ladders command.\n By default, this command \u2022 Does not remove existing via ladders in the block To remove the existing via ladders before via ladder insertion, use the  -clean\u00a0true option.\n \u2022 Targets all pins specified in the via ladder constraints, whether on signal nets or clock nets To restrict via ladder insertion to specific nets, use the  -nets option.\n \u2022 Inserts a single via ladder on each target pin If the constraints specify more than one via ladder template for a pin, the command inserts the via ladder using the first template that does not cause a DRC violation.\n \u25e6 By default, if all of the via ladder templates cause a DRC violation, the command inserts the via ladder with the lowest DRC cost.\n \u25e6 To ignore detail routing shapes when checking for DRC violations, use the -ignore_routing_shape_drcs\u00a0true option.\n \u25e6 To ignore the line-end cut enclosure rule, use the -relax_line_end_via_enclosure_rule\u00a0true option.\n \u25e6 To ignore metal spacing rules on the pin layer when the via ladder shape is fully enclosed within the pin, use the  -relax_pin_layer_metal_spacing_rules\u00a0true option.\n \u25e6 To prevent the insertion of via ladders that cause DRC violations, use the -allow_drcs\u00a0false option.\n Note: If a pin is too small to accommodate any of the via ladders specified for it, the  insert_via_ladders command does not insert a via ladder for that pin.\n \u2022 Uses via cuts other than those specified in the template if they improve compliance with fat via rules To require the command to use only those via cuts specified in the template, use the -strictly_honor_cut_table\u00a0true option.\n \u2022 Centers the via ladder cuts at the intersection of routing tracks between adjacent layers To shift the via ladder cuts on transition layers off the routing tracks for improved DRC compliance, use the  -shift_vias_on_transition_layers\u00a0true option.\n       \u2022 Honors nondefault width rules for the wires on all layers of the via ladder To use the default width for wires on lower layers of the via ladder and honor the nondefault width only for the top layer, use the  -ndr_on_top_layer_only\u00a0true option.\n \u2022 Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted above the pin layer be fully contained within the pin shape boundary, which includes the pin shape and its extensions.\n To specify this requirement, use one or both of the following options: \u25e6 -connect_within_metal\u00a0true This option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join.\n \u25e6 -connect_within_metal_for_via_ladder\u00a0true This option controls the via enclosures only for performance and electromigration via ladders.\n By default, the tool uses the global setting specified by the -connect_within_metal option.\n To explicitly specify the behavior for performance and electromigration via ladders, set this option to  true or  false.\n \u2022 Does not extend the via enclosures to meet the minimum length rule for the layer To enable patching of the via enclosures to meet the minimum length rule and allow additional stacking of the via ladder, use the  -allow_patching\u00a0true option.\n \u2022 Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion.\n In many cases, the via ladder rule specifies the maximum number of stagger tracks.\n To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, use the -auto_stagger\u00a0true option.\n \u2022 Does not report on the insertion status To report the via ladder insertion status for each target pin, use the  -verbose\u00a0true option.\n       To output detailed information about insertion failures, use the  -user_debug\u00a0true option.\n The detailed information reports the following types of violations: \u25e6 Internal DRC violations These are DRC violations internal to a via ladder.\n These violations are never allowed.\n \u25e6 Hard DRC violations These are DRC violations between a via ladder and a fixed shape, such as a pin, preroute, or obstruction.\n These violations are never allowed.\n \u25e6 Soft DRC violations These are DRC violations between a via ladder and a detail routing shape, which can be rerouted.\n These violations are allowed if one or more of the following options are  true :  -allow_drcs,  -ignore_rippable_shapes, or -ignore_routing_shape_drcs.\n After inserting the via ladders, the command reports statistics on the inserted ladders and any DRC violations caused by the insertion.\n See Also \u2022 Defining Via Ladder Constraints \u2022 Verifying Via Ladders \u2022 Updating Via Ladders \u2022 Querying Via Ladders \u2022 Removing Via Ladders"}
{"header": "How do I Verifying Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To prevent via ladders from being edited, set the design.enable_via_ladder_protection application option to  true.\n fc_shell>\u00a0 set_app_options -name design.enable_via_ladder_protection \\ -value true When the  design.enable_via_ladder_protection application option is  true, the following commands process only objects that do not belong to via ladders: \u2022 remove_shapes \u2022 remove_vias       \u2022 remove_objects \u2022 set_attribute \u2022 set_via_def \u2022 add_to_edit_group If an object belongs to a via ladder, these commands issue a warning message and do not process the object.\n The following example sets the  design.enable_via_ladder_protection application option to  true and attempts to remove a collection of shapes: fc_shell>\u00a0 set_app_options -name design.enable_via_ladder_protection \\ -value true...\n fc_shell>\u00a0 sizeof_collection [get_shapes -of net1] 77  fc_shell>\u00a0 remove_shapes [get_shapes -of net1] -verbose Warning:\u00a0Cannot\u00a0edit\u00a0PATH_32_7403\u00a0because\u00a0it\u00a0is\u00a0part\u00a0of\u00a0via_ladder.\n (NDM-160) 76"}
{"header": "How do I Updating Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To verify that the via ladders in the block match the via ladder constraints and are properly connected to pins, use the  verify_via_ladders command.\n By default, this command checks all via ladders.\n To restrict the checking to specific nets, use the  -nets option.\n Note: If you use the  -shift_vias_on_transition_layers\u00a0true option when you insert the via ladders, you must also use this option when you verify the via ladders; otherwise, the command reports false violations.\n A via ladder matches the via ladder constraints if the pattern of connected vias and wires for the via ladder structure satisfies any of the via ladder templates assigned to the connected pin.\n The command flags a violation in the following situations: \u2022 A via ladder is connected to a pin that does not have a via ladder constraint \u2022 A via ladder is connected to a pin with a via ladder constraint, but none of the templates correctly describe the current via ladder structure \u2022 A pin has a via ladder constraint, but does not have a via ladder connected to it       A via ladder is properly connected to a pin if all the via enclosures at the base of the via ladder touch the same pin and that pin is logically connected to the same net as the via ladder.\n The command flags a violation in the following situations: \u2022 An enclosure of the via ladder base touches a different pin, unless the pins are must- join pins that belong to the same must-join set \u2022 An enclosure of the via ladder base does not touch any pin \u2022 An enclosure of the via ladder touches a pin that is not of the same net as the via ladder By default, the  verify_via_ladders command reports the via ladder insertion status for each target pin, which can result in a very large report.\n To limit the number of via ladders reported for each category to 40, use the  -report_all_via_ladders\u00a0false option with the  verify_via_ladders command."}
{"header": "How do I Manual Via Ladder Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use the following methods to update existing via ladders in a design: \u2022 Use the  refresh_via_ladders command \u2022 Automatic updates during the  route_group,  route_auto, and  route_eco commands is enabled by default by setting the  route.auto_via_ladder.update_during_route application option to  true Both of these methods perform the following tasks: \u2022 Verifies the existing via ladders based on the current via ladder constraints \u2022 Removes invalid via ladders \u2022 Inserts via ladders where needed based on the settings of the route.auto_via_ladder application options By default, the tool \u25e6 Updates all pins with via ladder constraints, whether on signal nets or clock nets By default, during the  route_group command, the via ladder updates is restricted to only those nets specified in the  route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to  true.\n \u25e6 Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted about the pin layer be fully contained within the pin shape boundary, which includes       the pin shape and its extensions.\n To specify this requirement, set the following application options: \u25aa route.auto_via_ladder.connect_within_metal This application option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join.\n To prevent changes to the pin shape boundary, set this application option to  true.\n \u25aa route.auto_via_ladder.connect_within_metal_for_via_ladder This application option controls the via enclosures only for performance and electromigration via ladders.\n By default, the tool uses the global setting specified by the  route.auto_via_ladder.connect_within_metal application option.\n To explicitly specify the behavior for performance and electromigration via ladders, set this application option to  true or  false.\n \u25e6 Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion.\n In many cases, the via ladder rule specifies the maximum number of stagger tracks.\n To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, the  route.auto_via_ladder.auto_stagger application option is set to  true by default.\n \u25e6 Reports the via ladder insertion status for each target pin To limit the number of via ladders reported for each category to 40, set the route.auto_via_ladder.report_all_via_ladders application option to  false.\n See Also \u2022 Inserting Via Ladders \u2022 Verifying Via Ladders \u2022 Querying Via Ladders \u2022 Removing Via Ladders"}
{"header": "How do I Querying Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To manually insert a via ladder, 1.\n Create the shapes that compose the via ladder by using the  create_shape and create_via commands.\n 2.\n Create the via ladder by using the  create_via_ladder command.\n At a minimum, you must specify the shapes that compose the via ladder by using the -shapes option.\n The command creates a via ladder named VIA_LADDER_ n, where  n is a unique integer.\n Use the following options with the  create_via_ladder command to specify attributes of the created via ladder: \u2022 -via_rule This option specifies the via ladder rule associated with the created via ladder.\n It sets the  via_rule_name attribute of the created via ladder.\n \u2022 -electromigration This option specifies that the via ladder is an electromigration via ladder.\n It sets the is_electromigration attribute of the created via ladder to  true.\n \u2022 -high_performance This option specifies that the via ladder is a performance via ladder.\n It sets the is_high_performance attribute of the created via ladder to  true.\n \u2022 -pattern_must_join This option specifies that the via ladder is a pattern-must-join via ladder.\n It sets the is_pattern_must_join attribute of the created via ladder to  true.\n \u2022 -pin This option specifies the physical pin connected to the created via ladder.\n It sets the pin attribute of the created via ladder.\n See Also \u2022 Querying Via Ladders \u2022 Removing Via Ladders"}
{"header": "How do I Removing Via Ladders", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To query the via ladders in a block, use the  get_via_ladders command.\n To report on the via ladders in a block, use the  report_via_ladders command."}
{"header": "How do I Checking Routability", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove via ladders and their associated shapes, use the  remove_via_ladders command.\n You must specify the via ladders to remove.\n To remove all via ladders from the block, use the asterisk (*) wildcard character, as shown in the following example: fc_shell>\u00a0 remove_via_ladders * To remove via ladders only from specific nets, use the  -nets option."}
{"header": "How do I Routing Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After placement is completed, you can use the  check_routability command to check whether your block is ready for detail routing.\n By default, this command checks for \u2022 Blocked standard cell ports A standard cell port is considered blocked if none of its physical pins is accessible.\n A standard cell pin is considered accessible if the pin contains a via that extends to a neighboring layer, there is a path on the pin layer that is at least as long as the search range distance, or there is a shorter path on the pin layer that ends at a via to a neighboring layer.\n By default, the search range distance is two times the layer pitch.\n To change this distance, use the  -standard_cell_search_range option to specify a different pitch multiplier, up to a maximum of 10.\n If you specify a value larger than 10, the command sets the value to 10.\n By default, the tool does not check whether via connections are fully inside the standard cell pins.\n To enable this check, use the -connect_standard_cells_within_pins\u00a0true option.\n To disable the checking of blocked standard cell ports, use the -check_standard_cell_blocked_ports\u00a0false option.\n       \u2022 Blocked top-level or macro cell ports A top-level or macro cell port is considered blocked if none of its physical pins is accessible.\n A top-level or macro pin is considered accessible if a legal path can be extended from the pin to a certain distance around it.\n This path can be just on the pin layer or can extend to a neighboring layer by a single via.\n By default, the distance is 10 times the layer pitch.\n To change this distance for same-layer paths, use the  -blocked_range option to specify a different pitch multiplier, up to a maximum of 40.\n To change this distance for neighboring-layer paths through a via, use the  -blocked_range_via_side option to specify a different pitch multiplier, up to a maximum of 40.\n If you specify a value larger than 40 for either of these options, the command sets its value to 40.\n By default, the command checks whether a pin is accessible in either the horizontal or vertical direction.\n To require that the pin is accessible in the preferred direction for its layer, use the  -obey_direction_preference\u00a0true option.\n To disable the checking of blocked top-level or macro cell ports, use the -check_non_standard_cell_blocked_ports\u00a0false option.\n \u2022 Out-of-boundary pins This check verifies that all pins are within the block boundary.\n To disable the checking of out-of-boundary pins, use the  -check_out_of_boundary false option.\n \u2022 Minimum grid violations This check verifies that all pins, including those within library cells, are on the minimum grid, as defined by the  gridResolution attribute in the technology file.\n To disable the checking of minimum grid violations, use the  -check_min_grid\u00a0false option.\n \u2022 Incorrect via definitions This check verifies that \u25e6 Uncolored via arrays do not have more than 20 rows or columns \u25e6 Custom or asymmetric simple via definitions do not have more than 1000 cuts \u25e6 The design does not contain more than 65535 via definitions You cannot disable these checks.\n       \u2022 Invalid real metal via cut blockages This check verifies that all real metal via cut blockages match a legal cut size, as defined by the  cutWidthTbl,  cutHeightTbl, and  minWidth attributes in the technology file.\n To disable this check, use the  -check_via_cut_blockage\u00a0false option.\n \u2022 Minimum width settings This check verifies that the nondefault minimum width and shield width settings are no larger than the maximum width defined in the technology file.\n You cannot disable these checks.\n The  check_routability command also supports the following optional checks: \u2022 Blocked power or ground ports To enable this check, use the  -check_pg_blocked_ports\u00a0true option.\n \u2022 Redundant power or ground shapes To enable this check, use the  -check_redundant_pg_shapes\u00a0true option.\n \u2022 Staggered power and ground vias that block the routing tracks To enable this check, use the  -check_routing_track_space\u00a0true option.\n \u2022 Blocked ports on frozen nets To enable this check, use the  -check_frozen_net_blocked_ports\u00a0true option.\n \u2022 Blocked unconnected pins To enable this check, use the  -check_no_net_pins\u00a0true option.\n \u2022 Real metal blockages that overlap library cell pins To enable this check, use the  -check_real_metal_blockage_overlap_pin\u00a0true option.\n \u2022 Invalid real metal via cut blockages in the library cells To enable this check, use the  -check_lib_via_cut_blockage\u00a0true option.\n       \u2022 Shielding checks These checks detect possible issues with shielding by checking for the following conditions: \u25e6 Signal net shapes with a  shape_use attribute of  shield_route.\n \u25e6 PG net shapes, which might be a PG strap or rail, but have a  shape_use attribute of detail_route.\n \u25e6 Signal, clock, or PG nets that have a shielding nondefault rule but no associated shield shapes, which might be caused by inappropriate  shape_use attributes.\n To enable these checks, use the  -check_shield\u00a0true option.\n \u2022 Via ladder checks These checks detect possible issues with via ladder insertion by checking for the following conditions: \u25e6 Library cell pins whose top-layer terminals have multiple pin shapes but do not have a  pattern_must_join attribute This check applies only to signal and secondary PG pins.\n \u25e6 Missing performance or electromigration via ladder on a pin that has the is_em_via_ladder_required attribute \u25e6 Via ladder application options that do not have the required settings To enable these checks, use the  -via_ladder\u00a0true option.\n The  check_routability command supports the following additional pin connection controls that apply to all pin access checks: \u2022 Pin access edges During frame view extraction, the tool annotates the frame views with information about the pin access edges.\n By default, the  check_routability command ignores the pin access edges and allows pin connections at any point.\n You can restrict pin connections to the defined access edges by setting the  -obey_access_edges option to  true.\n You can further restrict pin connections to the access edge mark, which can be a narrow rectangle, a short line, or even a single point, by setting the -access_edge_whole_side option to  true.\n In addition, the command can report unconnected pins that do not have an access edge defined.\n To enable this check, use the  -report_no_access_edge\u00a0true option.\n \u2022 Via rotation By default, pin connections can use rotated vias.\n To disallow pin connections that use rotated vias, set the  -allow_via_rotation option to  false.\n       By default, this command considers the following routing layer constraints when checking for blocked ports: \u2022 The global minimum and maximum routing layer constraints set by the -min_routing_layer and  -max_routing_layer options of the  set_ignored_layers command These constraints can cause blocked ports only if they are defined as hard constraints.\n By default, these constraints are soft constraints.\n They are hard constraints only if the  route.common.global_min_layer_mode and route.common.global_max_layer_mode application options are set to  hard.\n \u2022 The net-specific minimum and maximum routing layer constraints set by the -min_routing_layer and  -max_routing_layer options of the  set_routing_rule command These constraints can cause blocked ports only if they are defined as hard constraints.\n By default, the net-specific minimum layer constraint is a soft constraint and the net- specific maximum layer constraint is a hard constraint.\n They are hard constraints only if the  route.common.net_min_layer_mode and  route.common.net_max_layer_mode application options are set to  hard.\n \u2022 The clock minimum and maximum routing layer constraints set by the  -min_routing_layer and  -max_routing_layer options of the set_clock_routing_rules command These constraints can cause blocked ports only if they are defined as hard constraints.\n By default, the clock minimum layer constraint is a soft constraint and the clock maximum layer constraint is a hard constraint.\n They are hard constraints only if the route.common.net_min_layer_mode and  route.common.net_max_layer_mode application options are set to  hard.\n \u2022 The freeze layer constraints set by the  route.common.freeze_layer_by_layer_name and  route.common.freeze_via_to_frozen_layer_by_layer_name application options To ignore the routing layer constraints during the blocked port checks, use the -honor_layer_constraints\u00a0false option.\n You can use the error browser to examine the errors detected by the  check_routability command.\n By default, the error data generated by the  check_routability command is named check_routability.err; to"}
{"header": "How do I Routing Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "specify a different name for the error data, use the -error_data option.\n The error data is saved in the design library when you save the block.\n For information about using the error browser, see the  Fusion Compiler Graphical User Interface User Guide."}
{"header": "How do I Defining Routing Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Routing constraints provide guidance during routing.\n  Table\u00a029  describes the types of guidance provided by the routing constraints.\n Table 29 Routing Constraints Guidance Description                   \u2022   \u2022           onWireTrack onGrid      physical_status  locked                 Table 29 Routing Constraints (Continued) Guidance Description                         \u2022  \u2022 derive_metal_cut_route_guides     \u2022 \u2022  \u2022"}
{"header": "How do I Reserving Space for Top-Level Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A routing blockage defines a region where routing is not allowed on specific layers.\n Zroute considers routing blockages to be hard constraints.\n To define a routing blockage, use the  create_routing_blockage command.\n At a minimum, you must define the boundary of the routing blockage and the affected layers.\n \u2022 To create a rectangular routing blockage, use the  -boundary option to specify the lower-left and upper-right corners of the rectangle using the following syntax:  {\u00a0{ llx lly }\u00a0{ urx ury }\u00a0}.\n \u2022 To create a rectilinear routing blockage, use the  -boundary option to specify the coordinates of the polygon using the following syntax:  {\u00a0{ x1 y1 }\u00a0{ x2 y2 }\u00a0...\n }.\n You can also create a rectilinear routing blockage by specifying the polygon as the combined area of a heterogeneous collection of objects with physical geometry, such as poly_rects, geo_masks, shapes, layers, and other physical objects.\n If you specify a layer, the resulting area includes the area of every shape on the layer.\n For all other objects, the resulting area includes the area of each object.\n You can create multiple routing blockages by specifying the boundary polygon as a geo_mask or a collection of physical objects.\n If the resulting area resolves to multiple, noncontiguous polygons, the command creates multiple routing blockages, one corresponding to each polygon.\n \u2022 To specify the affected layers, use the  -layers option.\n Specify the routing layers by using the layer names from the technology file.\n The layers can be metal, via, or poly layers.\n By default, the tool creates a routing blockage named RB_ objId in the current block that prevents routing of all nets within the routing blockage boundary.\n The routing blockage is considered as real metal for RC extraction and DRC checking and the router must meet the minimum spacing requirements between the routing blockage boundary and the net shapes.\n Use the following options to change the default behavior: \u2022 -name\u00a0 blockage_name Specifies a name for the routing blockage.\n \u2022 -cell\u00a0 cell Creates the routing blockage in a different physical cell.\n When you use this option, the tool creates the routing blockage in the cell's reference block using the coordinate system of the cell's top-level block.\n \u2022 -zero_spacing       Disables the minimum spacing rule between the routing blockage boundary and the net shapes (zero minimum spacing).\n This option also prevents the routing blockage from being treated as real metal during extraction and DRC checking.\n When you use this option, the net shapes can touch, but not overlap, the routing blockage boundary.\n Note: When you create a routing blockage to prevent via insertion, you must use the  -zero_spacing option; otherwise, frame view extraction does not use the route guide to trim the via region.\n \u2022 -net_types\u00a0 list_of_types Applies the routing blockage only to the specified net types.\n Specify one or more of the following net types:  analog_ground,  analog_power, analog_signal,  clock,  deep_nwell,  deep_pwell,  ground,  nwell,  power,  pwell, reset,  scan,  signal,  tie_high, and  tie_low.\n To remove the net type settings and prevent routing of all nets in the routing blockage, use the  -net_types\u00a0unset setting.\n To prevent signal routing on the M1 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types signal -layers M1 To prevent vias on the V1 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types signal -layers V1 -zero_spacing To prevent PG routing on the M2 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types {power ground} -layers M2"}
{"header": "How do I Querying Routing Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To reserve space for top-level routing, create a corridor routing blockage by using the -reserve_for_top_level_routing option when you create the routing blockage.\n During block-level implementation, a corridor routing blockage acts as a regular blockage to prevent routing in the blockage area.\n During frame view extraction, the tool removes the corridor routing blockage to allow top-level routing in this area."}
{"header": "How do I Removing Routing Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To find routing blockages, use the  get_routing_blockages command.\n For example, to get all the routing blockages in a block, use the following command: fc_shell>\u00a0 get_routing_blockages * To find the routing blockages for specific nets, use the  -of_objects option to specify the nets of interest.\n For example, to find the routing blockages for the n1 net, use the following command: fc_shell>\u00a0 get_routing_blockages -of_objects [get_nets n1] To find the routing blockages in a specific location, use the  get_objects_by_location -classes\u00a0routing_blockage command."}
{"header": "How do I Defining Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove routing blockages from the current block, use the  remove_routing_blockages command.\n \u2022 To remove specific routing blockages, specify the routing blockages, either as a list or collection, such as that returned by the  get_routing_blockages command.\n \u2022 To remove all routing corridors, specify the  -all option."}
{"header": "How do I Using Routing Guides to Control the Routing Direction", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Routing guides provide routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic describes how to create user-defined routing guides.\n Note: User-defined routing guides are honored by Zroute; however, they are not honored by the Advanced Route tool.\n To define a routing guide, use the  create_routing_guide command.\n When you define a routing guide, you must specify \u2022 Its rectangular boundary To specify the boundary, use the  -boundary option to specify the lower-left and upper- right corners of the rectangle using the following syntax: {{ llx lly }\u00a0{ urx ury }} \u2022 Information specific to the purpose of the routing guide The following table describes the user-defined routing guides.\n Table 30 User-Defined Routing Guides Purpose Option     -preferred_direction_only     -switch_preferred_direction     -max_patterns   -horizontal_track_utilization -vertical_track_utilization       Purpose Option   -access_preference   -river_routing By default, the tool creates a routing guide named RD# n in the current block, where  n  is a unique integer.\n Use the following options to change the default behavior: \u2022 To specify a name for the routing guide, use the  -name option.\n \u2022 To specify the routing layers affected by the routing guide, use the  -layers option.\n Specify the routing layers by using the layer names from the technology file.\n \u2022 To create the routing guide in a different physical cell, use the  -cell option.\n When you use this option, the tool creates the routing guide in the cell's reference block using the coordinate system of the cell's top-level block.\n See Also \u2022 Deriving Routing Guides \u2022 Querying Routing Guides \u2022 Removing Routing Guides"}
{"header": "How do I Using Routing Guides to Limit Edges in the Nonpreferred", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use a routing guide to control the routing direction within the routing guide boundary, either by requiring routes to be in the preferred direction within the routing guide boundary or by switching the preferred direction within the routing guide boundary.\n \u2022 To force the router to route all nets in the preferred direction within the routing guide boundary, use the  -preferred_direction_only option with the create_routing_guide command.\n You can use this type of routing guide to prevent wrong-way jog wires on specific layers.\n By default, this routing guide applies to all layers within the routing guide boundary.\n To require preferred direction routing only for specific layers, use the  -layers option to specify the affected layers.\n       For example, to force the router to use only the preferred direction on the M4 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -layers {M4} -preferred_direction_only \u2022 To switch the preferred routing direction within the routing guide boundary, use the -switch_preferred_direction option with the  create_routing_guide command.\n You can use this type of routing guide to allow routing over macros, which might reduce congestion for a block that contains much detour routing.\n By default, this routing guide applies to all layers within the routing guide boundary.\n To switch the preferred routing direction only for specific layers, use the  -layers option to specify the affected layers.\n For example, to switch the preferred routing direction for the M1 and M2 layers within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -layers {M1 M2} -switch_preferred_direction Note: If a switch-preferred-direction routing guide overlaps with a preferred- direction-only routing guide, the switch-preferred-direction routing guide takes precedence."}
{"header": "How do I Using Routing Guides to Control the Routing Density", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use a routing guide to limit the number of occurrences of a specific routing pattern within the routing guide boundary on specific layers.\n Zroute tries to route the nets within the routing guide to meet this constraint; however, if the number of edges in the nonpreferred direction exceeds the specified threshold, Zroute reports a violation.\n To create this type of routing guide, use the  -max_patterns option with the create_routing_guide command.\n Use the following syntax to specify the routing pattern and its threshold for each affected layer: {\u00a0{ layer pattern limit }\u00a0...\n } In addition to using the  -max_patterns option, you must also use the  -layers option when you create this type of routing guide.\n Specify the same layers in the  -layers option as those specified in the  -max_patterns option.\n       If you do not specify a pattern threshold for a layer, the routing pattern has no limit for that layer.\n Currently, the only supported pattern is  non_pref_dir_edge, which represents the edges in the nonpreferred direction.\n For example, to limit the number of edges in the nonpreferred direction to two on M2 and to three on M4, with no limits on other layers, use the following command: fc_shell>\u00a0 create_routing_guide -boundary {{50 50} {200 200}} \\ -max_patterns {{M2 non_pref_dir_edge 2} {M4 non_pref_dir_edge 3}} \\ -layers {M2 M4}"}
{"header": "How do I Using Routing Guides to Prioritize Routing Regions", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the maximum track utilization is 100 percent.\n You can use a routing guide to control the routing density within the routing guide boundary.\n \u2022 To set the maximum track utilization for layers with a horizontal preferred direction, use the  -horizontal_track_utilization option with the  create_routing_guide command.\n \u2022 To set the maximum track utilization for layers with a vertical preferred direction, use the  -vertical_track_utilization option with the  create_routing_guide command.\n By default, when you create these routing guides, they apply to all layers within the routing guide boundary.\n To set the routing density only for specific layers, use the  -layers option to specify the affected layers.\n For example, to set a maximum track utilization of 50 percent for all layers with a horizontal preferred direction and a maximum track utilization of 30 percent for all layers with a vertical preferred direction within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -horizontal_track_utilization 50 -vertical_track_utilization 30"}
{"header": "How do I Using Routing Guides to Encourage River Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use a routing guide to prioritize regions within the routing guide boundary for routing.\n The regions are called access preference areas.\n You prioritize the access preference areas by assigning strengths to them.\n Access preference areas with higher strengths are preferred for routing.\n You can define access preference areas for both wires and vias.\n When you define a via access-preference area, you are defining a preference       area for the via surrounds on the specified metal layer for vias coming from both above and below that metal layer.\n To create this type of routing guide, use the  -access_preference option with the create_routing_guide command.\n Use the following syntax to specify the access preference areas and their strengths: { layer [{wire_access_preference\u00a0 wire_rect wire_strength }] [{via_access_preference\u00a0 via_rect via_strength }]\u00a0...} You can define multiple access preference areas.\n To define the relative preference of the access preference areas, use strength values between 0 and 1.\n If access preference areas overlap, the stronger access preference area takes precedence over the weaker access preference area.\n To require routing in a specific access preference area, use a strength value of 1.\n When you define access preference areas with a strength of 1, all access preference areas with a strength less than 1 are ignored and Zroute treats the access preference routing guide as a hard constraint.\n The following example creates an access preference routing guide whose boundary is a rectangle with its lower-left corner at (0, 0) and its upper-right corner at (300, 300).\n It contains one wire access-preference area with coordinates of (0, 0) and (2, 1) and two via access-preference areas, one with coordinates of (0, 0) and (5, 5) and one with coordinates of (40, 40) and (45, 45).\n The wire access-preference area is slightly preferred over areas outside of the access preference area because it has a strength of 0.2.\n The via access-preference area with coordinates at (40, 40) and (45, 45) is ignored, because routing is required in the via access-preference area with coordinates at (0, 0) and (5, 5), which has a strength of 1.\n fc_shell>\u00a0 create_routing_guide -boundary {{0 0} {300 300}} \\ -access_preference {M1 {wire_access_preference {{0 0} {2 1}} 0.2} {via_access_preference {{0 0} {5 5}} 1.0} {via_access_preference {{40 40} {45 45}} 0.5}} To report information about the access preference routing guides defined for your block, use the  report_routing_guides command."}
{"header": "How do I Querying Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "River routing is a special routing topology that tries to minimize the space taken by the router by compressing the routes to follow a particular contour.\n River routing is useful if there are tight routing channels or you need to minimize the space taken by routing.\n You can use a routing guide to encourage river routing within the routing guide boundary.\n To create this type of routing guide, use the  -river_routing option with the create_routing_guide command.\n You must also use the  -layers option to specify the affected layers.\n       For example, to encourage river routing on the M2 layer within the rectangle with its lower- left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell>\u00a0 create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -river_routing -layers {M2}"}
{"header": "How do I Removing Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To find routing guides, use the  get_routing_guides command.\n For example, to get all the routing guides in your block, use the following command: fc_shell>\u00a0 get_routing_guides * To find the routing guides in a specific location, use the  get_objects_by_location -classes\u00a0routing_guide command."}
{"header": "How do I Deriving Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove routing guides from the current block, use the  remove_routing_guides command.\n \u2022 To remove specific routing guides, specify the routing rules, either as a list or collection, such as that returned by the  get_routing_guides command.\n \u2022 To remove all routing guides, specify the  -all option.\n For example, to remove the new_width_rule routing rule, use the following command: fc_shell>\u00a0 remove_routing_rules new_width_rule"}
{"header": "How do I Deriving Pin Access Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Routing guides provides routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic described how to derive the following types of routing guides: \u2022 Deriving Pin Access Routing Guides \u2022 Deriving Metal Cut Routing Guides See Also \u2022 Defining Routing Guides"}
{"header": "How do I Deriving Metal Cut Routing Guides", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you reuse hard macros, such as IP blocks, at a smaller technology node, it can cause routability issues to the macro pins.\n You can use routing guides and blockages to enable access to the hard macro pins.\n To create these routing guides, which are referred to as  pin access routing guides, and the associated blockages, use the  derive_pin_access_routing_guides command.\n You must specify the following information: \u2022 The hard macros around which to create the routing guides and routing blockages (the -cells option) \u2022 The metal layers for which to create the routing guides and routing blockages (the -layers option) \u2022 The width of the routing guides and blockages in the x- and y-directions (the  -x_width and  -y_width options) For each specified hard macro, the command creates routing guides to enable routing to the pins on the specified layers.\n In addition, the command creates metal blockages that surround the macro on the specified layers, with cutouts to allow pin access, and via blockages that cover the macro on the via layers adjacent to the specified metal layers.\n Vertical routing guides and blockages have the specified x-width.\n Horizontal routing guides and blockages have the specified y-width.\n By default, the command creates pin cutouts only in the preferred routing direction.\n To also create pin cutouts in the nonpreferred direction, use the  -nonpreferred_direction option.\n To extend the pin cutouts beyond the metal blockages, use the  -pin_extension option to specify the extension distance in microns.\n To enable proper routing to pins of different sizes, the command sets the is_rectangle_only_rule_waived attribute on the macro pins to  true to waive the rectangle-only rule.\n For example, the following command creates the routing guides and blockages shown in Figure\u00a0100.\n fc_shell>\u00a0 derive_pin_access_routing_guides -cells myMacro \\ -layers {M2 M3} -x_width 0.6 -y_width 0.7 In the figure, the two red pins are on M2 and the green pin is on M3.\n The figure shows the routing guides created on both the M2 and M3 layers, the metal blockages created on the M3 layer, and the via blockage created on the V2 and V3 layers.\n The tool also creates metal blockages on the M2 layer, which have cutouts for the M2 pins, and via blockages on the V1 and V2 layers.\n       Figure 100 Pin Access Routing Guides and Blockages If a hard macro already has pin access routing guides and their associated blockages, the command removes these existing objects and creates new routing guides and blockages.\n If you move a hard macro after deriving the pin access routing guides, you must regenerate the pin access routing guides.\n You cannot manually modify pin access routing guides."}
{"header": "How do I Controlling Routing Around the Block Boundary", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If your technology file defines metal cut allowed and forbidden preferred grid extension rules and your block already contains boundary cells, you can create routing guides for these rules by using the  -add_metal_cut_allowed option with the  derive_metal_cut_routing_guides command.\n When you use this option, the derive_metal_cut_routing_guides command creates the following routing guides: \u2022 Metal cut allowed routing guides, which cover the area taken up by all the placeable site rows reduced by the vertical shrink factor, which is 50 percent of the smallest site row height \u2022 Forbidden preferred grid extension routing guides, which cover the remaining area up to the block boundary To check the inserted routing guides, use the  -check_only option with the derive_metal_cut_routing_guides command.\n By default, the checking results are stored in an error data file named  block_name.err.\n To specify a different name for the error data file, use the  -error_view option."}
{"header": "How do I Inserting Metal Shapes in the Preferred Direction", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To control routing around the block boundary, use the derive_perimeter_constraint_objects command to place rectangular metal shapes,       routing guides, and routing blockages along the boundary edges, as described in the following topics: \u2022 Inserting Metal Shapes in the Preferred Direction \u2022 Inserting Routing Guides Along the Nonpreferred-Direction Edges \u2022 Inserting Routing Blockages Along the Boundary Edges \u2022 Removing Perimeter Constraint Objects If you change the block boundary after creating the constraint objects, you must regenerate the objects.\n You cannot manually modify the constraint objects.\n To check the perimeter constraint objects, use the  -check_only option with the derive_perimeter_constraint_objects command.\n By default, the checking results are stored in an error data file named  block_name.err.\n To specify a different name for the error data file, use the  -error_view option See Also \u2022 Removing Perimeter Constraint Objects"}
{"header": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert rectangular metal shapes along the preferred-direction edges of the current block, use the  derive_perimeter_constraint_objects command with the -perimeter_objects\u00a0metal_preferred option.\n When you specify this object type, the command creates one or more rectangular metal shapes parallel to each preferred-direction boundary edge.\n The metal shapes are floating; they are not connected to any logical nets.\n \u2022 If your technology does not specify a maximum area for these floating shapes, you can insert continuous metal shapes along the preferred-direction boundary edges, as described in  Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges.\n \u2022 If your technology specifies a maximum area for these floating shapes or you need more flexibility in placing the metal shapes, insert multiple metal shapes, called metal stubs, along the preferred-direction boundary edges, as described in  Inserting Metal Stubs Parallel to Preferred-Direction Edges.\n In addition to inserting metal shapes along the preferred-direction edges, you can insert short metal shapes perpendicular to the nonpreferred-direction edges, as described in Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges.\n       Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges To insert continuous rectangular metal shapes along the preferred-direction edges of the current block, use the  derive_perimeter_constraint_objects command with the -perimeter_objects\u00a0metal_preferred option.\n When you specify this option, the command creates a single rectangular metal shape parallel to each preferred-direction boundary edge.\n By default, \u2022 The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n \u2022 The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the  -layers option.\n \u2022 The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \u201cDefault Width Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 The metal shapes abut the nonpreferred-direction edges To specify an offset from the nonpreferred-direction edges, use the -spacing_from_boundary option.\n Use the following format to specify the offset for each layer: {{ layer_name offset_value }\u00a0...} The offset value must be a positive value.\n \u2022 The metal shapes are placed on the closest wire track to the preferred-direction edge Figure\u00a0101 shows the metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed on the closest track to the edge.\n W is the default width for the layer and S is the spacing specified for the layer by the -spacing_from_boundary option.\n       Figure 101 Continuous Metal Shape Perimeter Constraint Objects W W W S S S S S S Inserting Metal Stubs Parallel to Preferred-Direction Edges To insert metal stubs along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the  -perimeter_objects metal_preferred and  -stub options.\n When you specify both of these options, the command creates rectangular metal shapes parallel to each preferred-direction boundary edge based on the parameters you specify with the  -stub option.\n Use the following format to specify the shape parameters in microns: { offset_value start_value length_value spacing_value } By default, \u2022 The metal shapes are offset from the preferred-direction edge by the value specified in the  offset_value argument The offset value is measured from the block edge to the center of the metal shape.\n It can be a positive value, zero, or a negative value.\n The absolute value of a negative value must be greater than the stub width.\n A positive value must be less than half of the smaller of the width or height of the block boundary.\n \u2022 The first metal shape is offset from the nonpreferred-direction edge by the value specified in the  start_value argument The start value must be greater than or equal to 0 and less than the smaller of the width or height of the block boundary.\n For horizontal shapes, the metal shapes start at the left edge.\n For vertical shapes, the metal shapes start at the bottom edge.\n Note: When you use the  -stub option, the command uses the specified start_value and ignores the  -spacing_from_boundary option.\n       \u2022 The metal shapes have the length specified by the  length_value argument The length value must be greater than 0 and less than or equal to the smaller of the width or height of the block boundary.\n \u2022 The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \u201cDefault Width Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 The metal shapes are separated the space specified by the  spacing_value argument The spacing value must be greater than or equal to 0.\n \u2022 The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n \u2022 The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the  -layers option.\n Figure\u00a0102 shows the metal stubs inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed at the specified offset, O, from the horizontal (preferred-direction) edge, where O is measured from the boundary to the center of the shape.\n The first metal stub is placed at the specified offset, S, from the vertical (nonpreferred-direction) edge.\n Each metal shape has a width of W, the default width for the layer and the specified length, L.\n The spacing between metal stubs is the specified spacing, SP.\n Figure 102 Metal Stub Perimeter Constraint Objects S S S W W SP SP SP W SP SP SP SP SP O O O L       Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges To insert additional short metal shapes in the preferred direction perpendicular to the nonpreferred-direction boundary edges, \u2022 Specify the length of the metal shapes by using the  -short_metal_length option \u2022 Specify the distance between the metal shapes by using the  -metal_spacing option For both of these options, you use the following format to specify the value for each layer: {{ layer_name value }\u00a0...} Figure\u00a0103 shows the short metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape has a width of W, which is the default width for the layer, and a length of L, which is the length specified for the layer by the -short_metal_length option.\n The offset from the nonpreferred-direction edge is S, which is the spacing specified for the layer by the  -spacing_from_boundary option.\n The distance between short metal shapes is SS, which is specified for the layer by the -metal_spacing option.\n Figure 103 Metal Shape Perimeter Constraint Objects With Additional Short Shapes L W W W S S S SS"}
{"header": "How do I Inserting Routing Blockages Along the Boundary Edges", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To insert maximum pattern routing guides along the nonpreferred-direction edges of the current block, use the  derive_perimeter_constraint_objects command with the -perimeter_objects\u00a0mprg_nonpreferred option.\n When you specify this object type, the command creates maximum pattern routing guides parallel to each nonpreferred-direction boundary edge.\n The maximum edge threshold for these routing guides is zero.\n       By default, \u2022 The routing guides are inserted only in the top-level block To insert routing guides in all soft macros in a hierarchical block, use the -hierarchical option.\n \u2022 The routing guides are inserted on all routing layers To insert the routing guides only on specific routing layers, use the  -layers option.\n \u2022 The routing guides have the default metal width specified for the routing layer in the technology file To specify a different width in microns, use the  -width_nonpreferred option.\n For information about specifying the default metal width for a layer, see the \u201cDefault Width Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 The routing guides abut the preferred-direction edges \u2022 The routing guides are offset from the nonpreferred-direction edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns, use the  -spacing_nonpreferred option.\n For information about specifying the minimum spacing for a layer, see the \u201cMinimum Spacing Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n Figure\u00a0104 shows the routing guides inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n S is the spacing specified by the -spacing_nonpreferred option.\n W is the width specified by the  -width_nonpreferred option.\n       Figure 104 Routing Guide Perimeter Constraint Objects S S S W W W See Also \u2022 Using Routing Guides to Limit Edges in the Nonpreferred Direction"}
{"header": "How do I Removing Perimeter Constraint Objects", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can insert routing blockages along the preferred-direction edges, the nonpreferred- direction edges, or all edges.\n \u2022 To insert routing blockages along the preferred-direction edges of the current block, use the  derive_perimeter_constraint_objects command with the -perimeter_objects\u00a0route_blockage_preferred option.\n \u2022 To insert routing blockages along the preferred-direction edges of the current block, use the  derive_perimeter_constraint_objects command with the -perimeter_objects\u00a0route_blockage_nonpreferred option.\n \u2022 To insert routing blockages along all edges of the current block, use the derive_perimeter_constraint_objects command with the  -perimeter_objects {route_blockage_preferred\u00a0route_blockage_nonpreferred} option.\n When you specify this object type, the command creates routing blockages parallel to the boundary edges in the specified directions.\n       By default, \u2022 The routing blockages are inserted only in the top-level block To insert routing blockages in all soft macros in a hierarchical block, use the -hierarchical option.\n \u2022 The routing blockages are inserted on all routing layers To insert the routing blockages only on specific routing layers, use the  -layers option.\n \u2022 The routing blockages have the default metal width specified for the routing layer in the technology file To specify a different width in microns for preferred-direction routing blockages, use the  -width_preferred option.\n To specify a different width in microns for nonpreferred- direction routing blockages, use the  -width_nonpreferred option.\n For information about specifying the default metal width for a layer, see the \u201cDefault Width Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 The routing blockages are offset from the boundary edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns tor preferred-direction routing blockages, use the -spacing_preferred option.\n To specify a different offset in microns tor nonpreferred- direction routing blockages, use the  -spacing_nonpreferred option.\n For information about specifying the minimum spacing for a layer, see the \u201cMinimum Spacing Rule\u201d topic in the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 The routing blockages do not have pin cutouts To generate pin cutouts, use the  -pin_cutout option.\n \u2022 Cut layer routing blockages are not created To create via blockages, specify the via layers in the  -layers option.\n By default, the width of the cut layer routing blockages is the maximum width for the preferred-direction and nonpreferred-direction routing blockages.\n \u25e6 To specify the width for cut layer routing blockages along the horizontal edges, use the  -width_cut_layer_horizontal option.\n \u25e6 To specify the width for cut layer routing blockages along the vertical edges, use the -width_cut_layer_vertical option.\n       By default, the cut layer routing blockages are offset from the boundary edges by the is the maximum spacing for the preferred-direction and nonpreferred-direction routing blockages \u25e6 To specify the spacing for cut layer routing blockages along the horizontal edges, use the  -spacing_cut_layer_horizontal option.\n \u25e6 To specify the spacing for cut layer routing blockages along the vertical edges, use the  -spacing_cut_layer_vertical option."}
{"header": "How do I Routing Nets Within a Specific Region", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  derive_perimeter_constraint_objects command places the inserted constraint objects in an edit group named PC_Edit_Group_ blockname _ n.\n Each time you run the derive_perimeter_constraint_objects command, it creates a unique edit group.\n To remove a group of constraint objects, use the following command: fc_shell>\u00a0 remove_objects [get_attribute \\ [get_edit_groups PC__Edit_Group_ blockname _ n ] objects]"}
{"header": "How do I Defining Routing Corridors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To route one or more nets within a specific region, 1.\n Define a routing corridor by using the  create_routing_corridor command, as described in  Defining Routing Corridors.\n 2.\n Assign the nets and supernets to the routing corridor by using the add_to_routing_corridor command, as described in  Assigning Nets to a Routing Corridor.\n 3.\n Verify that the routing corridors are valid by using the  check_routing_corridors command, as described in  Verifying Routing Corridors.\n If necessary, modify the routing corridors, as described in  Modifying Routing Corridors.\n 4.\n Route the nets by using the route_group command, as described in  Routing Critical Nets.\n 5.\n Remove the routing corridors, as described in  Removing Routing Corridors.\n See Also \u2022 Reporting Routing Corridors"}
{"header": "How do I Assigning Nets to a Routing Corridor", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A routing corridor restricts Zroute global routing for specific nets to the region defined by a set of connected rectangles.\n In addition to specifying the region in which the routing occurs, you can also specify the minimum and maximum routing layers for each of the rectangles that comprise the routing corridor.\n Routing corridors are intended to be used to route critical nets before signal routing.\n Zroute global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations.\n Note: If a routing guide overlaps with a routing corridor and its attributes conflict with the routing corridor, the routing corridor takes precedence.\n For example,  Figure\u00a0105 shows a routing corridor named corridor_1, which is made up of six rectangles.\n This routing corridor is associated with the nets shown in yellow.\n The figure on the left shows the nets before routing, while the figure on the right shows the nets routed within the routing corridor.\n Figure 105 Using a Routing Corridor Before routing After routing To define a routing corridor, use the  create_routing_corridor command.\n At a minimum, you must define the boundary of the routing corridor.\n \u2022 To create a rectangular routing corridor, use the  -boundary option to specify the lower- left and upper-right corners of the rectangle using the following syntax:  {\u00a0{ llx lly } { urx ury }\u00a0}.\n \u2022 To create a rectilinear routing corridor, use the  -boundary option to specify the coordinates of the polygon using the following syntax:  {\u00a0{ x1 y1 }\u00a0{ x2 y2 }\u00a0...\n }.\n       \u2022 To create a path-based routing corridor, use the  -path option to specify the path and the  -width option to specify the width in microns.\n Specify the path using the following syntax:  {\u00a0{ x1 y1 }\u00a0{ x2 y2 }\u00a0...\n }.\n By default, path-based routing corridors have flush end caps at the start and end of the path.\n To change the end cap style, use the  -start_endcap and  -end_endcap options.\n Valid styles are  flush,  full_width, and  half_width.\n By default, the tool creates a routing corridor named CORRIDOR_ objId in the current block that honors the existing minimum and maximum routing layer constraints (for information about specifying routing layer constraints, see  Specifying the Routing Resources ).\n Use the following options to change the default behavior.\n \u2022 To specify a name for the routing corridor, use the  -name option.\n \u2022 To create the routing guide in a different physical cell, use the  -cell option.\n When you use this option, the tool creates the routing guide in the cell's reference block using the coordinate system of the cell's top-level block.\n \u2022 To specify the minimum and maximum routing layers for the routing corridor, use the -min_layer_name and  -max_layer_name options.\n Specify the routing layers by using the layer names from the technology file."}
{"header": "How do I Verifying Routing Corridors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To assign nets and supernets to a routing corridor, use the  add_to_routing_corridor command.\n You must specify the routing corridor and the nets or supernets to add to it.\n You can assign a net or supernet to only one routing corridor and that routing corridor must cover all pins connected to the associated nets.\n In addition, the supernets must belong to the same block as the routing corridor.\n For example, to define a routing corridor named corridor_a and assign the nets named n1 and n2 to this routing corridor, use the following commands: fc_shell>\u00a0 create_routing_corridor -name corridor_a \\ -boundary { {10 10} {20 35} } \\ -min_layer_name M2 -max_layer_name M4 fc_shell>\u00a0 create_routing_corridor_shape -routing_corridor corridor_a \\ -boundary { {20 25} {40 35} } \\ -min_layer_name M2 -max_layer_name M4 fc_shell>\u00a0 create_routing_corridor_shape -routing_corridor corridor_a \\ -boundary { {40 10} {50 35} } \\ -min_layer_name M2 -max_layer_name M4 fc_shell>\u00a0 add_to_routing_corridor corridor_a [get_nets {n1 n2}]       Note: You can also assign nets or supernets to the routing corridor by using the -object option when you use the  create_routing_corridor command to create the routing corridor."}
{"header": "How do I Modifying Routing Corridors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To successfully route a net within a routing corridor, the routing corridor must meet the following requirements: \u2022 It must be a contiguous region; all regions that comprise the routing corridor must be connected.\n \u2022 It must contain the pins that connect to the nets and supernets associated with the routing corridor.\n To verify that a routing corridor meets these requirements, use the check_routing_corridors command.\n fc_shell>\u00a0 check_routing_corridors RC_0 You can view the errors detected by the  check_routing_corridors command in the message browser."}
{"header": "How do I Reporting Routing Corridors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can make the following modifications to an existing routing corridor: \u2022 Add new shapes to the routing corridor.\n To add new shapes, use the  create_routing_corridor_shape command.\n Use the -routing_corridor option to specify the routing corridor that you want to update.\n You must specify the boundary of the routing corridor by using the  -boundary or -path option (for details about these options, see  Defining Routing Corridors ).\n You can also specify the minimum and maximum routing layers for the shape by using the -min_layer_name and  -max_layer_name options.\n \u2022 Remove rectangles from the routing corridor.\n To remove shapes, use the  remove_routing_corridor_shapes command.\n \u2022 Change the nets and supernets associated with the routing corridor.\n To add nets or supernets to a routing corridor, use the  add_to_routing_corridor command.\n To remove nets or supernets from a routing corridor, use the remove_from_routing_corridor command.\n You can also modify routing corridors in the GUI by using the Create Route Corridor tool, the Move/Resize tool, or the Delete tool, or by editing the attributes in the Properties dialog box."}
{"header": "How do I Removing Routing Corridors", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the routing corridors in your block, use the  report_routing_corridors command.\n By default, the command reports all routing corridors; to report specific routing corridors, specify the routing corridors to report.\n By default, the command reports the following information for each routing corridor: its name; the shapes associated with the routing corridor, including their names, minimum routing layer, maximum routing layer, and boundary; the connectivity of the routing corridor shapes; and the nets and supernets associated with the routing corridor.\n To output a Tcl script that re-creates the routing corridors, use the  -output option.\n To report the routing corridor for a specific net or supernet, use the get_routing_corridors command.\n When you run this command, you must use the -of_objects option to specify the nets of interest."}
{"header": "How do I Using Nondefault Routing Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove routing corridors from the current block, use the  remove_routing_corridors command.\n \u2022 To remove specific routing corridors, specify the routing corridors, either as a list or collection, such as that returned by the  get_routing_corridors command.\n \u2022 To remove all routing corridors, specify the  -all option.\n You can also remove routing corridors in the GUI by using the Delete tool."}
{"header": "How do I Defining Nondefault Routing Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute supports the use of nondefault routing rules, both for routing and for shielding.\n \u2022 For routing, you can use nondefault routing rules to define stricter wire width and spacing rules, to define the pin tapering distance, to specify the vias used when routing nets with nondefault routing rules, and to specify multiple-patterning mask constraints.\n \u2022 For shielding, you can use nondefault routing rules to define the minimum width and spacing rules.\n For information about working with nondefault routing rules, see the following topics: \u2022 Defining Nondefault Routing Rules \u2022 Reporting Nondefault Routing Rule Definitions \u2022 Removing Nondefault Routing Rules \u2022 Modifying Nondefault Routing Rules       \u2022 Assigning Nondefault Routing Rules to Nets \u2022 Reporting Nondefault Routing Rule Assignments"}
{"header": "How do I Assigning Nondefault Routing Rules to Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a nondefault routing rule, use the  create_routing_rule command.\n When you define a nondefault routing rule, you must specify a name for the nondefault routing rule.\n You use the name to assign the nondefault routing rule to nets or clocks.\n The following topics describe how to create nondefault routing rules for various purposes: \u2022 Defining Minimum Wire Width Rules \u2022 Defining Minimum Wire Spacing Rules \u2022 Defining Minimum Via Spacing Rules \u2022 Specifying Nondefault Vias \u2022 Specifying Mask Constraints \u2022 Defining Shielding Rules \u2022 Reporting Nondefault Routing Rule Definitions \u2022 Removing Nondefault Routing Rules \u2022 Modifying Nondefault Routing Rules You can create a single routing rule that serves multiple purposes.\n In addition, you can assign multiple nondefault routing rules to a net.\n Defining Minimum Wire Width Rules You can define nondefault minimum wire width rules that are stricter than the minimum width rules defined in the technology file.\n Nondefault minimum width rules are hard constraints, which must be met during routing.\n Note: If you specify a nondefault width that violates the  signalRouteMaxWidth setting in the technology file, the tool ignores the nondefault width.\n       The minimum width defined in a nondefault routing rule applies to all metal segments, including via enclosures.\n To avoid DRC violations, ensure that the enclosures for nondefault vias meet the minimum width rule.\n To define a minimum wire width rule, use the  create_routing_rule command.\n You can specify the minimum width by specifying a multiplier that is applied to the default width for each layer, by specifying the minimum width in microns for each layer, or both.\n \u2022 To use a multiplier to specify the minimum width, use the following syntax: create_routing_rule\u00a0 rule_name [-default_reference_rule\u00a0|\u00a0-reference_rule_name\u00a0 ref_rule ] -multiplier_width\u00a0 multiplier The multiplier value must be between 0.001 and 2000.\n The default width for each layer is determined from the reference rule, which is either the default routing rule or the reference rule specified in the  -reference_rule_name option.\n For example, to define a nondefault routing rule named new_width_rule that uses the default routing rule as the reference rule and defines the nondefault width as two times the default width, use the following command: fc_shell>\u00a0 create_routing_rule new_width_rule -multiplier_width 2.0 \u2022 To specify the minimum width values for each layer, use the following syntax: create_routing_rule\u00a0 rule_name [-default_reference_rule\u00a0|\u00a0-reference_rule_name\u00a0 ref_rule ] -widths\u00a0{ layer 1 width 1 layer 2 width 2 \u2026\u00a0 layer n width n } Specify the routing layers by using the layer names from the technology file.\n You can specify a single width value per layer.\n Zroute uses the wire width from the reference rule, which is either the default routing rule or the reference rule specified in the -reference_rule_name option, for any layers not specified in the  -widths option.\n For example, to define a nondefault routing rule named new_width_rule2 that uses the default routing rule as the reference rule and defines nondefault width rules for the M1 and M4 layers, use the following command: fc_shell>\u00a0 create_routing_rule new_width_rule2 \\ -widths {M1 0.8 M4 0.9} \u2022 If you specify both with  -multiplier_width option and the  -widths option, the tool uses the  -widths option to determine the base width, and then applies the multiplier to that value to determine the minimum width requirement.\n For example, to define a nondefault routing rule named new_width_rule3 that uses the default routing rule as the reference rule and defines the nondefault width as 0.8 for the       M1 layer, 0.9 for the M4 layer, and two times the default width for all other layers, use the following command: fc_shell>\u00a0 create_routing_rule new_width_rule3 \\ -multiplier_width 2.0 -widths {M1 0.4 M4 0.45} Defining Minimum Wire Spacing Rules You can define nondefault minimum wire spacing rules that are stricter than the rules defined in the technology file.\n Nondefault wire spacing rules can be defined as hard constraints, which must be met, or as soft constraints, which Zroute tries to meet.\n Note: The spacing rules defined in the technology file are always considered hard constraints.\n By default, Zroute checks the nondefault spacing rules between signal nets and other signal nets, PG nets, and blockages, but not between shapes of the same signal net or between signal nets and shield wires for PG nets.\n For information about modifying these checks, see  Configuring Nondefault Spacing Checks.\n To define a minimum wire spacing rule, use the  create_routing_rule command.\n You can specify the minimum spacing by specifying a multiplier that is applied to the default spacing for each layer, by specifying the minimum spacings in microns for each layer, or both.\n \u2022 To use a multiplier to specify the minimum spacing, use the following syntax: create_routing_rule\u00a0 rule_name [-default_reference_rule\u00a0|\u00a0-reference_rule_name\u00a0 ref_rule ] -multiplier_spacing\u00a0 multiplier The multiplier value must be between 0.001 and 2000.\n The default wire spacing for each layer is determined from the reference rule, which is either the default routing rule or the reference rule specified in the  -reference_rule_name option.\n For example, to define a nondefault routing rule named new_spacing_rule that uses the default routing rule as the reference rule and defines the nondefault spacing as two times the default spacing, use the following command: fc_shell>\u00a0 create_routing_rule new_spacing_rule \\ -multiplier_spacing 2.0 \u2022 To specify the minimum spacing values for each layer, use the following syntax: create_routing_rule\u00a0 rule_name -spacings\u00a0{\u00a0 layer 1 { spacing 11 spacing 12 ...\n spacing 1n } layer 2 { spacing 21 spacing 22 ...\n spacing 2n }...\n layer n { spacing n1 spacing n2 ...spacing nn }\u00a0} -spacing_weight_levels\u00a0{\u00a0 layer 1 { weight 11 weight 12 ...\n weight 1n }       layer 2 { weight 21 weight 22 ...\n weight 2n }...\n layer n { weight n1 weight n2 ...\n weight nn }\u00a0} Specify the routing layers by using the layer names from the technology file.\n You can define multiple spacing values per layer.\n Zroute uses the spacing values from the reference rule, which is either the default routing rule or the reference rule specified in the  -reference_rule_name option, for any layers not specified in the  -spacings option.\n If you specify more than one spacing value per layer, you must assign a weight to each spacing value by using the  -spacing_weight_levels option.\n The valid weight values are  low,  medium,  high, and  hard.\n When you assign a weight level other than hard, the spacing rule is a soft spacing rule.\n By default, Zroute does not fix soft routing rule violations.\n To fix soft routing rules, you must map the weight levels to routing effort levels, as described in  Specifying the Routing Effort for Soft Spacing Violations.\n For example, to define a nondefault routing rule named new_spacing_rule2 that uses the default routing rule as the reference rule and defines nondefault spacing rules for the M1 and M4 layers, use the following command: fc_shell>\u00a0 create_routing_rule new_spacing_rule2 \\ -spacings { M1 {0.12 0.24} M4 {0.14 0.28} } \\ -spacing_weight_levels { M1 {hard medium} M4 {hard medium} } \u2022 If you specify both with  -multiplier_spacing option and the  -spacings option, the tool uses the  -spacings option to determine the base spacing, and then applies the multiplier to that value to determine the minimum wire spacing requirement.\n To limit spacing to one side of the net, use the  -single_side_spacing option with the create_routing_rule command.\n For example, the following command creates single-side spacing rules on the M2, M3, and M4 metal layers METAL2, METAL3, and METAL4: fc_shell>\u00a0 create_routing_rule new_spacing_rule3 \\ -spacings {M2 1.300 M3 1.400 M4 1.500 } \\ -single_side_spacing  \\ -widths {M1 0.230 M2 0.280 M3 0.280 M4 0.280 M5 0.280 M6 0.440}       Configuring Nondefault Spacing Checks You can configure the checking of nondefault spacing rules by enabling or disabling checks between signal nets and other objects.\n In addition, you can ignore"}
{"header": "How do I Assigning Nondefault Routing Rules to Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "violations of nondefault spacing rules for short parallel distances.\n \u2022 To honor nondefault spacing rules between shapes of the same signal net, set the route.detail.var_spacing_to_same_net application option to  true.\n \u2022 To honor nondefault spacing rules between signal nets and shield wires for PG nets \u25e6 For all signal nets, set the  route.common.ignore_var_spacing_to_shield application option to  false \u25e6 For specific signal nets, use the  -ignore_spacing_to_shield\u00a0false option when you define the nondefault spacing rule with the  create_routing_rule command \u2022 To ignore nondefault spacing rules between signal nets and PG nets \u25e6 For all signal nets, set the  route.common.ignore_var_spacing_to_pg application option to  true \u25e6 For specific signal nets, use the  -ignore_spacing_to_pg\u00a0true option when you define the nondefault spacing rule with the  create_routing_rule command Note: When you ignore nondefault spacing rules between signal nets and PG nets, the rules are also ignored between the signal nets and the shield wires regardless of the setting of the  route.common.ignore_var_spacing_to_shield and create_routing_rule\u00a0-ignore_spacing_to_shield options.\n \u2022 To ignore nondefault spacing rules between signal nets and blockages \u25e6 For all signal nets, set the  route.common.ignore_var_spacing_to_blockage application option to  true \u25e6 For specific signal nets, use the  -ignore_spacing_to_blockage\u00a0true option when you define the nondefault spacing rule with the  create_routing_rule command       You can relax the nondefault spacing checks for specific nondefault routing rules by ignoring violations for short parallel distances, as shown in  Figure\u00a0106.\n This technique increases the flexibility of DRC convergence without adversely affecting crosstalk.\n Figure 106 Ignoring Nondefault Spacing Rule Violations To define the length thresholds within which to ignore the nondefault spacing violations, use the  -spacing_length_thresholds option when you create the nondefault routing rule with the  create_routing_rule command.\n The length threshold values are in microns and must have a one-to-one correspondence with the spacing entries specified in the -spacings option.\n For example, fc_shell>\u00a0 create_routing_rule new_rule \\ -spacings { M1 {0.09 0.15 0.2} M2 {0.09 0.15 0.2} M3 {0.09 0.15 0.2} } \\ -spacing_weight_levels { M1 {hard medium low} M2 {hard medium low} M3 {hard medium low} } \\ -spacing_length_thresholds { M1 {0.01 0 0} M2 {0.01 0 0} M3 {0.01 0 0} } Specifying the Routing Effort for Soft Spacing Violations By default, Zroute does not fix soft spacing violations.\n To fix soft spacing violations, you must assign a routing effort to each of the soft weight levels.\n These assignments apply to all soft spacing rules.\n       To assign a routing effort for each weight level, use the following syntax to set the route.common.soft_rule_weight_to_effort_level_map application option: set_app_options -name\u00a0route.common.soft_rule_weight_to_effort_level_map -value\u00a0{\u00a0{ weight effort }\u00a0...\n } Each  weight argument can be one of  low,  medium, or  high.\n You should specify each weight level only one time; if you specify a weight level multiple times, the router uses the last specification.\n Each  effort argument can be one of the following values: \u2022 off (the default) Zroute does not fix the soft spacing rule violations.\n \u2022 low Zroute uses a small number of rip-up and reroute passes to resolve soft spacing rule violations.\n \u2022 medium Zroute uses a medium number of rip-up and reroute passes to resolve soft spacing rule violations.\n Note that you cannot specify this effort level for the  low weight level.\n \u2022 high Zroute treats soft spacing rule violations the same as regular design rule violations during rip up and reroute.\n Note that you cannot specify this effort level for the  low weight level.\n For example, to assign low routing effort to low-weight soft spacing rules, medium routing effort to medium-weight soft spacing rules, and high routing effort to high-weight soft spacing, use the following command: fc_shell>\u00a0 set_app_options \\ -name route.common.soft_rule_weight_to_effort_level_map \\ -value { {low low} {medium medium} {high high} } Defining Minimum Via Spacing Rules You can define nondefault minimum via spacing rules that are stricter than the rules defined in the technology file.\n Nondefault via spacing rules are hard constraints that must be met.\n To define a minimum via spacing rule, use the  -via_spacings option with the create_routing_rule command using the following syntax: create_routing_rule\u00a0 rule_name -via_spacings\u00a0{\u00a0{ layer1 layer2 spacing }\u00a0...\n }       Specify the routing layers by using the layer names from the technology file.\n You can define a single width value per layer pair.\n The minimum via spacing for vias between any unspecified layer combinations is determined from the technology file.\n For vias on the same layer, the router uses the minimum spacing defined in the  Layer section for the via layer.\n For vias on different layers, the router uses the minimum spacing defined in the  DesignRule section for the via layer combination.\n For example, to define a nondefault routing rule named via_spacing_rule that defines nondefault spacing rules between vias on the V1 layer and between vias on the V1 and V2 layers, and uses the minimum spacing rules defined in the technology file between vias on all other layer combinations, use the following command: fc_shell>\u00a0 create_routing_rule via_spacing_rule \\ -via_spacings {{V1 V1 2.3} {V1 V2 3.2}} Specifying Nondefault Vias By default, when routing nets with nondefault routing rules, Zroute selects vias based on the design rules.\n To specify the vias to use when routing nets with nondefault routing rules, use the create_routing_rule command.\n You can define the nondefault vias by using either the -cuts option or the  -vias option.\n \u2022 When you use the  -cuts option, the tool determines the suitable via definitions from the technology file based on the specification in the  -cuts option and the rules defined in the technology file.\n \u2022 When you use the  -vias option, you explicitly specify the nondefault via definitions, including the allowed cut numbers and rotation for each via definition.\n Specifying Nondefault Vias Using the -cuts Option The syntax for specifying nondefault vias using the  -cuts option is create_routing_rule\u00a0 rule_name -cuts\u00a0{\u00a0{ cut_layer1 { cut_name1,\u00a0 ncuts }\u00a0{ cut_name2,\u00a0 ncuts }\u00a0\u2026} { cut_layer2 { cut_name1,\u00a0 ncuts }\u00a0{ cut_name2,\u00a0 ncuts }\u00a0\u2026}...\n { cut_layern { cut_name1,\u00a0 ncuts }\u00a0{ cut_name2,\u00a0 ncuts }\u00a0\u2026} } The  cut_layer arguments refer to the via layer names in the technology file and the cut_name arguments refer to the cut names defined in the  cutNameTbl attribute in the associated  Layer section in the technology file.\n You can specify multiple cut names per layer.\n For each cut name, you must specify the minimum number of cuts, which must be an integer between 1 and 255.\n       The tool searches for the vias defined in the  ContactCode section of the technology file that meet the rules defined in the technology file for the specified cut name, such as the cutWidthTbl,  cutHeightTbl, and  fatTblFatContactNumber rules.\n In addition, the width of the via enclosure must meet the nondefault width and the  xLegalWidthTbl and yLegalWidthTbl rules defined in the technology file for the adjacent metal layers.\n If the fat metal contact rule is not defined for a via layer, the tool searches for the default vias that meet the cut width, cut height, and via enclosure width requirements.\n The minimum number of cuts required is the larger of the  ncuts value in the  -cuts option and the value defined in the  fatTblFatContactMinCuts attribute.\n For the selected vias, the tool always allows both the rotated and unrotated orientations for the via.\n For example, assume the following information is defined in the technology file: Layer\u00a0\"VIA1\"\u00a0{ fatTblThreshold\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0(\u00a00,\u00a00.181,\u00a00.411\u00a0) fatTblFatContactNumber"}
{"header": "How do I Assigning Nondefault Routing Rules to Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "=\u00a0(\u00a0\"2,3,4,5,6\u00a0\",\"5,6,20\",\u00a0\"5,6,20\"\u00a0) fatTblFatContactMinCuts\u00a0=\u00a0(\u00a0\"1,1,1,1,1\",\u00a0\"1,1,1\",\u00a0\u00a0\"2,2,2\"\u00a0)  cutNameTbl\u00a0\u00a0\u00a0=\u00a0(\u00a0\u00a0Vsq,\u00a0\u00a0Vrect\u00a0) cutWidthTbl\u00a0\u00a0=\u00a0(\u00a0\u00a00.05,\u00a0\u00a00.05\u00a0\u00a0) cutHeightTbl\u00a0=\u00a0(\u00a0\u00a00.05,\u00a0\u00a00.13\u00a0\u00a0) \u2026 }  ContactCode\u00a0\"VIA12_LH\"\u00a0{ contactCodeNumber\u00a0=\u00a05 cutWidth\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.13 cutHeight\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.05 \u2026 } ContactCode\u00a0\"VIA12_LV\"\u00a0{ contactCodeNumber\u00a0=\u00a06 cutWidth\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.05 cutHeight\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.13 \u2026 } ContactCode\u00a0\"VIA12_P\"\u00a0{ contactCodeNumber\u00a0=\u00a020 cutWidth\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.05 cutHeight\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a00.05 \u2026 } If you use the following command, fc_shell>\u00a0 create_routing_rule cut_rule -cuts {VIA1 {Vrect 1}} The tool selects the following vias: {VIA12_LH 1x1 R}, {VIA12_LH 1x1 NR}, {VIA12_LV 1x1 R}, {VIA12_LV 1x1 NR}, {VIA12_LH 1x2 R}, {VIA12_LH 1x2 NR}, {VIA12_LH 2x1       R}, {VIA12_LH 2x1 NR}, {VIA12_LV 1x2 R}, {VIA12_LV 1x2 NR}, {VIA12_LV 2x1 R}, and {VIA12_LV 2x1 NR}.\n Specifying Nondefault Vias Using the -vias Option The syntax for specifying nondefault vias using the  -vias option is create_routing_rule\u00a0 rule_name -vias\u00a0{\u00a0{ via_type 1 cut_number 1 orientation 1 } { via_type 2 cut_number 2 orientation 2 }...\n { via_type n cut_number n orientation n } } You can specify multiple via types per layer; each via type must be a via definition defined in the technology file or a via definition created by the  create_via_def command.\n For each via type, you must explicitly specify the allowed cut numbers and orientation.\n To specify the orientation, use  NR to indicate that the via is not rotated or  R to indicate that the via is rotated.\n The order of via specification is not important; during routing, Zroute selects the lowest cost nondefault via.\n For example, to specify the vias selected by the  -cuts option in the previous example, use the following command: fc_shell>\u00a0 create_routing_rule via_rule \\ -vias { {VIA12_LH 1x1 R} {VIA12_LH 1x1 NR} {VIA12_LV 1x1 R} {VIA12_LV 1x1 NR} {VIA12_LH 1x2 R} {VIA12_LH  1x2 NR} {VIA12_LH 2x1 R} {VIA12_LH  2x1 NR} {VIA12_LV 1x2 R} {VIA12_LV 1x2 NR} {VIA12_LV 2x1 R} {VIA12_LV 2x1 NR} } Specifying Mask Constraints If you are using the precolored design flow for a design that uses multiple-patterning technology, you can set mask constraints on timing-critical nets, such as clock nets, by defining a precoloring rule and applying it to the nets.\n For details about the mask constraints, see  Mask Constraints.\n To define a precoloring rule, use the  create_routing_rule command using the following syntax: create_routing_rule\u00a0 rule_name -mask_constraints { layer 1 constraint 1 layer 2 constraint 2 \u00a0...\n  layer n constraint n } where  constraint is one of  same_mask,  mask1_soft, or  mask2_soft.\n For example, to define a precoloring routing rule that sets  mask_one constraints on the M4 and M5 layers, use the following command: fc_shell>\u00a0 create_routing_rule clock_mask1 \\ -mask_constraints {M4 mask_one M5 mask_one}       Note: To ensure DRC convergence, you should set double-patterning mask constraints only on a very few timing-critical nets.\n Defining Shielding Rules To define shielding rules, use the  create_routing_rule command using the following syntax: create_routing_rule\u00a0 rule_name -shield_widths\u00a0{ layer 1 width 1 layer 2 width 2 \u2026\u00a0 layer n width n } -shield_spacings\u00a0{ layer 1 spacing 1 layer 2 spacing 2 \u2026\u00a0 layer n spacing n } [-snap_to_track] Specify the routing layers by using the layer names from the technology file.\n You can define a single width and spacing value per layer.\n Zroute uses the default wire width for any layers not specified in the  -shield_widths option and the default spacing for any layers not specified in the  -shield_spacings option.\n By default, shielding wires are not snapped to the routing tracks.\n To snap shielding wires to the routing tracks, use the  -snap_to_track option when you define the nondefault routing rule.\n For example, to specify a shielding rule that uses spacing of 0.1 microns and a width of 0.1 microns for M1 through M5 and spacing of 0.3 microns and a width of 0.3 microns for M6, use the following command: fc_shell>\u00a0 create_routing_rule shield_rule \\ -shield_widths {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} \\ -shield_spacings {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} Reporting Nondefault Routing Rule Definitions To report the nondefault routing rules defined by the  create_routing_rule command, use the  report_routing_rules\u00a0-verbose command.\n By default, this command reports all of the nondefault routing rules for the current block.\n To limit the report to specific nondefault routing rules, specify the rule names as an argument to the command.\n fc_shell>\u00a0 report_routing_rules { rule_names } To output a Tcl script that contains the  create_routing_rule commands used to define the specified nondefault routing rules, use the  -output option when you run the report_routing_rules command.\n Removing Nondefault Routing Rules To remove nondefault routing rules from the current block, use the remove_routing_rules command.\n When you remove a nondefault routing rule, the rule       is removed from all nets to which it is applied and the rule definition is removed from the design library.\n \u2022 To remove specific routing rules, specify the routing rules.\n \u2022 To remove all routing rules, specify the  -all option.\n For example, to remove the new_width_rule routing rule, use the following command: fc_shell>\u00a0 remove_routing_rules new_width_rule Modifying Nondefault Routing Rules To change the definition for an existing rule, you must use the  remove_routing_rules command to remove the rule and then use the  create_routing_rule command to redefine the rule.\n The tool issues an error message if you try to redefine an existing routing rule."}
{"header": "How do I Controlling Off-Grid Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides two commands for assigning nondefault routing rules to nets: \u2022 set_clock_routing_rules This command assigns nondefault routing rules to clock nets before clock tree synthesis.\n During clock tree synthesis and optimization, the tool propagates the nondefault routing rules to the newly created clock nets.\n \u2022 set_routing_rule This command assigns nondefault routing rules to signal nets and to clock nets after clock tree synthesis.\n The following topics describe how to assign nondefault routing rules to nets: \u2022 Assigning Nondefault Routing Rules to Clock Nets \u2022 Assigning Nondefault Routing Rules to Signal Nets \u2022 Reporting Nondefault Routing Rule Assignments Assigning Nondefault Routing Rules to Clock Nets To assign a clock routing rule to a clock net, use the  -rule option with the set_clock_routing_rules command.\n The specified rule must be a rule that you previously defined with the  create_routing_rule command.\n To reset a clock routing rule to the default routing rule, use the  -default_rule option.\n To change a clock routing rule, first reset it to the default routing rule and then use the  -rule option after resetting the assignment to the default routing rule.\n       By default, the  set_clock_routing_rules command assigns the specified clock routing rule to all clock trees in the block.\n  Table\u00a031  shows the options used to restrict the routing rule assignment.\n Table 31 Restricting Clock Routing Rule Assignments To assign a nondefault routing rule to Use this option  -clocks\u00a0 clocks 2 -net_type\u00a0root 2 -net_type\u00a0sink  2 -net_type\u00a0internal  -nets\u00a0 nets Figure\u00a0107 shows the root, internal, and sink nets of a clock tree after clock tree synthesis.\n By default, the root-net routing rule is applied to all the single-fanout clock nets starting from the clock root up to the point where the clock tree branches out to a fanout of more than one.\n Internal-net routing rules are applied to the nets from this point until the sink nets.\n Figure 107 Root, Internal, and Sink Clock Net Types Sink nets Internal nets Root nets 200 sinks 200 sinks 200 sinks The following example specifies routing rules for the root, internal, and sink nets: fc_shell>\u00a0 set_clock_routing_rules -rules NDR1 -net_type root fc_shell>\u00a0 set_clock_routing_rules -rules NDR2 -net_type internal fc_shell>\u00a0 set_clock_routing_rules -rules NDR3 -net_type sink 2.\n You can use this option with the  -clocks option to further restrict the assignment.\n This option is not valid with the -nets option.\n       To specify a transitive fanout limit to use when identifying root nets, use the set_clock_tree_options\u00a0-root_ndr_fanout_limit command.\n For example, to specify that any clock net with a transitive fanout of more than 300 be considered as a root net, use the following command: fc_shell>\u00a0 set_clock_tree_options -root_ndr_fanout_limit 300 Figure\u00a0108 shows the root, internal, and sink nets of the same clock tree when a transitive fanout limit of 300 is used for identifying the clock root nets.\n Figure 108 Using a Fanout Limit for Selecting Root Nets Sink nets Internal nets Root nets 200 sinks 200 sinks 200 sinks When calculating the transitive fanout of clock nets for the purpose of identifying root nets, the tool includes only the valid clock sinks; It does not include the ignore pins.\n If a net identified as a root net is less than 10 microns, the tool uses internal-net routing rules for that net.\n Note: Specifying a smaller value with the  set_clock_tree_options -root_ndr_fanout_limit command increases the number of clock nets that are assigned the root-net routing rule, which can increase routing congestion.\n During clock tree synthesis and optimization, the tool also honors nondefault routing rules set by using the  set_routing_rule command.\n However, the tool does not propagate these routing rules to any new clock nets it creates.\n If a net is assigned more than one nondefault routing rule, the tool uses the following priority to determine the effective routing rule: 1.\n Nondefault routing rule set by the  set_routing_rule command 2.\n Net-specific clock routing rule set by the  set_clock_routing_rules\u00a0-nets command       3.\n Clock-specific clock routing rule set by the  set_clock_routing_rules\u00a0-clocks command 4.\n Global clock routing rule set by the  set_clock_routing_rules command Assigning Nondefault Routing Rules to Signal Nets To assign a nondefault routing rule to a net, use the  -rule option with the set_routing_rule command.\n The specified rule must be a rule that you previously defined with the  create_routing_rule command.\n You must specify the nets to which to assign the nondefault routing rule.\n You can assign multiple nondefault routing rules to a net.\n To change the routing rule assignment for one or more nets, \u2022 Use the  -default_rule option to reset the nets to the default routing rule.\n To assign different nondefault routing rules to the nets, use the  -rule option after resetting the nets to the default routing rule.\n \u2022 Use the  -no_rule option to remove all routing rules from the nets and allow the tool to automatically assign a routing rule to them.\n \u2022 Use the  -clear option to remove all routing rules and net-specific layer constraints from the nets.\n For example, to assign a nondefault routing rule called WideMetal to the CLK net, use the following command: fc_shell>\u00a0 set_routing_rule -rule WideMetal [get_nets CLK] To reset the routing rule for the CLK net to the default routing rule, use the following command: fc_shell>\u00a0 set_routing_rule -default_rule [get_nets CLK] Reporting Nondefault Routing Rule Assignments The Fusion Compiler tool provides commands to report the nondefault routing rules assigned by the  set_routing_rule command and the clock routing rules assigned by the set_clock_routing_rules command.\n \u2022 To report the nondefault routing rules assigned by the  set_routing_rule command, use the  -of_objects option with the  report_routing_rules command.\n fc_shell>\u00a0 report_routing_rules -of_objects [get_nets *] \u2022 To report the clock routing rule assignments, use the  report_clock_routing_rules command.\n This command reports only the routing rules assigned by the set_clock_routing_rules command."}
{"header": "How do I Preventing Off-Grid Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can prevent off-grid routing of wires or vias by requiring them to be aligned to the wire track or discourage off-grid routing of vias by increasing the cost associated with off-grid routing."}
{"header": "How do I Discouraging Off-Grid Routing for Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, wires and vias need to be aligned to the wire track grid for a metal layer only if the  onWireTrack or  onGrid attribute is set to 1 in its  Layer section in the technology file.\n To override the technology file settings, set the following application options: \u2022 route.common.wire_on_grid_by_layer_name This option controls off-grid routing for metal layers.\n \u2022 route.common.via_on_grid_by_layer_name This option controls off-grid routing for via layers.\n Use the following syntax to set these options: {\u00a0{ layer true|false}\u00a0...\n } Specify the layers by using the layer names from the technology file.\n Specify  true to forbid off-grid routing and  false to allow off-grid routing.\n If you use either of these options, the tool ignores all settings for the  onWireTrack and onGrid attributes in the technology file and uses only the settings specified by these options.\n If you do not specify a layer in these options, off-grid routing is allowed on that layer, regardless of the setting in the technology file.\n For example, to prevent off-grid routing for wires on the M2 and M3 metal layers and for vias on the V2 via layer, regardless of the settings in the technology file, use the following commands: fc_shell>\u00a0 set_app_options \\ -name route.common.wire_on_grid_by_layer_name \\ -value {{M2 true} {M3 true}} fc_shell>\u00a0 set_app_options \\ -name route.common.via_on_grid_by_layer_name \\ -value {{V2 true}}"}
{"header": "How do I Routing Must-Join Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To discourage off-grid routing for vias, you can increase the cost of routing the via enclosure metal shapes off the wire track grid.\n To specify the extra cost multiplier for the metal layers on which the via enclosures are routed, set the route.common.extra_via_off_grid_cost_multiplier_by_layer_name application option.\n Use the following syntax to set this option: {\u00a0{ layer multiplier }\u00a0...\n } Specify the layers by using the layer names from the technology file.\n The cost multiplier must be a value between 0.0 and 20.0.\n When you specify this option, the effective cost is the base cost times (1+multiplier).\n For example, assume that the technology file defines the VIA12 layer between the M1 and M2 metal layers and the VIA23 via layer between the M2 and M3 metal layers.\n To set the extra cost multiplier for the via enclosures on the M2 metal layer (and therefore the vias on the VIA12 and VIA23 via layers) to 0.5 (for an effective via cost of 1.5 times the base cost), use the following command: fc_shell>\u00a0 set_app_options \\ -name route.common.extra_via_off_grid_cost_multiplier_by_layer_name \\ -value {{M2 0.5}}"}
{"header": "How do I Controlling Pin Connections", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When a pin is defined as a must-join pin, the router connects all terminals of the pin as a single net.\n The terminals of a must-join pin are specified with the  must_join_port library pin attribute.\n By default, Zroute connects must-join pins using a random structure, as shown in the following figure: Figure 109 Default Must-Join Pin Connection To achieve better electromagnetic results, Zroute can use the via ladder insertion capabilities to connect the must-join pins with a simplified structure, which is referred to as a pattern-based must-join connection.\n       The following figure shows the simplified structure: Figure 110 Single-Level Pattern-Based Must-Join Pin Connection The single-level structure shown in  Figure\u00a0110 is the default structure used for a pattern- based must-join connection.\n To use a multi-level structure, which is shown in  Figure\u00a0111, set the  route.auto_via_ladder.pattern_must_join_over_pin_layer application option to 2.\n Figure 111 Multi-Level Pattern-Based Must-Join Pin Connection Zroute automatically uses a pattern-based must-join pin connection when a library cell pin has a  pattern_must_join attribute and you use one of the following commands to perform the routing:  route_auto,  route_group, or  route_eco.\n To query cells with the  pattern_must_join attribute, use the following command: fc_shell>\u00a0 get_attribute \\ [get_lib_pins -all -of_objects */*/frame ] pattern_must_join To get a list of pins that are marked with the  pattern_must_join attribute, use the following command: fc_shell>\u00a0 get_lib_pins -all \\ -of_objects */*/frame -filter \"pattern_must_join==true\" By default, a via ladder is not inserted if there are fixed shapes on higher layers that block the insertion.\n To increase the insertion rate, you can allow staggering of the vias on each level of the via ladder to avoid the fixed shapes.\n To specify the maximum number of tracks allowed for staggering on each level, set the route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks application option.\n You can specify a value between 0 and 9 for each level; the default is 0, which disables staggering.\n       For example, to allow staggering of up to three tracks on the first level, use the following command: fc_shell>\u00a0 set_app_options -name \\ route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks \\ -value {3 0} Figure\u00a0112 shows the possible solutions to avoid a blockage on the M3 layer when you allow staggering of up to three tracks.\n Figure 112 Pattern-Based Must-Join Pin Connection With Staggering By default, the pattern-based must-join connections are updated each time you run the route_auto,  route_group, or  route_eco command.\n \u2022 During the  route_group command, the updates are restricted to only those nets specified in the  route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true.\n \u2022 To disable all updates during each of these routing commands, set the route.auto_via_ladder.update_pattern_must_join_during_route application option to  false.\n If Zroute cannot create a pattern-based must-join connection, it reports a \u201cNeeds pattern must join pin connection\u201d DRC violation.\n See Also \u2022 Inserting Via Ladders"}
{"header": "How do I Controlling Pin Tapering", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, Zroute connects a signal route to a pin by using wires or vias anywhere on the pin.\n To restrict the allowed types of pin connections on a per-layer basis, use the following       syntax to set the  route.common.connect_within_pins_by_layer_name application option: set_app_options -name\u00a0route.common.connect_within_pins_by_layer_name -value\u00a0{\u00a0{ layer mode }\u00a0...\n } Valid values for the  mode argument are \u2022 off (the default) There are no restrictions on pin connections.\n \u2022 via_standard_cell_pins Only the connections to standard cell pins by using a via are restricted.\n When using a via connection, the via\u2019s metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to macro cell and pad cell pins by using a via or to any pins by using wires.\n \u2022 via_wire_standard_cell_pins The connections to standard cell pins by using a via or a wire are restricted.\n When using a via connection, the via\u2019s metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n \u2022 via_all_pins The connections to any pins (standard cell, macro cell, or pad cell) by using a via are restricted.\n When using a via connection, the via\u2019s metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to any pins by using wires.\n \u2022 via_wire_all_pins The connections to any pins by using a via or a wire are restricted.\n When using a via connection, the via\u2019s metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n For example, if you use the following command (or use the default settings), all of the connections shown in  Figure\u00a0113 are valid and no DRC violations are reported: fc_shell>\u00a0 set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 off}}       Figure 113 Unrestricted Pin Connections If you set the mode for M1 to  via_all_pins, as shown in the following example, the via enclosures must be inside the pin shape.\n The connections shown on the left side of Figure\u00a0114 are valid; however, the connections on the right side of the figure cause DRC violations.\n fc_shell>\u00a0 set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_all_pins}} Figure 114 Restricted Via-to-Pin Connections No DRC Violations DRC Violations If you set the mode for M1 to  via_wire_standard_cell_pins, as shown in the following example, both the via enclosures and wires must be inside the pin shape.\n The connections       shown on the left side of  Figure\u00a0115 are valid; however the connections on the right side of the figure cause DRC violations.\n fc_shell>\u00a0 set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_wire_standard_cell_pins}} Figure 115 Restricted Via-to-Pin and Wire-to-Pin Connections DRC Violations No DRC Violations"}
{"header": "How do I Specifying the Tapering Method", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Pin tapering is the method used to connect wires with nondefault routing rules to pins.\n Zroute supports pin tapering for both hard and soft nondefault routing rules; the tapering implementation is the same for both types of nondefault routing rules.\n Note: By default, if a net has both a nondefault routing rule defined by the create_routing_rule command and voltage-based spacing rules defined in the technology file, Zroute performs pin tapering on that net based on the nondefault routing rule.\n To disable pin tapering on these nets, set the route.detail.enable_ndr_tapering_on_voltage_rule application option to  false.\n You can specify the method used for pin tapering and control the tapering width, as described in the following topics: \u2022 Specifying the Tapering Method \u2022 Controlling the Tapering Width"}
{"header": "How do I Controlling the Tapering Width", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You specify the tapering method for a nondefault routing rule when you define the rule with the  create_routing_rule command.\n By default, Zroute uses distance-based pin tapering; it uses the default routing rule within the tapering distance from the pin and uses the nondefault routing rule beyond the tapering distance.\n However, advanced process nodes are very sensitive to jogs and fat metal, and sometimes the tapering distance is not sufficient to fix the routing DRC violations on nets with nondefault routing rules.\n In these cases, you can use layer-based tapering, which targets DRC violations on nets with nondefault routing rules.\n Note: Distance-based tapering and layer-based tapering are mutually exclusive.\n If you define a routing rule that uses both a distance-based tapering option and a layer-based tapering option, the tool uses the layer-based tapering settings and ignores the distance-based tapering settings.\n When Zroute performs distance-based pin tapering, it \u2022 Determines the tapering distance, which is about 10 times the mean number of tracks for all routing layers.\n To explicitly specify the tapering distance, use the  -taper_distance option when you create a nondefault routing rule with the  create_routing_rule command.\n \u2022 Uses the same tapering distance for all pins.\n To specify a different tapering distance for driver pins, use the -driver_taper_distance option when you create a nondefault routing rule with the create_routing_rule command.\n To perform layer-based pin tapering, use the  -taper_over_pin_layers or -taper_under_pin_layers option when you create a nondefault routing rule with the  create_routing_rule command.\n To specify a different layer-based tapering distance for driver pins, use the  -driver_taper_over_pin_layers or -driver_taper_under_pin_layers option.\n \u2022 For pins on the M1 or M2 layers, use the  -taper_over_pin_layers option (or the -driver_taper_over_pin_layers option for driver pins) to specify the number of layers on or above the pin layer available for tapering.\n A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers above the pin layer.\n \u2022 For pins on upper layers, use the  -taper_under_pin_layers option (or the -driver_taper_under_pin_layers option for driver pins)to specify the number of layers on or below the pin layer available for tapering.\n A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers below the pin layer."}
{"header": "How do I Controlling Via Ladder Connections", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the wire is tapered to the default routing width, which is the routing width that is defined for the metal layer in the technology file.\n \u2022 To taper the wire to the pin width rather than the default routing width, change the route.detail.pin_taper_mode application option to  pin_width from its default of default_width before you perform detail routing.\n \u2022 To enable pin tapering only when required to avoid DRC violations, set the route.detail.use_wide_wire_effort_level application option to either  low or high.\n This setting improves the nondefault via rate at a cost of longer runtime.\n You should use this option only when the majority of pins on the nets being routed are accessible with nondefault vias.\n \u2022 To disable tapering for certain types of pins, set one or more of the following application options to  true :  route.detail.use_wide_wire_to_input_pin, route.detail.use_wide_wire_to_output_pin, route.detail.use_wide_wire_to_macro_pin, route.detail.use_wide_wire_to_pad_pin, and route.detail.use_wide_wire_to_port.\n \u2022 To disable tapering for all pins, set the  -taper_distance option to 0 when you create the nondefault routing rule with the  create_routing_rule command."}
{"header": "How do I Setting the Rerouting Mode", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If a pin has a via ladder, by default, Zroute connects to the topmost layer of a via ladder and not directly to the existing pin geometry.\n To modify the connection constraints, set the following application options: \u2022 route.detail.via_ladder_upper_layer_via_connection_mode To allow vias to connect to the top level of a via ladder from below, set this application option to  any.\n \u2022 route.detail.allow_default_rule_nets_via_ladder_lower_layer_connection To allow nets with default routing rules to connect directly to the pin or to any layer of the via ladder, set this application option to  true."}
{"header": "How do I Routing Application Options", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, Zroute can reroute nets as needed.\n You can prevent rerouting or limit rerouting to minor changes by setting the  physical_status attribute on the nets.\n \u2022 To freeze the net and prevent rerouting, set the attribute to  locked.\n \u2022 To limit rerouting to minor changes, set the attribute to  minor_change.\n \u2022 To allow Zroute to reroute the nets as needed, set the attribute to  unrestricted.\n For example, to prevent rerouting of the net1 net, which uses the default routing rule, use the following command: fc_shell>\u00a0 set_attribute -objects [get_nets net1] \\ -name physical_status -value locked"}
{"header": "How do I Routing Clock Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides application options that affect the individual routing engines (global routing, track assignment, and detail routing), as well as application options that affect all three routing engines.\n \u2022 For information about the application options that affect all three routing engines, see the  route.common_options man page.\n \u2022 For information about the application options that affect global routing, see the route.global_options man page.\n \u2022 For information about the application options that affect track assignment, see the route.track_options man page.\n \u2022 For information about the application options that affect detail routing, see the route.detail_options man page.\n Zroute uses these option settings whenever you perform routing functions.\n When you run a routing command, Zroute writes the settings for any routing options that you have set (or that the tool has set for you) in the routing log.\n To display the settings for all routing options, not only those that have been set, set the  route.common.verbose_level application option to 1.\n fc_shell>\u00a0 set_app_options \\ -name route.common.verbose_level -value 1"}
{"header": "How do I Routing Critical Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To route clock nets before routing the rest of the nets in the block, use the  route_group command with the appropriate option to select the nets.\n \u2022 To route all clock nets, use the  -all_clock_nets option.\n \u2022 To route specific clock nets, use the  -nets option.\n For example, to route all clock nets, use the following command: fc_shell>\u00a0 route_group -all_clock_nets The  route_group command runs global routing, track assignment, and detail routing on the clock nets.\n \u2022 When routing clock nets, the  route_group command uses A-tree routing to minimize the distance between each pin and driver.\n \u2022 When routing clock mesh nets, by default, the  route_group command uses Steiner routing, which minimizes the total wire length.\n To use comb routing, set the route.common.clock_topology application option to  comb before routing the clock mesh nets.\n \u2022 By default, if the block contains existing global routes, the  route_group command ignores them during global routing.\n To perform incremental global routing by reusing existing global routes, use the  -reuse_existing_global_route\u00a0true option.\n \u2022 If the block contains existing detail routes for the clock nets, the  route_group command performs incremental detail routing.\n \u2022 By default, the detail router performs a maximum of 40 search and repair iterations.\n To modify the maximum number of detail routing iterations, use the -max_detail_route_iterations option.\n Note: Zroute stops before completing the maximum number of iterations if it determines that all violations have been fixed or that it cannot fix the remaining violations."}
{"header": "How do I Routing Secondary Power and Ground Pins", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To route a group of critical nets before routing the rest of the nets in the block, use the route_group command.\n To specify the nets to route, use one of the following options: \u2022 -nets Use this option to specify the nets on the command line: fc_shell>\u00a0 route_group -nets  collection_of_critical_nets \u2022 -from_file Use this option to specify the nets in a file: fc_shell>\u00a0 route_group -from_file  file_name If the specified nets are associated with a routing corridor, the nets are routed within the defined region.\n Note that global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations.\n By default, the  route_group command ignores existing global routes, reuses dangling wires and existing detail routes on the specified nets, and runs global routing, track assignment, and detail routing on the specified nets.\n \u2022 To perform incremental global routing, set the  -reuse_existing_global_route option to  true.\n Note: You cannot use the  -reuse_existing_global_route\u00a0true option when routing the nets in a routing corridor.\n If you use this option, the global router ignores the routing corridors.\n \u2022 To disable the reuse of dangling wires, set the  -utilize_dangling_wires option to false.\n \u2022 To stop after global routing, set the  -stop_after_global_route option to  true.\n By default, the detail router performs a maximum of 40 iterations search and repair iterations.\n If Zroute determines before then that all violations have been fixed or that it cannot fix the remaining violations, it stops.\n To change the maximum number of detail routing iterations, use the  -max_detail_route_iterations option.\n By default, the  route_group command does not fix soft DRC violations, such as bridge rule violations.\n To enable the fixing of soft DRC violations after the final detail routing       iteration, set the  route.common.post_group_route_fix_soft_violations application option to  true.\n fc_shell>\u00a0 set_app_options \\ -name route.common.post_group_route_fix_soft_violations \\ -value true"}
{"header": "How do I Verifying the Secondary Power and Ground Pin Attributes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To use Zroute to perform secondary power and ground pin routing, 1.\n Verify that the secondary power and ground pins have the appropriate attributes in the standard cell frame views.\n 2.\n Set the routing constraints for secondary power and ground pin routing.\n 3.\n Perform secondary power and ground pin routing by using the  route_group command.\n The following topics describe these steps."}
{"header": "How do I Setting the Routing Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you use Zroute to perform secondary power and ground pin routing, you must verify that the cell libraries have the correct attributes on the secondary power and ground pins of the standard cell frame views.\n The following attributes are required for secondary power and ground pins: \u2022 is_secondary_pg This attribute must have a setting of  true.\n \u2022 port_type This attribute must have a setting of  power or  ground.\n To verify that these attributes are correctly set on the library pins in the standard cell frame view, use the following command: fc_shell>\u00a0 report_attributes -application \\ [get_lib_pins -of_objects  reflib / cell /frame -all \\ -filter \"name ==  attr_name \"] where  reflib is the cell library name,  cell is the name of the library cell you want to check (or * if you want to check all library cells), and  attr_name is either  is_secondary_pg or port_type.\n       See Also \u2022 Identifying Secondary PG Pins"}
{"header": "How do I Routing the Secondary Power and Ground Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can set routing constraints for secondary power and ground pin routing in the same way as for regular signal routing.\n For example, you can set constraints by \u2022 Defining the minimum and maximum routing layers by using the  set_routing_rule command For more information about using the  set_routing_rule command, see  Specifying Net-Specific Layer Constraints.\n \u2022 Specifying the preferred pin connections by setting the route.common.single_connection_to_pins and route.common.connect_within_pins_by_layer_name application options For example, to require a single connection to the secondary power and ground pins and require that the M1 connections use vias contained within the pin shapes, use the following command: fc_shell>\u00a0 set_app_options \\ -name route.common.single_connection_to_pins \\ -value standard_cell_pins fc_shell>\u00a0 set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_standard_cell_pins}} \u2022 Defining the maximum number of power or ground pins in a cluster by setting the route.common.number_of_secondary_pg_pin_connections application option A cluster is a set of connected secondary power or ground pins that has one connection to a PG strap or ring.\n By default, the value of this option is 0, which means that there is no limit on the number of secondary power or ground pins in a cluster.\n For example, to connect all secondary power and ground pins directly to a PG strap or ring, use the following command: fc_shell>\u00a0 set_app_options \\ -name route.common.number_of_secondary_pg_pin_connections \\ -value 1       \u2022 Defining a nondefault routing rule for secondary power and ground pin routing For example, to define a nondefault routing rule named wideSVDD for wide M1 and M2 and set the nondefault routing rule on the VDD2 net, to which the secondary power and ground pins are connected, use the following commands: fc_shell>\u00a0 create_routing_rule wideSVDD -widths { M1 0.3 M2 0.3 } fc_shell>\u00a0 set_routing_rule -rule wideSVDD {VDD2} For more information about using nondefault routing rules, see  Using Nondefault Routing Rules.\n By default, the constraints apply to both the secondary power and ground connections and the tie-off connections.\n To separate these connections so that you can set constraints only for the secondary power and ground connections, set the route.common.separate_tie_off_from_secondary_pg application option to  true."}
{"header": "How do I Routing Signal Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "If the secondary power and ground pins have the appropriate attributes in the frame view, you can use Zroute to route the secondary power and ground pins.\n By default, Zroute performs four topology ECO iterations to fix secondary PG cluster fanout violations.The topology ECO iterations can be time consuming, so you can control the effort level, and therefore the runtime, by setting the route.detail.topology_eco_effort_level application option to one of the following values: \u2022 off, which disables topology ECO; this is the default \u2022 low, which peforms one topology ECO iteration \u2022 medium, which peforms four topology ECO iterations \u2022 high, which peforms eight topology ECO iterations For example, to connect the secondary power pins to the VDD1 net, run the following command: fc_shell>\u00a0 route_group -nets VDD1 The following example add new cells, which have secondary power and ground pins, to a block; logically connects the power and ground pins; and then connects the secondary power pins to the VDD2 net.\n fc_shell>\u00a0 add_buffer {TOP/U1001/Z} {libA/BUFHVT} \\ -new_cell_names mynewHVT fc_shell>\u00a0 add_buffer {TOP/U1002/Z} {libA/BUFHVT} \\ -new_cell_names mynewHVT fc_shell>\u00a0 legalize_placement       fc_shell>\u00a0 connect_pg_net -automatic fc_shell>\u00a0 route_group -nets {VDD2}"}
{"header": "How do I Global Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you route the signal nets, all clock nets must be routed without violations.\n You can route the signal nets by using one of the following methods: \u2022 Use the task-specific commands to perform the standalone routing tasks.\n \u25e6 To perform global routing, use the  route_global command.\n For details see,  Global Routing.\n \u25e6 To perform track assignment, use the  route_track command.\n For details see,  Track Assignment.\n \u25e6 To perform detail routing, use the  route_detail command.\n For details see,  Detail Routing.\n When you run a standalone routing command, such as  route_global or route_detail, Zroute reads in the block at the beginning of each routing command and updates the block at the end of each command.\n The router does not check the input data.\n For example, if the track assignment step is skipped and you run detail routing directly, Zroute might generate bad routing results.\n If you need to customize your routing flow or you need to run a large block step-by- step, you might want to use the standalone routing commands instead of automatic routing.\n \u2022 Use automatic routing (the  route_auto command).\n The  route_auto basic command performs global routing, track assignment, and detail routing.\n For details, see  Routing Signal Nets by Using Automatic Routing.\n When you run  route_auto, Zroute reads the block before starting routing and updates the block when all routing steps are done.\n If you stop automatic routing before it performs detail routing, Zroute checks the input data when you restart routing with this command.\n Use the  route_auto command when you run routing to verify convergence, congestion, and design rule quality-of-results (QoR).\n You also might want to use route_auto if congestion QoR is your main goal, rather than timing QoR.\n Zroute can insert redundant vias during signal routing.\n For information about this capability, see  Inserting Redundant Vias on Signal Nets."}
{"header": "How do I Global Routing During Design Planning", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run global routing, \u2022 Define the common routing application options For information about the common routing application options, see the route.common_options man page.\n \u2022 Define the global routing application options For information about the global routing application options, see the route.global_options man page.\n To perform standalone global routing, use the  route_global command.\n By default, global routing is not timing-driven.\n For information about enabling timing-driven global routing, see  Timing-Driven Global Routing.\n The global router divides a block into global routing cells.\n By default, the width of a global routing cell is the same as the height of a standard cell and is aligned with the standard cell rows.\n For each global routing cell, the routing capacity is calculated according to the blockages, pins, and routing tracks inside the cell.\n Although the nets are not assigned to the actual wire tracks during global routing, the number of nets assigned to each global routing cell is noted.\n The tool calculates the demand for wire tracks in each global routing cell and reports the overflows, which are the number of wire tracks that are still needed after the tool assigns nets to the available wire tracks in a global routing cell.\n For advanced node designs, via density can be a concern.\n To enable via density modeling, set the  route.global.via_cut_modeling application option to  true.\n The tool then calculates the number of vias in each global routing cell and reports via overflows.\n Global routing is done in two phases: \u2022 The initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell \u2022 The rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows The tool might perform several rerouting phases.\n At the end of each rerouting phase, the tool recalculates the overflows.\n You should see a reduction in the total number of global routing cells with overflow and in the total overflow numbers.\n The global router stops and exits from the rerouting phase when the congestion is solved or cannot be solved further or after the maximum number of phases has occurred, as defined by the  -effort_level option.\n You can force the global router to perform the maximum number of phases based on the specified effort level by setting the route.global.force_full_effort application option to  true.\n By default, the tool       uses medium effort and performs a maximum of three rerouting phases.\n You can perform up to six rerouting phases by specifying ultra effort.\n There are five global routing effort levels:  minimum,  low,  medium,  high, and  ultra.\n \u25e6 Minimum ( -effort_level\u00a0minimum ) The minimum effort level uses two times larger global routing cells relative to the other effort levels.\n It also has a much lower congestion cost and runs only one rerouting phase.\n It should only be used for prototype routing or for an initial congestion evaluation, not for detail routing.\n \u25e6 Low ( -effort_level\u00a0low ) Low effort runs a maximum of two rerouting phases with very similar congestion cost.\n It is faster in comparison to medium effort and has reasonable QoR.\n If your block is not very congested, you can use the low effort level.\n \u25e6 Medium ( -effort_level\u00a0medium ) Medium effort is the default effort level and runs a maximum of three rerouting phases.\n Global routing stops after the third phase or when the overflow is resolved, whichever occurs first.\n \u25e6 High ( -effort_level\u00a0high ) High effort runs up to four rerouting phases.\n If your block is congested, use the high effort level.\n \u25e6 Ultra ( -effort_level\u00a0ultra ) Ultra effort runs up to six rerouting phases.\n If your block is very congested, use the ultra effort level.\n At the end of global routing, the following information is stored in the design library: \u2022 The g-links and g-vias on each routed net This information is used for the next routing steps.\n After Zroute performs track assignment and detail routing, it removes these g-links and g-vias from the design library.\n \u2022 The congestion data This information is used to generate a congestion map.\n By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the  route.global.export_soft_congestion_maps application option to  true before performing global routing.\n The soft congestion data includes demand from soft nondefault spacing rules, as well as tool-generated soft rules.\n       The global router reports block statistics and congestion data after the initial routing phase and after each rerouting phase.\n When global routing is complete, the global router reports a summary of the wire length and via count.\n Example\u00a019 shows a global routing report.\n In the congestion report, the Overflow value is the total number of wires in the block that do not have a corresponding track available.\n The Max value corresponds to the highest number of overutilized wires in a single global routing cell.\n The GRCs value is the total number of overcongested global routing cells in the block.\n Example 19 Global Routing Report Start\u00a0Global\u00a0Route\u00a0...\n...\n Design\u00a0statistics: Design\u00a0Bounding\u00a0Box\u00a0(0.00,0.00,3180.00,1154.00) Number\u00a0of\u00a0routing\u00a0layers\u00a0=\u00a010 layer\u00a0M1,\u00a0dir\u00a0Hor,\u00a0min\u00a0width\u00a0=\u00a00.05,\u00a0min\u00a0space\u00a0=\u00a00.05\u00a0pitch\u00a0=\u00a00.15 layer\u00a0M2,\u00a0dir\u00a0Ver,\u00a0min\u00a0width\u00a0=\u00a00.06,\u00a0min\u00a0space\u00a0=\u00a00.06\u00a0pitch\u00a0=\u00a00.15...\n Net\u00a0statistics: Total\u00a0number\u00a0of\u00a0nets\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0255165 Number\u00a0of\u00a0nets\u00a0to\u00a0route\u00a0\u00a0=\u00a0248716 Number\u00a0of\u00a0single\u00a0or\u00a0zero\u00a0port\u00a0nets\u00a0=\u00a01721 4728\u00a0nets\u00a0are\u00a0fully\u00a0connected, of\u00a0which\u00a04728\u00a0are\u00a0detail\u00a0routed\u00a0and\u00a00\u00a0are\u00a0global\u00a0routed.\n 1648\u00a0nets\u00a0have\u00a0non-default\u00a0rule\u00a0clock_spacing...\n phase3.\n Routing\u00a0result: phase3.\n Both\u00a0Dirs:\u00a0Overflow\u00a0=\u00a0\u00a03320\u00a0Max\u00a0=\u00a03\u00a0GRCs\u00a0=\u00a0\u00a04405\u00a0(0.08%) phase3.\n H\u00a0routing:\u00a0Overflow\u00a0=\u00a0\u00a01759\u00a0Max\u00a0=\u00a02\u00a0(GRCs\u00a0=\u00a0\u00a01)\u00a0GRCs\u00a0=\u00a0\u00a02756\u00a0(0.10%) phase3.\n V\u00a0routing:\u00a0Overflow\u00a0=\u00a0\u00a01560\u00a0Max\u00a0=\u00a03\u00a0(GRCs\u00a0=\u00a020)\u00a0GRCs\u00a0=\u00a0\u00a01649\u00a0(0.06%) phase3.\n M1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Overflow\u00a0=\u00a0\u00a01475\u00a0Max\u00a0=\u00a02\u00a0(GRCs\u00a0=\u00a0\u00a01)\u00a0GRCs\u00a0=\u00a0\u00a02426\u00a0(0.09%) phase3.\n M2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Overflow\u00a0=\u00a0\u00a01265\u00a0Max\u00a0=\u00a03\u00a0(GRCs\u00a0=\u00a020)\u00a0GRCs\u00a0=\u00a0\u00a01343\u00a0(0.05%)...\n Overflow\u00a0over\u00a0macro\u00a0areas  phase3.\n Both\u00a0Dirs:\u00a0Overflow\u00a0=\u00a0\u00a0\u00a0293\u00a0Max\u00a0=\u00a0\u00a02\u00a0GRCs\u00a0=\u00a0\u00a0\u00a0300\u00a0(0.04%) phase3.\n H\u00a0routing:\u00a0Overflow\u00a0=\u00a0\u00a0\u00a0133\u00a0Max\u00a0=\u00a0\u00a01\u00a0(GRCs\u00a0=\u00a0129)\u00a0GRCs\u00a0=\u00a0\u00a0\u00a0139\u00a0(0.03%) phase3.\n V\u00a0routing:\u00a0Overflow\u00a0=\u00a0\u00a0\u00a0160\u00a0Max\u00a0=\u00a0\u00a02\u00a0(GRCs\u00a0=\u00a0\u00a02)\u00a0GRCs\u00a0=\u00a0\u00a0\u00a0161\u00a0(0.04%) phase3.\n M1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Overflow\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0Max\u00a0=\u00a0\u00a00\u00a0(GRCs\u00a0=\u00a0\u00a00)\u00a0GRCs\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0(0.00%) phase3.\n M2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Overflow\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0Max\u00a0=\u00a0\u00a00\u00a0(GRCs\u00a0=\u00a0\u00a00)\u00a0GRCs\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0(0.00%)...\n Density\u00a0distribution: Layer\u00a0\u00a0\u00a0\u00a00.0\u00a0\u00a00.1\u00a0\u00a00.2\u00a0\u00a00.3\u00a0\u00a00.4\u00a0\u00a00.5\u00a0\u00a00.6\u00a0\u00a00.7\u00a0\u00a00.8\u00a0\u00a00.9\u00a0\u00a01.0\u00a0\u00a01.1\u00a0\u00a01.2\u00a0\u00a0> 1.2 M1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a086.6\u00a010.5\u00a00.37\u00a01.46\u00a00.02\u00a00.44\u00a00.18\u00a00.14\u00a00.07\u00a00.03\u00a00.10\u00a00.00\u00a00.00\u00a00.02 M2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a068.2\u00a014.4\u00a07.71\u00a04.54\u00a02.07\u00a01."}
{"header": "How do I Global Routing During Design Planning", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "55\u00a00.66\u00a00.28\u00a00.13\u00a00.03\u00a00.33\u00a00.00\u00a00.00\u00a00.02...\n phase3.\n Total\u00a0Wire\u00a0Length\u00a0=\u00a021154552.81 phase3.\n Layer\u00a0M1\u00a0wire\u00a0length\u00a0=\u00a0947324.93 phase3.\n Layer\u00a0M2\u00a0wire\u00a0length\u00a0=\u00a03959478.25...\n phase3.\n Total\u00a0Number\u00a0of\u00a0Contacts\u00a0=\u00a02530044 phase3.\n Via\u00a0VIA12SQ_C\u00a0count\u00a0=\u00a01050582 phase3.\n Via\u00a0VIA23SQ_C\u00a0count\u00a0=\u00a0856311...\n phase3.\n completed.\n       Before proceeding to detail routing, display the congestion map in the GUI and check the overflow distribution.\n The congestion report and map help you to identify congested areas.\n For more information about the congestion report, see  Generating a Congestion Report.\n For more information about the congestion map, see  Generating a Congestion Map."}
{"header": "How do I Timing-Driven Global Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During design planning you can perform exploration-mode global routing by using the -floorplan\u00a0true option with the  route_global command.\n fc_shell>\u00a0 route_global -floorplan true If you are using the hierarchical flow, enable virtual-flat global routing by using the  -virtual_flat option with the  route_global command.\n When you set the -virtual_flat option to  all_routing, Zroute routes all the nets in the block and preserves the hierarchy and pin constraints.\n You can increase the virtual-flat global routing speed by routing only the top-level nets.\n To do this, set the  -virtual_flat option to top_and_interface_routing_only.\n When the  -virtual_flat option is set to  off, which is the default, Zroute ignores the physical hierarchy and routes the block as flat.\n fc_shell>\u00a0 route_global -floorplan true -virtual_flat all_routing"}
{"header": "How do I Crosstalk-Driven Global Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  route_global command is not timing-driven.\n To enable timing-driven global routing, set the  route.global.timing_driven application option before you run the  route_global command.\n During timing-driven global routing, the global router considers the impact of layer resistance by minimizing the usage of pin access layers, even if this increases wire length.\n By default, when you enable timing-driven global routing, the tool 1.\n Calculates the net delays of the block If the design library contains global route information, the tool uses the global route information to calculate the net delays; otherwise, it uses virtual routing to calculate the net delays.\n The global routing results can vary depending on whether the initial net delays were calculated by using global route information or virtual routing.\n To remove existing global route information from the signal nets in the block, use the  -global_route and -net_types\u00a0signal options with the  remove_routes command, as shown in the following example: fc_shell>\u00a0 remove_routes -global_route -net_types signal 2.\n Performs an initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell       3.\n Performs two rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows 4.\n Updates the design timing based on the first three global routing phases 5.\n Identifies newly critical nets based on the timing update 6.\n Performs three rerouting phases, in which the tool rips up and reroutes the newly critical nets To increase the number of rerouting phases after the timing update, set the global routing effort level to  high or  ultra by using the  -effort_level option with the  route_global command.\n To reduce runtime, at a possible cost to the timing QoR, set the route.global.advance_node_timing_driven_effort application option.\n \u2022 When you set this application option to  medium, the tool rips up and reroutes the newly critical nets only if doing so does not increase congestion.\n In addition, the number of rerouting phases is reduced for medium-, high-, and ultra-effort global routing.\n \u2022 When you set this application option to  low, the tool does not perform the timing update and the number of rerouting phases is reduced for medium, high-, and ultra- effort global routing.\n The following table summarizes the timing-driven global routing behavior based on the effort level settings.\n The shaded cell shows the default behavior.\n Table 32 Number of Rerouting Phases Based on the Effort Level Settings route.global.advance_node_timing_driven_effort setting route_global -effort_level setting low medium high (default) low    medium   3,4 3,5 high  3,4 3,4 ultra  3,4 3,4 To control the tradeoff between timing QoR and DRC convergence, set the route.global.timing_driven_effort_level application option.\n By default, this option has a setting of  high, which favors timing QoR over DRC convergence.\n 3.\n Timing update performed after the second rerouting phase.\n 4.\n Newly critical nets are ripped up and rerouted only if it does not increase congestion.\n 5.\n Newly critical nets are always ripped up and rerouted."}
{"header": "How do I Incremental Global Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  route_global command is not crosstalk-driven.\n To enable crosstalk-driven global routing, set the  route.global.crosstalk_driven and time.si_enable_analysis application options to  true before you run the  route_global command.\n When you enable crosstalk-driven global routing, the tool calculates the net delays before invoking the global router.\n If the design library contains global route information, the tool uses the global route information to calculate the net delays; otherwise, it uses virtual routing to calculate the net delays.\n The global routing results can vary depending on whether the initial net delays were calculated by using global route information or virtual routing.\n To remove existing global route information from the signal nets in the block, use the  -global_route and  -net_types\u00a0signal options with the  remove_routes command, as shown in the following example: fc_shell>\u00a0 remove_routes -global_route -net_types signal"}
{"header": "How do I Track Assignment", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the global router ignores existing global routes.\n To perform incremental global routing by reusing the existing global routes, use the  -reuse_existing_global_route true option when you run global routing.\n Note that this option affects only the global router and not the net delay calculation that occurs before timing-driven or crosstalk-driven global routing."}
{"header": "How do I Detail Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run track assignment, \u2022 Define the common routing application options For information about the common routing application options, see the route.common_options man page.\n \u2022 Define the global routing application options For information about the track assignment application options, see the route.track_options man page.\n \u2022 Complete global routing To perform standalone track assignment, run the  route_track command.\n       The main task of track assignment is to assign routing tracks for each global route.\n During track assignment, Zroute performs the following tasks: \u2022 Assigns tracks in horizontal partitions.\n \u2022 Assigns tracks in vertical partitions.\n \u2022 Reroutes overlapping wires.\n After track assignment finishes, all nets are routed but not very carefully.\n There are many violations, particularly where the routing connects to pins.\n Detail routing works to correct those violations.\n Note: Because track assignment replaces the global routes with actual metal shapes, the block no longer contains global routes after track assignment completes.\n By default, the  route_track command is not timing-driven or crosstalk-driven.\n \u2022 To enable timing-driven mode, set the  route.track.timing_driven application option.\n \u2022 To enable crosstalk-driven mode, set the  route.track.crosstalk_driven and time.si_enable_analysis application options to  true.\n At the end of track assignment, Zroute reports a summary of the wire length and via count.\n Example\u00a020 shows a track assignment report.\n Example 20 Track Assignment Report Wire\u00a0length\u00a0and\u00a0via\u00a0report: --------------------------- Number\u00a0of\u00a0M1\u00a0wires:\u00a0215327\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a00 Number\u00a0of\u00a0M2\u00a0wires:\u00a01124740\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0VIA12SQ_C:\u00a01067462...\n Total\u00a0number\u00a0of\u00a0wires:\u00a02508734\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0vias:\u00a02769482  Total\u00a0M1\u00a0wire\u00a0length:\u00a0924480.9 Total\u00a0M2\u00a0wire\u00a0length:\u00a04147032.0...\n Total\u00a0wire\u00a0length:\u00a021281278.0  Longest\u00a0M1\u00a0wire\u00a0length:\u00a01541.7 Longest\u00a0M2\u00a0wire\u00a0length:\u00a0926.0..."}
{"header": "How do I Routing Signal Nets by Using Automatic Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run detail routing, \u2022 Define the common routing application options For information about the common routing application options, see the route.common_options man page.\n \u2022 Define the detail routing application options For information about the detail routing application options, see the route.detail_options man page.\n \u2022 Complete global routing and track assignment The detail router uses the general pathways suggested by global routing and track assignment to route the nets, and then it divides the block into partitions and looks for DRC violations in each partition.\n When the detail router finds a violation, it rips up the wire and reroutes it to fix the violation.\n During detail routing, Zroute concurrently addresses routing design rules and antenna rules and optimizes via count and wire length.\n For more information about antenna rules, see  Finding and Fixing Antenna Violations.\n To perform standalone detail routing, run the  route_detail command.\n By default, the  route_detail command \u2022 Performs detail routing on the whole block You can restrict the routing to a specific area of the block by using the  -coordinates option (or by specifying or selecting the bounding box in the GUI).\n \u2022 Uses one uniform partition for the first iteration and adjusts the partitioning for subsequent iterations Zroute uses the single uniform partition for the first iteration to generate all DRC violations for the chip at the same time.\n At the beginning of each subsequent iteration, the router checks the distribution of the DRC violations.\n If the DRC violations are evenly distributed, the detail router uses a uniform partition.\n If the DRC violations are located in some local areas, the detail router uses nonuniform partitions.\n In some cases, such as when a design contains standard cells with long pins, you can improve the detail routing QoR and reduce the runtime by increasing the partition size.\n To enable this feature, set the  route.detail.optimize_partition_size_for_drc application option to  true.\n       \u2022 Performs iterations until one of the following conditions exists: \u25e6 All of the violations have been fixed \u25e6 The maximum number of iterations has been reached By default, the maximum number of iterations is 40.\n You can change this limit by setting the  -max_number_iterations option.\n fc_shell>\u00a0 route_detail -max_number_iterations 20 \u25e6 It cannot fix any of the remaining violations You can change the effort that the detail router uses for fixing the remaining violations before it gives up by setting the route.detail.drc_convergence_effort_level application option.\n fc_shell>\u00a0 set_app_options \\ -name route.detail.drc_convergence_effort_level -value high You can force the detail router to complete the maximum number of iterations, regardless of the DRC convergence status, by setting the route.detail.force_max_number_iterations application option to  true.\n fc_shell>\u00a0 set_app_options \\ -name route.detail.force_max_number_iterations -value true \u2022 Is not timing-driven To enable timing-driven detail routing, set the  route.detail.timing_driven application option to  true.\n fc_shell>\u00a0 set_app_options \\ -name route.detail.timing_driven -value true By default, when you enable timing-driving detail routing, Zroute uses medium effort to assign timing-critical nets to low-resistance metal layers.\n To change the extent to which timing-driven detail routing prefers lower-resistance metal layers when routing timing- critical nets, set the  route.common.rc_driven_setup_effort_level application option.\n To increase the effort level to use more low-resistance metal layers for routing, set the option to  high.\n To reduce the effort level, set the option to  low.\n To disable resistance-based routing layer preferences, set the option to  off.\n \u2022 Does not fix shorted nets over macro cells If default detail routing leaves shorted nets over macro cells, analyze the block to determine if the shorts are caused by the availability of only a single layer for routing over the macro cells.\n If so, use routing guides to encourage river routing over the macros with shorted nets and rerun detail routing.\n For details, see  Using Routing Guides to Encourage River Routing.\n       If shorted nets remain after using river routing, enable the fixing of shorted nets over macro cells by automatically ripping up and rerouting the shorted nets by setting the route.detail.repair_shorts_over_macros_effort_level application option to low,  medium, or  high and running incremental detail routing.\n The higher the effort level, the more ECO routing iterations are performed, which can reduce the number of DRC violations at the expense of runtime.\n fc_shell>\u00a0 set_app_options \\ -name route.detail.repair_shorts_over_macros_effort_level \\ -value high \u2022 Does not fix soft DRC violations, such as bridge rule violations To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_detail_route_fix_soft_violations application option to true.\n fc_shell>\u00a0 set_app_options \\ -name route.common.post_detail_route_fix_soft_violations \\ -value true You can run additional detail routing iterations on a routed block by running incremental detail routing (the  -incremental option).\n Be sure to use the  -incremental option; otherwise, Zroute restarts at iteration 0 with a fixed-size partition.\n fc_shell>\u00a0 route_detail -incremental true By default, incremental detail routing does not fix soft DRC violations, such as bridge rule violations.\n To enable the fixing of soft DRC violations after the final incremental detail routing iteration, set the route.common.post_incremental_detail_route_fix_soft_violations application option to  true.\n fc_shell>\u00a0 set_app_options \\ -name route.common.post_incremental_detail_route_fix_soft_violations \\ -value true Note: Incremental detail routing does not fix open nets.\n To fix open nets, you must run ECO routing.\n For information about ECO routing, see  Performing ECO Routing.\n If you want to override certain runtime-intensive application options, you can run detail routing in early mode.\n To turn on the early mode in detail routing, use the set_qor_strategy command with the  -mode option set as  early.\n fc_shell>\u00a0 set_qor_strategy -mode early -stage pnr       Early mode detail routing automatically creates a new DRC type called skipped regions that can detect dirty regions with pin overflow.\n To identify the dirty regions, open the error browser and select  Skipped region.\n If you want to view the DRC violations before postroute optimization, you can save the block after a specified number of iterations by setting the route.detail.save_after_iterations application option.\n The saved block is called DR_itr n, where n is the specified iteration.\n You can use a string other than DR as the prefix by setting the  route.detail.save_cell_prefix application option.\n Zroute generates a DRC violations summary at the end of each iteration.\n After completing detail routing, Zroute outputs a final summary report.\n This report includes all violations detected by Zroute, as well as information about the redundant via conversion rates.\n If you want an additional report that excludes violations that are not of interest to you, specify the rules to exclude by setting the  route.detail.report_ignore_drc application option.\n The syntax to set this option is set_app_options\u00a0-name\u00a0route.detail.report_ignore_drc\u00a0-value\u00a0 list_of_drcs The values used in the  list_of_drcs argument are the DRC names used in the summary report.\n If the DRC name includes a space, you must enclose the name in double quotation marks.\n For a complete list of the supported DRC names, see the man page.\n Example\u00a021 shows a detail routing report.\n Example 21 Detail Routing Report Start\u00a0DR\u00a0iteration\u00a00:\u00a0uniform\u00a0partition Routed\u00a0\u00a01/27405\u00a0Partitions,\u00a0Violations\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00 Routed\u00a0\u00a0137/27405\u00a0Partitions,\u00a0Violations\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0264 \u2026  DR\u00a0finished\u00a0with\u00a07398\u00a0violations  DRC-SUMMARY: @@@@@@@\u00a0TOTAL\u00a0VIOLATIONS\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a07398 Diff\u00a0net\u00a0spacing\u00a0:\u00a0194 Same\u00a0net\u00a0spacing\u00a0:\u00a04 Diff\u00a0net\u00a0via-cut\u00a0spacing\u00a0:\u00a02328 Same\u00a0net\u00a0via-cut\u00a0spacing\u00a0:\u00a01 Less\u00a0than\u00a0minimum\u00a0width\u00a0:\u00a05 Less\u00a0than\u00a0minimum\u00a0area\u00a0:\u00a036 Short\u00a0:\u00a087 End\u00a0of\u00a0line\u00a0enclosure\u00a0:\u00a04742 Less\u00a0than\u00a0NDR\u00a0width\u00a0:\u00a01  Total\u00a0Wire\u00a0Length\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a023928849\u00a0micron Total\u00a0Number\u00a0of\u00a0Contacts\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02932706 Total\u00a0Number\u00a0of\u00a0Wires\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02878293 Total\u00a0Number\u00a0of"}
{"header": "How do I Routing Signal Nets by Using Automatic Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "PtConns\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a088536 Total\u00a0Number\u00a0of\u00a0Routed\u00a0Wires\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02878293 Total\u00a0Routed\u00a0Wire\u00a0Length\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a023920011\u00a0micron Total\u00a0Number\u00a0of\u00a0Routed\u00a0Contacts\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02932706 Layer\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0M1\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0962827\u00a0micron Layer\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0M2\u00a0:\u00a0\u00a0\u00a0\u00a04233755\u00a0micron       \u2026 Via\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0VIA78SQ_C\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01742 Via\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0VIA78SQ_C(rot)\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a09 \u2026  Redundant\u00a0via\u00a0conversion\u00a0report: --------------------------------  Total\u00a0optimized\u00a0via\u00a0conversion\u00a0rate\u00a0=\u00a098.96%\u00a0(2902130\u00a0/\u00a02932706\u00a0vias)  Layer\u00a0VIA1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a097.81%\u00a0(1091973/\u00a01116367\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a097.81%\u00a0(1091973\u00a0vias) Un-optimized\u00a0=\u00a0\u00a02.19%\u00a0(24394\u00a0\u00a0\u00a0vias) \u2026  Total\u00a0double\u00a0via\u00a0conversion\u00a0rate\u00a0\u00a0\u00a0\u00a0=\u00a098.96%\u00a0(2902130\u00a0/\u00a02932706\u00a0vias)  Layer\u00a0VIA1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a097.81%\u00a0(1091973/\u00a01116367\u00a0vias) Layer\u00a0VIA2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a099.97%\u00a0(1071650/\u00a01071978\u00a0vias) \u2026  The\u00a0optimized\u00a0via\u00a0conversion\u00a0rate\u00a0based\u00a0on\u00a0total\u00a0routed\u00a0via\u00a0count\u00a0= 98.96%\u00a0(2902130\u00a0/\u00a02932706\u00a0vias)  Layer\u00a0VIA1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a097.81%\u00a0(1091973/\u00a01116367\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a097.81%\u00a0(1091973\u00a0vias) Un-optimized\u00a0=\u00a0\u00a02.19%\u00a0(24394\u00a0\u00a0\u00a0vias) \u2026  Total\u00a0number\u00a0of\u00a0nets\u00a0=\u00a0255165 0\u00a0open\u00a0nets,\u00a0of\u00a0which\u00a00\u00a0are\u00a0frozen Total\u00a0number\u00a0of\u00a0excluded\u00a0ports\u00a0=\u00a00\u00a0ports\u00a0of\u00a00\u00a0unplaced\u00a0cells\u00a0connected\u00a0to\u00a00 nets 0\u00a0ports\u00a0without\u00a0pins\u00a0of\u00a00\u00a0cells\u00a0connected\u00a0to 0\u00a0nets 0\u00a0ports\u00a0of\u00a00\u00a0cover\u00a0cells\u00a0connected\u00a0to\u00a00 non-pg\u00a0nets Total\u00a0number\u00a0of\u00a0DRCs\u00a0=\u00a07398 Total\u00a0number\u00a0of\u00a0antenna\u00a0violations\u00a0=\u00a0antenna\u00a0checking\u00a0not\u00a0active Information:\u00a0Routes\u00a0in\u00a0non-preferred\u00a0voltage\u00a0areas\u00a0=\u00a08170\u00a0(ZRT-559)  Topology\u00a0ECO\u00a0iteration\u00a01\u00a0ended\u00a0with\u00a00\u00a0qualifying\u00a0violations."}
{"header": "How do I Shielding Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run automatic routing, \u2022 Set the common routing application options For information about the common routing application options, see the route.common_options man page.\n \u2022 Set the global routing application options For information about the detail routing application options, see the route.global_options man page.\n       \u2022 Set the track assignment application options For information about the detail routing application options, see the route.track_options man page.\n \u2022 Set the detail routing application options For information about the detail routing application options, see the route.detail_options man page.\n To run automatic routing, use the  route_auto command.\n By default, the  route_auto command ignores existing global routes and sequentially invokes global routing, track assignment, and detail routing.\n The tool does not save the block between routing steps.\n Use the following options to change the default behavior: \u2022 To perform incremental global routing, use the  -reuse_existing_global_route\u00a0true option.\n \u2022 To stop after track assignment, use the  -stop_after_track_assignment\u00a0true option.\n \u2022 To change the number of search and repair iterations during detail routing from the default of 40, use the  -max_detail_route_iterations option.\n \u2022 To save the block after each routing step, set the  -save_after_global_route, -save_after_track_assignment, and  -save_after_detail_route options to  true.\n The tool uses  auto as the default prefix for the saved block names.\n To specify the prefix, use the  -save_cell_prefix option.\n By default, the  route_auto command is not timing-driven or crosstalk-driven and does not fix soft DRC violations, such as bridge rule violations.\n \u2022 To enable timing-driven mode, set the  route.global.timing_driven, route.track.timing_driven, and  route.detail.timing_driven application options to  true.\n By default, when you enable timing-driving routing, Zroute uses medium effort to assign timing-critical nets to low-resistance metal layers.\n To change the extent to which timing-driven routing prefers lower-resistance metal layers when routing timing-critical nets, set the  route.common.rc_driven_setup_effort_level application option.\n To increase the effort level to use more low-resistance metal layers for routing, set the option to  high.\n To reduce the effort level, set the option to  low.\n To disable resistance- based routing layer preferences, set the option to  off.\n       \u2022 To enable crosstalk-driven mode, set the  route.global.crosstalk_driven, route.track.crosstalk_driven, and  time.si_enable_analysis application options to  true.\n \u2022 To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_detail_route_fix_soft_violations application option to true.\n fc_shell>\u00a0 set_app_options \\ -name route.common.post_detail_route_fix_soft_violations \\ -value true"}
{"header": "How do I Defining the Shielding Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute shields routed nets net shieldingshielding nets  by generating shielding wires that are based on the shielding widths and spacing defined in the shielding rules.\n In addition to shielding nets on the same layer, you also have the option to shield one layer above and one layer below.\n Shielding above or below the layer is called  coaxial shielding.\n  Figure\u00a0116 shows an example of coaxial shielding.\n Coaxial shielding provides even better signal isolation than same-layer shielding, but it uses more routing resources.\n Figure 116 Coaxial Shielding You can perform shielding either before or after signal routing.\n Shielding before signal routing, which is referred to as preroute shielding, provides better shielding coverage but can result in congestion issues during signal routing.\n Preroute shielding is typically used to shield critical clock nets.\n Shielding after signal routing, which is referred to as postroute shielding, has a very minimal impact on routability, but provides less protection to the shielded nets.\n       Figure\u00a0117 shows the Zroute shielding flow, which is described in the topics that follow.\n Figure 117 Zroute Shielding Flow"}
{"header": "How do I Performing Preroute Shielding", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you perform shielding, you must 1.\n Define the shielding rules.\n To define shielding rules, use the  -shield_spacings and  -shield_widths options of the  create_routing_rule command.\n For example, to specify a shielding rule that uses spacing of 0.1 microns and width of 0.1 microns for metal1 through metal5 and spacing of 0.3 microns and width of 0.3 microns for metal6, use the following command: fc_shell>\u00a0 create_routing_rule shield_rule \\ -shield_widths {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} \\ -shield_spacings {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} For more information about the  create_routing_rule command, see  Using Nondefault Routing Rules.\n       2.\n Assign shielding rules to the nets to be shielded.\n To avoid congestion issues and achieve the best balance of DRC convergence and timing closure, you should apply shielding rules only to high-frequency or critical clock nets and apply double-spacing rules to the lower-frequency clock nets.\n \u25e6 To assign shielding rules to clock nets, use the  set_clock_routing_rules command.\n Note: You can use the  set_clock_routing_rules command only before clock tree synthesis.\n \u25e6 To assign shielding rules to signal nets, use the  set_routing_rule command.\n For more information about these commands, see  Assigning Nondefault Routing Rules to Nets."}
{"header": "How do I Soft Shielding Rules During Signal Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To provide the most protection for critical clock nets, perform shielding on those nets after clock tree routing but before signal net routing.\n To add shielding to the routed clock nets based on the assigned shielding rules, use the create_shields command.\n By default, the  create_shields command \u2022 Performs shielding on all nets that have predefined shielding rules, except those marked as frozen To explicitly specify the nets on which to perform shielding, use the  -nets option.\n \u2022 Does not perform shielding on wires that are less than four pitches long To specify the minimum wire length in microns on which to perform shielding for each layer, set the  route.common.min_shield_length_by_layer_name application option.\n Use the following syntax to set this option: {\u00a0{ layer wire_length }\u00a0...\n } Specify the routing layers by using the layer names from the technology file.\n If you do not specify a value for a layer, Zroute uses the default minimum length of four pitch lengths for that layer.\n Note: Wires that are less than the minimum length are not considered when computing the shielding ratio.\n       \u2022 Ties the shielding wires to the ground net If the block contains multiple ground nets or you want to tie the shielding wires to the power net, use the  -with_ground option to specify the power or ground net to which to tie the shielding wires.\n If the shielding wires can be tied to multiple power or ground nets, specify the nets by setting the  route.common.shielding_nets application option before running the create_shields command.\n Note: If you specify both the  create_shields\u00a0-with_ground option and the route.common.shielding_nets option, the tool issues a warning message and uses the  route.common.shielding_nets setting.\n \u2022 Performs same-layer shielding To perform coaxial shielding, use the  -coaxial_above and  -coaxial_below options.\n By default, the  create_shields command leaves one routing track open between each used track.\n To change the default behavior, use one of the following methods: \u25e6 Specify the number of open tracks between coaxial shielding segments by using the following options: \u25aa -coaxial_above_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding above the shielded net segment layer ( -coaxial_above\u00a0true ).\n \u25aa -coaxial_below_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding below the shielded net segment layer ( -coaxial_below\u00a0true ).\n For either of these options, you can specify an integer between zero and seven.\n \u25e6 Specify the number of open tracks between coaxial shielding segments on a per- layer basis by using the  -coaxial_skip_tracks_on_layers option To disable shielding on a specific layer, set the value to -1; otherwise, specify an integer between 0 and 7 to specify the number of tracks to skip.\n \u25e6 Specify the spacing between coaxial shielding segments by using the following options: \u25aa -coaxial_above_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding above the shielded net segment layer ( -coaxial_above true ).\n       \u25aa -coaxial_below_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding below the shielded net segment layer ( -coaxial_below true ).\n You cannot use this method when performing incremental shielding.\n Note: You cannot mix these methods of specifying coaxial shielding.\n If the generated coaxial shielding wires violate minimum area or minimum length rules, Zroute automatically patches the wires to satisfy these design rules.\n \u2022 Connects the shielding wires to the standard-cell power or ground pins and the standard-cell rails To prevent connections to the standard-cell power and ground pins, set the -ignore_shielding_net_pins option to  true.\n To prevent connections to the standard-cell rails, set the  -ignore_shielding_net_rails option to  true.\n \u2022 Creates the shielding wires such that they surround the shielded routing shape To trim the shielding wires so that they align with the shielded routing shape ends, set the  -align_to_shape_end option to  true.\n To force Zroute to create shielding wires only in the preferred direction, set the  -preferred_direction_only option to  true.\n Note that the  -preferred_direction_only option does not honor route guides to change the preferred routing direction.\n When you set either of these options to  true, extra effort is required to connect the shielding wires to the power and ground network and any shielding wires that are not connected to the power and ground network are deleted.\n For example, to perform coaxial shielding below the shielded net segment layer on the clock nets, prevent signal routing below the shielded net segment layer, and tie the shielding wires to VSS, use the following command: fc_shell>\u00a0 create_shields -nets $clock_nets \\ -coaxial_below true -coaxial_below_skip_tracks 0 \\ -with_ground VSS When you run the  create_shields command, it reports both the net-based and length- based average shielding ratios, as shown in the following example: Shielded\u00a082%\u00a0side-wall\u00a0of\u00a0(reset) Shielded\u00a096%\u00a0side-wall\u00a0of\u00a0(clk) Shielded\u00a02\u00a0nets\u00a0with\u00a0average\u00a0ratio\u00a0as\u00a0follows.\n 1)\u00a089.00%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0ratio/number\u00a0of\u00a0shielded\u00a0nets) 2)\u00a087.92%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0length/total\u00a0shielded\u00a0net\u00a0length)       Note: In some cases there is a slight difference in the shielding ratios reported by the  create_shields and  report_shields commands.\n This is due to graph connectivity differences between the two commands.\n When the reported values differ, use the values reported by the  report_shields command.\n The difference in reported values is typically less than three percent, but can be up to five percent.\n If you use the  -preferred_direction_only\u00a0true option when running the create_shields command, but Zroute must use some nonpreferred direction wires for shielding, the shielding ratio report specifies the percentage of nonpreferred direction wires.\n By default, the power and ground structure is not included in the shielding ratio calculation.\n To include the power and ground structure within a threshold distance in the shielding ratio calculation, set the  route.common.pg_shield_distance_threshold application option, which specifies the distance threshold in microns.\n fc_shell>\u00a0 set_app_options \\ -name route.common.pg_shield_distance_threshold -value  distance Note that this option affects only the shielding ratio calculation and does not change the routing behavior."}
{"header": "How do I Performing Postroute Shielding", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute considers shielding rules as soft rules during signal routing.\n If a net has a shielding rule and is not shielded before signal routing, by default, Zroute reserves shielding space during the whole routing process: global routing, track assignment, and detail routing.\n At the end of detail routing, it reports the shielding space violations and the locations where shielding wires cannot be established.\n The following log file example shows shielding soft spacing violations, which are highlighted in bold text: DRC-SUMMARY: @@@@@@@\u00a0TOTAL\u00a0VIOLATIONS\u00a0=\u00a013 Diff\u00a0net\u00a0var\u00a0rule\u00a0spacing\u00a0:\u00a02 Same\u00a0net\u00a0spacing\u00a0:\u00a02 Less\u00a0than\u00a0minimum\u00a0area\u00a0:\u00a04 Short\u00a0:\u00a01 Soft spacing (shielding) : 2 Signal routing only reserves space for the shielding; it does not actually insert it.\n You must run  create_shields after signal routing to physically place the shielding wires.\n The reported soft rule violations help you to understand the shielding rate.\n Note that the router reserves space only for same-layer shielding and not for coaxial shielding; therefore, postroute coaxial shielding can produce a very low shielding rate.\n       If you want to use power and ground nets for shielding, and do not want Zroute to reserve space for the shielding when power and grounds nets are available, set the route.common.allow_pg_as_shield application option to  true before running signal routing."}
{"header": "How do I Shielding Example", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform postroute shielding, you use the same command,  create_shields, that is used for preroute shielding.\n If you want to use the default spacings and widths from the technology file for postroute shielding, you do not need to define and assign nondefault routing rules.\n If you specify the nets to be shielded by using the  -nets option, the  create_shields command shields these nets with the default spacing and widths.\n Postroute shielding should introduce few to no DRC violations.\n If DRC violations are created during shielding, the  create_shields command triggers five detail routing iterations to fix them.\n If this does not fix the DRC violations, you can fix the remaining violations by running incremental detail routing with the  route_detail -incremental\u00a0true command.\n It is possible that postroute shielding might break some tie-off connections during the shield trimming process.\n In this case, use the  route_eco command instead of the  route_detail command to rebuild the tie-off connections and to fix the DRC violations."}
{"header": "How do I Performing Incremental Shielding", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Example\u00a022 provides an example of shielding clock nets using preroute shielding and shielding critical nets using postroute shielding.\n Example 22 Shielding Flow Example #\u00a0Define\u00a0shielding\u00a0rule create_routing_rule\u00a0shield_rule\u00a0\\ -shield_widths\u00a0{M1\u00a00.1\u00a0M2\u00a00.1\u00a0M3\u00a00.1\u00a0M4\u00a00.1\u00a0M5\u00a00.1\u00a0M6\u00a00.3}\u00a0\\ -shield_spacings\u00a0{M1\u00a00.1\u00a0M2\u00a00.1\u00a0M3\u00a00.1\u00a0M4\u00a00.1\u00a0M5\u00a00.1\u00a0M6\u00a00.3}  #\u00a0Assign\u00a0shielding\u00a0rule\u00a0to\u00a0clock\u00a0nets set_clock_routing_rules\u00a0-clocks\u00a0CLK\u00a0\\ -rules\u00a0shield_rule  #\u00a0Perform\u00a0clock\u00a0tree\u00a0synthesis synthesize_clock_trees  #\u00a0Route\u00a0the\u00a0clock\u00a0nets,\u00a0reusing\u00a0the\u00a0global\u00a0routing\u00a0result route_group\u00a0-all_clock_nets\u00a0-reuse_existing_global_route\u00a0true  #\u00a0Perform\u00a0preroute\u00a0shielding\u00a0for\u00a0the\u00a0clock\u00a0nets create_shields\u00a0-nets\u00a0$clock_nets\u00a0-with_ground\u00a0VSS        #\u00a0Assign\u00a0shielding\u00a0rule\u00a0to\u00a0critical\u00a0nets set_routing_rule\u00a0-rule\u00a0shield_rule\u00a0$critical_nets  #\u00a0Route\u00a0signal\u00a0nets\u00a0using\u00a0shielding\u00a0soft\u00a0rules route_auto  #\u00a0Perform\u00a0postroute\u00a0shielding\u00a0for\u00a0critical\u00a0nets create_shields\u00a0-nets\u00a0$critical_nets\u00a0-with_ground\u00a0VSS"}
{"header": "How do I Reporting Shielding Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, Zroute does not perform incremental shielding on nets that are modified after they were shielded.\n However, you can enable this capability for nets that were initially shielded with the  create_shields command by changing the route.common.reshield_modified_nets application option from its default of  off.\n When you enable incremental shielding, Zroute performs incremental shielding during detail routing by removing the existing shielding from the modified nets and optionally reshielding these nets based on the new topology.\n \u2022 To remove the existing shielding only, set the route.common.reshield_modified_nets option to  unshield.\n \u2022 To remove the existing shielding and reshield the modified nets, set the route.common.reshield_modified_nets option to  reshield.\n Note: Zroute automatically detects the nets modified within the Fusion Compiler tool; however, nets modified externally and input by reading a DEF file are not supported by incremental shielding."}
{"header": "How do I Querying Shield Shapes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you run the  create_shields command, you can \u2022 Query the shield shapes associated with a shielded net by using the  get_shapes -shield_only command, as described in  Querying Shield Shapes \u2022 Report the shielding statistics by using the  report_shields command, as described in Reporting Shielding Statistics"}
{"header": "How do I Reporting Shielding Statistics", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To query the shield shapes associated with a shielded net, use the  get_shapes command with the  -shield_only option, as shown in the following example: fc_shell>\u00a0 get_shapes -shield_only -of_objects [get_nets myclk] {PATH_19_4317\u00a0PATH_19_4318\u00a0PATH_19_4319\u00a0PATH_19_4320\u00a0PATH_19_4322       PATH_17_11590\u00a0PATH_17_11591\u00a0PATH_17_11592\u00a0PATH_17_11593\u00a0PATH_17_11594 PATH_17_11595\u00a0PATH_17_11596\u00a0PATH_17_11597\u00a0PATH_17_11599\u00a0PATH_17_11600 PATH_17_11601\u00a0PATH_17_11602\u00a0PATH_17_11604\u00a0PATH_17_11605\u00a0PATH_17_11606 PATH_17_11607\u00a0PATH_17_11608\u00a0PATH_17_11609\u00a0PATH_17_11610\u00a0PATH_17_11611 PATH_17_11612\u00a0PATH_17_11613\u00a0PATH_17_11614\u00a0PATH_17_11615\u00a0PATH_17_11616 PATH_17_11617\u00a0PATH_17_11618\u00a0PATH_17_11619\u00a0PATH_17_11620\u00a0PATH_17_11621 PATH_17_11622\u00a0PATH_17_11623\u00a0PATH_17_11624\u00a0PATH_17_11625\u00a0PATH_17_11626}"}
{"header": "How do I Performing Shielding Checks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the shielding statistics, use the  report_shields command.\n Note: In some cases there is a slight difference in the shielding ratios reported by the  create_shields and  report_shields commands.\n This is due to graph connectivity differences between the two commands.\n When the reported values differ, use the values reported by the  report_shields command.\n The difference in reported values is typically less than three percent, but can be up to five percent.\n By default, the power and ground structure is not included in the shielding ratio calculation.\n To include the power and ground structure within a threshold distance in the shielding ratio calculation, set the  route.common.pg_shield_distance_threshold application option, which specifies the distance threshold in microns.\n fc_shell>\u00a0 set_app_options \\ -name route.common.pg_shield_distance_threshold -value  distance The default report generated by the  report_shields command provides overall statistics, as shown in  Reporting Shielding Statistics.\n Example 23 Default Shielding Report fc_shell>\u00a0 report_shields...\n Shielded\u00a082%\u00a0side-wall\u00a0of\u00a0(reset) Shielded\u00a096%\u00a0side-wall\u00a0of\u00a0(clk) Shielded\u00a02\u00a0nets\u00a0with\u00a0average\u00a0ratio\u00a0as\u00a0follows.\n 1)\u00a089.00%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0ratio/number\u00a0of\u00a0shielded\u00a0nets) 2)\u00a087.92%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0length/total\u00a0shielded\u00a0net\u00a0length) You can output the statistics for each layer by using the  -per_layer\u00a0true option with the report_shields command, as shown in  Example\u00a024.\n Example 24 Layer-Based Shielding Report fc_shell>\u00a0 report_shields -per_layer true...\n Shielded\u00a082%\u00a0side-wall\u00a0of\u00a0(reset) Layer:\u00a0M1\u00a0\u00a0ratio:\u00a00% Layer:\u00a0M2\u00a0\u00a0ratio:\u00a040%       Layer:\u00a0M3\u00a0\u00a0ratio:\u00a085% Layer:\u00a0M4\u00a0\u00a0ratio:\u00a080% Shielded\u00a096%\u00a0side-wall\u00a0of\u00a0(clk) Layer:\u00a0M3\u00a0\u00a0ratio:\u00a00% Layer:\u00a0M4\u00a0\u00a0ratio:\u00a096% Layer:\u00a0M5\u00a0\u00a0ratio:\u00a0100% Shielded\u00a02\u00a0nets\u00a0with\u00a0average\u00a0ratio\u00a0as\u00a0follows.\n 1)\u00a089.00%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0ratio/number\u00a0of\u00a0shielded\u00a0nets) 2)\u00a087.92%\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(total\u00a0shield\u00a0length/total\u00a0shielded\u00a0net\u00a0length)"}
{"header": "How do I Performing Postroute Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During routing, Zroute can detect possible issues with shielding by checking for the following conditions: \u2022 Signal net shapes with a  shape_use attribute of  shield_route.\n \u2022 PG net shapes, which might be a PG strap or rail, but have a  shape_use attribute of detail_route.\n \u2022 Signal, clock, or PG nets that have a shielding nondefault rule but no associated shield shapes, which might be caused by inappropriate  shape_use attributes.\n To enable these checks, set the  route.common.check_shield application option to  true."}
{"header": "How do I Performing Postroute Logic Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can perform two types of postroute optimization: \u2022 Logic optimization This optimization improves the timing, area, and power QoR and fixes logical DRC violations and performs legalization and ECO routing.\n To perform these optimizations, use the  route_opt command, as described in  Performing Postroute Logic Optimization.\n \u2022 Routability optimization This optimization increases the spacing between cells to fix routing DRC violations caused by pin access issues.\n To perform this optimization, use the optimize_routability command, as described in  Fixing DRC Violations Caused by Pin Access Issues.\n If you run both logic optimization and routability optimization, you should first perform the logic optimization and then the routability optimization."}
{"header": "How do I Performing Postroute Optimization Using the hyper_route_opt", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before performing postroute optimization, ensure that the block is fully routed and legalized and does not have excessive logical or routing DRC violations.\n \u2022 To verify the legality of the design, use the  check_legality command.\n \u2022 To verify the routing, use the  check_routes command.\n To perform postroute logic optimization, 1.\n Update the clock latency by using the  compute_clock_latency command.\n 2.\n Run the  route_opt command two times.\n The legalization and ECO routing performed by the first  route_opt run might impact the block timing, which is then optimized by the second  route_opt run.\n As the number of changes during postroute logic optimization decreases, the timing improvement from subsequent  route_opt runs decreases.\n The  route_opt command performs the following tasks: 1.\n Performs extraction and updates the timing By default, the  route_opt command uses the PrimeTime delay calculation engine, which requires that you use cell libraries generated by O-2018.06 or later versions of the Library Manager tool.\n Before using PrimeTime delay calculation, use the check_consistency_settings command to verify that the Fusion Compiler and PrimeTime settings are consistent, as described in Checking for Consistency in Timing Analysis and Extraction Settings in the  Fusion Compiler Timing Analysis User Guide.\n The  route_opt command supports both graph-based analysis (GBA), the default, and path-based analysis (PBA).\n To enable path-based optimization, use the time.pba_optimization_mode application option.\n \u25e6 To use path-based timing for the worst path of each endpoint, which is identified by using graph-based analysis, set this application option to  path.\n This is the recommended setting because it provides the best tradeoff between runtime and QoR.\n \u25e6 To use exhaustive path-based search algorithms for each endpoint, set this application option to  exhaustive.\n Using this setting increases the runtime.\n       2.\n Performs the enabled optimizations By default, the  route_opt command optimizes for setup, hold, area, and logical DRC violations for the data paths in the block.\n To enable additional optimizations, set the application options shown in  Table\u00a033  before running the  route_opt command: Table 33 Application Options to Enable route_opt Optimizations Optimization Application option settings 6   route_opt.flow.enable_ccd true 7 route_opt.flow.enable_cto true  route_opt.flow.enable_clock_power_recovery area  route_opt.flow.enable_clock_power_recovery power 8 route_opt.flow.enable_power true   route_opt.flow.enable_ml_opto true time.pba_optimization_mode path   set_app_options\u00a0-name route_opt.flow.enable_irdrivenopt\u00a0-value\u00a0true set_app_options\u00a0-name\u00a0opt.common.ir_drop_threshold -value\u00a010 set_app_options-name opt.common.power_integrity-value\u00a0true   set_app_options\u00a0-name ccd.ccd_opt_voltage_drop_enable_ml_predictor\u00a0-value true Note: The  route_opt command honors only the  route_opt application options; it does not honor the settings of the  opt application options, except the opt.common.allow_physical_feedthrough application option.\n 3.\n Legalizes the block 4.\n Performs ECO routing 6.\n For information about setting application options to control concurrent clock and data optimization, see  Controlling Concurrent Clock and Data Optimization.\n 7.\n This optimization is supported only when concurrent clock and data optimization is not enabled.\n 8.\n The type of power optimization performed depends on scenario configuration.\n Total power optimization is performed if there is an active scenario with both leakage power and dynamic power enabled.\n Leakage power optimization is performed if there is an active scenario with only leakage power enabled.\n       By default, the  route_opt command performs five detail routing iterations during the ECO routing phase.\n To change the number of iterations, use the route.detail.eco_max_number_of_iterations application option.\n To perform track assignment instead, set the  route_opt.eco_route.mode application option to  track.\n If the PrimeTime tool reports setup or hold violations during signoff timing analysis, you can use the following process to fix these violations: 1.\n Specify the target endpoints and their PrimeTime timing information by using the set_route_opt_target_endpoints command with the  -setup_timing and -hold_timing options.\n 2.\n Optimize the endpoints by using the  route_opt command.\n 3.\n Remove the adjusted timing information by using the set_route_opt_target_endpoints\u00a0-reset command.\n You can also use this process to perform incremental optimization on specific endpoints.\n In this case, use the  -setup_endpoints,  -hold_endpoints, and  -ldrc_objects options to specify the endpoints.\n To close the final setup, hold, or logical DRC violations with minimal disturbance to the block, use size-only mode when you run the  route_opt command.\n To enable size- only mode, set the  route_opt.flow.size_only_mode application option to one of the following values: \u2022 true_footprint, which allows resizing a cell only to a library cell that is an exact physical match, as determined by the tool after analysis This ensures that legalization or ECO routing is not required after resizing \u2022 footprint, which allows resizing a cell only to a library cell that has the same footprint attribute in the library \u2022 equal, which allows resizing a cell only to a library cell that is equal in size \u2022 equal_or_smaller, which allows resizing a cell only to a library cell that is equal or smaller in size To disable size-only mode, set the  route_opt.flow.size_only_mode application option to  none or  \"\", which is the default."}
{"header": "How do I Fixing DRC Violations Caused by Pin Access Issues", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The recommended flow for performing postroute logic optimization consists of multiple iterations of the  route_opt command with different settings.\n However, you can reduce       the number of postroute optimization iterations by using a single iteration of the hyper_route_opt command.\n The postroute optimization flow using the  hyper_route_opt command consists of the following steps: 1.\n Enable different settings for postroute optimization using the same settings as for the route_opt command.\n For example, you can \u25e6 Specify the path-based analysis (PBA) mode by using the time.pba_optimization_mode application option \u25e6 Enable concurrent clock and data optimization by using the route_opt.flow.enable_ccd application option \u25e6 Enable power optimization by using the  route_opt.flow.enable_power application option 2.\n (Optional) Specify settings for metal fill insertion, PG augmentation, and so on that should to be performed during the different stages of optimization and ECO routing within the  hyper_route_opt command by using the snps_hyper_route_opt_post_eco Tcl-callback procedure.\n 3.\n (Optional) To improve the timing QoR, the  hyper_route_opt command can debank sequential multibit registers.\n To enable this feature, set the route_opt.flow.enable_multibit_debanking application option to  true.\n By default, the  route_opt.flow.enable_multibit_debanking application option is set to  false.\n 4.\n Run postroute optimization using the  hyper_route_opt command.\n 5.\n (Optional) Specify endpoints to target by using the set_route_opt_target_endpoints command and optimize these endpoints by using the  route_opt command if there are any violating endpoints remaining after the hyper_route_opt command.\n 6.\n (Optional) Fix any remaining route DRC violations by using the  route_detail -incremental command."}
{"header": "How do I Analyzing and Fixing Signal Electromigration Violations", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In advanced process nodes, the distance between pins decreases, which can result in DRC violations caused by pin access issues.\n These types of DRC violations can be fixed by using keepout margins to increase the spacing between cells.\n       If your postroute design has DRC violations, analyze the violations to determine if they are caused by pin access issues.\n If so, run the  optimize_routability command to increase the spacing between cells where the DRC violations occur.\n The  optimize_routability command performs the following tasks: \u2022 Analyzes the cells with DRC violations to find violations where cells abut By default, the command considers all DRC violations.\n To consider only specific DRC violations, use the  -drc_rules option.\n To consider only violations on specific layers, use the  -layer_rules option.\n To preview the number of DRC violations and affected cells, use the -check_drc_rules option.\n When you use this option, the command generates a report but does not move any cells.\n \u2022 Sets keepout margins on these cells on the side of the cell where the error occurs By default, the command uses the site width as the keepout width.\n To specify a keepout width in microns, use the  -keepout_width option.\n Note: These keepout margins are in addition to any existing keepout margins on the cells; the command does not modify the existing keepout margins.\n To try to fix the DRC violations by flipping the cells instead of adding keepout margins, use the  -flip option.\n \u2022 Legalizes the affected cells You must use one of the following methods to complete the routes for the cells moved by the optimization: \u2022 Run ECO routing by using the  route_eco command.\n \u2022 Run ECO routing by using the  -route option with the  optimize_routability command.\n To fix the DRC in the areas that have changes, set the route.common.eco_fix_drc_in_changed_area_only application option to  on.\n When you use this option, the command runs the  route_eco and  check_routes commands after completing the optimization.\n After moving the cells and performing ECO routing, remove the keepout margins from the cells by using the  optimize_routability\u00a0-remove_keepouts command."}
{"header": "How do I Loading the Signal Electromigration Constraints", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Signal electromigration problems result from an increase in current density caused by the use of smaller line widths and higher operational speeds in IC designs.\n Electromigration can lead to shorts or opens due to metal ion displacement caused by the flow of electrons.\n The more frequently a net switches, the more susceptible it is to electromigration.\n To analyze and fix signal electromigration violations in a detail routed block, 1.\n Apply the signal electromigration constraints by using the read_signal_em_constraints command.\n For more information, see  Loading the Signal Electromigration Constraints.\n 2.\n Apply switching activity by either reading in a SAIF file with the  read_saif command or annotating the switching activity information on the nets with the set_switching_activity command.\n For more information, see  Annotating the Switching Activity.\n 3.\n Report the signal electromigration information by using the  report_signal_em command.\n For more information, see  Analyzing Signal Electromigration.\n 4.\n Fix any signal electromigration violations by using the  fix_signal_em command.\n For more information, see  Fixing Signal Electromigration Violations.\n The following example script shows the signal electromigration flow.\n #\u00a0Open\u00a0the\u00a0block\u00a0and\u00a0apply\u00a0the\u00a0signal\u00a0electromigration\u00a0constraints open_block\u00a0block1_routed read_signal_em_constraints\u00a0em.itf  #\u00a0Load\u00a0switching\u00a0information read_saif\u00a0block1.saif  #\u00a0Perform\u00a0signal\u00a0electromigration\u00a0analysis report_signal_em\u00a0-violated\u00a0-verbose\u00a0>\u00a0block1.signal_em.rpt  #\u00a0Fix\u00a0signal\u00a0electromigration\u00a0violations fix_signal_em"}
{"header": "How do I Analyzing Signal Electromigration", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports the following formats for specifying electromigration constraints: \u2022 Interconnect Technology File (ITF) An ITF file can contain the following types of electromigration constraints: delta temperature, duration and duty ratio, via size, via direction, metal length, and via-to-via spacing relaxation.\n The Fusion Compiler tool supports both unencrypted and encrypted ITF files.\n \u2022 Advanced Library Format (ALF) An ALF file can contain the following types of electromigration constraints: temperature, metal width, and contact area.\n The electromigration constaints are stored in the design library as a lookup table.\n The tool determines the limit values by looking up the values in the lookup table and then using linear interpolation or extrapolation.\n To load the signal electromigration constaints into the design library, use the read_signal_em_constraints command.\n By default, the command reads an unencrypted ITF file.\n To read an encrypted ITF file, use the  -encrypted option.\n To read an ALF file, use the  -format\u00a0ALF option.\n The constraints loaded by the read_signal_em_constraints command overwrite any existing signal electromigration constraints in the design library.\n For example, to read an unencrypted ITF file, use the following command: fc_shell>\u00a0 read_signal_em_constraints em.itf For example, to read an encrypted ITF file, use the following command: fc_shell>\u00a0 read_signal_em_constraints -encrypted em.itf.enc To read an ALF file, use the following command: fc_shell>\u00a0 read_signal_em_constraints -format ALF em.alf"}
{"header": "How do I Fixing Signal Electromigration Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The comandsreport_signal_emreport_signal_em comand report_signal_em command performs signal electromigration analysis for each net by calculating the current on every edge and comparing this data with the constraints set by the  read_signal_em_constraints command.\n For example, fc_shell>\u00a0 report_signal_em -violated -verbose       The  report_signal_em command performs a timing update, if needed, and analyzes all nets for electromigration.\n The  -verbose option causes the report to show detailed electromigration analysis information, which usually produces a very large report when used by itself.\n To get a report with a reasonable size, use the  -violated option as well, which limits the report to only the nets with electromigration violations.\n To limit the analysis to specific nets, use the  -nets option.\n set_em_options comandcomandset_em_options You can specify settings for electromigration analysis by setting the application options shown in the following table.\n Table 34 Application Options for Signal Electromigration Analysis Application option Default Description em.net_delta_temperature    em.net_duration_condition_for_peak    em.net_global_rms_relaxation_factor    em.net_metal_line_number      em.net_min_duty_ratio    em.net_use_waveform_duration false false true   em.net_violation_rule_types   When you perform signal electromigration analysis, the tool computes three current values: \u2022 Average \u2022 Root mean square \u2022 Peak The default report generated by the  report_signal_em command lists the number of nets with electromigration violations and the types of constraints violated (mean, absolute       average, RMS, or peak).\n If you use the  -verbose option, the report displays detailed information about the violations, as shown in  Example\u00a025.\n Example 25 Verbose Electromigration Report fc_shell>\u00a0 report_signal_em -violated -verbose...\n Net\u00a0Name:\u00a0clks/trimch_macroout_cb_group_gpaf0lts1_gpu_c_0_s_0[3] Violations:\u00a0RMS\u00a0PEAK  Flag\u00a0Segment\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Layer\u00a0BBox\u00a0Coordinates\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Width/Cut\u00a0Required AVERAGE\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RMS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0PEAK -------------------------------------------------------------------------------------- v\u00a0\u00a0\u00a0\u00a0PATH_36_392230\u00a0\u00a0M6D\u00a0\u00a0\u00a0(1450.000,\u00a0995.612\u00a0->\u00a01452.715,\u00a0995.652)\u00a0\u00a0\u00a00.040\u00a0\u00a0\u00a0\u00a0\u00a00.085 1.514e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a09.650e-01\u00a0(5.231e-01)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01.365e+00\u00a0(1.349e+00) VIA_S_11051278\u00a0\u00a0V5D\u00a0\u00a0\u00a0(1449.969,\u00a0995.582\u00a0->\u00a01450.071,\u00a0995.682)\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- 1.465e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a07.380e-01\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01.044e+00\u00a0(-) v\u00a0\u00a0\u00a0\u00a0PATH_35_765189\u00a0\u00a0M5A\u00a0\u00a0\u00a0(1450.001,\u00a0994.973\u00a0->\u00a01450.039,\u00a0995.651)\u00a0\u00a0\u00a00.038\u00a0\u00a0\u00a0\u00a0\u00a00.047 1.417e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a06.088e-01\u00a0(4.981e-01)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a08.609e-01\u00a0(1.274e+00) VIA_S_11051279\u00a0\u00a0V5D\u00a0\u00a0\u00a0\u00a0(1449.969,\u00a0994.942\u00a0->\u00a01450.071,\u00a0995.042)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- 1.369e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a05.249e-01\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a07.423e-01\u00a0(-) PATH_36_392231\u00a0\u00a0M6D\u00a0\u00a0\u00a0(1407.370,\u00a0994.972\u00a0->\u00a01450.040,\u00a0995.012)\u00a0\u00a0\u00a00.040\u00a0\u00a0\u00a0\u00a0\u00a0- 1.311e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02.047e-01\u00a0(5.231e-01)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02.894e-01\u00a0(9.443e-01) VIA_S_11051280\u00a0\u00a0V5D\u00a0\u00a0\u00a0(1407.339,\u00a0994.942\u00a0->\u00a01407.441,\u00a0995.042)\u00a0\u00a0\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- 1.252e-02\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01.926e-01\u00a0(-)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02.723e-01\u00a0(-)...\n The report shows the segment name (Segment column), layer name (Layer column), location coordinates (Bbox Coordinates column), metal width or via cut number (Width/Cut column), the constraint value (Required column), the average, RMS, and peak current in mA for the wire segment or via at that location.\n The letter \u201cv\u201d in the Flag column indicates a violation at that location.\n A hyphen in the Required column means that there is no electromigration constraint for that metal or via layer.\n In the AVERAGE, RMS, and PEAK columns, the first value is the calculated value and the value in parenthesis is the limit imposed by the electromigration constraints, where a hyphen indicates that there is no electromigration constraint."}
{"header": "How do I Performing ECO Routing", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before fixing signal electromigration violations, make sure that the block is detail routed, the signal electromigration constraints are defined in the design library, the switching activity is defined for all boundary nets, crosstalk analysis is enabled, and there are no timing or DRC violations.\n You can optionally use the  report_signal_em command first to report electromigration violations before attempting to fix them.\n       To fix signal electromigration violations, use the  fix_signal_em command, which performs the following tasks: \u2022 Runs signal electromigration analysis for nets by calculating the current on every edge of a net and comparing it with the constraints set by the read_signal_em_constraints command.\n \u2022 Fixes violations by applying nondefault routing rules to widen the metal shapes and then performing ECO routing.\n The  fix_signal_em command runs a single fixing iteration; if violations remain after running this command, you must rerun it to address the remaining violations.\n By default, the command fixes signal electromigration violations on all nets.\n To fix the violations only on specific nets, use the  -nets option.\n See Also \u2022 Analyzing Signal Electromigration \u2022 Performing ECO Routing"}
{"header": "How do I Routing Nets in the GUI", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Whenever you modify the nets in your block, you need to run engineering change order (ECO) routing to reconnect the routing.\n To run ECO routing, use the  route_eco command.\n The  route_eco command sequentially performs global routing, track assignment, and detail routing to reconnect the routing.\n By default, the  route_eco command \u2022 Considers timing and crosstalk during routing, which means that the tool performs extraction and updates the timing before performing the routing.\n The extraction and timing update can be time consuming and might not be necessary for your block.\n To prevent the extraction and timing update, use the following commands to disable the timing-driven and crosstalk-driven modes: fc_shell>\u00a0 set_app_options \\ -name route.global.crosstalk_driven -value false fc_shell>\u00a0 set_app_options \\ -name route.global.timing_driven -value false fc_shell>\u00a0 set_app_options \\ -name route.track.crosstalk_driven -value false fc_shell>\u00a0 set_app_options \\ -name route.track.timing_driven -value false fc_shell>\u00a0 set_app_options \\ -name route.detail.timing_driven -value false       \u2022 Works on all open nets in the block To perform ECO routing only on specific nets, use the  -nets option to specify the nets.\n \u2022 Ignores existing global routes To honor the existing global routes and perform incremental global routing, set the -reuse_existing_global_route option to  true.\n \u2022 Relieves congestion by reusing dangling wires instead of rerouting detail routed wires To disable the reuse of dangling wires, set the  -utilize_dangling_wires option to false.\n \u2022 Performs a maximum of 40 detail routing iterations To change the maximum number of detail routing iterations, use the -max_detail_route_iterations option.\n \u2022 Fixes hard DRC violations on the entire block by rerouting any wires, whether modified or not \u25e6 To fix DRC violations only in the neighborhood of the open nets, set the -open_net_driven option to  true.\n Note: When you use the  -nets option to perform ECO routing on specific nets, Zroute fixes DRC violations only within the bounding box of the specified nets.\n In this case, Zroute ignores the setting of the  -open_net_driven option.\n \u25e6 To change the scope of rerouting performed by the ECO router, use the  -reroute option.\n \u25aa To limit rerouting to modified wires, set this option to  modified_nets_only.\n \u25aa To first attempt to fix DRC violations by rerouting modified nets and then reroute other nets if necessary, set this option to  modified_nets_first_then_others.\n A common use for this option is to route the clock nets affected by an ECO in a fully routed block.\n \u25e6 To enable the fixing of soft DRC violations, such as bridge rule violations, after the final detail routing iteration, set the route.common.post_eco_route_fix_soft_violations application option to true.\n Zroute generates a DRC violations summary at the end of each detail routing iteration.\n Before reporting the final DRC violations, Zroute merges redundant violations.\n For more       information about the DRC violations reported by Zroute, see  Performing Design Rule Checking Using Zroute.\n Zroute also reports the nets changed during ECO routing.\n By default, it reports the first 100 changed nets.\n You can use the  -max_reported_nets option to set a different limit on the reported nets.\n To report all changed nets, set the  -max_reported_nets option to -1.\n See Also \u2022 Routing Nets in the GUI"}
{"header": "How do I Modifying Routed Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To route nets interactively in the active layout view, draw the routes with the layout editing tolsCreate Route tol Create Route tool.\n To activate the Create Route tool, click the button on the Edit toolbar or choose Create > Route.\n To draw route segments, you click points in the layout view.\n The tool displays flylines and target port and pin locations to guide you in drawing the route segments.\n It can also check for routing design rule violations as you draw the route segments.\n You can set options to adjust the routing, control the tool operation, and enable or disable routing aids.\n By default, the Create Route tool \u2022 Ignores routing blockages To force the tool to honor these blockages, change the setting in the Mouse Tool Options panel.\n Note: The Create Route tool does not honor routing guides defined by the create_routing_guide command.\n \u2022 Uses the metal width and metal spacing requirements defined in the technology file and ignores nondefault routing rules To force the tool to honor nondefault routing rules, change the setting in the Mouse Tool Options panel.\n When you enable this feature, the Create Route tool honors the metal width and metal spacing requirements from the nondefault routing rule and uses these settings to determine the width and pitch of the routes.\n Note: The shielding width and shield spacing defined in the nondefault routing rule are not used by the Create Route tool.\n       If you route on grid and know that there no obstacles, you can reduce runtime by skipping the spacing checks during automatic welding and automatic alignment.\n To force the tool to ignore the spacing requirements during these tasks, change the settings in the Mouse Tool Options panel.\n You can reverse and reapply Create Route tool operations by using the GUI undo and redo capabilities.\n For detailed information about using the Create Route tool, click on the Mouse Tool Options panel after you activate the Create Route tool.\n This opens a Help page in the man page viewer."}
{"header": "How do I Cleaning Up Routed Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can modify routed nets in the GUI by using the following tools: \u2022 Area Push tool To activate the Area Push tool, click the button on the Edit toolbar or choose Edit > Area Push.\n You can use the Area Push tool to move unfixed objects away from a rectangular area on a layer while maintaining their physical connections.\n You select the layer and control whether the tool complies with nondefault routing rules.\n The tool supports both interactive and batch push operations.\n \u2022 Spread Wire tool To activate the Spread Wires tool, click the button on the Edit toolbar or choose Edit > Spread Wires.\n You can use the Spread Wires tool to move selected, unfixed wires evenly between two points on a layer while maintaining their physical connections.\n You control whether the tool spreads the wires by layer and whether the tool complies with nondefault routing rules.\n \u2022 Stretch Connected tool To activate the Stretch Connected tool, click the button or choose Edit > Stretch Connected.\n You can use the Stretch Connected tool to move and stretch unfixed wire shapes while optionally maintaining their physical connections.\n \u2022 Quick Connect tool To activate the Quick Connect tool, click the button or choose Edit > Route Utilities > Quick Connect.\n You can use the Quick Connect tool to quickly connect wires to pin shapes, port shapes, terminals, or other wires.\n       If you need assistance while using these tools, click to open a Help page in the man page viewer."}
{"header": "How do I Analyzing the Routing Results", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After routing is complete, you can clean up the routed nets by running the remove_redundant_shapes command.\n fc_shell>\u00a0 remove_redundant_shapes By default, this command reads the DRC information stored in the design view of the block and then removes dangling and floating net shapes from all nets in the block based on this information.\n To run the  check_routes command to get the DRC information instead of using the information stored in the design view, use the  -initial_drc_from_input false option.\n You can restrict the removal to \u2022 Specific nets by using the  -nets option \u2022 Specific layers by using the  -layers option \u2022 Fixed or unfixed route types by using the  -route_types option When removing dangling net shapes, the tool does not change topologies or connections and does not touch terminals.\n In addition, no changes are made to open nets or nets with DRC violations.\n You can disable the removal of dangling net shapes by using the -remove_dangling_shapes\u00a0false option.\n You can disable the removal of floating net shapes by using the  -remove_floating_shapes\u00a0false option.\n In addition to removing dangling and floating net shapes, this command can also remove loops in the specified nets.\n To remove loops, use the  -remove_loop_shapes\u00a0true option.\n By default, the  remove_redundant_shapes does not report the changes it makes.\n To report the changes, use the  -report_changed_nets\u00a0true option.\n For example, to remove dangling net shapes, floating net shapes, and loops from the net named my_net, use the following command: fc_shell>\u00a0 remove_redundant_shapes -nets my_net \\ -remove_loop_shapes true After cleaning up the routed nets, reverify the routing, as described in  Performing Design Rule Checking Using Zroute."}
{"header": "How do I Generating a Congestion Report", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can analyze the routing results by reporting on the cell placement and routing statistics.\n The following topics describe how to perform these tasks: \u2022 Generating a Congestion Report \u2022 Generating a Congestion Map \u2022 Performing Design Rule Checking Using Zroute \u2022 Performing Signoff Design Rule Checking \u2022 Performing Design Rule Checking in an External Tool \u2022 Performing Layout-Versus-Schematic Checking \u2022 Reporting the Routing Results \u2022 Reporting the Wire Length \u2022 Using the DRC Query Commands"}
{"header": "How do I Generating a Congestion Map", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To generate a congestion report, run the  report_congestion command.\n fc_shell>\u00a0 report_congestion By default, the  report_congestion command uses the congestion map stored with the block to report an overflow summary for the entire block.\n If a congestion map is not stored with the design, the command generates a congestion map by running global routing in congestion-map-only mode.\n Note: By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to  true before performing global routing.\n The command calculates the overflow as the sum of the overflow for each layer, ignoring any underflow.\n  Example\u00a026 shows the default report, which includes only the hard congestion data.\n Example 26 Default Global Route Congestion Report **************************************** Report\u00a0:\u00a0congestion Design\u00a0:       Version: Date\u00a0\u00a0\u00a0: ****************************************  Layer\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0overflow\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#\u00a0GRCs\u00a0has Name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0total\u00a0\u00a0|\u00a0\u00a0max\u00a0\u00a0|\u00a0overflow\u00a0(%)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0max\u00a0overflow --------------------------------------------------------------- Both\u00a0Dirs\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a039\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a08\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a014\u00a0\u00a0(\u00a00.26%)\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 H\u00a0routing\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a06\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04\u00a0\u00a0(\u00a00.07%)\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02 V\u00a0routing\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a033\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a08\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a010\u00a0\u00a0(\u00a00.18%)\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01 In the default congestion report, \u2022 \u201cH routing\u201d refers to results for horizontal routes only and \u201cV routing\u201d refers to results for vertical routes only.\n \u2022 The total overflow value is the total number of wires in the block that do not have a corresponding track available.\n The max overflow value is the highest number of overutilized wires in a single global routing cell.\n \u2022 The GRCs overflow value is the total number of overcongested global routing cells in the design.\n The GRCs max overflow value is the number of global routing cells that have the maximum overflow.\n Note: The overflow and global routing cell numbers reported by the report_congestion command might look slightly more optimistic than those reported by the  route_global command because the tool rounds down the congestion information before saving it with the design.\n Use the following options to modify the default behavior: \u2022 -rerun_global_router Use this option to rerun the global routing even if the block already has a congestion map.\n \u2022 -boundary\u00a0 coordinates Use this option to restrict the reporting to a specific region of the block.\n \u2022 -layers\u00a0 layers Use this option to restrict the reporting to specific layers.\n \u2022 -mode\u00a0global_route_cell_edge_based Use this option to report overflow information for each global routing cell.\n \u2022 -include_soft_congestion_maps       Use this option to output soft congestion reports, if they exist.\n A soft congestion report includes the demand from the soft nondefault spacing rules, as well as tool-generated soft rules.\n The command outputs a soft congestion report for each spacing weight level of the soft nondefault spacing rules used in the block.\n Each soft congestion report contains the sum of the hard and soft congestion with a weight level of at least the current soft level.\n See Also \u2022 Global Routing \u2022 Defining Minimum Wire Spacing Rules \u2022 Generating a Congestion Map"}
{"header": "How do I Performing Design Rule Checking Using Zroute", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To display the global route congestion map, choose  View > Map > Global Route Congestion in the GUI.\n If the design library contains global route congestion information for the block, the tool generates the congestion map based on this information; otherwise, you must click Reload to generate the congestion map.\n When you click Reload, the tool opens a dialog box that contains the following command: route_global\u00a0-congestion_map_only\u00a0true Note: By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to  true before performing global routing.\n When you click OK in this dialog box, the tool generates a new congestion map.\n If you want to use different options for the  route_global command, you can modify this command before clicking OK.\n       Figure\u00a0118 shows an example of a congestion map.\n Figure 118 Global Route Congestion Map By default, the congestion map displays only the hard congestion data.\n To display soft congestion data, select the desired rule level in the Rule level drop-down list.\n The rule level refers to the spacing weight level of the soft nondefault spacing rules.\n The congestion map displays the sum of the hard and soft congestion with a weight level of at least the selected rule level.\n The congestion map shows the borders between global routing cells highlighted with different colors that represent the congestion values.\n The congestion map supports two methods for calculating the congestion value: \u2022 Sum of overflow for each layer (the default) In this mode, the tool calculates the congestion value as the sum of the overflow for all selected layers.\n Underflow is not considered; if a layer has underflow, it contributes zero overflow to the total overflow calculation.\n \u2022 Total demand minus total supply In this mode, the tool calculates the congestion value by subtracting the supply for all selected layers from the demand for all selected layers.\n Note that because this calculation considers the underflow, it produces a more optimistic congestion result in regions that contain both overflow and underflow.\n For example, assume that the METAL2 layer is heavily congested with a demand of 13 routing tracks and a supply of only 7 tracks for an overflow of 6.\n The METAL4 is       moderately congested with an overflow of 4, and the METAL6 layer is not congested and contains an underflow of 3.\n Other layers are not used in the congestion calculation in this example.\n \u2022 The sum of overflow calculation results in a congestion value of 6+4=10.\n The underflow of 3 for the METAL4 layer is not used in the calculation.\n \u2022 The total demand calculation results in a congestion value of 6+4-3=7.\n In this case, the underflow of 3 for the METAL4 layer is used in the calculation.\n To select the mode, select either \u201cSum of overflow for each layer\u201d or \u201cTotal demand minus total supply\u201d in the \u201cCongestion calculation\u201d section of the Map Mode panel.\n By default, all metal layers are selected in the congestion map, except those specified as ignored layers with the  set_ignored_layers command.\n To display the congestion map for a subset of layers, select (or deselect) the layers on the Map Mode panel.\n For example, if the global routing report shows that the maximum overflow occurs on the METAL2 layer, you can deselect all layers, except for METAL2, to display only the METAL2 congestion.\n The Map Mode panel also displays a histogram showing the number of global routing cells in different ranges (bins) of congestion values for the selected layers.\n If your block contains global routing cells that have no available routing resources, an additional bin named Blocked is displayed that shows the number of global routing cells with no routing resources.\n You can select which bins to display in the congestion map by selecting or deselecting them on the Map Mode panel.\n If the block shows congested areas, zoom into the congested area to see the congestion value on the global routing cell.\n For example, in  Figure\u00a0119, the red highlight on the edge of the global routing cell shows 18/9.\n This means there are 9 wire tracks available, but 18 tracks are needed.\n       Figure 119 Global Route Overflow on Global Routing Cell"}
{"header": "How do I Performing Signoff Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To use Zroute to check the routing design rules defined in the technology file, run the check_routes command.\n By default, the  check_routes command checks for routing DRC violations, unconnected nets, antenna rule violations, and voltage area violations on all routed signal nets in the block, except those marked as user nets, frozen nets, and PG nets.\n \u2022 To verify the routing only for specific nets, specify the nets by using the  -nets option.\n \u2022 To check user routes, set the  -check_from_user_shapes option to  true.\n \u2022 To check frozen routes, set the  -check_from_frozen_shapes option to  true.\n A net is considered frozen when its  physical_status attribute is set to  locked.\n       To disable checks for routing DRC violations, set the  -drc option to  false.\n To disable checks for unconnected nets, set the  -open_net option to  false.\n To disable checks for antenna rule violations, set the  -antenna option to  false.\n To disable checks for voltage area violations, set the  -voltage_area option to  false.\n To save time, you can restrict the routing verification to specific regions of the block by using the  -coordinates option to specify the lower-left and upper-right coordinates for each rectangular region.\n When you perform area-based DRC, the  check_routes command checks only for DRC violations and voltage area violations.\n It does not check for unconnected nets, antenna violations, or tie-to-rail violations, as these are net-based violations.\n Note: The  -coordinates option and the  -nets option are mutually exclusive; you can use only one of these options.\n The  check_routes command reports the following DRC violations: \u2022 Spacing violations \u25e6 Different-net wire spacing \u25e6 Different-net nondefault wire spacing (note that the DRC report refers to nondefault routing rules as variable rules) \u25e6 Different-net via-cut spacing \u25e6 Different-net nondefault via-cut spacing (note that the DRC report refers to nondefault routing rules as variable rules) \u25e6 Different-net fat extension spacing \u25e6 Dog bone spacing \u25e6 End-of-line spacing \u25e6 Enclosed via spacing \u25e6 Same-net spacing \u25e6 Same-net via-cut spacing \u25e6 Same-net fat extension spacing \u25e6 Special notch spacing \u25e6 U-shape spacing \u25e6 Via-cut to metal spacing \u25e6 Soft spacing       \u2022 Area violations \u25e6 Less than minimum area \u25e6 Less than minimum enclosed area \u25e6 Fat wire via keepout area \u25e6 Jog wire via keepout area \u2022 Length and width violations \u25e6 Less than minimum width \u25e6 Less than minimum length \u25e6 Less than minimum edge length \u25e6 Protrusion length \u2022 Contact violations \u25e6 Needs fat contact \u25e6 Needs poly contact \u25e6 Needs fat contact on extension \u25e6 Over maximum stack level \u2022 Enclosure violations \u25e6 End-of-line wire via enclosure \u25e6 Jog wire via enclosure \u25e6 T-shape wire via enclosure \u2022 Others \u25e6 Open nets, except when doing area-based DRC By default, the  check_routes command reports a maximum of 200 open nets.\n To report all open nets, use the  -report_all_open_nets\u00a0true option (or select \u201cReport all open nets\u201d in the GUI).\n \u25e6 Antenna violations, except when doing area-based DRC \u25e6 Nets crossing the top-cell boundary \u25e6 Frozen layers \u25e6 Minimum layer       \u25e6 Maximum layer \u25e6 Voltage area violations Note: These violations are also reported after each detail route iteration.\n The  check_routes command saves the error data to a file named zroute.err.\n You cannot control the naming of the error data file generated by the  check_routes command, but you can rename the error data file after running the command.\n To rename the error data file, use the following commands: fc_shell>\u00a0 write_drc_error_data -error_data zroute.err \\ -file_name export.err fc_shell>\u00a0 open_drc_error_data -file_name export.err fc_shell>\u00a0 attach_drc_error_data [get_drc_error_data export.err] \\ -name  newname.err After you run the  check_routes command, you can use the DRC query commands to get more information about the violations or use the error browser to examine the violations in the GUI.\n For information about analyzing the DRC violations, see  Using the DRC Query Commands.\n For information about using the error browser, see the  Fusion Compiler Graphical User Interface User Guide.\n After running  check_routes, you can use the following command to run incremental detail routing that uses the  check_routes results as input: fc_shell>\u00a0 route_detail -incremental true \\ -initial_drc_from_input true Note: Incremental detail routing does not fix open nets.\n To fix open nets, you must run ECO routing.\n For information about ECO routing, see  Performing ECO Routing."}
{"header": "How do I Performing Design Rule Checking in an External Tool", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Signoff design rule checking runs the IC\u00a0Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry runset.\n To perform signoff design rule checking, run the  signoff_check_drc command, as described in  Performing Signoff Design Rule Checking.\n In addition, you can use the  signoff_fix_drc command to automatically fix the DRC violations detected by the  signoff_check_drc command.\n For more information, see  Automatically Fixing Signoff DRC Violations.\n Note: An IC\u00a0Validator license is required to run the  signoff_check_drc and signoff_fix_drc commands."}
{"header": "How do I Performing Layout-Versus-Schematic Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Calibre interface You can perform design rule checking with the Calibre tool, convert the Calibre DRC error file to an Fusion Compiler error data file, and then report or view the errors in the Fusion Compiler tool.\n To convert the Calibre DRC error file to an Fusion Compiler error data file, use the read_drc_eror_file comandcomandsread_drc_eror_file read_drc_error_file command.\n For example, fc_shell>\u00a0 read_drc_error_file -file  Calibre_error_file By default, the command generates an error data file named  cell_name.err, where cell_name is derived from the Calibre error report.\n You can specify a name for the error data file by using the  -error_data option.\n Note: The  read_drc_error_file command supports only flat Calibre DRC error files; it does not support Calibre hierarchy DRC error files.\n You can load the error data file created by the  read_drc_error_file command into the error browser to report or display the DRC violations.\n For information about using the error browser, see the  Fusion Compiler Graphical User Interface User Guide."}
{"header": "How do I Reporting the Routing Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform layout-versus-schematic (LVS) checking, which checks for inconsistencies in the physical layout, use the  check_lvs command.\n By default, the  check_lvs command performs the following checks for all signal, clock, and PG nets: \u2022 Shorted nets A shorted net occurs when a net shapes from different nets touch or intersect.\n By default, the command \u25e6 Checks for shorts between net shapes in the top-level design, including shapes in top-level blockages To disable checking for shapes in top-level blockages, use the -check_top_level_blockages\u00a0false option.\n \u25e6 Does not check for shorts between net shapes in the top-level design and net- shapes in child cells To enable this checking, use the  -check_child_cells\u00a0true option.\n To exclude certain types of child cells from checking, use the  -exclude_child_cell_types       option to specify one or more of the following cell types:  abstract,  analog, black_box,  corner,  cover,  diode,  end_cap,  fill,  filler,  flip_chip_driver, flip_chip_pad,  lib_cell,  macro,  module,  pad,  pad_spacer,  physical_only, and  well_tap.\n \u25e6 Does not check for shorts with zero-spacing blockages To enable this checking, use the  -check_zero_spacing_blockages\u00a0true option.\n Note: The  check_lvs command supports only default routing blockages that apply to all net types and have a blockage group ID of 0.\n If the blockage applies only to specific net types or has a nonzero blockage group ID, the command ignores the blockage.\n In addition, the command ignores corridor routing blockages (which are created when you use the  -reserve_for_top_level_routing option with the  create_routing_blockage command) and boundary routing blockages (which are created when you use the  -boundary_internal or  -boundary_external options with the  create_routing_blockage command).\n \u2022 Open nets An open net occurs when the pins of a net are not connected by its net shapes.\n By default, the command \u25e6 Treats power and ground terminals as unconnected voltage sources To treat power and ground terminals as connected, use the -treat_terminal_as_voltage_source\u00a0true option.\n For example, assume your block contains the layout shown in  Figure\u00a0120.\n By default, the  check_lvs command reports two opens for this layout.\n If you use the -treat_terminal_as_voltage_source\u00a0true option, no opens are reported.\n       Figure 120 Layout With Power and Ground Terminals \u25e6 Reports open nets as the bounding box of the open net and does not report floating pins To report detailed open locations, use the  -open_reporting\u00a0detailed option.\n Note that using this option might increase the runtime.\n To report the floating pins, use the  -report_floating_pins\u00a0true option.\n \u2022 Floating net shapes A floating net shape occurs when a net shape is not physically connecting to a pin of its net.\n To perform a subset of these checks, use the  -checks option to specify one or more of the following checks:  short (shorted nets),  open (open nets), and  floating_routes (floating net shapes).\n To check only specific nets, use the  -nets option to specify the nets of interest.\n By default, the  check_lvs command reports a maximum of 20 violations for each type of error.\n To change this limit, use the  -max_errors option.\n To report all violations, specify the maximum number of violations as zero ( -max_errors\u00a00 ).\n You can view the violations reported by the  check_lvs command in the GUI by using the error browser.\n For information about using the error browser, see the  Fusion Compiler Graphical User Interface User Guide.\n To reduce the runtime required by the  check_lvs command, enable multithreading by using the  set_host_options command, as described in  Enabling Multicore Processing."}
{"header": "How do I Reporting the Wire Length", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report statistics about the routing results, use the  report_design\u00a0-routing command.\n This command reports the following information: \u2022 Final wiring statistics, including the \u25e6 Number of signal net shapes for each metal layer \u25e6 Signal wire length for each metal layer \u25e6 Number of PG net shapes for each metal layer \u25e6 PG wire length for each metal layer \u25e6 Horizontal and vertical wire distribution for each metal layer \u25e6 Total number of signal net shapes for the block \u25e6 Total signal wire length for the block \u2022 Final via statistics, including the \u25e6 Simple vias used in each via layer, including the number of instances of each via \u25e6 Double via conversion rate for each via layer \u25e6 Double via conversion rate for the block \u25e6 Custom vias used in the block, including the number of instances of each user- defined via By default, this command reports the information only for the top-level block.\n To report the information for the entire physical hierarchy, use the  -hierarchical option.\n See Also \u2022 Defining Vias"}
{"header": "How do I Using the DRC Query Commands", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the total wire length at any stage of the routing flow, use the consolidated report_wirelength command.\n This command supports all net types, except power ground nets, by default such as signal nets, clock nets.\n It also supports non-stripe power ground nets by option control.\n This command generates a report, which includes the following information in the form of two tables, as shown in the figure: \u2022 Total wire length per layer with separate global and detailed routing lengths \u2022 Total wire length by both horizontal and vertical direction       In the generated report, \u2022 Virtual value means the estimated routing wire length for each net.\n For each net, the engine provides a virtual routing length before real routing.\n It remains even after route_auto.\n \u2022 BestAvailable means the sum of wire length of all nets irrespective of the stage they are in the current design.\n This command also supports slanting wires and counts the real length of an angle wire in total and counts the projection length of the x-axis and y-axis."}
{"header": "How do I Saving Route Information", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can get information about DRC violations by using the  get_drc_errors command to create a collection of DRC violations and then using the  get_attribute command to query the attributes of the errors.\n Some attributes that provide information about DRC errors are  type_name,  bbox,  objects, and  shape.\n Note that the availability of attribute values depends on the error type and the verification method used.\n For a list of all attributes associated with DRC errors, use the  list_attributes\u00a0-application\u00a0-class drc_error command.\n Before you run the  get_drc_errors command, you must load the error data files that you want to query.\n To determine the error data files attached to the current block, use the  get_drc_error_data command.\n You must use the  -all option to include both the opened and unopened error data files in the result.\n fc_shell>\u00a0 get_drc_error_data -all       To load an error data file, use the  open_drc_error_data command.\n fc_shell>\u00a0 open_drc_error_data zroute.err To determine the error data types included in the error data file, use the get_drc_error_types command.\n fc_shell>\u00a0 get_drc_error_types -error_data zroute.err By default, the  get_drc_errors command creates a collection that contains all DRC violations contained in the specified error data file.\n Use the  -filter option to restrict the returned errors.\n For example, to return only \u201cDiff net spacing\u201d errors, use the following command: fc_shell>\u00a0 get_drc_errors -error_data zroute.err \\ -filter {type_name == \"Diff net spacing\"} To get the nets associated with an error, use the  get_attribute command.\n For example, fc_shell>\u00a0 get_attribute [get_drc_errors -error_data zroute.err 859] \\ objects {u0_1/n237}"}
{"header": "How do I Deriving Mask Colors", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To save the route information, use the  write_routes command.\n This command generates a Tcl script that reproduces the metal shapes and vias for a block, including their attribute settings.\n Note that the  write_routes command reproduces routes, but not routing blockages.\n To generate a Tcl script that reproduces routing blockages, use the  write_floorplan command."}
{"header": "How do I Inserting and Removing Cut Metal Shapes", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "At advanced technology nodes, mask colors must be assigned to wires and vias to ensure correct processing of the net shapes during mask synthesis.\n The  route_detail command and other routing commands in the tool usually add the necessary mask colors during routing.\n For net shapes that do not have a color assignment, use the derive_mask_constraint command to derive the color mask for the specified wires and vias from the nearest underlying tracks.\n In case of wide wires that occupy multiple tracks, the command takes the mask color opposite to the next unoccupied track.\n The following example derives the mask color for the net shapes of the net1 net.\n fc_shell>\u00a0 derive_mask_constraint \\ [get_shapes -of_objects [get_nets net1]]       Use options to the  derive_mask_constraint command to control how the mask colors are derived.\n \u2022 Derive cut mask constraints for the specified nets or vias.\n fc_shell>\u00a0 derive_mask_constraint -derive_cut_mask \\ [get_vias -within {{600 600} {700 700}}] \u2022 Derive mask constraints from overlapping or touching pins or ports.\n fc_shell>\u00a0 derive_mask_constraint -follow_pin_mask \\ [get_shapes -of_objects [get_nets net1]] \u2022 Derive the mask constraint from the wider overlapping or touching object rather than the wire track.\n fc_shell>\u00a0 derive_mask_constraint -follow_wider_object_mask \\ [get_shapes -of_objects [get_nets net1]] See Also \u2022 Multiple-Patterning Concepts"}
{"header": "How do I 7", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "Cut metal shapes are used in double-patterning designs to reduce the line-end minimum spacing.\n A cut metal layer and the dimensions of the cut metal shapes inserted on that layer are defined in a  Layer section in the technology file.\n The width of the cut metal shapes is defined by the  cutMetalWidth attribute.\n The height of the cut metal shapes is defined by either the  cutMetalHeight or  cutMetalExtension attribute.\n A cut metal layer corresponds to the metal layer with the same mask number.\n For example, cutMetal1 corresponds to metal1.\n For information about the technology file, see the  Synopsys Technology File and Routing Rules Reference Manual.\n After the routing is finalized, you add cut metal shapes by using the  create_cut_metals command.\n This command inserts a cut metal shape between metal shapes when all of the following conditions are met: \u2022 The spacing between the metal shapes in the preferred direction is  cutMetalWidth.\n \u2022 There is no existing cut metal shape in the location.\n \u2022 The metal shapes are on a metal layer that corresponds to a cut metal layer defined in the technology file.\n The command inserts cut metal shapes between net shapes, a net shape and a PG shape, a PG shape and an obstruction, and metal shapes within a child cell.\n After inserting       the cut metal shapes, the command propagates the color of the metal shapes to the cut metal shapes.\n When you write a DEF file for a block with cut metal shapes, you must use the  -version 5.8 option with the  write_def command.\n When you write a GDSII or OASIS file for a block with cut metal shapes, you must use the  -connect_below_cut_metal option with the  write_gds or  write_oasis command.\n If the routing changes after inserting cut metal shapes, you must remove the existing cut metal shapes and reinsert them.\n To remove all cut metal shapes from a block, use the remove_cut_metals command."}
{"header": "How do I Inserting Tap Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides chip finishing and design for manufacturing and yield capabilities that you can apply throughout the various stages of the design flow to address process design issues encountered during chip manufacturing.\n For information about the chip finishing and design for manufacturing features, see the following topics: \u2022 Inserting Tap Cells \u2022 Performing Boundary Cell Insertion \u2022 Finding and Fixing Antenna Violations \u2022 Inserting Redundant Vias \u2022 Optimizing Wire Length and Via Count \u2022 Reducing Critical Areas \u2022 Inserting Metal-Insulator-Metal Capacitors \u2022 Inserting Filler Cells \u2022 Inserting Metal Fill"}
{"header": "How do I Using the create_tap_cells Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A  tap cell is a special nonlogic cell with a well tie, substrate tie, or both.\n These cells are typically used when most or all of the standard cells in the library contain no substrate or well taps.\n Generally, the design rules specify the maximum distance allowed between every transistor in a standard cell and a well or substrate tap.\n Before global placement (during the floorplanning stage), you can insert tap cells in the block to form a two-dimensional array structure to ensure that all standard cells placed subsequently comply with the maximum diffusion-to-tap distance limit.\n After you insert the tap cells, visually check to ensure that all standard-cell placeable areas are properly protected by tap cells.\n       The Fusion Compiler tool provides two methods to insert a tap cell array: \u2022 Insert the tap cell array based on the site rows and the maximum distance between tap cells To use this method, use the  create_tap_cells command, as described in  Using the create_tap_cells Command.\n \u2022 Insert the tap cell array using a specified offset and pitch, and optionally insert additional tap cells near the boundary To use this method, use the  create_cell_array command, as described in  Using the create_cell_array Command.\n Advanced nodes often require the insertion of additional tap cells to manage the substrate and well noise.\n You can use the following capabilities to insert additional tap cells after standard tap cell insertion: \u2022 Insertion of tap walls A  tap wall is a row or column of tap cells placed linearly without any gaps between cells.\n You can insert a tap wall outside or inside of the boundary of a block, macro, or hard placement blockage.\n A tap wall that is outside a boundary is called an  exterior tap wall.\n A tap wall that is inside a boundary is called an  interior tap wall.\n \u25e6 To insert an exterior tap wall, use the  create_exterior_tap_walls command, as described in  Inserting Exterior Tap Walls.\n \u25e6 To insert an interior tap wall, use the  create_interior_tap_walls command, as described in  Inserting Interior Tap Walls.\n \u2022 Insertion of tap meshes A  tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window.\n To insert a tap mesh, use the  create_tap_meshes command, as described in  Inserting Tap Meshes.\n \u2022 Insertion of dense tap arrays A  dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the  create_tap_cells command.\n To insert a dense tap array, use the create_dense_tap_cells command, as described in  Inserting Dense Tap Arrays."}
{"header": "How do I Using the create_cell_array Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "ad_tap_cel_aray comandcomandsad_tap_cel_aray To add a tap cell array based on the site rows, use the  create_tap_cells command.\n You must specify the name of the library cell to use for tap cell insertion ( -lib_cell option) and the maximum distance, in microns, between tap cells ( -distance option).\n       For example, fc_shell>\u00a0 create_tap_cells -lib_cell myreflib/mytapcell -distance 30 Note: If the  place.legalize.enable_pin_color_alignment_check application option is  true (its default is  false ), the command ensures that internal cell pins and metal of the tap cells align with a routing track of the appropriate color when inserting the tap cells and shifts the tap cells to avoid violating color alignment.\n To avoid signoff DRC errors due to this shifting, reduce the tap distance slightly when this application option is  true.\n By default, the  create_tap_cells command inserts tap cells in every row for the entire block.\n The tool starts inserting the tap cells at the left edge of the row and uses the specified tap distance to determine the location of the subsequent tap cells.\n In addition, if a tap cell does not exist within the minimum tap distance (half the specified tap distance) from each row edge adjacent to the block\u2019s boundary, a hard macro, or a hard placement blockage, the tool inserts an additional tap cell.\n  Figure\u00a0121  shows the default tap cell placement for a block that uses the every-row insertion pattern.\n Note that extra tap cells are added to the right of the hard macro to ensure that a tap cell exists within the minimum tap distance from the edge of the hard macro.\n Figure 121 Default Tap Cell Placement       You can modify the following aspects of the default behavior: \u2022 The library cell used for tap cell insertion on rows with a mirrored (MX) orientation Use the  -mirrored_row_lib_cell option to specify the library cell to use for mirrored rows.\n \u2022 The pattern used to insert the tap cells Use the  -pattern option to specify one of the following tap cell insertion patterns: \u25e6 every_row (the default) This pattern inserts tap cells in every row.\n For this pattern, the tap distance specified with the  -distance option should be approximately twice the maximum diffusion-to-tap value specified in the technology design rules.\n \u25e6 every_other_row This pattern inserts tap cells only in the odd-numbered rows.\n For this pattern, the tap distance specified with the  -distance option should be approximately twice the maximum diffusion-to-tap value specified in the technology design rules.\n \u25e6 stagger This pattern inserts tap cells in every row with the tap cells in even rows offset by half the offset value ( -offset option) relative to the odd rows, which produces a checkerboard-like pattern.\n For this pattern, the tap distance specified with the -distance option should be approximately four times the maximum diffusion-to-tap value specified in the technology design rules.\n \u2022 The offset from the left edge of the row Use the  -offset option to shift the pattern startpoint to the right by the specified distance in microns.\n \u2022 The handling of fixed cells By default, tap cells are inserted at the computed tap locations, regardless of whether a fixed cell occupies that location.\n Use the  -skip_fixed_cells option to prevent the insertion of tap cells in locations occupied by fixed cells.\n By default, when you use this option, the command considers the fixed cell as a blockage and breaks the row at the fixed cell, which can result in a tap cell being inserted on each side of the fixed cell.\n To prevent tap cells from overlapping fixed cells without breaking the row, use the -preserve_distance_continuity option with the  -skip_fixed_cells option.\n When you use both options, the command shifts the tap cell to avoid overlap with the fixed cell.\n The  -preserve_distance_continuity option shifts only those tap cells whose computed tap location is occupied by an instance of one of the specified library cells.\n       For example, the following command shifts tap cells whose computed tap location is occupied by a fixed instance of the mylib/cell1 library cell: fc_shell>\u00a0 create_tap_cells -lib_cell mylib/tap -distance 30 \\ -skip_fixed_cells -preserve_distance_continuity mylib/cell1 When you use the  -skip_fixed_cells option, you can also specify the minimum horizontal spacing between the boundary and a corner tap cell that is above or below a blocked area by using the  -min_horizontal_periphery_spacing option.\n This option specifies the minimum number of unit tiles between the boundary and an affected corner tap cell.\n Figure\u00a0122 shows how using this option affects the tap cell placement both with and without boundary cells.\n Figure 122 Tap Cell Boundary Row Spacing -min_horizontal_periphery_spac -min_horizontal_periphery_spac \u2022 The addition of extra tap cells You can use one or both of the following methods to prevent the insertion of extra tap cells: \u25e6 Use the  -row_end_tap_bypass option to specify that the boundary cells contain taps, so additional tap cells are not inserted at the boundary.\n Note that the command does not verify that the block has boundary cells or that the boundary cells actually contain taps.\n \u25e6 Use the  -at_distance_only option to allow the insertion of tap cells only at the specified tap distance, half of the tap distance, or one fourth of the tap distance (for the stagger pattern only).\n Note that using this option can cause DRC violations.\n \u2022 The regions in which to insert tap cells Use the  -voltage\u00a0area option to restrict the tap cell insertion to the specified voltage areas.\n       \u2022 The naming convention used to identify the inserted tap cell instances By default, the tool uses the following naming convention for inserted tap cells: tapfiller!\n library_cell_name!\n number Use the  -separator option to change the separator character from its default of \u201c!.\u201d To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: tapfiller!\n prefix!\n library_cell_name!\n number"}
{"header": "How do I Inserting Exterior Tap Walls", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "ad_tap_cel_aray comandcomandsad_tap_cel_aray To add a tap cell array with specific placement, use the  create_cell_array command.\n You must specify the name of the library cell to use for tap cell insertion ( -lib_cell option), and the x- and y-pitches.\n For example, fc_shell>\u00a0 create_cell_array -lib_cell myreflib/mytapcell \\ -x_pitch 10 -y_pitch 10 By default, the  create_cell_array command inserts a tap cell in each location in the specified grid for the entire block.\n The tool starts inserting the tap cells at the bottom-left of the core area and uses the specified x- and y-pitches to determine the location of the subsequent tap cells.\n The inserted tap cells are snapped to the site rows and placed in the default orientation for the site row.\n If a location is occupied by a fixed cell, hard macro, soft macro, or power-switch cell, the command does not insert a tap cell at that location.\n You can modify the following aspects of the default behavior: \u2022 The region in which to insert tap cells Use the  -voltage\u00a0area option to restrict the tap cell insertion to the specified voltage areas.\n Use the  -boundary option to restrict the tap cell insertion to the specified region.\n If you use both options, the command inserts tap cells only in the overlapping region.\n \u2022 The offset from the insertion region boundary Use the  -x_offset option to shift the pattern startpoint to the right by the specified distance in microns.\n Use the  -y_offset option to shift the pattern startpoint up by the specified distance in microns.\n       \u2022 The insertion pattern Use the  -checkerboard option to insert a tap cell in every other location in the specified grid.\n \u25e6 To place a tap cell in the lower-left corner, use the  -checkerboard\u00a0even option.\n \u25e6 To keep the lower-left corner empty, use the  -checkerboard\u00a0odd option.\n In some design methodologies, you must insert a tap cell in empty spaces in the checkerboard pattern that are above or below specific cells, such as critical area breaker cells or boundary cells.\n To enable the insertion of these extra tap cells, use the -preserve_boundary_row_lib_cells option to specify the affected library cells.\n \u2022 The snapping behavior To disable snapping of the inserted tap cells to the site rows, set the -snap_to_site_row\u00a0false option.\n When you set this option to  false, the tool uses R0 as the default orientation for the inserted cells.\n \u2022 The orientation of the inserted tap cell instances To specify the orientation of the inserted tap cells, use the  -orient option to specify one of the following orientation values:  R0,  R90,  R180,  R270,  MX,  MY,  MXR90, or  MYR90.\n \u2022 The naming convention used to identify the inserted tap cell instances By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R # _C # _ number To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R # _C # _ number"}
{"header": "How do I Inserting Interior Tap Walls", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "An  exterior tap wall is a row or column of tap cells that is placed outside the boundary of a block, macro, or hard placement blockage.\n The tap cells in the tap wall are placed linearly without any gaps between cells.\n To insert an exterior tap wall, use the  create_exterior_tap_walls command.\n You must specify the following information: \u2022 The tap cell used in the tap wall (the  -lib_cell option) By default, the command inserts the tap cells with R0 orientation.\n To place the cells with a different orientation, use the  -orientation option.\n If the design has a FinFET grid, follow these guidelines when selecting the tap cell to ensure proper insertion of the tap wall: \u25e6 For horizontal tap walls, ensure that the cell\u2019s width in the specified orientation is an integer multiple of the x-pitch of the FinFET grid \u25e6 For vertical tap walls, ensure that the cell\u2019s height in the specified orientation is an integer multiple of the y-pitch of the FinFET grid By default, the tool uses the following naming convention for inserted tap cells: extTapWall__ library_cell_name _R # _C # _ number To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R # _C # _ number \u2022 The side along which to insert the tap wall (the  -side option) You can specify only a single side,  top,  bottom,  right, or  left.\n To insert a tap wall on more than one side, run the command multiple times.\n \u2022 The tap insertion region (the  -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox\u00a0{{ llx lly }\u00a0{ urx ury }} The bounding box must span a portion of the object\u2019s edge on the specified side along which to insert the tap wall.\n If the bounding box spans multiple edges along the specified side, the command inserts the tap wall along the longest edge.\n If the bounding box does not span any edges of the specified side, the command issues an error message.\n       By default, a horizontal tap wall starts at the left edge of the specified bounding box and abuts the top or bottom boundary edge; a vertical tap wall starts at the bottom edge of the specified bounding box and abuts the left or right boundary edge.\n To specify margins for the tap wall insertion, use the  -x_margin and  -y_margin options.\n If the specified region, including the margins, is too small to fit a tap wall, the command does not insert tap cells.\n You should ensure that the insertion region does not contain any placement blockages, fixed cells, or macros.\n These obstructions can prevent the insertion of the tap cells and result in an incomplete or missing tap wall.\n When inserting the tap wall, the command does not honor the standard cell rows or sites and does not cross the object boundary.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"header": "How do I Inserting Tap Meshes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "An  interior tap wall is a row or column of tap cells that is placed inside the boundary of the standard cell placement area of a block, a macro, hard placement blockage, or nondefault voltage area.\n Note: You can insert interior tap walls only for designs with a single site definition.\n To insert an interior tap wall, use the  create_interior_tap_walls command.\n You must specify the following information: \u2022 The tap cell used in the tap wall (the  -lib_cell option) The specified tap cell must be a single-height cell that matches the row height and site width.\n By default, the command inserts the tap cells with the row orientation.\n To place the cells with a different orientation, use the  -orientation option.\n By default, the tool uses the following naming convention for inserted tap cells: tapfiller__ library_cell_name _R # _C # _ number To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R # _C # _ number \u2022 The side along which to insert the tap wall (the  -side option) You can specify only a single side,  top,  bottom,  right, or  left.\n To insert a tap wall on more than one side, run the command multiple times.\n       By default, the tap cells are placed along all edges on the specified side of the standard cell placement area with no gaps between the tap cells.\n \u2022 To specify the tap insertion region, use the  -bbox option to specify the lower-left and upper-right corners of its bounding box: -bbox\u00a0{{ llx lly }\u00a0{ urx ury }} When you use this option, the command inserts a tap wall along the longest edge on the specified side of the placeable area encompassed by the bounding box.\n The alignment of the tap wall depends on the number of corners of the edge segment encompassed by the bounding box.\n \u25e6 If the edge segment does not contain a corner, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall.\n \u25e6 If the edge segment contains one corner, the tap wall starts at that corner.\n \u25e6 If the edge segment contains two corners along the specified side, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall.\n For a horizontal tap wall with two corners, the spacing between the last two cells might be shortened to align with the right corner.\n If there is not enough space, the last cell might not abut the right corner.\n \u2022 For horizontal tap walls, you can specify a gap distance between tap cells by using the -x_spacing option.\n If you specify a value smaller than the tap cell width, the command uses a spacing of zero.\n If you specify a value that is not a multiple of the site width, the command rounds it down to a multiple of the site width.\n When inserting the tap wall, the command honors the standard cell rows and sites; if the rows and sites are not defined, the command does not insert tap cells.\n Obstructions such as placement blockages, fixed cells, and macros can prevent the insertion of the tap cells and result in an incomplete or missing tap wall.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"header": "How do I Inserting Dense Tap Arrays", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A  tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window.\n A tap mesh is typically inserted outside of a place and route block, but you can insert one in any area that is either completely inside or completely outside the core area.\n To insert a tap mesh, use the  create_tap_meshes command.\n You must specify the following information: \u2022 The tap cell used in the tap mesh (the  -lib_cell option) By default, the command inserts the tap cells with R0 orientation.\n To place the cells with a different orientation, use the  -orientation option.\n By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R # _C # _ number To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R # _C # _ number \u2022 The tap insertion region (the  -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox\u00a0{{ llx lly }\u00a0{ urx ury }} \u2022 The mesh window (the  -mesh_window option) You specify the size of the mesh window by specifying an integer value for the pitch in the x- and y-directions.\n -mesh_window\u00a0{ x_pitch y_pitch } The mesh window is aligned with the lower-left corner of the tap insertion region.\n When inserting the tap mesh, the command does not honor the standard cell rows or sites.\n It places a tap cell in the lower-left corner of each mesh window.\n If that location is blocked, the command uses the closest available location, which is measured as the Manhattan distance to the lower-left corner of the mesh window.\n If there is no available location, the command issues a warning and does not place a tap cell in that mesh window.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"header": "How do I Performing Boundary Cell Insertion", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "A  dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the  create_tap_cells command.\n To insert a dense tap array, use the  create_dense_tap_cells command.\n You must specify the following information: \u2022 The tap cell used in the tap wall (the  -lib_cell option) You must specify the same tap cell as when you ran the  create_tap_cells command.\n By default, the tool uses the following naming convention for inserted tap cells: tapfiller!\n library_cell_name!\n number Use the  -separator option to change the separator character from its default of \u201c!.\u201d To identify the tap cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: tapfiller!\n prefix!\n library_cell_name!\n number \u2022 The tap distance (the  -distance option) The specified distance must be smaller than the tap distance used by the create_tap_cells command.\n \u2022 The tap insertion region (the  -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox\u00a0{{ llx lly }\u00a0{ urx ury }} The  create_dense_tap_cells command first removes the existing tap cells that are completely within the tap insertion region, and then reinserts the tap cells with the specified tap distance to create a denser array in the specified region.\n To avoid tap rule violations, specify the same tap cell insertion pattern as was used by the  create_tap_cells command.\n The  create_dense_tap_cells command supports the following options to control the tap cell insertion:  -offset,  -pattern, -skip_fixed_cells, and  -at_distance_only.\n For details about these options, see the man page.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"header": "How do I Specifying the Boundary Cell Insertion Requirements", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before placing the standard cells, you can add boundary cells to the block.\n Boundary cells consist of end-cap cells, which are added to the ends of the cell rows and around the boundaries of objects such as the core area, hard macros, blockages, and voltage areas, and corner cells, which fill the empty space between horizontal and vertical end-cap cells.\n End-cap cells are typically nonlogic cells such as a decoupling capacitor for the power rail.\n Because the tool accepts any standard cell as an end-cap cell, ensure that you specify suitable end-cap cells.\n To insert boundary cells, 1.\n Specify the boundary cell insertion requirements by using the set_boundary_cell_rules command, as described in  Specifying the Boundary Cell Insertion Requirements.\n 2.\n Insert the boundary cells based on the specified rules by using the compile_boundary_cells or  compile_targeted_boundary_cells command, as described in  Inserting Boundary Cells.\n 3.\n Verify the boundary cell placement by using the  check_boundary_cells or check_targeted_boundary_cells command, as described in  Verifying the Boundary Cell Placement.\n This process supports a single site definition per run.\n The  compile_boundary_cells and  compile_targeted_boundary_cells commands determine the site definition based on the library cells specified with the  set_boundary_cell_rules command, and insert boundary cells only in the regions that use this site definition.\n If your design has multiple site definitions, you must run this process one time for each site definition."}
{"header": "How do I Specifying the Library Cells for Boundary Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify the boundary cell insertion requirements, use the  set_boundary_cell_rules command.\n You use this command to specify the following requirements: \u2022 The library cells to use for the boundary cells, as described in  Specifying the Library Cells for Boundary Cell Insertion \u2022 The rules used to place the boundary cells, as described in  Specifying Boundary Cell Placement Rules \u2022 The naming convention used for the inserted cells, as described in  Specifying the Naming Convention for Boundary Cells \u2022 The creation of routing guides to honor the metal cut allowed and forbidden preferred grid extension rules, as described in  Creating Routing Guides During Boundary Cell Insertion       Note: This feature is supported only by the  compile_boundary_cells command; it is not supported by the  compile_targeted_boundary_cells command.\n \u2022 The creation of placement blockages to honor the minimum jog and minimum separation rules, as described in  Creating Placement Blockages During Boundary Cell Insertion Note: This feature is supported only by the  compile_boundary_cells command; it is not supported by the  compile_targeted_boundary_cells command.\n Note: The settings specified by the  set_boundary_cell_rules command are saved in the design library.\n See Also \u2022 Reporting the Boundary Cell Insertion Requirements"}
{"header": "How do I Specifying Boundary Cell Placement Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Boundary cells include both end-cap cells placed on the left, right, top, and bottom boundaries, and inside and outside corner cells.\n You can specify different library cells for each boundary cell type.\n To specify the library cells, use the following options with the set_boundary_cell_rules command: \u2022 -left_boundary_cell and  -right_boundary_cell These options specify a single library cell that is used for the end-cap cells for the left and right boundaries, respectively.\n \u2022 -top_boundary_cells and  -bottom_boundary_cells These options specify a list of library cells that are used for the end-cap cells for the top and bottom boundaries, respectively.\n The command inserts the cells in the specified order.\n If the remaining space is smaller than the current cell, the command inserts the next cell in order that fits in the remaining space.\n For a vertical-row block, rows start at the bottom and end at the top, so the top boundary is along the left side of the block and the bottom boundary is along the right side of the block.\n For the flipped rows in a double-back block, the top boundary cells are used on the bottom boundaries and the bottom boundary cells are used on the top boundaries.\n \u2022 -top_tap_cell and  -bottom_tap_cell       These options specify a single library cell that is used for the tap cells on the top and bottom boundary rows, respectively.\n The tool inserts the tap cells to ensure that the end-cap cells inserted on the top and bottom boundary rows comply with the maximum diffusion-to-tap distance limit.\n \u2022 -top_left_outside_corner_cell,  -top_right_outside_corner_cell, -bottom_left_outside_corner_cell, and  -bottom_right_outside_corner_cell These options specify a single library cell that is used for each outside corner location.\n \u2022 -top_left_inside_corner_cells,  -top_right_inside_corner_cells, -bottom_left_inside_corner_cells, and  -bottom_right_inside_corner_cells These options specify a list of library cells for each inside corner location.\n The tool inserts the first corner cell that matches the size of the inside corner.\n If none matches exactly, it inserts the first cell that can be placed without violating any rules.\n Figure\u00a0123 shows the boundary and corner cell locations for a horizontal-row block with two hard macros or blockages.\n Note that the cell locations are flipped when the row is flipped.\n Figure 123 Boundary Cell Locations"}
{"header": "How do I Specifying the Naming Convention for Boundary Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, \u2022 When you run the  compile_boundary_cells command, the tool places the boundary cells in their default orientation around the core area, hard macros, and hard placement blockages.\n \u2022 When you run the  compile_targeted_boundary_cells command, the tool places the boundary cells in their default orientation around the specified objects.\n To flip the boundary cell orientations, use one or more of the following options with the  set_boundary_cell_rules command: -mirror_left_boundary_cell,  -mirror_right_boundary_cell, -mirror_left_outside_corner_cell,  -mirror_right_outside_corner_cell, -mirror_left_inside_corner_cell,  -mirror_right_inside_corner_cell, -mirror_left_inside_horizontal_abutment_cell, and -mirror_right_inside_horizontal_abutment_cell.\n You cannot flip the orientation of the top and bottom boundary cells.\n In addition, when you use the  compile_boundary_cells command, you can modify the following aspects of the default placement behavior: \u2022 Swapping of the top and bottom inside corner cells on flipped rows Use the  -do_not_swap_top_and_bottom_inside_corner_cell option with the set_boundary_cell_rules command to prevent the command from using the bottom inside corner cell on the top inside corner of flipped rows and the top inside corner cell on the bottom inside corner of flipped rows.\n \u2022 Consideration of voltage areas Use the  -at_va_boundary option with the  set_boundary_cell_rules command to insert horizontal boundary cells on both sides of the voltage area boundaries.\n \u2022 Existence of one-unit-tile gaps Use the  -no_1x option with the  set_boundary_cell_rules command to prevent boundary cell insertion from creating one-unit-tile gaps.\n When you use this option, the command does not insert boundary cells on a row when the row length equals two times the corner cell width plus one unit tile width.\n Note that if the row length equals two times the corner cell width, the command does insert boundary cells.\n \u2022 Distance between tap cells Use the  -tap_distance option with the  set_boundary_cell_rules command to specify the distance in microns between the tap cells inserted on the top and bottom boundary rows.\n       \u2022 Insertion of boundary cells on short rows Use the  -min_row_width option with the  set_boundary_cell_rules command to prevent insertion of boundary cells on short rows.\n This option defines the width threshold for inserting boundary cells on a row.\n If the row width is less than the specified value, the command does not insert boundary cells on the row.\n \u2022 Insertion of boundary cells in child blocks Use the  -insert_into_blocks option with the  set_boundary_cell_rules command to recursively insert boundary cells in the child blocks.\n By default, the tool does not insert boundary cells in the child blocks."}
{"header": "How do I Creating Routing Guides During Boundary Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the tool uses the following naming convention for inserted boundary cells: boundarycell!\n library_cell_name!\n number To change the separator character from its default of \u201c!,\u201d use the  -separator option with the  set_boundary_cell_rules command..\n To identify the boundary cells inserted in a specific run, use the  -prefix option with the set_boundary_cell_rules command to specify a prefix string.\n When you use this option, the tool uses the following naming convention: boundarycell!\n prefix!\n library_cell_name!\n number"}
{"header": "How do I Creating Placement Blockages During Boundary Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If your technology file defines metal cut allowed and forbidden preferred grid extension rules, you can create routing guides for these rules during boundary cell insertion by using the  -add_metal_cut_allowed option with the  set_boundary_cell_rules command.\n When you use this option, the  compile_boundary_cells command creates the following routing guides: \u2022 Metal cut allowed routing guides, which cover the area taken up by all the placeable site rows reduced by the vertical shrink factor, which is 50 percent of the smallest site row height \u2022 Forbidden preferred grid extension routing guides, which cover the remaining area up to the block boundary Note: This feature is supported only by the  compile_boundary_cells command; it is not supported by the  compile_targeted_boundary_cells command."}
{"header": "How do I Reporting the Boundary Cell Insertion Requirements", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If your technology has minimum jog or minimum separation requirements, you can create placement blockages for these requirements during boundary cell insertion with the  compile_boundary_cells command by using the following options with the set_boundary_cell_rules command: \u2022 -min_horizontal_jog If a horizontal edge of a macro, including its hard keepout margin, hard placement blockage, or voltage area, including its guard band, is less than the specified value, the  compile_boundary_cells\u00a0-add_placement_blockage command creates a placement blockage to prevent a violation.\n \u2022 -min_vertical_jog If a vertical edge of a macro, including its hard keepout margin, hard placement blockage, or voltage area, including its guard band, is less than the specified value, the  compile_boundary_cells\u00a0-add_placement_blockage command creates a placement blockage to prevent a violation.\n \u2022 -min_horizontal_separation If the continuous horizontal placement area is less than the specified value, the compile_boundary_cells\u00a0-add_placement_blockage command creates a placement blockage to prevent a violation.\n \u2022 -min_vertical_separation If the continuous vertical placement area is less than the specified value, the compile_boundary_cells\u00a0-add_placement_blockage command creates a placement blockage to prevent a violation.\n Note: By default, the  compile_boundary_cells command checks the specified rules, but does not create the placement blockages.\n To create the placement blockages, you must use the  -add_placement_blockage option with the compile_boundary_cells command.\n This feature is supported only by the  compile_boundary_cells command; it is not supported by the  compile_targeted_boundary_cells command."}
{"header": "How do I Removing Boundary Cell Insertion Requirements", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the boundary cell insertion requirements specified by the set_boundary_cell_rules command, use the  report_boundary_cell_rules command.\n This command reports only the user-specified settings; it does not report any default settings."}
{"header": "How do I Inserting Boundary Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove one or more of the boundary cell insertion requirements specified by the set_boundary_cell_rules command, use the  remove_boundary_cell_rules command."}
{"header": "How do I Verifying the Boundary Cell Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides several methods for inserting boundary cells, depending on where you want to insert the boundary cells.\n \u2022 To insert boundary cells around the core area, hard macros, and placement blockages, use the  compile_boundary_cells command.\n \u2022 To insert boundary cells only around one or more voltage areas, use the compile_boundary_cells command with the  -voltage_area option.\n \u2022 To insert boundary cells only around specific objects, use the compile_targeted_boundary_cells command with the  -target_objects option.\n You can use this command to insert boundary cells around specific macros, voltage areas, voltage area shapes, placement blockages, routing blockages, and the core area.\n The  set_boundary_cell_rules command configures boundary cell insertion for both the  compile_boundary_cells and  compile_targeted_boundary_cells commands.\n However, some rules are honored only by the  compile_boundary_cells command.\n For details, see  Specifying the Boundary Cell Insertion Requirements."}
{"header": "How do I Finding and Fixing Antenna Violations", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After inserting the boundary cells with the  compile_boundary_cells command, verify the placement by using the  check_boundary_cells command.\n To create an error data file to view the errors in the error browser, use the  -error_view option.\n For information about using the error browser, see the  Fusion Compiler Graphical User Interface User Guide.\n This command checks the boundary cell placement for the following issues: \u2022 Missing boundary or corner cells This check verifies that there are boundary and corner cells around the entire boundary, with no gaps.\n  Figure\u00a0124 shows a valid placement, as well as errors caused by missing cells.\n       Figure 124 Check for Missing Boundary or Corner Cells Note: For established nodes, boundary cells are inserted only on the left and right sides.\n In this case, the command verifies only that there are no gaps on these sides.\n \u2022 Incorrect boundary or corner cells This check verifies that the library cells used for the boundary and corner cells match the cells specified by the  set_boundary_cell_rules command.\n \u2022 Incorrect orientation of boundary cells This check verifies that the orientation of each boundary cell matches the allowed orientations specified by the  set_boundary_cell_rules command.\n \u2022 Short rows and edges This check verifies that each row of boundary cells is wider than the value specified by the  set_boundary_cell_rules\u00a0-min_row_width option and that the horizontal edges of each blockage are greater than the value specified by the set_boundary_cell_rules\u00a0-min_horizontal_jog option."}
{"header": "How do I Defining Antenna Rules", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In chip manufacturing, gate oxide can be easily damaged by electrostatic discharge.\n The static charge that is collected on wires during the multilevel metalization process can damage the device or lead to a total chip failure.\n The phenomenon of an electrostatic charge being discharged into the device is referred to as either antenna or charge- collecting antenna problems.\n       To prevent antenna problems, the tool verifies that for each input pin the metal antenna area divided by the gate area is less than the maximum antenna ratio given by the foundry: (antenna-area)/(gate-area) < (max-antenna-ratio) This check is based on the global and layer-specific antenna rules defined for the block and the antenna properties of the cells in the block.\n The antenna flow consists of the following steps: 1.\n  Define the antenna rules.\n 2.\n  Specify the antenna properties of the pins and ports.\n 3.\n  Analyze and fix the antenna violations."}
{"header": "How do I Calculating the Maximum Antenna Ratio", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Antenna rules define how to calculate the maximum antenna ratio for the nets in a block, as well as the antenna ratio for a pin.\n You must define a global antenna rule by using the define_antenna_rule command.\n You can also specify layer-specific antenna rules by using the  define_antenna_layer_rule command.\n The tool uses the global antenna rule whenever a layer-specific antenna rule does not exist.\n The following topics describe how to define the antenna rules: \u2022 Calculating the Maximum Antenna Ratio \u2022 Calculating the Antenna Ratio for a Pin"}
{"header": "How do I Calculating the Antenna Ratio for a Pin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To control the method used to calculate the maximum allowable antenna ratio, you must specify the following information: \u2022 How much protection the diodes provide (the diode protection mode) To specify the diode protection mode, use the  -diode_mode option with the define_antenna_rule command, as described in  Setting the Diode Protection Mode.\n This is a required option of the  define_antenna_rule command.\n \u2022 How to perform antenna ratio calculation with diode protection (the diode ratio vector) To specify the diode ratio vector, use the  -diode_ratio option with the define_antenna_layer_rule command, as described in  Specifying the Diode Ratio Vector.\n This is a required option of the  define_antenna_layer_rule command.\n       Setting the Diode Protection Mode The diode protection mode specifies how much protection the diodes provide.\n Advanced technology designs often use cells and macros with different gate oxide thicknesses, which affect the antenna rule calculations.\n The Fusion Compiler tool uses gate classes to represent the various gate oxide thicknesses.\n The tool supports up to four gate oxide thicknesses: gate class 0, gate class 1, gate class 2, and gate class 3.\n If a cell pin does not have gate class data, it is treated as gate class 0.\n The Fusion Compiler tool supports 18 diode protection modes, most of which support only a single gate oxide thickness.\n For advanced technology designs that use cells and macros with different gate oxide thicknesses, you must use one of the diode protection modes that support multiple gate oxide thicknesses: 14, 16, and 18.\n To specify the diode protection mode, use the  -diode_mode option with the define_antenna_rule command.\n This is a required option of the  define_antenna_rule command.\n Table\u00a035 defines how each of the diode protection mode settings affect the maximum antenna ratio for a net.\n The diode protection mode also affects the computation of the maximum antenna ratio for individual diodes.\n The antenna ratio calculation formulas for diodes are shown in  Table\u00a037 ; these formulas use the values in the diode ratio vector specified in the  -diode_ratio option of the  define_antenna_layer_rule command, as described in  Specifying the Diode Ratio Vector.\n Table 35 Diode Protection Mode Settings Diode protection mode Definition                           Table 35 Diode Protection Mode Settings (Continued) Diode protection mode Definition                                        Specifying the Diode Ratio Vector The diode ratio vector specifies the values used to calculate the maximum antenna ratio.\n To specify the diode ratio vector, use the  -diode_ratio option with the define_antenna_layer_rule command.\n If you do not specify a diode ratio, the tool uses {0 0 1 0 0}.\n The actual usage of the diode ratio vector depends on the diode mode that was specified in the  define_antenna_rule\u00a0-diode_mode option.\n       Table\u00a036 shows the format of the diode ratio vector for the various diode modes.\n  Table\u00a037 shows how the vector values are used to calculate the maximum antenna ratio for each diode mode.\n In this table, \u2022 dp represents the diode protection value specified for an output pin.\n For information about specifying this value, see  Specifying Antenna Properties.\n \u2022 layerMaxRatio represents the maximum antenna ratio for the layer, as specified by the  -ratio option of the  define_antenna_layer_rule command or one the -metal_ratio or  -cut_ratio option of the  define_antenna_rule command if the layer-specific value is not defined.\n For examples of the maximum antenna ratio calculations, see \u2022 Example for Diode Modes 2, 3, and 4 \u2022 Example for Diode Modes 5 and 6 \u2022 Example for Diode Modes 7 and 8 \u2022 Example for Diode Mode 14 With Multiple Gate Oxide Thicknesses Table 36 Diode Ratio Vector Formats Diode modes Format  { v0 v1 v2 v3 [ v4 ]} v4  v4    {{ v0 v1 v2 v3 [ v4 ]}{ s0 s1 s2 s2 s4 s5 }} { s0 s1 s2 s3 s4 s5}  { v0 1 v1 1 v2 1 v3 1 v4 1 v5 1 v6 1 v7 1 v8 1 v9 1 } { v0 2 v1 2 v2 2 v3 2 v4 2 v5 2 v6 2 v7 2 v8 2 v9 2 } { v0 3 v1 3 v2 3 v3 3 v4 3 v5 3 v6 3 v7 3 v8 3 v9 3 } { v0 4 v1 4 v2 4 v3 4 v4 4 v5 4 v6 4 v7 4 v8 4 v9 4 }   { v0 1 v1 1 v2 1 v3 1 v4 1 v5 1 v6 1 v7 1 } { v0 2 v1 2 v2 2 v3 2 v4 2 v5 2 v6 2 v7 2 } { v0 3 v1 3 v2 3 v3 3 v4 3 v5 3 v6 3 v7 3 } { v0 4 v1 4 v2 4 v3 4 v4 4 v5 4 v6 4 v7 4 }   { v0 1 v1 1 v2 1 v3 1 v4 1 v5 1 v6 1 v7 1 v8 1 v9 1 v10 1 v11 1 } { v0 2 v1 2 v2 2 v3 2 v4 2 v5 2 v6 2 v7 2 v8 2 v9 2 v10 2 v11 2 } { v0 3 v1 3 v2 3 v3 3 v4 3 v5 3 v6 3 v7 3 v8 3 v9 3 v10 3 v11 3 } { v0 4 v1 4 v2 4 v3 4 v4 4 v5 4 v6 4 v7 4 v8 4 v9 4 v10 4 v11 4 }        Table 37 Antenna Ratio Calculation Based on Diode Mode Diode mode Calculation    \u2022 dp v0 v4 dp v1 v2 v3 v4 \u2022 dp v0 v4 dp v1 v2 v3 \u2022 dp v0 layerMaxRatio   \u2022 v0 v4 v1 v2 v3 v4 \u2022 v0 v4 v1 v2 v3 \u2022 v0    \u2022 v0 v4 v1 v2 v3 v4 \u2022 v0 v4 v1 v2 v3 \u2022 v0    \u2022 v0 v4 v1 v2 v3 v4 \u2022 v0 v4 v1 v2 v3 \u2022 v0  \u2022    \u2022 v0 v4 v1 v2 v3 v4 \u2022 v0 v4 v1 v2 v3 \u2022 v0  \u2022        Table 37 Antenna Ratio Calculation Based on Diode Mode (Continued) Diode mode Calculation   \u2022 v0 v1 v2 v3 v4 \u2022 v0    \u2022 v0 v1 v2 v3 v4 \u2022 v0    \u2022 v0 s0 \u2022 v1 s1 \u2022 v2 s2 \u2022 v3  \u2022 v4 s4 \u2022 v4 s5   \u2022 v0 s0 \u2022 v1 s1 \u2022 v2 s2 \u2022 v3 s3 \u2022 v4 s4 \u2022 v4 s5         Table 37 Antenna Ratio Calculation Based on Diode Mode (Continued) Diode mode Calculation   \u2022 dp v1 v2  v5 v6 dp v7  \u2022 v3  v8 v9    \u2022 dp v0 v4 dp v1 v2 v3 v4 \u2022 dp v0 v4 dp v1 v2 v3 \u2022 dp v0 layerMaxRatio \u2022 v5 v6 dp  v6 dp v7   \u2022 v0 v4 v1 v2 v3 v4 \u2022 v0 v4 v1 v2 v3 \u2022 v0    \u2022 dp v0 v4 dp v1 v2 v3 v4 \u2022 dp v0 v4 dp v1 v2 v3 \u2022 dp v0 layerMaxRatio \u2022 v5 v6 dp  v6 dp v7  \u2022 v8 v9  v10 v11 \u2022       Example for Diode Modes 2, 3, and 4 Assume that the antenna area is calculated using surface area in single-layer mode (antenna mode 1), the diode ratio vector for the M1 layer is {0.7 0.0 200 2000}, the layerMaxRatio value for the M1 layer is 400, and the following diodes are connected to a single M1 net: diode A with a diode-protection value of 0.5, diode B with a diode-protection value of 1.0, and diode C with a diode"}
{"header": "How do I Calculating the Antenna Ratio for a Pin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "-protection value of 1.5.\n In this example, the  v4 value is not specified so a value of 0 is used.\n Use the following commands to define the antenna rules for this example: fc_shell>\u00a0 define_antenna_rule -mode 1 -diode_mode  diode_mode  \\ -metal_ratio 400 -cut_ratio 20 fc_shell>\u00a0 define_antenna_layer_rule -mode 1 -layer \"M1\" \\ -ratio 400 -diode_ratio {0.7 0.0 200 2000} The maximum antenna ratio for each diode is computed by using the formula for the diode mode from  Table\u00a037.\n In this case, \u2022 If  dp > v0  and  v4 <>0, allowable max-antenna-ratio = min ((( dp  +  v1 ) *  v2  +  v3 ),  v4 ) \u2022 If  dp > v0  and  v4 =0, allowable max-antenna-ratio = ( dp  +  v1 ) *  v2  +  v3 \u2022 If  dp <= v0, allowable max-antenna-ratio =  layerMaxRatio Table\u00a038 shows the maximum antenna ratio for each diode calculated using this formula.\n Table 38 Calculation of Maximum Antenna Ratio for Each Diode Diode Protection value Maximum Antenna Ratio    v0      v0      v0         The maximum antenna ratio for the net is computed by using the formula for the diode mode from  Table\u00a036 : \u2022 For diode mode 2, the maximum antenna ratio for the net is the largest of the maximum antenna ratio values for the diodes, 2300.\n \u2022 For diode mode 3, the maximum antenna ratio for the net is the sum of the maximum antenna ratios for the diodes, 400 + 2200 + 2300 = 4900.\n \u2022 For diode mode 4, the maximum antenna ratio for the net is computed by using the formula from  Table\u00a037 using the sum of the diode-protection values of the diodes, (0.5+1.0+1.5) * 200 + 2000 = 2600.\n Example for Diode Modes 5 and 6 Assume that the antenna area is calculated using surface area in single-layer mode (antenna mode 1), the diode ratio vector for the M1 layer is {0 0 1 0} (the default diode ratio vector), the  layerMaxRatio value for the M1 layer is 400, and the following diodes are connected to a single M1 net: diode A with a diode-protection value of 0.5, diode B with a diode-protection value of 1.0, and diode C with a diode-protection value of 1.5.\n In this example, the  v4  value is not specified so a value of 0 is used.\n Use the following command to define the antenna rules for this example: fc_shell>\u00a0 define_antenna_rule -mode 1 -diode_mode  diode_mode  \\ -metal_ratio 400 -cut_ratio 20 Because this example uses the global  layerMaxRatio value and the default diode ratio vector, you do not need to define a layer-specific antenna rule.\n As shown in  Table\u00a037, for diode modes 5 and 6, the maximum antenna ratio is computed as metal_area  / ( gate_area +  equi_gate_area ) where the equivalent gate area,  equi_gate_area, is computed by using the diode ratio vector: ( diode_protection +  v1 ) * ( v2  +  v3 ).\n \u2022 For diode mode 5, the equivalent gate area is computed using the maximum diode protection, which is 1.5, so the maximum antenna ratio for the net is metal_area  / ( gate_area + ((1.5 + 0) * (1 + 0))) =  metal_area /(gate_area + 1.5) \u2022 For diode mode 6, the equivalent gate area is computed using the total diode protection, which is 0.5+1.0+1.5=3.0, so the maximum antenna ratio for the net is metal_area  / (gate_area + ((3.0 + 0) * (1 + 0))) =  metal_area /(gate_area + 3.0)       Example for Diode Modes 7 and 8 Assume that the antenna area is calculated using surface area in single-layer mode (antenna mode 1), the diode ratio vector for the M1 layer is {0.7 0.0 150 800}, the layerMaxRatio value for the M1 layer is 400, and the following diodes are connected to a single M1 net: diode A with a diode-protection value of 0.5, diode B with a diode-protection value of 1.0, and diode C with a diode-protection value of 1.5.\n In this example, the  v4 value is not specified so a value of 0 is used.\n Use the following commands to define the antenna rules for this example: fc_shell>\u00a0 define_antenna_rule -mode 1 -diode_mode  diode_mode  \\ -metal_ratio 400 -cut_ratio 20 fc_shell>\u00a0 define_antenna_layer_rule -mode 1 -layer \"M1\" \\ -ratio 400 -diode_ratio {0.7 0.0 150 800} As shown in  Table\u00a037, for diode modes 7 and 8, the maximum antenna ratio is computed as ( metal_area -  equi_gate_area ) /  gate_area where the equivalent gate area,  equi_gate_area, is computed by using the diode ratio vector: ( diode_protection +  v1 ) * ( v2  +  v3 ).\n \u2022 For diode mode 7, the equivalent metal area is computed using the maximum diode protection, which is 1.5, so the maximum antenna ratio for the net is ( metal_area - ((1.5 + 0) * (150 + 800))) /  gate_area = ( metal_area - 1025) /  gate_area \u2022 For diode mode 8, the equivalent metal area is computed using the total diode protection, which is 0.5+1.0+1.5=3.0, so the maximum antenna ratio for the net is ( metal_area - ((3.0 + 0) * 150 + 800)) /  gate_area = ( metal_area - 1250) /  gate_area Example for Diode Mode 14 With Multiple Gate Oxide Thicknesses Assume that the antenna area is calculated using surface area in single-layer mode (antenna mode 1), the design contains cells with two different gate oxide thicknesses, the diode ratio vector for the first oxide thickness (gate class 0) for the M1 layer is {1 0 1e9 1e9 0 1 2 285 1 285}, the diode ratio vector for the second oxide thickness (gate class 1) for the M1 layer is {1 0 1e9 1e9 1 0 2 165 1 28}, and the  layerMaxRatio value for the M1 layer is 285.\n For diode mode 14, the diode ratio vector contains 10 values for each gate class.\n Because the design uses only two gate oxide thicknesses, only the vectors for gate class 0 and gate class 1 are used.\n However, you must specify all 40 values when defining the antenna       rule.\n For unused gate classes (gate class 2 and gate class 3 in this example), specify very large ratios to disable the checks.\n Use the following commands to define the antenna rules for this example: fc_shell>\u00a0 define_antenna_rule -mode 1 -diode_mode 14 \\ -metal_ratio 285 -cut_ratio 10 fc_shell>\u00a0 define_antenna_layer_rule -mode 1 -layer \"M1\" \\ -ratio 285 -diode_ratio {1 0 1e9 1e9 0 1 2 285 1 285 \\ 1 0 1e9 1e9 1 0 2 165 1 28 \\ 1 0 1e9 1e9 0 1 2 1e9 1 1e9 \\ 1 0 1e9 1e9 0 1 2 1e9 1 1e9 } The following table shows the vector usage:                                   1 1 1 1 1 1 1 1 1 1   2 2 2 2 2 2 2 2 2 2   3 3 3 3 3 3 3 3 3 3   4 4 4 4 4 4 4 4 4 4 Here: \u2022 V0: Defines which gate areas are used for the check for the first formula: \u25e6 0: Gate area of all gates that belong to the current gate class \u25e6 1: Total gate area regardless of gate class \u2022 V1: Defines the diode protection multiplier for the connected to diode case for the first formula \u2022 V2: Defines the offset value for the connected to diode case for the first formula       \u2022 V3: Defines the ratio requirement for"}
{"header": "How do I Calculating the Antenna Ratio for a Pin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "the not connected to diode case for the first formula \u2022 V4: Defines which gate areas are used for the check for the second formula: \u25e6 0: Gate area of all gates that belong to the current gate class \u25e6 1: Total gate area regardless of gate class \u2022 V5: Defines the gate area multiplier for the connected to diode case for the second formula \u2022 V6: Defines the diode protection multiplier for the connected to diode case for the second formula \u2022 V7: Defines the ratio requirement for the connected to diode case for the second formula \u2022 V8: Defines the gate area multiplier for the not connected to diode case for the second formula \u2022 V9: Defines the antenna ratio requirement for the not connected to diode case for the second formula"}
{"header": "How do I Specifying Antenna Properties", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool supports several ways to calculate the antenna ratio (antenna-area/gate-area).\n You control this calculation by specifying the following information: \u2022 How the antenna area is calculated (the antenna area mode) \u2022 Which metal segments are considered for the calculation (the antenna recognition mode) To specify these modes, use the  -mode option with the  define_antenna_rule and define_antenna_layer_rule commands, as described in  Setting the Antenna Mode.\n This is a required option for both of these commands.\n       Setting the Antenna Mode The antenna mode controls the antenna ratio calculation by determining \u2022 How the antenna area is calculated (the antenna area mode) The tool supports the following area calculation modes: \u25e6 Surface area, which is calculated as W x L \u25e6 Sidewall area, which is calculated as (W + L) x 2 x thickness Note: If you use sidewall area calculation, you must define the metal thickness by specifying the  unitMinThickness,  unitNomThickness, and unitMaxThickness attributes in each  Layer section of the technology file.\n \u2022 Which metal segments are considered for the calculation (the antenna recognition mode) To tool supports the following antenna recognition modes: \u25e6 Single-layer mode In single-layer mode, the tool considers only the metal segments on the current layer; the metal segments on all lower layers are ignored.\n This mode allows the best routability.\n In this mode, the antenna ratio is calculated as antenna_ratio = connected metal area of the layer / total gate area \u25e6 Accumulated-ratio mode In accumulated-ratio mode, the tool considers the metal segments on the current layer and the lower-layer segments connected to the input pins.\n In this mode, the antenna ratio is calculated as antenna_ratio = accumulation of the single-layer mode ratios of the current layer and layers below \u25e6 Accumulated-area mode In accumulated-area mode, the tool considers the metal segments on the current and lower layers.\n In this mode, the antenna ratio is calculated as antenna_ratio = connected metal area of the current and lower layers/ total gate area For a detailed example of the antenna recognition modes, see  Antenna Recognition Mode Example.\n       The Fusion Compiler tool supports six antenna modes, which are described in  Table\u00a039.\n To specify the antenna mode, use the  -mode option with the  define_antenna_rule and define_antenna_layer_rule commands.\n This is a required option for both commands.\n Table 39 Antenna Mode Settings Antenna mode value Area calculation mode Antenna recognition mode                   Antenna Recognition Mode Example Figure\u00a0125 shows a layout example with a lateral view, which is used to explain the antenna recognition modes.\n  Table\u00a040  shows the antenna ratios for each antenna recognition mode for this layout example.\n Figure 125 Layout Example for Antenna Recognition Modes       Table 40 Antenna Recognition Modes and Ratios Considered segments Antenna ratio   \u2022 \u2022 \u2022  \u2022 \u2022 \u2022  \u2022 \u2022  \u2022   \u2022 \u2022 \u2022  \u2022 \u2022 \u2022  \u2022  \u2022  \u2022  \u2022  \u2022  \u2022        Table 40 Antenna Recognition Modes and Ratios (Continued) Considered segments Antenna ratio   \u2022 \u2022 \u2022  \u2022 \u2022 \u2022  \u2022  \u2022  \u2022"}
{"header": "How do I Analyzing and Fixing Antenna Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In general, the antenna properties for standard cells and hard macros are defined in their frame views in the reference libraries.\n You can set default values for the antenna properties, which apply to cells that do not have antenna properties defined in the reference libraries.\n \u2022 route.detail.default_diode_protection Specifies the diode protection value used for standard cell output pins during antenna analysis if the diode protection value is not specified in the e view of the cell.\n \u2022 route.detail.default_gate_size Specifies the gate size used for standard cell input pins during antenna analysis if the gate size is not specified in the e view of the cell.\n \u2022 route.detail.default_port_external_antenna_area Specifies the antenna area used for ports (top-level pins) during antenna analysis if the antenna area is not specified in the e view of the cell.\n \u2022 route.detail.default_port_external_gate_size Specifies the gate size used for ports (top-level pins) during antenna analysis if the gate size is not specified in the e view of the cell.\n \u2022 route.detail.macro_pin_antenna_mode Specifies how macro cell pins are treated for antenna considerations.\n       \u2022 route.detail.port_antenna_mode Specifies how the ports (top-level pins) are treated for antenna considerations.\n If you are using a hierarchical flow and create a block abstraction for a block, you must use the  derive_hier_antenna_property command to extract the antenna information from the block to use at the next level of hierarchy.\n Note: If the hierarchical antenna properties are not defined for all layers for a macro, Zroute treats the data as incomplete, skips antenna analysis, and issues a ZRT-311 warning message.\n If you get this error message, see  SolvNet article 027178, \u201cDebugging the ZRT-311 Message.\u201d See Also \u2022 Annotating Antenna Properties on Hard Macro Cells"}
{"header": "How do I Inserting Diodes During Detail Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "antena rulescheckingenabling If the design library contains antenna rules, Zroute automatically analyzes and antena violationsenablingfixing fixes antenna violations.\n antena violationsfixingdisablingantena rulescheckingdisabling To disable the analysis and correction of antenna rules during detail routing, set the  route.detail.antenna application option to  false.\n Just like other design rules, antenna rules are checked and corrected during detail routing.\n This concurrent antenna rule correction architecture reduces total runtime by minimizing the iterations.\n By default, Zroute \u2022 Checks antenna rules and corrects violations for all clock and signal nets To disable fixing of antenna violations on specific nets, set the route.detail.skip_antenna_fixing_for_nets application option.\n Note that Zroute analyzes the antenna rules and reports the antenna violations on these nets, but does not fix the violations.\n \u2022 Does not check or correct antenna rules for power and ground nets To check and correct antenna rules for power and ground nets, set the route.detail.check_antenna_on_pg application option to  true.\n \u2022 Starts fixing antenna violations in the second iteration, after initial routing is complete and the basic DRC violations have been fixed To change the iteration in which Zroute starts fixing antenna violations, set the route.detail.antenna_on_iteration application option.\n       \u2022 Performs layer hopping to fix antenna violations Layer hopping decreases the antenna ratio by splitting a large metal polygon into several upper-level polygons.\n Zroute performs the following types of layer hopping: \u25e6 Breaking the antenna with a higher-level metal segment Zroute uses this technique to fix most antenna violations.\n For antenna violations that happen at metal-N, inserting a small segment of metal-(N+1) close to the gate reduces the ratio between the remaining metal-N, making the ratio much lower.\n This approach is not suitable for fixing top-metal layer antenna violations when the output pin can provide only limited protection because there is no way for the router to break antenna violations at the topmost metal layer.\n \u25e6 Moving down to a lower-level metal Zroute uses this technique to fix only topmost layer antenna violations when output pins provide only limited protection.\n For antenna violations that happen at metal-N, replace part of the metal-N with metal-(N-1 or lower) to reduce the ratio.\n However, splitting the metal layer into many pieces might have a negative impact on RC and timing delay.\n Zroute can also insert diodes to fix antenna violations.\n To enable the insertion of diodes to fix antenna violations, set the  route.detail.insert_diodes_during_routing application option to  true.\n To force Zroute to fix antenna violations by inserting diodes, disable layer hopping by setting the  route.detail.hop_layers_to_fix_antenna application option to  false.\n For information about inserting diodes to fix antenna violations, see  Inserting Diodes During Detail Routing.\n If both layer hopping and diode insertion are enabled, by default, Zroute first tries to use layer hopping to fix the antenna violation.\n To change the preference to diode insertion, set the  route.detail.antenna_fixing_preference application option to use_diodes.\n To delete the redundant diodes that are not needed to fix antenna violations, set the route.detail.delete_redundant_diodes_during_routing application option to  true.\n Spare diodes are not deleted as they do not connect to any nets.\n Port protection diodes that are inserted by detail route are not deleted.\n As with other design rule violations, antenna violations are reported at the end of each detail routing iteration.\n For example, DRC-SUMMARY: @@@@@@@\u00a0TOTAL\u00a0VIOLATIONS\u00a0=\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0506 @@@@\u00a0Total\u00a0number\u00a0of\u00a0instance\u00a0ports\u00a0with\u00a0antenna\u00a0violations\u00a0=\u00a0\u00a0\u00a01107 antena ruleschecking To check for antenna violations, use the  check_routes\u00a0-antenna\u00a0true command."}
{"header": "How do I Inserting Diodes After Detail Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "One way to protect gates from antenna effects is to provide a discharge path for the accumulated charge to leave the net.\n However, the discharge path should not allow current to flow during normal chip operation.\n Discharging can be accomplished by inserting a reverse-biased diode on the net close to the gate that is being protected.\n To enable diode insertion during detail routing, set the route.detail.insert_diodes_during_routing application option to  true.\n To control diode insertion, set the following application options: \u2022 To specify a preference for fixing antenna violations by using diode insertion rather than layer hopping, set the  route.detail.antenna_fixing_preference application option to  use_diodes.\n \u2022 To require fixing of antenna violations by using diode insertion, disable layer hopping by setting the  route.detail.hop_layers_to_fix_antenna application option to  false.\n \u2022 By default, when you enable diode insertion, Zroute can fix an antenna violation either by adding a new diode or by using an existing spare diode.\n Zroute determines which method to use, based on which is closest to the required location: an empty location for a new diode or an existing spare diode.\n \u25e6 To specify a preference for using a new diode or using an existing spare diode, set the  route.detail.diode_preference application option to  new or  spare, respectively.\n To reset the diode preference to the default behavior, set the route.detail.diode_preference application option to  none.\n \u25e6 If you want Zroute to use only one of these methods, set the route.detail.diode_insertion_mode application option to  new to force the insertion of new diodes or to  spare to force the use of existing spare diodes.\n To reset the diode insertion method to the default behavior, set the route.detail.diode_insertion_mode application option to  new_and_spare.\n Note: To take advantage of spare diodes for antenna violation fixing, you need to add the spare diodes either before or after standard-cell placement and before routing the areas where antenna violations might occur.\n \u2022 When inserting new diodes, Zroute selects the diodes from the reference libraries and inserts them into existing open spaces.\n To control which diodes are used, set the route.detail.diode_libcell_names application option.\n When you specify the diode library cells, use only the cell names.\n If you include the library name, the tool does not recognize the diode cells.\n       \u2022 By default, Zroute reuses existing filler cell locations for diode insertion.\n To prevent Zroute from reusing these locations, set the route.detail.reuse_filler_locations_for_diodes application option to  false.\n Zroute considers voltage areas when inserting diode cells and also observes the logic hierarchy assignments for diode cells.\n \u2022 If a pin has an antenna violation, the diode cells are inserted at the same level of logic hierarchy as the violating pin.\n \u2022 If a top-level port has an antenna violation, by default, the diode cells are inserted at the top level.\n However, if the port belongs to a voltage area, you can insert the diode cells in the logic hierarchy associated with the voltage area by setting the route.detail.use_lower_hierarchy_for_port_diodes application option to  true.\n To remove the redundant diodes during routing, set the route.detail.delete_redundant_diodes_during_routing application option to  true."}
{"header": "How do I Inserting Redundant Vias", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can fix antenna violations after detail routing by explicitly specifying which violations to fix and providing constraints for fixing them.\n Based on the specified constraints and the setting of the  route.detail.diode_insertion_mode application option, Zroute either inserts new diodes or reuses existing spare diodes to fix the specified violations.\n To insert diodes after detail routing, use the  create_diodes command.\n When you use this command, you must use the  -options option to specify the location of each antenna violation to fix by specifying the port and cell instance, the reference cell for the diode, the number of diodes to insert, the highest allowed routing layer used for connecting the diode, and the maximum distance from the specified pin that the diode can be inserted.\n If a diode cannot be inserted or reused within the specified distance, the tool does not insert a diode for that violation.\n Use the following format to specify these values: { port_name instance_name diode_reference number_of_diodes max_routing_layer max_routing_distance } Note: You can use this command to insert diodes for top-level ports by specifying the name of the top-level block for the cell instance.\n       The  create_diodes command uses the following application options to control diode insertion: \u2022 To control whether Zroute inserts new diodes or reuses spare diodes, set the route.detail.diode_insertion_mode application option.\n \u2022 To control whether Zroute can reuse filler cell locations, set the route.detail.reuse_filler_locations_for_diodes application option.\n \u2022 To specify the logic hierarchy in which to insert the diodes for top-level ports, set the route.detail.use_lower_hierarchy_for_port_diodes application option.\n For example, to insert 2 Adiode diode cells to fix an antenna violation on the A port of the CI cell instance, where the diodes must be inserted using no higher layer than M5 and within 2.5 microns of the port, enter the following command: fc_shell>\u00a0 create_diodes {{A CI Adiode 2 M5 2.5}}"}
{"header": "How do I Inserting Redundant Vias on Clock Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Redundant via insertion is an important design-for-manufacturing (DFM) feature that is supported by Zroute throughout the routing flow.\n In each routing stage, Zroute concurrently optimizes via count as well as wire length.\n The redundant via result is measured by the redundant via conversion rate, which is defined as the percentage of single vias converted into redundant vias.\n You should also pay attention to the number of unoptimized single vias.\n If a block has fewer unoptimized single vias, it is usually better for DFM.\n The following topics describe how to insert redundant vias: \u2022 Inserting Redundant Vias on Clock Nets \u2022 Inserting Redundant Vias on Signal Nets"}
{"header": "How do I Inserting Redundant Vias on Signal Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute can insert redundant vias on clock nets either during or after routing.\n This topic describes how to insert redundant vias during clock routing.\n For information about postroute redundant via insertion, see  Postroute Redundant Via Insertion.\n To insert redundant vias on clock nets during clock routing, 1.\n Specify the redundant vias in a nondefault routing rule by using the create_routing_rule command, as described in  Specifying Nondefault Vias.\n Be sure to consider both DFM and routing when you select the redundant vias; otherwise, if you select the redundant vias based only on DFM considerations, you could negatively impact the routability.\n In addition to using nondefault routing rules to define the redundant vias for clock nets, you can also use them to define stricter wire width and spacing rules and to define the tapering distance.\n For more information about nondefault routing rules, see  Using Nondefault Routing Rules.\n 2.\n Assign the nondefault routing rule to the clock nets by using the set_clock_routing_rules command.\n fc_shell>\u00a0 set_clock_routing_rules -rules clock_via_rule 3.\n Run clock tree synthesis.\n fc_shell>\u00a0 synthesize_clock_trees 4.\n Route the clock nets.\n fc_shell>\u00a0 route_group -all_clock_nets \\ -reuse_existing_global_route true Zroute reserves space for the redundant vias during global routing and inserts the redundant vias during detail routing."}
{"header": "How do I Viewing the Default Via Mapping Table", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can perform redundant via insertion in the following ways: \u2022 Postroute redundant via insertion \u2022 Concurrent soft-rule-based redundant via insertion \u2022 Near 100 percent redundant via insertion In general, you should start with postroute redundant via insertion.\n If postroute redundant via insertion results in a redundant via rate of at least 80 percent, you can try to improve       the redundant via rate by using concurrent soft-rule-based redundant via insertion.\n If postroute redundant via insertion results in a redundant via rate of at least 90 percent, you can try to improve the redundant via rate by using near 100 percent redundant via insertion.\n Note: As the redundant via rate increases, it becomes more difficult to converge on the routing design rules and you might see a reduction in signal integrity; therefore, you should use near 100 percent redundant via insertion only for those blocks that truly require such a high redundant via rate.\n In addition, achieving very high redundant via rates might require you to modify the floorplan utilization to allow enough space for the redundant vias.\n The following topics describe the default via mapping table, how to define a customized via mapping table, how to insert redundant vias by using various methods, and how to report the redundant via rate.\n \u2022 Viewing the Default Via Mapping Table \u2022 Defining a Customized Via Mapping Table \u2022 Postroute Redundant Via Insertion \u2022 Concurrent Soft-Rule-Based Redundant Via Insertion \u2022 Near 100 Percent Redundant Via Insertion \u2022 Preserving Timing During Redundant Via Insertion \u2022 Reporting Redundant Via Rates"}
{"header": "How do I Defining a Customized Via Mapping Table", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, Zroute reads the default contact codes from the technology file and generates an optimized via mapping table.\n To see the default mapping table, use the add_redundant_vias\u00a0-list_only\u00a0true command.\n In most cases you achieve better results if you use a customized mapping table rather than the default mapping table.\n For information about defining a customized mapping table, see  Defining a Customized Via Mapping Table.\n If you have not previously defined a customized mapping table for the block, you can see the default mapping table by using the  add_redundant_vias\u00a0-list_only\u00a0true command.\n Note: After you have created a customized mapping table by using the method described in  Defining a Customized Via Mapping Table, this command shows the customized mapping table.\n       Example\u00a027 shows an example of a default via mapping table.\n Example 27 Default Via Mapping Table fc_shell>\u00a0 add_redundant_vias -list_only...\n Redundant\u00a0via\u00a0optimization\u00a0will\u00a0attempt\u00a0to\u00a0replace\u00a0the\u00a0following\u00a0vias:  VIA12SQ_C\u00a0\u00a0\u00a0\u00a0->\u00a0VIA12SQ_C_2x1\u00a0\u00a0\u00a0\u00a0VIA12SQ_C_2x1(r)\u00a0VIA12SQ_C_1x2\u00a0\u00a0\u00a0\u00a0VIA12SQ_ C_1x2(r) VIA12SQ_C(r)\u00a0->\u00a0VIA12SQ_C_2x1\u00a0\u00a0\u00a0\u00a0VIA12SQ_C_2x1(r)\u00a0VIA12SQ_C_1x2\u00a0\u00a0\u00a0\u00a0VIA12SQ_ C_1x2(r)...\n VIA89(r)\u00a0\u00a0\u00a0\u00a0\u00a0->\u00a0VIA89_C_1x2(r)\u00a0\u00a0VIA89_1x2(r)\u00a0\u00a0VIA89_1x2\u00a0\u00a0\u00a0\u00a0VIA89_C_1x2 VIA89_C_2x1(r)\u00a0\u00a0VIA89_2x1(r)\u00a0\u00a0VIA89_2x1\u00a0\u00a0\u00a0\u00a0VIA89_C_2x1 VIA9RDL\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0->\u00a0VIA9RDL_2x1\u00a0\u00a0\u00a0\u00a0VIA9RDL_1x2"}
{"header": "How do I Postroute Redundant Via Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a customized via mapping, use the  add_via_mapping command.\n At a minimum, you must specify the source via and its replacement vias by using the  -from and  -to options.\n The vias listed in these options must be either vias defined in the technology file or design-specific vias created by the  create_via_def command.\n The vias listed in the  -from option must be simple vias or via arrays.\n The vias listed in the  -to option can be simple vias, simple via arrays, or custom vias.\n For information about creating design- specific vias, see  Defining Vias.\n Use the following options to refine the via mapping: \u2022 -weight By default, all mappings have the same priority, and Zroute selects the redundant vias to use based on routability.\n To set the priority for a mapping, use the  -weight option to assign an integer weight value between 1 and 10 to the mapping.\n If you do not assign a weight, the tool assigns a weight of 1.\n During redundant via insertion, Zroute uses the higher weighted redundant vias first.\n \u2022 -transform By default, Zroute can rotate or flip the via arrays during redundant via insertion (the -transform\u00a0all option).\n \u25e6 To allow only rotation of the via arrays during redundant via insertion, use the -transform\u00a0rotate option.\n \u25e6 To allow only flipping of the via arrays during redundant via insertion, use the -transform\u00a0flip option.\n \u25e6 To allow only the specified orientation of the via array during redundant via insertion, use the  -transform\u00a0none option.\n The tool saves the mappings defined by the  add_via_mapping command in a via mapping table in the design library.\n By default, if you try to add a via mapping that already exists in the table, the command fails.\n To overwrite an existing mapping definition, use the  -force option.\n Example\u00a028 shows an example of using the  add_via_mapping command to define a customized via mapping table.\n Example 28 Customized Via Mapping Table fc_shell>\u00a0 add_via_mapping \\ -from {VIA12 1x1} -to {VIA12T 2x1} -weight 5 fc_shell>\u00a0 add_via_mapping \\ -from {VIA12 1x1} -to {VIA12 2x1} -weight 1       To see the customized via mappings associated with a block, use the report_via_mapping command.\n \u2022 By default, this command shows all user-defined via mappings.\n \u2022 To show the via mappings for specific source vias, use the  -from option.\n \u2022 To show the via mappings for specific replacement vias, use the  -to option.\n To remove mappings from the via mapping table, use the  remove_via_mappings command.\n \u2022 To remove all via mappings, use the  -all option.\n \u2022 To remove the via mappings for specific source vias, use the  -from option.\n \u2022 To remove the via mappings for specific replacement vias, use the  -to option.\n Using a Subset of the Via Mapping Table for Redundant Via Insertion To use a subset of the via mapping table for redundant via insertion, specify which weight groups from the via mapping table to use by setting one or both of the route.common.redundant_via_include_weight_group_by_layer_name and route.common.redundant_via_exclude_weight_group_by_layer_name application options.\n \u2022 If you set only the route.common.redundant_via_include_weight_group_by_layer_name application option, Zroute selects redundant vias only from the specified weight groups.\n If you do not specify an entry for a layer, redundant via insertion is not performed on that layer.\n \u2022 If you set only the route.common.redundant_via_exclude_weight_group_by_layer_name application option, Zroute selects redundant vias from all weight groups in the original via mapping table, except the specified weight groups.\n If you do not specify an entry for a layer, all weight groups are used for that layer.\n \u2022 If you set both application options, Zroute selects redundant vias from the weight groups specified in the route.common.redundant_via_include_weight_group_by_layer_name application, excluding the weight groups specified in the route.common.redundant_via_exclude_weight_group_by_layer_name application option."}
{"header": "How do I Concurrent Soft-Rule-Based Redundant Via Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform postroute redundant via insertion, use the  add_redundant_vias command.\n This command can replace single-cut vias with multiple-cut via arrays, single-cut vias with other single-cut vias that have a different contact code, and multiple-cut via arrays       with different multiple-cut via arrays.\n During redundant via insertion, the detail router also checks the design rules within the neighboring partition to minimize DRC violations.\n By default, the  add_redundant_vias command inserts redundant vias on all nets.\n To insert redundant vias only on specific nets, use the  -nets option to specify the nets.\n Using net-specific redundant via insertion allows you to further improve the optimized via rate without causing large-scale routing and timing changes.\n After the vias are checked and replaced, the detail router rechecks for DRC violations and corrects any violations.\n If the percentage of redundant vias is not high enough, you can increase the effort level by using the  -effort option to get a better redundant via rate.\n Increasing the effort level to high can increase the redundant via rate by about 3 to 5 percent by shifting the vias to make room for additional vias.\n However, because high-effort redundant via insertion moves the vias more, it can result in a less lithography-friendly pattern at the 45-nm technology node and below.\n In this case, you should use concurrent soft-rule-based redundant via insertion to improve the redundant via rate.\n You can also try to increase the postroute redundant via rate by setting the route.detail.optimize_wire_via_effort_level application option to  high, which reduces the number of single vias and makes more room for redundant vias by reducing wire length.\n After you perform the initial postroute redundant via insertion, set the route.common.post_detail_route_redundant_via_insertion application option to enable automatic insertion of redundant vias after subsequent detail routing or ECO routing.\n This helps to maintain the redundant via rate in your block."}
{"header": "How do I Near 100 Percent Redundant Via Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Soft-rule-based redundant via insertion can improve the redundant via rate by reserving space for the redundant vias during routing.\n You can use concurrent soft-rule-based redundant via insertion during both initial routing and ECO routing.\n The actual via insertion is not done during routing; you must still perform postroute redundant via insertion by using the  add_redundant_vias command.\n Note: Reserving space during routing increases the routing runtime.\n You should use this method only when needed to improve the redundant via rate beyond that provided by postroute redundant via insertion and the postroute approach resulted in a redundant via rate of at least 80 percent.\n       To perform concurrent soft-rule-based redundant via insertion, 1.\n (Optional) Define the via mapping table as described in  Defining a Customized Via Mapping Table.\n 2.\n Enable concurrent soft-rule-based redundant via insertion.\n By default, concurrent redundant via insertion is disabled.\n \u25e6 To enable concurrent soft-rule-based redundant via insertion during initial routing, set the  route.common.concurrent_redundant_via_mode application option to reserve_space.\n fc_shell>\u00a0 set_app_options \\ -name route.common.concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during initial routing, set the  route.common.concurrent_redundant_via_effort_level application option.\n By default, Zroute uses low effort.\n The higher effort levels result in a better redundant via conversion rate at the expense of runtime.\n The low and medium efforts affect only global routing and track assignment, while high effort also affects detail routing, which can impact design rule convergence.\n Note: If you enable the  route.common.concurrent_redundant_via_mode option before running the  place_opt command, the redundant vias are considered during congestion estimation.\n \u25e6 To enable concurrent soft-rule-based redundant via insertion during ECO routing, set the  route.common.eco_route_concurrent_redundant_via_mode application option to  reserve_space.\n fc_shell>\u00a0 set_app_options \\ -name route.common.eco_route_concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during ECO routing, set the route.common.eco_route_concurrent_redundant_via_effort_level application option.\n Note: Using concurrent soft-rule-based redundant via insertion during ECO routing can impact timing and design rule convergence.\n In general, you should use this method only when you used near 100 percent redundant via insertion during initial routing.\n       3.\n Route the block.\n During routing, Zroute reserves space for the redundant vias and fixes hard design rule violations.\n 4.\n Perform postroute redundant via insertion.\n During postroute redundant via insertion, Zroute inserts the redundant vias in the reserved locations."}
{"header": "How do I Preserving Timing During Redundant Via Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can achieve a redundant via rate near 100 percent by using hard-rule-based redundant via insertion.\n Hard-rule-based redundant via insertion can improve the redundant via rate by treating redundant vias as hard design rules during routing.\n You can use nearly 100 percent redundant via insertion only during initial routing; this method is not supported during ECO routing.\n When you use near 100 percent redundant via insertion during initial routing, you should use soft-rule-based redundant via insertion during ECO routing to preserve the redundant via rate achieved during initial routing.\n Note: This method can result in a very large runtime increase for congested blocks.\n You should use this method only when needed to improve the redundant via rate beyond that provided by concurrent soft-rule-based redundant via insertion and the soft-rule-based approach resulted in a redundant via rate of at least 90 percent.\n To perform concurrent hard-rule-based redundant via insertion, 1.\n Enable nearly 100 percent via insertion by setting the route.common.concurrent_redundant_via_mode application option to insert_at_high_cost.\n (By default, concurrent redundant via insertion is disabled.) fc_shell>\u00a0 set_app_options \\ -name route.common.concurrent_redundant_via_mode \\ -value insert_at_high_cost To control the effort used to reserve space for the redundant vias, set the route.common.concurrent_redundant_via_effort_level application option.\n Note: If you enable the  route.common.concurrent_redundant_via_mode option before running the  place_opt command, the redundant vias are considered during congestion estimation.\n       2.\n Route the block.\n During routing, Zroute inserts the redundant vias and fixes hard design rule violations.\n In general, redundant via insertion has the same priority as other hard design rules; however, if design rule checking does not converge during detail routing, Zroute automatically relaxes the redundant via constraints to improve DRC convergence."}
{"header": "How do I Reporting Redundant Via Rates", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you insert redundant vias, it changes the timing of your block.\n Short nets tend to slow down due to increased capacitance, whereas long nets tend to speed up due to decreased resistance.\n Zroute redundant via insertion has a timing-preservation mode that allows you to perform redundant via insertion without affecting the block timing by preventing insertion of redundant vias on critical nets.\n To enable timing-preservation mode for redundant via insertion, define the timing preservation constraints by using the following options of the  add_redundant_vias command: \u2022 -timing_preserve_setup_slack_threshold \u2022 -timing_preserve_hold_slack_threshold \u2022 -timing_preserve_nets You should timing-preservation mode only at the end of the flow, after using the normal redundant via insertion flows, which converge both the redundant via rate and the timing QoR.\n Timing-preservation mode can slightly increase the redundant via rate while maintaining timing.\n However, if you use timing-preservation mode earlier in the flow, before timing is met, it might severely reduce the redundant via rate due to critical nets."}
{"header": "How do I Optimizing Wire Length and Via Count", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After redundant via insertion, whether concurrent or postroute, Zroute generates a redundant via report that provides the following information: \u2022 The via conversion rate for nondefault vias The via conversion rate for nondefault vias is listed at the top of the report as the total optimized via conversion rate.\n       \u2022 The optimized via conversion rate for each layer The optimized via conversion rate includes both double vias and DFM-friendly bar vias, which have a single cut but a larger metal enclosure.\n The tool reports two values for the via conversion rate: \u25e6 The total optimized via conversion rate This value is computed based on the total via count, which includes both fixed vias and routed vias.\n Fixed vias are vias that cannot be optimized by the router, such as unrouted vias and user-defined vias.\n \u25e6 The optimized via conversion rate based on the total routed via count This value is computed based only on the routed via count, which includes only those vias that can be optimized by the router.\n Note: The optimized via conversion rate is not useful if you are using bar vias.\n \u2022 The distribution of optimized vias by weight for each layer To determine the via conversion rate for conversions above a certain weight, you must add the reported conversion rates for those weights.\n For example, in  Example\u00a029, the via conversion rate for weight 5 and above for layer V03 is 10.75+64.50=75.25%.\n Note: The conversion rate for unweighted vias is reported as \u201cUn-optimized.\u201d \u2022 The total double via conversion rate for the block Note: The redundant via rate reported by the  report_design command differs from the redundant via rate reported by Zroute during redundant via insertion or the check_routes command.\n This difference occurs because the  report_design command reports the double via rate for both PG vias and signal vias, while Zroute reports the double via rate only for signal vias.\n In addition, Zroute bases the conversion rate only on the redundant via mapping.\n Example\u00a029 shows an example of the redundant via report.\n Example 29 Redundant Via Report Total\u00a0optimized\u00a0via\u00a0conversion\u00a0rate\u00a0=\u00a096.94%\u00a0(1401030\u00a0/\u00a01445268\u00a0vias) Layer\u00a0V01\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a041.89%\u00a0(490617\u00a0/\u00a01171301\u00a0vias) Weight\u00a010\u00a0\u00a0\u00a0\u00a0=\u00a0\u00a09.64%\u00a0(112869\u00a0\u00a0vias) Weight\u00a05\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a032.25%\u00a0(377689\u00a0\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0\u00a00.01%\u00a0(59\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0vias) Un-optimized\u00a0=\u00a058.11%\u00a0(680684\u00a0\u00a0vias)       Layer\u00a0V02\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a076.20%\u00a0(1567822/\u00a02057614\u00a0vias) Weight\u00a010\u00a0\u00a0\u00a0\u00a0=\u00a043.51%\u00a0(895270\u00a0\u00a0vias) Weight\u00a05\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a028.62%\u00a0(588805\u00a0\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0\u00a04.07%\u00a0(83747\u00a0\u00a0\u00a0vias) Un-optimized\u00a0=\u00a023.80%\u00a0(489792\u00a0\u00a0vias) Layer\u00a0V03\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a081.87%\u00a0(687115\u00a0/\u00a0839297\u00a0\u00a0vias) Weight\u00a010\u00a0\u00a0\u00a0\u00a0=\u00a064.50%\u00a0(541369\u00a0\u00a0vias) Weight\u00a05\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a010.75%\u00a0(90224\u00a0\u00a0\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0\u00a06.62%\u00a0(55522\u00a0\u00a0\u00a0vias) Un-optimized\u00a0=\u00a018.13%\u00a0(152182\u00a0\u00a0vias) Layer\u00a0V04\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a081.60%\u00a0(226833\u00a0/\u00a0277977\u00a0\u00a0vias) Weight\u00a010\u00a0\u00a0\u00a0\u00a0=\u00a081.45%\u00a0(226418\u00a0\u00a0vias) Weight\u00a01\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a0\u00a00.15%\u00a0(415\u00a0\u00a0\u00a0\u00a0\u00a0vias) Un-optimized\u00a0=\u00a018.40%\u00a0(51144\u00a0\u00a0\u00a0vias)...\n Layer\u00a0V09\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0=\u00a085.47%\u00a0(1329\u00a0\u00a0\u00a0/\u00a01555\u00a0\u00a0\u00a0\u00a0vias) Weight\u00a010\u00a0\u00a0\u00a0\u00a0=\u00a085.47%\u00a0(1329\u00a0\u00a0\u00a0\u00a0vias) Un-optimized\u00a0=\u00a014.53%\u00a0(226\u00a0\u00a0\u00a0\u00a0\u00a0vias)  Total\u00a0double\u00a0via\u00a0conversion\u00a0rate\u00a0\u00a0\u00a0\u00a0=\u00a046.69%\u00a0(2158006\u00a0/\u00a04622189\u00a0vias)"}
{"header": "How do I Reducing Critical Areas", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During detail routing, Zroute optimizes wire length and via count in the areas where DRC violations occur; however, it does not optimize the layout in areas where no DRC violations occur.\n To improve the manufacturing yield, use the  optimize_routes command to perform standalone optimization of wire length and via count after performing detail routing and redundant via insertion.\n By default, Zroute selects the nets to reroute based on the overall cost.\n For each selected net, Zroute determines whether to reroute all the shapes in the net or just a portion of them.\n To select the nets to reroute, use the  -nets option to specify the nets.\n When you specify the nets to optimize, you can also use the  -reroute_all_shapes_in_nets option to control whether Zroute must reroute all the associated net shapes.\n By default, Zroute performs a maximum of 40 detail routing iterations to fix DRC violations that exist after the optimization.\n You can use the  -max_detail_route_iterations option to control the maximum number of detail routing iterations."}
{"header": "How do I Performing Wire Spreading", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A critical area is a region of the block where, if the center of a random particle defect falls there, the defect causes circuit failure, thereby reducing yield.\n A conductive defect causes a short fault, and a nonconductive defect causes an open fault.\n       The following topics describe how to \u2022 Reduce critical area short faults by performing wire spreading \u2022 Reduce critical area open faults by performing wire widening"}
{"header": "How do I Performing Wire Widening", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you have performed detail routing and redundant via insertion, you can perform wire spreading to increase the average spacing between wires, which reduces the critical area short faults and therefore improves yield.\n To perform wire spreading, use the spread_zrt_wires comandcomandspread_zrt_wires spread_wires command.\n By default, the spread_wires command uses the following settings to spread the signal wires on the same layer: To perform wire spreading, use the spread_zrt_wires comandcomandspread_zrt_wires spread_wires command.\n By default, the spread_wires command uses the following settings to spread the signal wires on the same layer: \u2022 Spreads the wires by half a pitch in the preferred direction To modify the spread distance, use the  -pitch option.\n You specify the spread distance as a multiplier for the layer pitch.\n For example, to specify a spread distance of 1.5 times the layer pitch, use the following command: fc_shell>\u00a0 spread_wires -pitch 1.5 \u2022 Uses twice the layer pitch as the minimum jog length To modify the minimum jog length, use the  -min_jog_length option.\n You specify the minimum jog length as an integer multiple of the layer pitch.\n \u2022 Uses the minimum layer spacing plus one half the layer pitch as the minimum jog length To modify the minimum jog spacing, use the  -min_jog_spacing_by_layer_name option.\n You specify the minimum jog spacing in microns for each layer.\n The tool uses the default jog spacing for any unspecified layers.\n Figure\u00a0126 shows how the jog length and jog spacing values are used in wire spreading.\n Figure 126 Wire Spreading Results       In the following example, the minimum jog length is set to three times the layer pitch, the minimum jog spacing for the M1 layer is set to 0.07 microns, and the minimum jog spacing for the M2 layer is 0.08 microns.\n All other metal layers use the default minimum jog spacing.\n fc_shell>\u00a0 spread_wires -min_jog_length 3 \\ -min_jog_spacing_by_layer_name {{M1 0.07} {M2 0.08}} After spreading, the  spread_wires command performs detail routing iterations to fix any DRC violations caused as a result of spreading.\n When you change the layout, it can change the timing of your block.\n Wire spreading has a timing-preservation mode that allows you to perform wire spreading without affecting the block timing.\n To enable timing-preservation mode for wire spreading, define the timing preservation constraints by using the following options with the  spread_wires command: \u2022 -timing_preserve_setup_slack_threshold\u00a0 threshold \u2022 -timing_preserve_hold_slack_threshold\u00a0 threshold \u2022 -timing_preserve_nets\u00a0 nets The threshold values are floating-point numbers in library units.\n Wire spreading is performed only on nets with slack greater than or equal to the specified values or the nets specified in the  -timing_preserve_nets option, as well as adjacent nets on the same layer within two routing pitches."}
{"header": "How do I Inserting Metal-Insulator-Metal Capacitors", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you have performed detail routing, redundant via insertion, and wire spreading, you can perform wire widening to increase the average width of the wires, which reduces the critical area open faults and therefore improves yield.\n To perform wire widening, use the widen_zrt_wires comandcomandswiden_zrt_wireswire widening widen_wires command.\n By default, the  widen_wires command widens all wires in the block to 1.5 times their original width.\n For more flexibility, you can use the  -widen_widths_by_layer_name option to define up to five possible wire widths to use for each layer.\n For example, to define possible wire widths of 0.07 and 0.06 microns for the M1 layer; wire widths of 0.08 and 0.07 microns for the M2 layer; and 1.5 times the existing wire width for all other layers, enter the following command: fc_shell>\u00a0 widen_wires \\ -widen_widths_by_layer_name {{M1 0.07 0.06} {M2 0.08 0.07}} When you perform wire widening, the spacing between neighboring wires is decreased, which can reduce the improvement in critical area shorts gained from wire spreading.\n You can control the tradeoff between wire spreading and wire widening by using the       -spreading_widening_relative_weight option.\n By default, wire spreading and wire widening are given equal priority.\n To weight the priority toward wire widening and reduced critical area open faults, set this option to a value between 0.0 and 0.5.\n To weight the priority toward wire spreading and reduced critical area short faults, set this option to a value between 0.5 and 1.0.\n After widening, the  widen_wires command performs detail routing iterations to fix any DRC violations caused as a result of widening.\n Note that the widened wires do not trigger fat wire spacing rules.\n When you widen the wires, it changes the timing of your block.\n Wire widening has a timing-preservation mode that allows you to perform wire widening without affecting the block timing.\n To enable timing-preservation mode for wire widening, define the timing preservation constraints by using the following options with the  widen_wires command: \u2022 -timing_preserve_setup_slack_threshold\u00a0 threshold \u2022 -timing_preserve_hold_slack_threshold\u00a0 threshold \u2022 -timing_preserve_nets\u00a0 nets The threshold values are floating-point numbers in library units.\n Wire widening is not performed on nets with slack less than the specified values or the nets specified in the -timing_preserve_nets option."}
{"header": "How do I Inserting Filler Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "A metal-insulator-metal (MiM) capacitor is made of two special-purpose conducting layers separated by an insulator.\n This capacitor is inserted between two regular metal layers, as shown in  Figure\u00a0127.\n Figure 127 Cross-Section View of MiM Capacitor Layers maskName = \"mimtop\" M9 M9 M9 M8 maskName = \"mimbottom\" via via via M9 layer M8 layer MBOT layer MTOP layer MiM capacitor maskName = \"viaMimtop\" maskName = \"viaMimbottom\"       MiM capacitors are typically connected between power and ground to help maintain a constant supply voltage in the presence of electrical noise.\n The dimensions of a MiM capacitor are usually customized to fit the power strap geometry of a specific power plan.\n To insert an array of MiM capacitors into a block and connect them to the power rails, use the  create_mim_capacitor_array command.\n At a minimum, you must specify the MiM capacitor library cell, as well as the x- and y-increments of the array.\n For example, fc_shell>\u00a0 create_mim_capacitor_array \\ -lib_cell my_lib/mim_ref_cell -x_increment 20 -y_increment 20 By default, the  create_mim_capacitor_array command \u2022 Inserts MiM capacitors for the entire block To restrict the insertion to a specific region, use the  -boundary option to specify the rectangular or rectilinear region.\n You can specify only a single region.\n The command does not consider standard cells, macros, placement blockages, or voltage areas when inserting the MiM capacitors.\n \u2022 Inserts the MiM capacitors in the R0 orientation To change the orientation, use the  -orientation option.\n When you change the orientation, it affects all MiM capacitor cells in the inserted array.\n \u2022 Uses the following naming convention for the inserted MiM capacitor cells: mimcap!\n library_cell_name!\n number To identify the MiM capacitor cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: mimcap!\n prefix!\n library_cell_name!\n number"}
{"header": "How do I Standard Filler Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To ensure that all power nets are connected, you can fill empty space in the standard-cell rows with filler cells.\n The Fusion Compiler tool supports filler cells with and without metal       and supports both single-height and multiheight filler cells.\n Filler cell insertion is often used to add decoupling capacitors to improve the stability of the power supply.\n Note: Before inserting filler cells, ensure that the block is legalized by using the check_legality command.\n The Fusion Compiler tool can select the filler cells to use based on \u2022 An ordered list of filler cell references In the standard filler cell insertion flow, you specify an ordered list of filler library cells and the tool inserts the first cell that fits in each gap.\n If your technology requires specific filler cells abutting the standard cells, you can insert these required filler cells first, and then use standard filler cell insertion to fill the remaining space.\n For details about this method, see  Standard Filler Cell Insertion.\n \u2022 Threshold-voltage rules In the threshold-voltage-based flow, the tool selects the filler cells by using user-defined insertion rules, which are based the threshold-voltage types of the cells that border the gap.\n This flow is typically used only for established foundry nodes.\n For details about this method, see  Threshold-Voltage-Based Filler Cell Insertion."}
{"header": "How do I Controlling Standard Filler Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The standard filler cell insertion flow uses the  create_stdcell_fillers command to insert filler cells in the block and the  remove_stdcell_fillers_with_violation command to perform design rule checking on the filler cells and remove filler cells with violations.\n During filler cell insertion, the  create_stdcell_fillers command uses the placement legalizer to ensure that the inserted filler cells honor advanced node placement rules and physical constraints such as placement blockages and keepout margins.\n When the  place.legalize.enable_advanced_legalizer application option is set to  true, the command uses the advanced legalization algorithms for 2D rule checking and cell interaction, which can reduce filler cell insertion runtime.\n To insert filler cells in your block, 1.\n Ensure that the block is legalized by using the  check_legality command.\n When verifying that a block is fillable, the  check_legality command assumes that all standard cells that have a  design_type attribute of  filler can be used as filler cells.\n However, the  create_stdcell_fillers command inserts only the cells specified in       the  -lib_cells option.\n This difference might result in unfillable gaps after filler cell insertion even though the  check_legality command did not report any issues.\n 2.\n (Optional) Insert required filler cells to abut specific standard cells by using the create_left_right_filler_cells command, as described in  Abutting Standard Cells With Specific Filler Cells.\n 3.\n (Optional) Enable multithreaded filler cell insertion by using the  set_host_options command to specify the multicore configuration.\n fc_shell>\u00a0 set_host_options -max_cores  n The  create_stdcell_fillers command uses the multicore configuration only when the technology file contains minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules.\n Note: The multicore configuration specified with the  set_host_options command applies to all Fusion Compiler commands that support multicore processing.\n 4.\n Insert metal filler cells by using the  create_stdcell_fillers command.\n Use the  -lib_cells option to specify the metal filler library cells to insert.\n The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n To determine the filler cells available in a cell library, use the following command: fc_shell>\u00a0 get_lib_cells  ref_lib /* -filter \"design_type==filler\" To sort the filler cells by decreasing size, use the  sort_collection command, as shown in the following example: fc_shell>\u00a0 set FILLER_CELLS \\ [get_object_name [sort_collection -descending \\ [get_lib_cells  ref_lib /* -filter \"design_type==filler\"] area]] For more information, see  Controlling Standard Filler Cell Insertion.\n 5.\n Connect the inserted filler cells to the power and ground (PG) network by using the connect_pg_net\u00a0-automatic command.\n 6.\n Remove the metal filler cells with DRC violations by using the remove_stdcell_fillers_with_violation command.\n Removing the filler cells can expose new violations; therefore, you must sometimes run this command multiple times to remove all violating filler cells.\n For more information, see  Checking for Filler Cell DRC Violations.\n       7.\n Insert nonmetal filler cells by using the  create_stdcell_fillers command.\n Use the  -lib_cells option to specify the nonmetal filler library cells to insert.\n The tool tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n For more information, see  Controlling Standard Filler Cell Insertion.\n 8.\n Connect the inserted filler cells to the PG network by using the  connect_pg_net -automatic command.\n See Also \u2022 Generic ECO Flow for Timing or Functional Changes \u2022 Removing Filler Cells"}
{"header": "How do I Checking for Filler Cell DRC Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  create_stdcell_fillers command fills all empty space in the horizontal standard-cell rows of the entire block by inserting instances of the filler library cells specified by the  -lib_cells option.\n You can control the following aspects of the filler cell insertion: \u2022 The selection of filler cells based on lowest leakage current By default, the command does not consider leakage current when inserting filler cells.\n To reduce the leakage current, use the  -leakage_vt_order option to specify the threshold voltage layers in order of decreasing leakage current.\n The command uses this information to select the filler cells with the lowest leakage current that meet the legalization requirements.\n To check whether the filler cells inserted in the current block result in the lowest possible leakage power, use the  -leakage_vt_check option with the create_stdcell_fillers command.\n When you use this option, the command only checks the existing filler cells; it does not insert filler cells.\n You must also use the -lib_cells and  -leakage_vt_order options to specify the available filler cells.\n The check reports the filler cells that could be replaced with a specified filler cell with lower leakage current without causing legalization errors.\n By default, the command reports a maximum of 100 violations.\n To change the maximum number of reported violations, set the  chf.create_stdcell_fillers.max_leakage_vt_order_violations application option.\n       Note: This feature has the following requirements: \u25e6 You must enable the advanced legalizer by setting the place.legalize.enable_advanced_legalizer application option to true.\n For more information about the advanced legalizer, see  Enabling Advanced Legalization Algorithms.\n \u25e6 The threshold voltage layers must be defined in the technology file.\n A threshold voltage layer is identified by a  maskType attribute of  implant in the  Layer section of the technology file.\n \u2022 The percentage of empty space to fill By default, the command fills all the empty space.\n To leave some empty space, use the -utilization option to specify the percentage of empty space to fill.\n To control the relative amount of various types of filler cells, such as ULVT and LVT decoupling capacitor cells, use the  -type_utilization option to specify the insertion percentage for each type of cell.\n The sum of all the percentages specified in this option must be less than or equal to 100.\n When you use this option, the  create_stdcell_fillers command might leave some empty spaces.\n To fill these empty spaces, use the  -fill_remaining option.\n When you use this option, the command uses the cells specified in the  -lib_cells option but not the -type_utilization option to fill the empty spaces.\n For example, #\u00a0insert\u00a070\u00a0percent\u00a0ULVT\u00a0cells,\u00a030\u00a0percent\u00a0LVT\u00a0cells fc_shell>\u00a0 create_stdcell_fillers -lib_cells $FILLER_CELLS \\ -type_utilization { {*/DCAP16*ULVT */DCAP8*ULVT */DCAP4*ULVT */DCAP2*ULVT */DCAP1*ULVT} 70 {*/DCAP16*LVT */DCAP8*LVT */DCAP4*LVT */DCAP2*LVT */DCAP1*LVT} 30 } \\ -fill_remaining By default, the tool randomly selects the filler cells from the specified library cells.\n To control the cell selection priority, use the  -prefer_type_ordering option with the -type_utilization option.\n When you use the  -prefer_type_ordering option, the tool selects the library cells in each group specified in the  -type_utilization option in priority order, from left to right.\n If some of the cells are difficult to insert due to legalization rules or library cell size, specify them before cells that are easier to insert to       ensure that they are selected.\n For example, when the  -prefer_type_ordering option is used with the previous example, the tool \u25e6 First tries to insert the ULVT decoupling capacitors to a utilization of 70 percent, first trying to insert */DCAP16*ULVT cells, then */DCAP8*ULVT cells, and so on \u25e6 Then tries to insert the LVT decoupling capacitors to a utilization of 30 percent, first trying to insert */DCAP16*LVT cells, then */DCAP8*LVT cells, and so on \u25e6 Then filling the remaining gaps using the remaining cells specified in the -lib_cells option #\u00a0insert\u00a070\u00a0percent\u00a0ULVT\u00a0cells,\u00a030\u00a0percent\u00a0LVT\u00a0cells fc_shell>\u00a0 create_stdcell_fillers -lib_cells $FILLER_CELLS \\ -type_utilization { {*/DCAP16*ULVT */DCAP8*ULVT */DCAP4*ULVT */DCAP2*ULVT */DCAP1*ULVT} 70 {*/DCAP16*LVT */DCAP8*LVT */DCAP4*LVT */DCAP2*LVT */DCAP1*LVT} 30 } \\ -prefer_type_ordering  \\ -fill_remaining \u2022 The region in which to insert the filler cells \u25e6 Use the  -bboxes option to restrict filler cell insertion to the specified bounding boxes.\n \u25e6 Use the  -voltage_area option to restrict filler cell insertion to the specified voltage areas.\n \u2022 Whether to check for power net violations By default, the command does not check for power net violations, as this check increases runtime and is required only for metal filler cell insertion.\n However, this might result in the  remove_stdcell_fillers_with_violation command removing many decoupling capacitors.\n To prevent power net violations caused by filler cell insertion, use the  -rules check_pnet option.\n \u2022 Gap prevention By default, the command assumes that the smallest cell size is one unit site.\n If the smallest cell in your design is larger than one unit site, this could cause gaps during filler cell insertion.\n To prevent the command from inserting filler cells that leave a gap, specify the smallest cell size as a multiple of the unit site by using the -smallest_cell_size option.\n You can specify a value of 1, 2, or 3.\n       Note: The advanced legalizer automatically prevents gaps; therefore, this option is ignored when  place.legalize.enable_advanced_legalizer application option is set to  true.\n \u2022 The handling of hard placement blockages By default, the command honors hard placement blockages and does not insert filler cells in regions affected by these blockages.\n To ignore the hard placement blockages and insert filler cells in those regions, use the  -ignore_hard_blockages option.\n \u2022 The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name!\n number To identify the filler cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix!\n filler_library_cell_name!\n number \u2022 The behavior when the legalizer detects errors By default, the command fails if the legalizer detects an error.\n To force the command to complete filler cell insertion even when errors occur, use the  -continue_on_error option.\n When you use this option, the resulting block might have legalization errors that must be fixed manually."}
{"header": "How do I Fixing Remaining Mask Design Rule Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  remove_stdcell_fillers_with_violation command checks for DRC violations between all cell instances with  xofiller in their name and top-level signal routing objects and removes the violating filler cells.\n You can control the following aspects of the filler cell checking: \u2022 The string used to identify the filler cells To specify a different string to identify the filler cells, use the  -name option.\n \u2022 The region in which to check for violations To restrict filler cell check to specific regions, use the  -boundary option.\n       \u2022 The checked objects To check for violations between filler cells and all neighboring objects, such as signal net shapes, other filler cells, standard cells, PG rails, and terminals, use the -check_between_fixed_objects\u00a0true option.\n \u2022 Restrict DRC to shorts-checking only By default, the command removes all filler cells that cause a routing DRC violation.\n To remove only those filler cells that cause a short by overlapping a routing shape, use the -shorts_only\u00a0true option.\n \u2022 Whether double-patterning rules are checked The command checks for double-patterning violations only when the following criteria are met: \u25e6 The  route.common.color_based_dpt_flow application option is  true.\n \u25e6 The technology file defines double-patterning rules To check for DRC violations on filler cells before removing them, use the  -check_only true option.\n When you use this option, this command writes a report to a file named block _fillers_with_violation.rpt in the current working directory.\n The report lists the filler cells with violations and reports the first violation for each filler cell."}
{"header": "How do I Abutting Standard Cells With Specific Filler Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Some mask design rules are not handled during filler cell insertion because they have a low probability of occurrence and they require extensive computation time if handled during insertion.\n After filler cell insertion, use the  replace_fillers_by_rules command to fix these design rule violations.\n You must specify the rule to fix by using the  -replacement_rule option.\n  Table\u00a041 lists the design rules supported by this command and the keywords used to specify these rules.\n Table 41 Design Rules Supported by the replace_fillers_by_rules Command Design rule Description -replacement_rule keyword      end_orientation       half_row_adjacency       Table 41 Design Rules Supported by the replace_fillers_by_rules Command (Continued) Design rule Description -replacement_rule keyword     illegal_abutment       od_horiztonal_distance       horizontal_edges_distance        small_filler_stacking       max_vertical_constraint      od_tap_distance     random End Orientation Rule The end orientation rule searches for a continuous horizontal sequence of cells and modifies the orientation of the leftmost or rightmost filler cells if they are in the specified list of target filler cells.\n To select this rule, use the  -replacement_rule\u00a0end_orientation option with the replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The target filler cells To specify the target filler cells, use the  -target_fillers option.\n       \u2022 The orientation modification \u25e6 To change the orientation for the leftmost filler cells, use the  -left_end option.\n \u25e6 To change the orientation for the rightmost filler cells, use the  -right_end option.\n \u25e6 To change the orientation for both the leftmost and rightmost filler cells, use both options.\n The valid values for these options are \u25e6 inverse, which flips the cell from its existing orientation \u25e6 R0_or_MX, which changes an MY orientation to R0 or an R180 orientation to MX \u25e6 MY_or_R180, which changes an R0 orientation to MY or an MX orientation to R180 To report the cells whose orientation would be changed, without actually changing the orientations, use the  -check_only option.\n This option is valid only for the end orientation rule.\n Half Row Adjacency Rule The half row adjacency rule searches for half-height filler cells and replaces them based on the types of their neighboring standard cells.\n The standard cells are classified as one of the following types: \u2022 Inbound The top or bottom boundary of an inbound standard cell is at the half-height location of the cell rows.\n When a half-height filler cell abuts an inbound cell, the abutting side of the half-height filler cell must have inbound-cell interaction polygons (ICIP).\n \u2022 Regular The top and bottom boundaries of a regular standard cell are at the full-height location of the cell rows.\n When a half-height filler cell abuts a regular cell, the abutting side of the half-height filler cell must not have inbound-cell interaction polygons (ICIP).\n The replacement filler cells have the same height, width, and threshold voltage as the original filler cells.\n The cell libraries include both p-type and n-type replacement filler cells with inbound-cell interaction polygons (ICIP).\n For p-type half-height filler cells, the inbound- cell interaction polygons (ICIP) are at the bottom corners.\n For n-type half-height filler cells, the inbound-cell interaction polygons (ICIP) are at the top corners.\n  Figure\u00a0128  shows the replacement of the half-height filler cells using the half row adjacency rule.\n       Figure 128 Half-Height Filler Cell Replacement With Half Row Adjacency Rule Regular height Inbound height Inbound height FILL2_P FILL4_N Regular height Inbound height Inbound height FILL2_PR FILL4_NR Inbound-cell interaction polygons To select this rule, use the  -replacement_rule\u00a0half_row_adjacency option with the replace_fillers_by_rules command.\n The following table lists the options used to specify the replacement half-height filler cells.\n Each list can contain only one cell of each size.\n Table 42 Half-Height Replacement Filler Cells Abutting inbound standard cells Option to specify replacement filler cells  -p_none -n_none  -p_left -n_left  -p_right -n_right  -p_left_right -n_left_right   -p_left_center_right -n_left_center_right       Illegal Abutment Rule The illegal abutment rule restricts the filler cells that can abut certain other filler cells.\n To select this rule, use the  -replacement_rule\u00a0illegal_abutment option with the replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The filler cells considered for the check and their replacements The filler cells considered for the check are called  target cells.\n To specify the target filler cells and their replacements, use the following syntax with the  -replace_abutment option: {\u00a0{ target_cell 1 refill_cell 1 }\u00a0...\n } To ignore filler cells that have a  physical_status attribute of  fixed or  locked, use the  -skip_fixed_cells option with the  replace_fillers_by_rules command.\n \u2022 The filler cells that cannot abut the target filler cells These filler cells are called  illegal cells.\n To specify the illegal cells, use the -illegal_abutment option.\n Note that the target filler cells specified in the -replace_abutment option are also considered illegal cells.\n For example, the following command fixes illegal abutment violations where the FILL1a and FILL1b filler cells cannot abut the FILLx and FILLy cells: fc_shell>\u00a0 replace_fillers_by_rules -replacement_rule illegal_abutment \\ -replace_abutment { {FILL1a CFILL1a} {FILL1b CFILL1b} } \\ -illegal_abutment {FILLx FILLy} Figure\u00a0129 shows the original row, which violates this rule, and the resulting row, which uses the replacement filler cells to fix the violations.\n The target filler cells are shown in red, while the replacement filler cells are shown in green.\n Figure 129 Fixing an Illegal Abutment Violation       Maximum Horizontal Edge Length Rule The maximum horizontal edge length rule restricts the horizontal length of a sequence of abutted objects on a specific layer.\n To select this rule, use the  -replacement_rule\u00a0horizontal_edges_distance option with the  replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The maximum horizontal length To specify the maximum length, use the  -max_constraint_length option.\n \u2022 The layer to check To specify the layer, use the  -layer option.\n \u2022 The cells considered for the check and the filler cells that can be used to replace the violating filler cells The filler cells considered for the check are called  constrained cells.\n The filler cells considered to replace violating cells are called  unconstrained cells.\n \u25e6 To specify multiple constrained cell groups and their replacement cells, use the following syntax with the  -refill_table option: {\u00a0{{ refill_cell 1 { constrained_cells 1 }}\u00a0...\n } You can use this syntax to fix violations for threshold-voltage-based filler cells.\n \u25e6 To specify a single constrained cell group, use the  -constraint_fillers option.\n To specify the replacement cells, use the  -non_constraint_fillers option.\n Note: If you use both methods, the command uses only the information specified in the  -refill_table option.\n For example, the following command identifies and fixes maximum horizontal edge length violations where the horizontal length on the M2 layer exceeds 30 um: fc_shell>\u00a0 replace_fillers_by_rules \\ -replacement_rule horizontal_edges_distance \\ -max_constraint_length 30 -layer M2 \\ -refill_table { {{VT1_FILL1} {VT1_DECAP4 VT1_DECAP2}} {{VT2_FILL1} {VT2_DECAP4 VT2_DECAP2}} }       Maximum Horizontal Length Rule The maximum horizontal length rule restricts the horizontal length of a sequence of abutted filler cells.\n To select this rule, use the  -replacement_rule\u00a0od_horiztonal_distance option with the  replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The maximum horizontal length To specify the maximum length, use the  -max_constraint_length option.\n \u2022 The cells considered for the check and the filler cells that can be used to replace the violating filler cells The filler cells considered for the check are called  constrained cells.\n The filler cells considered"}
{"header": "How do I Abutting Standard Cells With Specific Filler Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "to replace violating cells are called  unconstrained cells.\n \u25e6 To specify multiple constrained cell groups and their replacement cells, use the following syntax with the  -refill_table option: {\u00a0{{ refill_cell 1 { constrained_cells 1 }}\u00a0...\n } You can use this syntax to fix violations for threshold-voltage-based filler cells.\n \u25e6 To specify a single constrained cell group, use the  -constraint_fillers option.\n To specify the replacement cells, use the  -non_constraint_fillers option.\n Note: If you use both methods, the command uses only the information specified in the  -refill_table option.\n For example, the following command identifies and fixes maximum horizontal length violations where the horizontal length exceeds 70 um: fc_shell>\u00a0 replace_fillers_by_rules \\ -replacement_rule od_horiztonal_distance -max_constraint_length 70 \\ -refill_table { {{VT1_FILL1} {VT1_DECAP4 VT1_DECAP2}} {{VT2_FILL1} {VT2_DECAP4 VT2_DECAP2}} } Figure\u00a0130 shows the original row, which violates this rule, and the resulting row, which uses unconstrained filler cells to fix the violation.\n The constrained cells are shown in red, while the unconstrained cells are shown in green.\n       Figure 130 Fixing a Maximum Vertical Edge Length Violation Maximum Stacking for Small Filler Cells Rule The maximum stacking for small filler cells rule restricts the stacking height of small filler cells.\n To select this rule, use the  -replacement_rule\u00a0small_filler_stacking option with the replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The maximum stacking height To specify the maximum stacking height, use the  -max_constraint_length option.\n \u2022 The cells considered for the check To specify the small filler cells to consider for the check, use the  -small_fillers option.\n \u2022 The filler cells that can be used to replace the violating filler cells To specify the filler cells that can be used to replace the violating filler cells, use the -replacement_fillers option.\n If the vertical stacking of the small filler cells specified in the  -small_fillers option exceeds the height specified in the  -max_constraint_length option, the command replaces two or three consecutive filler cells adjacent to the violating cell with one of the large filler cells specified in the  -replacement_fillers option.\n If it is not possible to replace the filler cells, the command reorders the filler cells to fix the violation.\n The command maintains the threshold voltage at the location of the violating filler cell; however, the threshold voltage at the location of non-violating filler cells might change.\n The command does not check for threshold voltage violations caused by these changes.\n       For example, the following command identifies and fixes maximum stacking violations where the stacking height exceeds 10 um: fc_shell>\u00a0 replace_fillers_by_rules \\ -replacement_rule small_filler_stacking -max_constraint_length 10 \\ -small_fillers {FILL1 FILL2} -replacement_fillers {FILL3 FILL4} \\ The following figures illustrate the replacement and reordering techniques used to fix maximum stacking violations.\n In these figures, the small filler cells are shown in red, while the large filler cells are shown in green.\n Figure\u00a0131 shows the original stack, which violates this rule, and the resulting stack, which uses a replacement filler cell to fix the violation.\n Figure 131 Fixing Maximum Stacking Violation by Replacement FILL1  vt1 FILL3 vt1 FILL1  vt1 FILL2  vt1 FILL1  vt1 FILL1  vt1 FILL1  vt1 10um FILL2  vt1 Figure\u00a0132 shows the original stack, which violates this rule, and the resulting stack, which uses reordering to fix the violation.\n Note that the threshold voltage of the FILL3 cell is changed so that the vt2 threshold voltage is maintained in the original location.\n Figure 132 Fixing Maximum Stacking Violation by Reordering FILL1  vt1 FILL1  vt1 FILL2  vt1 10um FILL2  vt1 FILL3 vt1 FILL3 vt2 FILL2  vt2 FILL2  vt2       Maximum Vertical Edge Length Rule The maximum vertical edge length rule restricts the vertical length of a stack of certain filler cells and standard cells.\n To select this rule, use the  -replacement_rule\u00a0max_vertical_constraint option with the  replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The maximum vertical length To specify the maximum vertical length, use the  -max_constraint_length option.\n \u2022 The cells considered for the check These cells are called  constrained cells.\n To specify the constrained filler cells, use the  -constraint_fillers option.\n By default, all standard cells are constrained.\n To exclude specific standard cells from consideration, use the  -exception_cells option.\n To ignore the length violation when a constrained cell abuts an exception cell, use the -no_violation_along_exception_cells option.\n \u2022 The filler cells that can be used to replace the violating filler cells These filler cells are called  unconstrained cells ; they are not considered when measuring the stack height.\n \u25e6 To specify the filler cells that can be used to break a continuous edge of constrained cells, use the  -non_constraint_fillers option.\n \u25e6 To specify the filler cells whose left side can be used to break a continuous edge of constrained cells, use the  -non_constraint_left_fillers option.\n \u25e6 To specify the filler cells whose right side can be used to break a continuous edge of constrained cells, use the  -non_constraint_right_fillers option.\n Note: Any filler cells that are not identified as constrained, unconstrained, or exception cells are considered constrained cells.\n For example, the following command identifies and fixes maximum vertical edge length violations where the vertical length exceeds 180 um: fc_shell>\u00a0 replace_fillers_by_rules \\ -replacement_rule max_vertical_constraint -max_constraint_length 180 \\ -constraint_fillers {DECAP8 DECAP4} -non_constraint_fillers {FILL1} \\ -exception_cells {BUF1 TAP1} Figure\u00a0133 shows the original stack, which violates this rule, and the resulting stack, which uses unconstrained filler cells to fix the violation.\n The constrained cells are shown in red, while the unconstrained cells are shown in green.\n       Figure 133 Fixing a Maximum Vertical Edge Length Violation Tap Cell Spacing Rule The tap cell spacing rule restricts the distance between a target tap cell\u2019s oxide diffusion (OD) layer and the OD layers of its neighboring cells on the left and right sides.\n To select this rule, use the  -replacement_rule\u00a0od_tap_distance option with the replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The disallowed spacing range The spacing distance is specified as the number of sites.\n To specify the disallowed spacing range, use the  -tap_distance_range option.\n \u2022 The tap cells considered for the check These cells are called  target cells.\n To specify the target tap cells, use the  -tap_cells option.\n \u2022 The tap cells used to replace the violating tap cells These cells are called  replacement cells.\n \u25e6 To specify the replacement tap cell for left-side violations, use the -left_violation_tap option.\n \u25e6 To specify the replacement tap cell for right-side violations, use the -right_violation_tap option.\n \u25e6 To specify the replacement tap cell for both-side violations, use the -both_violation_tap option.\n Note: The target and replacement tap cells must all have the same size.\n       By default, the command measures the distance to the cells that abut the target tap cell.\n If the tap cells abut library cells that do not have an OD layer, use the -adjacent_non_od_cells option to specify these library cells.\n The command skips the specified non-OD cells and measures to distance from the target tap cell to the first neighbor with an OD layer.\n For example, the following command replaces tap cells named TAP that have a separation distance of three sites: fc_shell>\u00a0 replace_fillers_by_rules -replacement_rule od_tap_distance \\ -tap_cells {TAP} -tap_distance_range {3 3} \\ -left_violation_tap {TAPl} -right_violation_tap {TAPr} \\ -both_violation_tap {TAPb} Figure\u00a0134 shows the original row, which violates this rule, and the resulting row, which uses the replacement filler cells to fix the violations.\n The target filler cells are shown in red, while the replacement filler cells are shown in"}
{"header": "How do I Abutting Standard Cells With Specific Filler Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "green.\n Figure 134 Fixing a Tap Cell Spacing Violation Random Filler Cell Replacement To randomly replace existing filler cells, use the  -replacement_rule\u00a0random option with the  replace_fillers_by_rules command.\n When you select this rule, you must specify \u2022 The filler cells to be replaced and their replacements The filler cells to be replaced are called  target cells.\n To specify the target filler cells and their replacements, use the following syntax with the  -random_replace option: {\u00a0{ target_cell 1 { refill_cell 1a refill_cell 1b \u00a0...}}\u00a0...\n } To ignore filler cells that have a  physical_status attribute of  fixed or  locked, use the  -skip_fixed_cells option with the  replace_fillers_by_rules command.\n       When the command finds one of the target cells, it replaces it by randomly selecting one of the replacement cells specified for that target cell.\n For example, the following command replaces FILL1 cells with one of FILL1a, FILL1b, or FILL1c and replaces FILL2 cells with one of FILL2a or FILL2b: fc_shell>\u00a0 replace_fillers_by_rules -replacement_rule random \\ -random_replace { {FILL1 {FILL1a FILL1b FILL1c}} {FILL2\u00a0{FILL2a\u00a0FILL2b}}\u00a0}"}
{"header": "How do I Threshold-Voltage-Based Filler Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If your technology requires specific filler cells on the left or right sides of certain standard cells, use the  create_left_right_filler_cells command to insert these filler cells.\n After you run the  create_left_right_filler_cells command, perform standard filler cell insertion to fill the remaining gaps in the design.\n You must use the  -lib_cells option to specify the rules for filler cell insertion.\n Each rule uses the following format: { standard_cells }\u00a0{ left_filler_cells }\u00a0{ right_filler_cells } \u2022 For the  standard_cells argument, \u25e6 You must specify a list of one or more standard cells \u25e6 You can use wildcards to specify the cell names \u25e6 If you specify multiple rules for the same standard cell, the command uses only the last rule specified for that cell.\n \u2022 For the  left_filler_cells and  right_filler_cells arguments, \u25e6 At least one of these arguments must contain one or more filler library cells If only one of the arguments contains filler library cells, the tool inserts filler cells only on that side of the standard cells.\n \u25e6 The specified filler cells must meet the following requirements: \u25aa They must have a  design_type attribute of  lib_cell or  filler.\n \u25aa They must use the same site definition as the standard cells.\n \u25aa The height of the standard cells must be an integer multiple of the filler cell heights.\n \u25e6 The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n       \u25e6 You can use wildcards for the filler cell names.\n When you use wildcards, the order of the cells is the same as that returned by the get_lib_cells command.\n The following example inserts filler cells on the left and right sides of the SC1 standard cells and only on the left side of the SC2 standard cells.\n The left and right filler cells are specified in decreasing size order, so that the command inserts the largest possible filler cell.\n fc_shell>\u00a0 create_left_right_filler_cells \\ -lib_cells { { {mylib/SC1} {mylib/LF4X mylib/LF2X} {mylib/RF2X mylib/RF1X} } { {mylib/SC2} {mylib/LF2X mylib/LF1X} {} } } When the  create_left_right_filler_cells command inserts the filler cells, \u2022 It checks for legal locations for the filler cells, but does not check advanced rules such as minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules.\n \u2022 It inserts the filler cells immediately next to the standard cells; it does not consider the intercell spacing rules.\n See Also \u2022 Standard Filler Cell Insertion Controlling Cell-Based Filler Cell Insertion You can control the following aspects of the filler cell insertion with the create_left_right_filler_cells command: \u2022 The region in which to insert the filler cells By default, the command inserts filler cells next to the specified standard cells in the entire block.\n \u25e6 Use the  -boundaries option to restrict filler cell insertion to the specified regions.\n You can specify one or more rectangular or rectilinear regions.\n \u25e6 Use the  -voltage_areas option to restrict filler cell insertion to the specified voltage areas.\n \u2022 The orientation of the filler cells By default, the command uses the allowable orientations of the row to place the filler cells.\n To use the same orientation as the standard cell, use the -follow_stdcell_orientation option.\n When you use this option, the tool swaps the right and left filler cells when the cell is flipped.\n       \u2022 The handling of one-unit-tile gaps By default, the command does not consider the one-unit-tile rule.\n To prevent the tool from inserting filler cells that would leave a one-unit-tile gap, use the  -rules\u00a0no_1x option.\n When you enable this rule, do not include filler library cells with a width of one- unit tile in the  -lib_cells option; otherwise, the tool ignores this rule.\n \u2022 The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name!\n number To identify the filler cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix!\n filler_library_cell_name!\n number"}
{"header": "How do I Controlling Threshold-Voltage-Based Filler Cell Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the threshold-voltage-based flow, the tool selects the filler cells by using user-defined insertion rules, which are based the threshold-voltage types of the cells that border the gap.\n This flow is typically used only for established foundry nodes.\n To perform threshold-voltage-based filler cell insertion, 1.\n Ensure that the block is legalized by using the  check_legality command.\n 2.\n Annotate the threshold-voltage types on the reference cells by using the set_cell_vt_type command.\n For example, to specify that all cells whose names end with  _vtA have a threshold voltage type of  vtA  and the invx1 cell has a threshold voltage type of  default, use the following commands: fc_shell>\u00a0 set_cell_vt_type -lib_cells \"*/*_vtA\" -vt_type vtA fc_shell>\u00a0 set_cell_vt_type -lib_cells \"mylib/invx1\" -vt_type default 3.\n Define the rules for inserting the filler cells by using the  set_vt_filler_rule command.\n You define the rules by specifying the filler cells to insert based on the threshold- voltage types of the cells on the left and right of the gap being filled.\n For example, to specify that filler2x or filler1x cells can be inserted in a gap that has default threshold-voltage cells on the left and right sides and fillerA2x and fillerA1x cells       can be inserted in a gap that has vtA threshold-voltage cells on the left and right sides, use the following commands: fc_shell>\u00a0 set_vt_filler_rule -vt_type {default default} \\ -filler_cells {myLib/filler2x  myLib/filler1x} fc_shell>\u00a0 set_vt_filler_rule -vt_type {vtA vtA} \\ -filler_cells {myLib/fillerA2x  myLib/fillerA1x} 4.\n Insert the filler cells by using the  create_vtcell_fillers command."}
{"header": "How do I Removing the Threshold-Voltage Filler Cell Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  create_vtcell_fillers command fills all empty space in the horizontal standard-cell rows of the entire block.\n You can control the following aspects of the filler cell insertion: \u2022 The region in which to insert the filler cells \u25e6 Use the  -region option to restrict filler cell insertion to the specified regions.\n \u25e6 Use the  -voltage_area option to restrict filler cell insertion to the specified voltage areas.\n \u2022 The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name!\n number To identify the filler cells inserted in a specific run, use the  -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix!\n filler_library_cell_name!\n number To change the separator character from the default exclamation mark (!), use the -separator option."}
{"header": "How do I Removing Filler Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove the filler cell insertion rules and the threshold-voltage type annotations, use the -clear_vt_information option with the  create_vtcell_fillers command."}
{"header": "How do I Inserting Metal Fill", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Filler cells inserted by the Fusion Compiler tool have instance names that start with the string  xofiller.\n To remove all the filler cells from a block, use the  remove_cells command, as shown in the following example: fc_shell>\u00a0 remove_cells [get_cells xofiller*] If you used the standard filler cell insertion flow and want to remove only those filler cells with DRC violations, use the  remove_stdcell_fillers_with_violation command, as described in  Checking for Filler Cell DRC Violations."}
{"header": "How do I 8", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "After routing, you can fill the empty spaces in the block with metal wires to meet the metal density rules required by most fabrication processes.\n Before inserting metal fill, the block should be close to meeting timing and have very few or no DRC violations.\n To insert metal fill, run the  signoff_create_metal_fill command, as described in Inserting Metal Fill With IC\u00a0Validator In-Design.\n Note: An IC\u00a0Validator license is required to run the  signoff_create_metal_fill command."}
{"header": "How do I Preparing to Run IC\u00a0Validator In-Design Commands", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The IC\u00a0Validator In-Design feature provides the ability to use the IC\u00a0Validator tool to perform physical implementation and verification tasks within the Fusion Compiler tool.\n You can use IC\u00a0Validator In-Design to perform the following tasks: \u2022 Signoff design rule checking (the  signoff_check_drc command) \u2022 Fixing the violations detected during signoff design rule checking (the signoff_fix_drc command) \u2022 Augmenting the power grid based on voltage drop information (the signoff_create_pg_augmentation command) \u2022 Inserting metal fill (the  signoff_create_metal_fill command) \u2022 Fixing isolated vias (the  signoff_fix_isolated_via command) Note: An IC\u00a0Validator license is required to run the IC\u00a0Validator In-Design functions.\n To learn about using these IC\u00a0Validator In-Design functions, see the following topics: \u2022 Preparing to Run IC\u00a0Validator In-Design Commands \u2022 Performing Signoff Design Rule Checking \u2022 Automatically Fixing Signoff DRC Violations \u2022 Improving Instance Voltage Drop by Augmenting the Power Grid \u2022 Inserting Metal Fill With IC\u00a0Validator In-Design \u2022 Automatically Fixing Isolated Vias"}
{"header": "How do I Setting Up the IC\u00a0Validator Environment", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe the tasks you must perform before you run the IC\u00a0Validator In-Design commands: \u2022 Setting Up the IC\u00a0Validator Environment \u2022 Enabling IC\u00a0Validator Multicore Processing \u2022 Defining the Layer Mapping for IC\u00a0Validator In-Design Commands"}
{"header": "How do I Enabling IC\u00a0Validator Multicore Processing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To run an IC\u00a0Validator In-Design command, you must specify the location of the IC\u00a0Validator executable by setting the  ICV_HOME_DIR environment variable.\n You can set this variable in your.cshrc file.\n To specify the location of the IC\u00a0Validator executable, use commands similar to those shown in the following example: setenv\u00a0ICV_HOME_DIR\u00a0/root_dir/icv set\u00a0path\u00a0=\u00a0($path\u00a0$ICV_HOME_DIR/bin/LINUX.64) You must ensure that the version of the IC\u00a0Validator executable that you specify is compatible with the Fusion Compiler version that you are using.\n To report the version compatibility, use the  report_versions command.\n For more information about the IC\u00a0Validator tool, see the IC\u00a0Validator documentation, which is available on SolvNet."}
{"header": "How do I Running IC\u00a0Validator on Specific Hosts", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the IC\u00a0Validator In-Design commands use a single process to perform design rule checking.\n To reduce the turnaround time for design rule checking, use multicore processing, which includes multithreading, distributing processing, and parallel command execution.\n After you specify how many cores to use on different hosts, the IC\u00a0Validator tool determines exactly how to take advantage of multithreading and parallel command execution to achieve the fastest runtimes.\n To enable multicore processing, you must define the configuration by using the set_host_options command.\n By default, the configuration applies to all Fusion Compiler commands that support multicore processing.\n To define a configuration that applies only to the IC\u00a0Validator In-Design commands, use the  -target\u00a0ICV option.\n       You can enable multicore processing on specific hosts, by using a job scheduler such as the Load Sharing Facility (LSF), or by using a combination of these methods.\n The following topics describe these methods: \u2022 Running IC\u00a0Validator on Specific Hosts \u2022 Running IC\u00a0Validator Using a Job Scheduler \u2022 Running IC\u00a0Validator Using Hybrid Multicore Processing For general information about the  set_host_options command, see  Enabling Multicore Processing."}
{"header": "How do I Running IC\u00a0Validator Using a Job Scheduler", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable IC\u00a0Validator multicore processing on one or more specific hosts, use the set_host_options command to specify the following information: \u2022 The host names If you do not specify a host name or submit protocol, the IC\u00a0Validator tool runs on the host on which the Fusion Compiler tool is currently running.\n \u2022 The number of cores Use the  -num_processes or  -max_cores options to specify the number of cores.\n If you use both options, the IC\u00a0Validator tool uses the product of the settings as the number of cores.\n The specified number of cores applies to each specified host.\n For example, to enable the IC\u00a0Validator tool to use 4 cores on the current host, use the following command: fc_shell>\u00a0 set_host_options -target ICV -num_processes 4 To enable the IC\u00a0Validator tool to use 16 cores (8 cores each on machineA and machineB), use the following command: fc_shell>\u00a0 set_host_options -target ICV \\ -num_processes 2 -max_cores 4 {machineA machineB}"}
{"header": "How do I Running IC\u00a0Validator Using Hybrid Multicore Processing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable IC\u00a0Validator multicore processing using a job scheduler, use the set_host_options command to specify the following information: \u2022 The submit protocol \u25e6 To use LSF, use the  -submit_protocol\u00a0lsf option.\n The LSF  bsub command must be in your Linux path.\n \u25e6 To use the Univa Grid Engine (UGE) job scheduler, which was previously known as SGE (Sun Grid Engine) or GRD (Global Resource Directory), use the -submit_protocol\u00a0grid option.\n The Grid  qsub command must be in your Linux path.\n If you do not specify a host name or submit protocol, the IC\u00a0Validator tool runs on the host on which the Fusion Compiler tool is currently running.\n \u2022 The number of hosts to use Use the  -num_processes option to specify the number of hosts.\n \u2022 The number of cores to use on each host Use the  -max_cores option to specify the number of cores per host.\n \u2022 (Optional) Extra arguments needed for the submit command Use the  -submit_command option to specify the submit command with the extra arguments.\n For example, to enable 4 hosts to be acquired by LSF, each of which can use 8 cores (for a total of 32 cores), use the following command: fc_shell>\u00a0 set_host_options -submit_protocol lsf -target ICV \\ -num_processes 4 -max_cores 8 To set the memory requirement of the jobs in the previous example to 1000M, use the following command: fc_shell>\u00a0 set_host_options -submit_protocol lsf -target ICV \\ -num_processes 4 -max_cores 8 \\ -submit_command {bsub -R rusage[mem=1000]} To enable 4 hosts to be acquired by the Grid Engine, each of which can use 8 cores (for a total of 32 cores), use the following command: fc_shell>\u00a0 set_host_options -submit_protocol grid -target ICV \\ -num_processes 4 -max_cores 8       To set the process name of the jobs in the previous example to bnormal, use the following command: fc_shell>\u00a0 set_host_options -submit_protocol grid -target ICV \\ -num_processes 4 -max_cores 8 -submit_command \"qsub -P bnormal\""}
{"header": "How do I Defining the Layer Mapping for IC\u00a0Validator In-Design Commands", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you are using LSF, you can specify both specific hosts and an LSF configuration for adding additional hosts as they become available.\n To use this method, \u2022 Specify the configuration for the specific hosts as described in  Running IC\u00a0Validator on Specific Hosts.\n \u2022 Specify the LSF configuration as described in  Running IC\u00a0Validator Using a Job Scheduler, but use the  -add_hosts option in addition to the other command options.\n This configuration represents both optional resources and maximum resources \u2013 the resources can be given to the IC\u00a0Validator tool at the beginning, middle, or end of the run, or not given at all.\n For example, to use four cores on the current host and potentially acquire up to four more hosts from LSF, use the following commands: fc_shell>\u00a0 set_host_options -target ICV -max_cores 4 fc_shell>\u00a0 set_host_options -target ICV -add_hosts \\ -submit_protocol lsf -num_processes 4"}
{"header": "How do I Performing Signoff Design Rule Checking", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "A layer mapping file maps the technology layers to the layers used in the runset file.\n You specify the location of the layer mapping file by setting the signoff.physical.layer_map_file application option.\n Each line in the layer mapping file specifies a layer in the technology file and the corresponding layer in the runset file using the following syntax: tf_layer [: tf_purpose ][: use_type ][: mask_type ] runset_layer [: runset_data_type ] Each line can contain the following items: \u2022 tf_layer \u2013 Layer number in the technology file, a required item \u2022 tf_purpose \u2013 Purpose number in the technology file \u2022 use_type \u2013 Fusion Compiler usage of the geometries in the design       Valid values are  power,  ground,  signal,  clock,  boundary, hard_placement_blockage,  soft_placement_blockage,  routing_blockage, area_fill, and  track.\n \u2022 mask_type \u2013 Multiple-patterning mask constraint of the geometries Valid values for metal layers are  mask_one,  mask_two,  mask_three, and  mask_same.\n Via layers support the additional values  MASK_FOUR through  MASK_FIFTEEN.\n \u2022 runset_layer \u2013 Layer number in the runset file, a required item \u2022 runset_data_type \u2013 Layer data type number in the runset file Any text in a line that comes after a semicolon character ( ; ) is considered a comment and has no effect on layer mapping."}
{"header": "How do I Running the signoff_check_drc Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "IC\u00a0Validator In-Design signoff design rule checking (DRC) runs the IC\u00a0Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry signoff runset.\n You can perform signoff design rule checking by \u2022 Running the  signoff_check_drc command \u2022 Using the Live DRC feature in the Fusion Compiler GUI After place and route, use the  signoff_check_drc command to perform signoff design rule checking on the entire block.\n After engineering change orders (ECO), use either method to perform incremental signoff design rule checking on the modified portions of the block.\n See Also \u2022 Automatically Fixing Signoff DRC Violations"}
{"header": "How do I Setting Options for Signoff Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform signoff design rule checking by running the  signoff_check_drc command, 1.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 2.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n       3.\n Set the application options for signoff design rule checking.\n At a minimum, you must specify the foundry runset to use for design rule checking by setting the  signoff.check_drc.runset application option.\n For information about the options for command-based signoff design rule checking, see Setting Options for Signoff Design Rule Checking.\n 4.\n Save the block to disk.\n When you run signoff design rule checking, the IC\u00a0Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running signoff design rule checking.\n 5.\n Run signoff design rule checking by using the  signoff_check_drc command.\n By default, the  signoff_check_drc command performs the following tasks: 1.\n Loads the block into the IC\u00a0Validator tool, as described in  Reading Blocks for Signoff Design Rule Checking 2.\n Performs signoff design rule checking, as described in  Signoff Design Rule Checking 3.\n Generates an error data file and IC\u00a0Validator results files, as described in  Signoff DRC Results Files You can use the results files to view the violations in the error browser, as described in Using the Error Browser, or to perform automatic design rule fixing, as described in Automatically Fixing Signoff DRC Violations.\n You can use the following methods to analyze the DRC violations reported by the signoff_check_drc command: \u2022 View the violations in the error browser, as described in Using the Error Browser.\n \u2022 View the density of violations in a heat map, as described in  Viewing the Violations in an ICV Heat Map.\n See Also \u2022 Checking Signoff Design Rules Interactively in the GUI"}
{"header": "How do I Reading Blocks for Signoff Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  signoff_check_drc command, configure the run by setting the application options shown in  Table\u00a043.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n Table 43 Application Options for Signoff Design Rule Checking Application option Default Description signoff.check_drc.runset     signoff.check_drc.\n auto_eco_threshold_value    -auto_eco true  signoff.check_drc.\n excluded_cell_types    lib_cell  macro pad  filler  signoff.check_drc.\n fill_view_data read_if_uptodate      read  discard signoff.check_drc.\n ignore_blockages_in_cells true   true false signoff.check_drc.\n ignore_child_cell_errors false   false true signoff.check_drc.\n max_errors_per_rule    signoff.check_drc.\n read_design_views             Table 43 Application Options for Signoff Design Rule Checking (Continued) Application option Default Description signoff.check_drc.\n read_layout_views       signoff.check_drc.\n run_dir    signoff_check_drc      signoff.check_drc.\n user_defined_options         signoff.physical.\n layer_map_file            signoff.physical.\n merge_exclude_libraries     signoff.physical.\n merge_stream_files  signoff.physical.\n merge_stream_files"}
{"header": "How do I Signoff Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the IC\u00a0Validator tool reads the design view for the top-level block and library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances.\n \u2022 To read both the pin information and the routing blockages from the frame view for macro cells and I/O pad cells, set the signoff.check_drc.ignore_blockages_in_cells application option to  false.\n \u2022 To read the GDSII or OASIS data for specific reference cells, specify the stream files by setting the  signoff.physical.merge_stream_files application option.\n When you use this option, the GDSII or OASIS data replaces the cell library view for the cells defined in the specified stream files, except for cells in the cell libraries specified in the  signoff.physical.merge_exclude_libraries application option.\n \u2022 To read the layout view for specific reference cells, specify the cells by setting the signoff.check_drc.read_layout_views application option.\n The layout view is identical to the GDSII or OASIS data that was used to create it, but reduces the runtime for signoff design rule checking.\n Note: By default, layout views are not included in the cell libraries.\n To save the layout views, you must set the  lib.workspace.save_layout_views application option to  true during library preparation, as described in the Library Manager User Guide.\n \u2022 To read the design view for specific reference cells, specify the cells by setting the signoff.check_drc.read_design_views application option.\n Note: By default, design views are not included in the cell libraries.\n To save the design views, you must set the  lib.workspace.save_design_views application option to  true during library preparation, as described in the Library Manager User Guide.\n The order of precedence for child cell data is 1.\n GDSII or OASIS data specified with the  signoff.physical.merge_stream_files application option 2.\n Layout views specified with the  signoff.check_drc.read_layout_views application option If the IC\u00a0Validator tool cannot find a layout view and the cell is specified in the signoff.check_drc.read_design_views application option, it reads the design view.\n       Otherwise, it reads the frame view.\n If it cannot find the frame view, the cell is ignored during design rule checking.\n 3.\n Design views specified with the  signoff.check_drc.read_design_views application option If the IC\u00a0Validator tool cannot find a design view, it reads the frame view instead.\n If it cannot find the frame view, the cell is ignored during design rule checking.\n 4.\n Frame views For example, to read the design view for all blocks, use the following commands: fc_shell>\u00a0 set_app_options \\ -name signoff.check_drc.read_design_views -value {*} fc_shell>\u00a0 signoff_check_drc To read the design view for the top-level block and all instances of reference cells whose name start with mc, and the frame view for all other child blocks, use the following commands: fc_shell>\u00a0 set_app_options \\ -name signoff.check_drc.read_design_views -value {mc*} fc_shell>\u00a0 signoff_check_drc"}
{"header": "How do I Signoff DRC Results Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, signoff design rule checking has the following default behavior: \u2022 Performs checking on all cell types (standard cells, filler cells, macro cells, and I/O pad cells) To exclude certain cell types from design rule checking, set the  signoff.check_drc.\n excluded_cell_types application option.\n Specify one or more of the following values: lib_cell (standard cells),  filler (filler cells),  macro (macro cells), and  pad (I/O pad cells).\n \u2022 Performs design rule checking on the entire block \u25e6 To perform design rule checking only on those areas of the block that have been modified since the last run, use the  -auto_eco option.\n Note: You can use this option only if you have previously run the signoff_check_drc command and the percentage of change to the block since that run is less than the change threshold.\n The default change threshold is 20 percent; to modify the change threshold, set the signoff.check_drc.auto_eco_threshold_value application option.\n       By default, the tool compares the current block to the version used for the previous signoff_check_drc run.\n To compare the current block to a different block, use the  -pre_eco_design option to specify the comparison block.\n The tool gets the information required for incremental change detection from the error data file named block _sdrc.err, where  block is either the current block name or the name specified by the  -pre_eco_design option.\n By default, the DRC violations reported after performing incremental signoff design rule checking represent only the DRC violations detected in the changed areas of the block.\n To merge the initial DRC violations with the DRC violations detected during the incremental run, set the signoff.check_drc.merge_incremental_error_data application option to  true before running the  signoff_check_drc\u00a0-auto_eco command.\n By default, the command reads the initial DRC violations from the signoff_check_drc.err file.\n To read the initial DRC violations from a different error data file, specify the file name with the  signoff.check_drc.merge_base_error_name application option.\n \u25e6 To perform design rule checking only in specific regions, use the  -coordinates option, the  -excluded_coordinates option, or both.\n You can specify one or more regions for both options.\n If you specify both options, the command does not check design rules in the overlapping regions.\n To specify the coordinates, use the following format: {{x 1 y 1 }\u00a0{x 2 y 2 }\u00a0...\n {x n y n }} Note that there must be a space between each set of coordinates.\n \u2022 Performs design rule checking for all rules specified in the foundry runset \u25e6 To check only specific rules, use the  -select_rules option.\n Specify the rules by specifying a matching pattern for the rule names.\n The rule names are specified in the COMMENT section in the runset file.\n \u25e6 To prevent checking of specific rules, use the  -unselect_rules option.\n Specify the rules by specifying a matching pattern for the rule names.\n The rule names are specified in the COMMENT section in the runset file.\n Note: You can use this option with the  -select_rules option to customize the set of rules checked by the  signoff_check_drc command.\n For example, to restrict the  signoff_check_drc command to route validation, select the metal layer rules and exclude the metal density rules.\n       \u2022 Performs design rule checking for all routing layers \u25e6 To perform design rule checking only on specific routing layers, use the -select_layers option.\n Specify the routing layers by using the layer names from the technology file.\n \u25e6 To perform design rule checking on all runset layers, including nonrouting layers, use the  -check_all_runset_layers\u00a0true option.\n You would typically use this setting to perform a quick design rule check on the entire block after you complete design rule checking on the routing layers.\n When you use this option, the block information comes from the design view and the validation tool checks all layers, including the nonrouting layers.\n \u2022 Reports a maximum of 1000 errors for each rule, including both top-level and child- level violations \u25e6 To override the maximum error count, set the signoff.check_drc.max_errors_per_rule application option.\n \u25e6 To ignore child-level violations, set the signoff.check_drc.ignore_child_cell_errors application option to  true.\n The  signoff_check_drc command uses the options that you specify to generate the command used to invoke signoff design rule checking in the IC\u00a0Validator tool.\n You can specify additional options for the IC\u00a0Validator command line by setting the signoff.check_drc.user_defined_options application option.\n The string that you specify in this option is added to the command line used to invoke the IC\u00a0Validator tool.\n The Fusion Compiler tool does not perform any checking on the specified string.\n Generating Input for the Automatic Fixing Flow If you plan to use the signoff DRC results as input to the automatic fixing flow, set the signoff.check_drc.ignore_child_cell_errors application option to  true before you run the  signoff_check_drc command.\n Zroute can fix only top-level violations; using this option ensures that signoff design rule checking reports only fixable violations."}
{"header": "How do I Viewing the Violations in an ICV Heat Map", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  signoff_check_drc command writes its output files to the run directory, which is specified by the  signoff.check_drc.run_dir application option (or the signoff_check_drc_run directory if you do not use this option).\n The following files are written to the run directory: \u2022 The error data file By default, the error data generated by the  signoff_check_drc command is saved in a file named signoff_check_drc.err, which is stored in the design library.\n To specify the name for the error data file, use the  -error_data option.\n The error data shows child-       level errors on only one of the cell instances, which makes it easier to identify lower- level errors.\n You can use the error data file to report or display the DRC violations in the error browser.\n For information about using the error browser, see Using the Error Browser.\n \u2022 The IC\u00a0Validator results files You can use the following IC\u00a0Validator results files for debugging the signoff DRC results: \u25e6 block.LAYOUT_ERRORS This file contains details about the errors detected during the  signoff_check_drc run.\n \u25e6 block.RESULTS This file contains a summary of the  signoff_check_drc run results.\n \u25e6 signoff_check_drc.log This file contains a summary of the  signoff_check_drc run environment.\n \u25e6 icv_config_out This file contains the paths to the top-level block and the cell libraries.\n \u25e6 icv_sdrc.conclude This file contains an error summary report.\n \u25e6 layer.map This file contains the layer mapping file generated by the  signoff_check_drc command.\n \u25e6 signoff_check_drc.rc This file contains the IC\u00a0Validator runset environment variables.\n \u25e6./run_details directory This directory contains all the data generated by the IC\u00a0Validator tool for the signoff DRC run.\n For more information about these files, see the IC\u00a0Validator documentation."}
{"header": "How do I Configuring an ICV Heat Map", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "An ICV heat map displays the density of signoff DRC violations in a block.\n You can use the heat map to locate problematic areas in your design.\n       Note: This feature requires version P-2019.06 or later of the IC\u00a0Validator tool and an IC\u00a0Validator NXT license.\n To view the ICV heat map, 1.\n Enable the ICV heat map by setting the signoff.check_drc.enable_icv_explorer_mode application option to  true.\n fc_shell>\u00a0 set_app_options -name signoff.check_drc.enable_icv_explorer_mode \\ -value true 2.\n Perform signoff design rule checking as described in  Running the signoff_check_drc Command.\n 3.\n In the GUI, choose View > Map > ICV Heatmap.\n Figure\u00a0135 shows an ICV heat map.\n       Figure 135 ICV Heat Map"}
{"header": "How do I Highlighting Violations From the Error Browser Onto an ICV Heat", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can select or unselect violation types from the heat map, as shown in figure Figure\u00a0136 and  Figure\u00a0137.\n Figure 136 Violation Type       Figure 137 Violation Type in ICV Heat Map To control the opacity of the heat map squares, adjust the Alpha percentage value.\n Set this percentage to 100% to create a completely filled block.\n The lower you set the percentage, the more transparent the block becomes, as shown in  Figure\u00a0138 and  Figure\u00a0139.\n Figure 138 Completely Filled Block       Figure 139 You can adjust the range of colored squares by modifying the Bins value, as shown in Figure\u00a0140 and  Figure\u00a0141.\n Figure 140 Bins Value Set to 5       Figure 141 Bins Value Set to 8 You can select or unselect layers from the heat map, as shown in  Figure\u00a0142 and Figure\u00a0143.\n Figure 142 Selecting Layers       Figure 143 Selecting Layers in the ICV Heatmap You can modify the squares of the heat map by right-clicking the colored squares and selecting Set Style.\n See  Figure\u00a0144  and  Figure\u00a0145.\n       Figure 144 Set Style Figure 145 Select Style"}
{"header": "How do I Automatically Fixing Signoff DRC Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To highlight violations from the Error Browser: 1.\n In the GUI, choose View > Error Browser.\n 2.\n Select the error data generated from the DRC run.\n 3.\n Select violations from the Error Browser to automatically highlight them on the heat map."}
{"header": "How do I Creating an Autofix Configuration File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Zroute can use the signoff DRC results generated by the  signoff_check_drc command to automatically fix the detected design rule violations.\n To perform automatic fixing of the signoff DRC violations, 1.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 2.\n Set up the physical signoff options as described in  Setting Options for Signoff Design Rule Checking.\n 3.\n (Optional) Generate a configuration file that aids in the fixing process.\n The configuration file defines the layer-to-DRC-rule mapping.\n The  signoff_fix_drc command processes only those rules that are specified in the configuration file.\n By default, the  signoff_fix_drc command automatically generates the configuration.\n You can manually generate a configuration file, as described in  Creating an Autofix Configuration File.\n 4.\n Set the application options for signoff DRC fixing.\n For information about the options for signoff DRC fixing, see  Setting Options for Signoff Design Rule Checking.\n 5.\n Save the block to disk.\n When you run the  signoff_fix_drc command, the IC\u00a0Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running the  signoff_fix_drc command.\n 6.\n Run signoff DRC fixing by using the  signoff_fix_drc command as described in Running the signoff_fix_drc Command.\n If your block uses double-patterning technology, first perform signoff DRC fixing for all other routing design rules, and then perform signoff DRC fixing for only the double- patterning rules, as described in  Automatically Fixing Double-Patterning Odd-Cycle Violations."}
{"header": "How do I Setting Options for Signoff DRC Fixing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The autofix configuration file has the following format: \" mask_layer_name \"\u00a0\" full_IC_Validator_DRC_rule_comment \" You can put comments in the configuration file by starting the line with the pound sign (#).\n       If you have already run the  signoff_check_drc command, you can generate a configuration file by running the $ICV_HOME_DIR/contrib/generate_layer_rule_map.pl script.\n This script has the following syntax: generate_layer_rule_map.pl -dplog\u00a0 IC_Validator_log_file -tech_file\u00a0 technology_file -o\u00a0 config_file_name The IC\u00a0Validator log file that you specify in the  -dplog option is the log file that was generated by the previous  signoff_check_drc run.\n This file is called  runset.dp.log and is located in the run_details subdirectory of the signoff_drc_run directory (or the directory specified by the  signoff.check_drc.run_dir application option.\n To specify the location of the configuration file you created, use the signoff.fix_drc.config_file application option."}
{"header": "How do I Running the signoff_fix_drc Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  signoff_fix_drc command, configure the run by setting the application options shown in  Table\u00a044.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n Table 44 Application Options for Signoff DRC Fixing Application option Default Description signoff.fix_drc.\n advanced_guidance_for_rules all   signoff_fix_drc  all off signoff.fix_drc.check_drc local    local global signoff.fix_drc.\n custom_guidance    dpt           Table 44 Application Options for Signoff DRC Fixing (Continued) Application option Default Description signoff.fix_drc.\n fix_detail_route_drc global signoff_fix_drc  global  local signoff.fix_drc.\n init_drc_error_db    signoff_fix_drc signoff_check_drc   signoff.fix_drc.\n last_run_full_chip false    false true signoff.fix_drc.\n max_detail_route_iterations     signoff.fix_drc.\n max_errors_per_rule    signoff.fix_drc.run_dir    signoff_fix_drc      signoff.fix_drc.\n target_clock_nets false  false true signoff.fix_drc.\n user_defined_options"}
{"header": "How do I Automatically Fixing Double-Patterning Odd-Cycle Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  signoff_fix_drc command performs the following tasks: 1.\n Runs the  signoff_check_drc command to generate the initial signoff DRC results, as described in  Checking for DRC Violations If you have already run the  signoff_check_drc command, you can use the existing signoff DRC results instead of rerunning signoff design rule checking.\n To reuse the existing results, specify the directory that contains the results by setting the signoff.fix_drc.init_drc_error_db application option.\n You can specify either a relative path or an absolute path.\n If you specify a relative path, it is relative to the current working directory.\n For example, to use the results from the default  signoff_check_drc run directory, use the following commands: fc_shell>\u00a0 set_app_options \\ -name signoff.fix_drc.init_drc_error_db \\ -value signoff_check_drc_run fc_shell>\u00a0 signoff_fix_drc Note: To use existing signoff DRC results as input to the  signoff_fix_drc command, you must use the signoff DRC application options described in Generating Input for the Automatic Fixing Flow.\n 2.\n Runs two repair loops to fix the DRC violations In each repair loop, the  signoff_fix_drc command performs the following tasks; a.\n Tries to fix the DRC violations detected in the previous IC\u00a0Validator signoff DRC run, as described in  Fixing DRC Violations b.\n Runs IC\u00a0Validator signoff design rule checking on the modified block, as described in  Checking for DRC Violations To change the number of repair loops, use the  -max_number_repair_loop option; you can specify an integer between 1 and 10.\n If no signoff DRC violations remain after a loop, the tool does not perform additional repair loops.\n As the repair loop number increases, so does the physical scope of the rerouting performed by that repair loop.\n To change the scope, increase the number of the initial repair loop by using the  -start_repair_loop option.\n Note that increasing the initial loop number might cause a greater disturbance to the block, which would require additional design rule checking and fixing by Zroute.\n       3.\n Writes a summary report of the results For information about the summary report, see  Summary Report for Automatic Design Rule Fixing.\n Fixing DRC Violations In each repair loop, the  signoff_fix_drc command tries to fix the DRC violations detected in the previous signoff DRC run.\n \u2022 For the first loop, the tool uses the IC\u00a0Validator data in the directory specified by the signoff.fix_drc.init_drc_error_db application option (or the signoff_drc_run_init directory if you do not use this option).\n \u2022 For successive loops, the tool uses the IC\u00a0Validator DRC data from the previous loop, which is stored in the directory specified by the  signoff.fix_drc.run_dir application option (or the signoff_fix_drc_run directory if you do not use this option).\n When fixing DRC violations, the  signoff_fix_drc command has the following default behavior: \u2022 Tries to fix all design rule violations detected in the previous signoff DRC run except those design rules that have more than 1000 violations \u2022 Performs DRC fixing on data nets for the whole block To modify the regions for design rule fixing, use one or both of the following options: \u25e6 -coordinates This option restricts design rule fixing to the specified regions.\n \u25e6 -excluded_coordinates This option prevents design rule fixing in the specified regions.\n If you specify this option with the  -coordinates option, the command does not fix design rules in the overlapping regions.\n To specify the coordinates, use the following format: {{x 1 y 1 }\u00a0{x 2 y 2 }\u00a0...\n {x n y n }} Note that there must be a space between each set of coordinates.\n       To prevent fixes that might impact timing-critical nets, use one or both of the following options: \u25e6 -nets This option explicitly specifies the critical nets.\n \u25e6 -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold.\n The unit for the slack threshold setting is the library time unit.\n \u2022 Performs five iterations of detail routing after DRC fixing to fix any DRC violations introduced during DRC fixing \u2022 Saves the modified block in a design view named  block _ADR_# To change the default behavior, use the following options: \u2022 signoff.fix_drc.max_errors_per_rule This application option specifies the error threshold for ignoring a design rule.\n \u2022 signoff.fix_drc.fix_detail_route_drc This application option controls the scope of DRC fixing.\n To reduce runtime by performing DRC fixing only in areas near the signoff DRC violations, set this application option to  local.\n \u2022 signoff.fix_drc.target_clock_nets This application option controls whether DRC fixing targets data nets or clock nets.\n To target clock nets, set this application option to  true.\n \u2022 signoff.fix_drc.max_detail_route_iterations This application option specifies the number of detail routing iterations; you can specify an integer between 0 and 1000.\n Checking for DRC Violations When performing signoff design rule checking, the  signoff_fix_drc command has the following default behavior: \u2022 Reads the design view for the top-level block and library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances For information about changing the view used for specific cells, see  Reading Blocks for Signoff Design Rule Checking.\n \u2022 After the initial run, performs design rule checking only on those portions of the design affected by design rule fixing       To perform signoff design rule checking on the entire block for the last repair loop, set the  signoff.fix_drc.last_run_full_chip application option to  true.\n Setting this option to  true increases accuracy but also increases runtime.\n To perform signoff design rule checking on the entire block for all repair loops, set the signoff.fix_drc.check_drc application option to  global.\n Setting this option to global increases accuracy but can greatly increase runtime.\n \u2022 Does not check for violations in child blocks \u2022 Excludes rules that are not suitable for automatic design rule fixing To explicitly specify the design rules checked by the IC\u00a0Validator tool, set the -select_rules\u00a0 rules and  -unselect_rules\u00a0 rules application options.\n \u2022 Stores the IC\u00a0Validator results in the signoff_fix_drc_run directory To use a different run directory, set the  signoff.fix_drc.run_dir application option.\n Note: The IC\u00a0Validator results for the initial signoff DRC run are stored in the signoff_drc_run_init directory.\n In addition, you can specify options to add to the IC\u00a0Validator command line by setting the signoff.fix_drc.user_defined_options application option.\n See Also \u2022 Performing Signoff Design Rule Checking"}
{"header": "How do I Summary Report for Automatic Design Rule Fixing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If your block uses double-patterning technology, you must perform separate signoff DRC fixing runs for the non-double-patterning routing rules and the double-patterning routing rules.\n To perform automatic fixing of the signoff DRC violations for a block that uses double- patterning technology, 1.\n Perform automatic fixing for the non-double-patterning signoff DRC violations by using the process described in  Automatically Fixing Signoff DRC Violations.\n When you run the  signoff_check_drc and  signoff_fix_drc commands, use the -unselect_rules option to ignore the double-patterning rules during signoff design rule checking.\n fc_shell>\u00a0 signoff_check_drc -unselect_rules { list_of_dpt_rules } Note: To determine the double-patterning rules for your technology, see the design rule manual (DRM) provided by your vendor.\n 2.\n Perform automatic fixing for the double-patterning odd-cycle violations by using the process described in  Automatically Fixing Signoff DRC Violations.\n Before you run the  signoff_fix_drc command, set the signoff.fix_drc.custom_guidance application option to  dpt.\n fc_shell>\u00a0 set_app_options \\ -name signoff.fix_drc.custom_guidance -value dpt When you run the  signoff_check_drc and  signoff_fix_drc commands, use the -select_rules option to consider only the double-patterning rules during signoff design rule checking.\n fc_shell>\u00a0 signoff_check_drc -select_rules { list_of_dpt_rules } 3.\n Perform signoff design rule checking to verify the results by using the process described in  Performing Signoff Design Rule Checking."}
{"header": "How do I Checking Signoff Design Rules Interactively in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  signoff_fix_drc command writes a summary report file, result_summary.rpt, to the current working directory.\n  Example\u00a030  shows an example of this report.\n Example 30 result_summary.rpt Example Input\u00a0DRC\u00a0Error\u00a0Database............\n./inputs/signoff_check_drc_run Limit\u00a0to\u00a0Cell.......................\n my_design Maximum\u00a0Errors/Command..............\n 1000        SIGNOFF\u00a0AUTOFIX\u00a0DRC\u00a0SUMMARY: :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0REMAINING\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: :\u00a0TOTAL\u00a0:\u00a0PROCESSED\u00a0:\u00a0TARGETED\u00a0:\u00a0TARGETED\u00a0\u00a0:\u00a0\u00a0FIX\u00a0\u00a0\u00a0: DRC\u00a0NAME\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0DRC\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0DRC\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0DRC\u00a0:\u00a0DRC\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0RATE\u00a0\u00a0:\u00a0COMMENT M0.W.3\u00a0: Maximum\u00a0width\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0--\u00a0\u00a0\u00a0:\u00a01 ignored:\u00a0<#1> M4.L.3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: Edge\u00a0length\u00a0wi\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a04\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0--\u00a0\u00a0\u00a0:\u00a04\u00a0ignor ed:\u00a0<#2> M4.L.5:2\u00a0: Edge\u00a0length\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0--\u00a0\u00a0\u00a0:\u00a02 ignored:\u00a0<#2> M4.W.3\u00a0: Maximum\u00a0width\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0\u00a0\u00a0--\u00a0\u00a0\u00a0:\u00a01 ignored:\u00a0<#1> VIA1.S.10.3\u00a0: Space\u00a0of\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a010\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a010\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0100.0%\u00a0:\u00a08 ignored:\u00a0<#2> TOTAL\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02\u00a0:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a00\u00a0:\u00a0100.0%\u00a0:  NOTE: Reasons\u00a0:\u00a0Detail\u00a0Info #1\u00a0:\u00a0size\u00a0of\u00a0error\u00a0shapes\u00a0greater\u00a0than\u00a0threshold #2\u00a0:\u00a0shapes\u00a0associated\u00a0with\u00a0error\u00a0are\u00a0not\u00a0Zroute\u00a0modifiable The following table describes each of the columns in the summary report: Table 45 Definitions of Columns in result_summary.rpt Column heading Description     signoff_check_drc"}
{"header": "How do I Displaying Objects for Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Live DRC feature performs interactive signoff design rule checking in the Fusion Compiler GUI.\n Note: This feature requires version P-2019.06 or later of the IC\u00a0Validator tool.\n To perform interactive signoff design rule checking using Live DRC, 1.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 2.\n Set the application options for interactive signoff design rule checking.\n At a minimum, you must specify the following information: \u25e6 The foundry runset to use for design rule checking by setting the signoff.check_drc_live.runset application option \u25e6 The layer mapping file that maps the technology file layers to the runset layers by setting the  signoff.physical.layer_map_file application option For information about the options for interactive signoff design rule checking, see Setting Options for Interactive Design Rule Checking.\n 3.\n Ensure that the layout window displays the objects on which you want to perform design rule checking.\n By default, interactive design rule checking uses the frame view of each cell.\n If you want more detail than what is provided in the frame view, use the GDSII or OASIS view for specific cells by specifying the files containing the cells in the signoff.physical.merge_stream_files application option.\n For example, fc_shell>\u00a0 set_app_options \\ -name signoff.physical.merge_stream_files \\ -value {stdcell.gds macro.oas} For information about controlling the objects displayed for design rule checking, see Displaying Objects for Design Rule Checking.\n 4.\n Display the DRC toolbar by right-clicking in the GUI menu bar and selecting DRC Tools.\n For details about the icons in the DRC toolbar, see  DRC Toolbar.\n 5.\n Configure the rules to use for design rule checking by choosing Edit > Options > ICV- Live or by clicking the gear icon ( ) in the DRC toolbar.\n       To exclude all density or connectivity rules from design rule checking, set the signoff.check_drc_live.exclude_command_class application option.\n 6.\n Run design rule checking by choosing Edit > ICV > Run ICV-Live on Current View or by clicking the ICV Run button ( ) in the DRC toolbar.\n The first time that you run Live DRC, the tool performs the following initialization steps, which can take a couple of minutes: \u2022 Processes the IC Validator runset to get the list of available rules and caches the runset \u2022 Processes the GDSII or OASIS files specified in the signoff.physical.merge_stream_files application option Unless the layers, rules, or stream files change, subsequent runs do not perform this caching and therefore are much quicker.\n To reduce the initial runtime, you can perform this initialization before running Live DRC by using the  signoff_init_live_drc command.\n The tool displays the design rule checking results in the error browser.\n You can select errors in the error browser and then fix them interactively.\n For information about using the error browser, see Using the Error Browser See Also \u2022 Running the signoff_check_drc Command"}
{"header": "How do I DRC Toolbar", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you run interactive design rule checking, the IC\u00a0Validator tool performs design rule checking on what is displayed in the layout window, plus an extension of 1 micron.\n You can modify the size of the extension by setting the  signoff.check_drc_live.halo application option.\n Use the View Settings and Hierarchy Settings panels to control the layers, levels, and cell types displayed in the layout window.\n \u2022 Display the View Settings panel by clicking the View Settings icon ( ) in the panel area.\n \u25e6 Specify the number of levels to display in the Level field.\n \u25e6 Select the Layers tab and enable visibility for the desired layers.\n \u2022 Display the Hierarchy Settings panel by clicking the Hierarchy Settings icon ( ) in the View Settings panel or the menu bar.\n       \u25e6 Specify the number of view levels in the \u201cView level\u201d field.\n \u25e6 Select Standard, \u201cFill Cell,\u201d and Block in the \u201cExpanding cell types\u201d section.\n Figure\u00a0146 shows the View Settings and Hierarchy Settings panels used to control the layout window display for design rule checking.\n Figure 146 Settings Used to Display Objects for Design Rule Checking"}
{"header": "How do I Setting Options for Interactive Design Rule Checking", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The DRC toolbar provides buttons that you can use to configure and run interactive design rule checking with Live DRC, and to view the reported DRC violations in the layout view.\n Figure\u00a0147 shows the DRC toolbar.\n       Figure 147 DRC Toolbar Table 46 DRC Toolbar Buttons Button Description               signoff.physical.merge_stream_files"}
{"header": "How do I Improving Instance Voltage Drop by Augmenting the Power Grid", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run interactive design rule checking, configure the run by setting the application options shown in  Table\u00a047.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n Table 47 Application Options for Interactive Design Rule Checking Application option Default Description signoff.check_drc_live.\n check_only_visible_layers all_layers    all_layers visible_involved visible_only signoff.check_drc_live.\n default_layers    signoff.check_drc_live.\n exclude_command_class {{density\u00a0true} {connectivity\u00a0true}}    signoff.check_drc_live.\n halo    signoff.check_drc_live.\n hierarchy_level visible   signoff.check_drc_live.\n keep_enclosing_results false      true     signoff.check_drc_live.halo          Table 47 Application Options for Interactive Design Rule Checking (Continued) Application option Default Description signoff.check_drc_live.\n run_dir         signoff.check_drc_live.\n runset     signoff.check_drc_live.\n user_defined_options         signoff.physical.\n layer_map_file          signoff.physical.\n merge_stream_files"}
{"header": "How do I Standard Power Grid Augmentation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Power grid augmentation is a technique used to improve the instance voltage drop.\n When you augment the power grid, the added metal shapes act as parallel resistors, which reduces the resistance of the power grid as seen by the standard cells.\n  Figure\u00a0148 shows an example of power grid augmentation and how it lowers the power grid resistance.\n Figure 148 Power Grid Augmentation The Fusion Compiler tool supports the following methods of power grid augmentation: \u2022 Standard power grid augmentation, which inserts as many PG augmentation shapes as possible to lower the instance voltage drop \u2022 Timing-driven power grid augmentation, which inserts PG augmentation shapes in the specified regions of the block, except around timing-critical nets \u2022 Guided power grid augmentation, which inserts PG augmentation shapes only from cells with IR violations to their tap with the minimum path resistance Each method uses RedHawk Fusion analysis to drive the power grid augmentation and uses the IC Validator tool to insert the PG augmentation shapes.\n For detailed information about performing power grid augmentation, see the topic associated with the method you want to use.\n See Also \u2022 RedHawk and RedHawk-SC Fusion"}
{"header": "How do I Setting Options for Power Grid Augmentation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Standard power grid augmentation inserts as many PG augmentation shapes as possible to lower the instance voltage drop.\n To perform standard power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis.\n The IC\u00a0Validator tool uses the results of this voltage drop analysis to drive the power grid augmentation.\n 3.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 4.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n 5.\n Set the application options for performing power grid augmentation, as described in Setting Options for Power Grid Augmentation.\n At a minimum, you must define the power and ground nets on which to perform PG augmentation.\n \u25e6 To specify the power net, set the signoff.create_pg_augmentation.power_net_name application option.\n \u25e6 To specify the ground net, set the signoff.create_pg_augmentation.ground_net_name application option.\n If your design contains more than one power net, you must perform PG augmentation once for each power net.\n 6.\n Save the block to disk.\n When you run the  signoff_create_pg_augmentation command, the IC\u00a0Validator tool uses the on-disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running the  signoff_create_pg_augmentation command.\n 7.\n Perform power grid augmentation by using the  signoff_create_pg_augmentation command.\n When you run this command, you must specify the technology node for which to perform the augmentation by using the  -node option.\n       If you must perform incremental PG augmentation because your design contains more than one power net, use the  -mode\u00a0add command on subsequent runs to append the PG augmentation shapes to the existing shapes.\n 8.\n Run voltage drop analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis.\n This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n During standard PG augmentation, the  signoff_create_pg_augmentation command performs the following tasks: 1.\n Inserts PG augmentation shapes for the specified regions When the IC\u00a0Validator tool inserts the PG augmentation shapes, it considers the routing design rules to ensure that it does not create design rule violations.\n By default, the command performs PG augmentation for the entire block.\n To specify the regions for PG augmentation, use one or more of the following options: \u25e6 -coordinates_ground This option restricts PG augmentation for the ground net to the specified regions.\n \u25e6 -excluded_coordinates_ground This option prevents PG augmentation for the ground net in the specified regions.\n If you specify this option with the  -coordinates_ground option, the command does not perform PG augmentation in the overlapping regions.\n \u25e6 -coordinates_power This option restricts PG augmentation for the power net to the specified regions.\n \u25e6 -excluded_coordinates_power This option prevents PG augmentation for the power net in the specified regions.\n If you specify this option with the  -coordinates_power option, the command does not perform PG augmentation in the overlapping regions.\n The shapes added during PG augmentation have a  shape_use attribute of pg_augmentation.\n You can use this attribute to query the shapes added during PG augmentation.\n For example, fc_shell>\u00a0 get_shapes -filter {shape_use=~pg_augmentation}       2.\n Generates a summary report that shows the following information for each PG net: \u25e6 The distribution of power grid augmentation shapes added on each layer \u25e6 The total number of metal shapes added, the total number of via shapes added, and the total number of all shapes added 3.\n Saves the updated block to disk See Also \u2022 Timing-Driven Power Grid Augmentation \u2022 Guided Power Grid Augmentation \u2022 Removing PG Augmentation Shapes"}
{"header": "How do I Timing-Driven Power Grid Augmentation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  signoff_create_pg_augmentation command, configure the run by setting the application options shown in  Table\u00a048.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff.\n create_pg_augmentation.\n ground_net_name     signoff.\n create_pg_augmentation.po wer_net_name    signoff.\n create_pg_augmentation.\n run_dir     signoff_create_pg_augmentation            Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff.\n create_pg_augmentation.\n user_defined_options"}
{"header": "How do I Guided Power Grid Augmentation", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Timing-driven power grid augmentation inserts PG augmentation shapes in the specified regions of the block, except around timing-critical nets.\n By default, the tool does not perform timing-driven PG augmentation.\n To perform timing-driven power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis.\n The IC\u00a0Validator tool uses the results of this voltage drop analysis to drive the power grid augmentation.\n 3.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 4.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n 5.\n Set the application options for performing power grid augmentation, as described in Setting Options for Power Grid Augmentation.\n At a minimum, you must define the power and ground nets on which to perform PG augmentation.\n \u25e6 To specify the power net, set the signoff.create_pg_augmentation.power_net_name application option.\n \u25e6 To specify the ground net, set the signoff.create_pg_augmentation.ground_net_name application option.\n If your design contains more than one power net, you must perform PG augmentation once for each power net.\n       6.\n Save the block to disk.\n When you run the  signoff_create_pg_augmentation command, the IC\u00a0Validator tool uses the on-disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running the  signoff_create_pg_augmentation command.\n 7.\n Perform timing-driven power grid augmentation by using the signoff_create_pg_augmentation command with one or both of the following options: \u25e6 -nets This option explicitly specifies the critical nets.\n \u25e6 -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold.\n The unit for the slack threshold setting is the library time unit.\n You must also specify the technology node for which to perform the augmentation by using the  -node option.\n If you must perform incremental PG augmentation because your design contains more than one power net, use the  -mode\u00a0add command on subsequent runs to append the PG augmentation shapes to the existing shapes.\n 8.\n Run voltage drop analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis.\n This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n During timing-driven PG augmentation, the  signoff_create_pg_augmentation command 1.\n Performs timing analysis, including multicorner-multimode analysis, to minimize timing impact 2.\n Identifies timing-critical nets based on the options you specify 3.\n Removes existing PG augmentation shapes By default, the command removes the PG augmentation shapes from the entire block.\n To keep the existing PG augmentation shapes, use the  -mode\u00a0add option.\n 4.\n Inserts PG augmentation shapes for the specified regions, except in the areas around the critical nets       5.\n Saves the updated block to disk 6.\n Generates a summary report See Also \u2022 Standard Power Grid Augmentation \u2022 Guided Power Grid Augmentation \u2022 Removing PG Augmentation Shapes"}
{"header": "How do I Removing PG Augmentation Shapes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Guided power grid augmentation inserts PG augmentation shapes only near cells with IR violations.\n For each candidate cell, guided PG augmentation inserts PG augmentation shapes in the region from the cell to its tap with the minimum path resistance.\n Because the shapes are added only in specific regions, guided PG augmentation inserts fewer metal shapes and uses less routing area, which decreases the coupling capacitance impacts.\n To perform guided power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop and minimum path resistance analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis and  Performing Minimum Path Resistance Analysis.\n The IC\u00a0Validator tool uses the results of these analyses to drive the power grid augmentation.\n 3.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 4.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n 5.\n Save the block to disk.\n When you run the  fix_pg_wire command, the IC\u00a0Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running the  fix_pg_wire command.\n       6.\n Perform guided power grid augmentation by using the  fix_pg_wire command with one or both of the following options: \u25e6 -number_pins This option specifies the number of worst IR-drop violators for which to perform PG augmentation.\n \u25e6 -voltage_drop_threshold This option enables the tool to automatically determine the cells to process based on a voltage drop threshold.\n In addition, you must specify \u25e6 The power and ground nets on which to perform PG augmentation by using the -supply_nets option \u25e6 The technology node for which to perform the augmentation by using the  -node option For information about the  fix_pg_wire command, see the man page.\n 7.\n Run voltage drop analysis using RedHawk Fusion, as described in  Performing Voltage Drop Analysis.\n This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n See Also \u2022 Standard Power Grid Augmentation \u2022 Timing-Driven Power Grid Augmentation \u2022 Removing PG Augmentation Shapes"}
{"header": "How do I ECO-Aware Removal of PG Augmentation Shapes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove PG augmentation shapes, use the  -mode\u00a0remove option with the signoff_create_pg_augmentation command.\n When you use this command, the IC\u00a0Validator tool removes all PG augmentation shapes from the current block."}
{"header": "How do I Inserting Metal Fill With IC\u00a0Validator In-Design", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To automatically remove PG augmentation shapes that are causing DRC violations after ECO, use the  -mode\u00a0remove_by_drc_auto option with the signoff_create_pg_augmentation command.\n This action removes DRC violating       PG augmentation metal shapes or vias from design, including any floating connections created due to removal of DRC violating shape.\n For example, fc_shell>\u00a0 signoff_create_pg_augmentation -node <nodename> -mode remove_by_drc_auto"}
{"header": "How do I Setting Options for Signoff Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After routing, you can fill the empty spaces in the block with fill shapes to meet the metal density rules required by most fabrication processes.\n Before inserting metal and via fill, the block should be close to meeting timing and have only a very few or no DRC violations.\n To insert metal fill, 1.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 2.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n 3.\n Set the application options for metal fill insertion.\n For information about the metal fill insertion options, see  Setting Options for Signoff Metal Fill Insertion.\n 4.\n Save the block to disk.\n When you run the  signoff_create_metal_fill command, the IC\u00a0Validator tool uses the on-disk information for the block, not the information in memory.\n To ensure accurate information, use the  save_block command to save the current state of the block before running the  signoff_create_metal_fill command.\n 5.\n Perform metal fill insertion by using the  signoff_create_metal_fill command as described in  Performing Metal Fill Insertion.\n The  signoff_create_metal_fill command respects routing blockages defined by the  create_routing_blockage command and does not insert metal fill in the blockages; however, it does not respect routing guides created by the create_routing_guide command.\n Note: If you are performing pattern-based metal fill insertion and the blockage layer numbers differ between the technology file and the foundry runset file, you must provide a layer mapping file, as described in  Defining the Layer Mapping for IC\u00a0Validator In-Design Commands.\n When the IC\u00a0Validator tool performs metal fill insertion, it creates an internal subdesign named  block.FILL in the design view of the block and inserts the fill cells in this internal       subdesign.\n The fill cells are named FILL_INST_#.\n To query the fill cells, use the get_fill_cells command.\n For information about the result files generated by the  signoff_create_metal_fill command, see  Signoff Metal Fill Result Files.\n After you insert metal fill, you can \u2022 Display the added metal fill in the layout view in the GUI, as described in  Viewing Metal Fill in the GUI \u2022 Modify the metal fill, as described in  Modifying Metal Fill \u2022 Perform extraction for timing analysis using the real metal fill, as described in Performing Real Metal Fill Extraction"}
{"header": "How do I Performing Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  signoff_create_metal_fill command, configure the run by setting the application options shown in  Table\u00a049.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n Table 49 Application Options for Signoff Metal Fill Insertion Application option Default Description Options that apply to all flows signoff.create_metal_fill.\n apply_nondefault_rules false   signoff.create_metal_fill.\n auto_eco_threshold_value    -auto_eco\u00a0true  signoff.create_metal_fill.\n flat false  false true signoff.create_metal_fill.\n read_design_views       signoff.create_metal_fill.\n read_layout_views             Table 49 Application Options for Signoff Metal Fill Insertion (Continued) Application option Default Description signoff.create_metal_fill.\n run_dir    signoff_create_metal_fill     signoff.create_metal_fill.\n user_defined_options         signoff.physical.\n merge_exclude_libraries     signoff.physical.\n merge_stream_files  signoff.physical.\n merge_stream_files        Options that apply only to pattern-based metal fill insertion signoff.create_metal_fill.\n runset      signoff.physical.\n layer_map_file           Options that apply only to track-based metal fill insertion       Table 49 Application Options for Signoff Metal Fill Insertion (Continued) Application option Default Description signoff.create_metal_fill.\n max_density_threshold     { layer_name max_density }   -mode\u00a0add  Options that apply only to timing-driven metal fill insertion (pattern-based or track-based) signoff.create_metal_fill.\n fill_over_net_on_adjacent_la yer false      signoff.create_metal_fill.\n fill_shielded_clock false    signoff.create_metal_fill.\n fix_density_errors false    signoff.create_metal_fill.\n space_to_clock_nets       -nets   signoff.create_metal_fill.\n space_to_nets        signoff.create_metal_fill.\n space_to_nets_on_adjacent_la yer"}
{"header": "How do I Pattern-Based Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use the  signoff_create_metal_fill command to perform the following tasks: \u2022 Pattern-Based Metal Fill Insertion \u2022 Track-Based Metal Fill Insertion \u2022 Using an IC\u00a0Validator Parameter File \u2022 Typical Critical Dimension Metal Fill Insertion \u2022 Timing-Driven Metal Fill Insertion \u2022 Incremental Metal Fill Insertion \u2022 Foundry Fill and Track Fill Combined for Different Flows of Foundry"}
{"header": "How do I Track-Based Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Pattern-based metal fill insertion is the default mode for the  signoff_create_metal_fill command.\n It inserts metal and via fill by using a foundry runset.\n Before running the signoff_create_metal_fill command, you must specify the runset by setting the signoff.create_metal_fill.runset application option.\n During pattern-based metal fill insertion, the  signoff_create_metal_fill command performs the following tasks: 1.\n Loads the block into the IC\u00a0Validator tool, as described in  Reading Blocks for Signoff Metal Fill Insertion 2.\n Removes existing metal and via fill By default, the command removes the metal and via fill from the entire block.\n For information about performing incremental metal fill insertion, see  Incremental Metal Fill Insertion.\n 3.\n Inserts metal and via fill in the empty regions By default, the command uses the spacing rules defined in the technology file to perform metal fill insertion on all metal and via layers for the entire block.\n The       command uses the metal fill mode specified in the runset file, which is either hierarchical or flat.\n To modify the default behavior, \u25e6 Set one or more of the following application options before running the signoff_create_metal_fill command: \u25aa signoff.create_metal_fill.apply_nondefault_rules To enable the use of nondefault spacing rules in addition to the spacing rules defined in the technology file, set this application option to  true.\n \u25aa signoff.create_metal_fill.flat To force the use of the flat metal fill mode, set this application option to  true.\n \u25e6 Use one or more of the following command options with the signoff_create_metal_fill command: \u25aa -select_layers or  -all_runset_layers To restrict the layers on which to insert metal fill, use these options, as described in  Specifying the Layers for Metal Fill Insertion.\n \u25aa -coordinates and  -excluded_coordinates To restrict the regions on which to insert metal fill, use these options, as described in  Specifying the Regions for Metal Fill Insertion.\n 4.\n Removes floating via fill from the specified via layers and from the via layers associated with the specified metal layers Floating via fill is via fill that does not have both an upper and lower metal enclosure.\n 5.\n Saves the fill data in the design view 6.\n Writes the result files to the run directory For information about the generated result files, see  Signoff Metal Fill Result Files.\n See Also \u2022 Timing-Driven Metal Fill Insertion       Reading Blocks for Signoff Metal Fill Insertion By default, the IC\u00a0Validator tool reads the design view for the top-level block and the library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances.\n \u2022 To read the GDSII or OASIS data for specific reference cells, specify the stream files by setting the  signoff.physical.merge_stream_files application option.\n When you use this option, the GDSII or OASIS data replaces the cell library view for the cells defined in the specified stream files, except for cells in the cell libraries specified with the  signoff.physical.merge_exclude_libraries application option.\n \u2022 To read the layout view for specific reference cells, specify the cells by setting the signoff.create_metal_fill.read_layout_views application option.\n The layout view is identical to the GDSII or OASIS data that was used to create them, but reduces the runtime for signoff design rule checking.\n Note: By default, layout views are not included in the cell libraries To save the layout views, you must set the  lib.workspace.save_layout_views application option to  true during library preparation, as described in the Library Manager User Guide.\n \u2022 To read the design view for specific reference cells, specify the cells by setting the signoff.create_metal_fill.read_design_views application option.\n Note: By default, design views are not included in the cell libraries To save the design views, you must set the  lib.workspace.save_design_views application option to  true during library preparation, as described in the Library Manager User Guide.\n The order of precedence for child cell data is 1.\n GDSII or OASIS data specified with the  signoff.physical.merge_stream_files application option 2.\n Layout views specified with the  signoff.create_metal_fill.read_layout_views application option If the IC\u00a0Validator tool cannot find a layout view and the cell is specified in the signoff.check_drc.read_design_views application option, it reads the design view.\n Otherwise, it reads the frame view.\n If it cannot find the frame view, the cell is ignored during design rule checking.\n       3.\n Design views specified with the  signoff.create_metal_fill.read_design_views application option If the IC\u00a0Validator tool cannot find a design view, it reads the frame view instead.\n If it cannot find the frame view, the cell is ignored during design rule checking.\n 4.\n Frame views Specifying the Layers for Metal Fill Insertion By default, the  signoff_create_metal_fill command inserts metal fill on all the metal routing layers and via fill on all the via layers.\n To modify the layers for metal fill insertion, use one of the following options: \u2022 -select_layers\u00a0 metal_fill_layers This option restricts metal fill insertion to the specified set of metal and via layers.\n \u2022 -all_runset_layers\u00a0true This option enables metal fill insertion on all the fill layers specified in the runset.\n This option applies only to pattern-based metal fill insertion.\n When you specify the layers for metal fill insertion, the  signoff_create_metal_fill command 1.\n Removes the existing metal and via fill from the block By default, the command removes all existing metal and via fill.\n For incremental metal fill insertion, the command removes metal and via fill only from the specified layers.\n 2.\n Inserts metal and via fill only on the specified layers 3.\n Removes floating via fill from the specified via layers and from the via layers associated with the specified metal layers For example, if you specify  -select_layers\u00a0{M2}, the tool removes floating via fill from the V1 and V2 layers.\n       Specifying the Regions for Metal Fill Insertion By default, the  signoff_create_metal_fill command inserts metal and via fill for the whole chip.\n To modify the regions for metal fill insertion, use one or both of the following options: \u2022 -coordinates This option restricts metal fill insertion to the specified regions.\n Note: The bounding box coordinates passed to the IC\u00a0Validator tool in the METAL_FILL_SELECT_WINDOW parameter are enlarged by 1 um to avoid DRC violations on the boundary of the specified regions during metal fill insertion.\n The actual metal fill insertion occurs within the regions specified by the  -coordinates option.\n In addition, when you use the  -coordinates option, the signoff_create_metal_fill command always uses the flat metal fill mode.\n \u2022 -excluded_coordinates This option prevents metal fill insertion in the specified regions.\n If you specify this option with the  -coordinates option, the command does not perform metal fill insertion in the overlapping regions.\n To specify the coordinates, use the following format: {{x 1 y 1 }\u00a0{x 2 y 2 }\u00a0...\n {x n y n }} Note that there must be a space between each set of coordinates.\n When you specify the regions for metal fill insertion, the  signoff_create_metal_fill command 1.\n Removes all existing metal and via fill from the block For standard metal fill insertion, the command removes all existing metal and via fill.\n For incremental metal fill insertion, the command removes metal and via fill only from the specified regions.\n 2.\n Inserts metal and via fill only on the specified regions 3.\n Removes floating via fill from the specified regions For example, to remove all metal fill from the block and then fill all empty regions outside the bounding box with corners at (100,150) and (300,200), use the following command: fc_shell>\u00a0 signoff_create_metal_fill \\ -excluded_coordinates {{100 150} {300 200}}"}
{"header": "How do I Using an IC\u00a0Validator Parameter File", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Track-based metal fill insertion inserts metal and via fill by using a runset derived from the attributes and rules in the technology file to create fill shapes aligned to tracks.\n It does not use the runset specified by the  signoff.create_metal_fill.runset application option.\n Track-based metal fill insertion offers the following benefits as compared to pattern-based metal fill insertion: \u2022 Higher density \u2022 Better control of density \u2022 Well-balanced mask distribution for double-patterning layers To perform track-based metal fill insertion, set the  -track_fill option of the signoff_create_metal_fill command to a value other than  off.\n Track-based metal fill insertion supports three modes: \u2022 Sparse This is the default mode.\n In this mode, track-based metal fill insertion skips one track between signal shapes and fill shapes.\n \u2022 Dense To enable this mode, use the  -fill_all_tracks\u00a0true option.\n In this mode, track- based metal fill insertion does not skip tracks between signal shapes and fill shapes.\n Note: If your block uses double-patterning technology, using this option increases runtime if the block is not precolored.\n \u2022 Mixed To use sparse mode for some layers and dense mode for other layers, you must set the appropriate parameters in a parameter file, as described in  Using an IC\u00a0Validator Parameter File.\n During track-based metal fill insertion, the  signoff_create_metal_fill command performs the following tasks: 1.\n Loads the block into the IC\u00a0Validator tool, as described in  Reading Blocks for Signoff Metal Fill Insertion 2.\n Removes existing metal and via fill By default, the command removes the metal and via fill from the entire block.\n For information about performing incremental metal fill insertion, see  Incremental Metal Fill Insertion.\n       3.\n Inserts metal and via fill in the empty regions By default, the command uses the design rules defined in the technology file to insert fill shapes on-track on all metal and via layers for the entire block.\n The fill shapes have a length of 5 microns and a width equal to the  defaultWidth attribute defined for the layer in the technology file.\n You can modify the default behavior by using \u25e6 Application options set before running the  signoff_create_metal_fill command: \u25aa signoff.create_metal_fill.apply_nondefault_rules To enable the use of nondefault spacing rules in addition to the spacing rules defined in the technology file, set this application option to  true.\n \u25e6 Command options used with the  signoff_create_metal_fill command: \u25aa -track_fill\u00a0 foundry_node To enable foundry-specific design rules, use the appropriate foundry keyword with the  -track_fill option.\n To see the list of supported keywords, use the following command: fc_shell>\u00a0 signoff_create_metal_fill -track_fill list \u25aa -select_layers To restrict the layers on which to insert metal fill, use this option, as described in Specifying the Layers for Metal Fill Insertion.\n \u25aa -coordinates and  -excluded_coordinates To restrict the regions on which to insert metal fill, use these options, as described in  Specifying the Regions for Metal Fill Insertion.\n \u25e6 Parameters set in the IC\u00a0Validator parameter file: \u25aa m x _fill_width,  m x _min_fill_length, and  m x _max_fill_length To change the size of the fill shapes, set these parameters, as described in Using an IC\u00a0Validator Parameter File.\n 4.\n Removes floating via fill from the specified via layers and from the via layers associated with the specified metal layers Floating via fill is via fill that does not have both an upper and lower metal enclosure.\n       5.\n (Optional) Trims the metal fill for each layer to try to meet the maximum density threshold defined by the  signoff.create_metal_fill.max_density_threshold application option The metal fill is trimmed only for those layers specified in the application option.\n If you do not set this option, the metal fill is not trimmed.\n 6.\n Saves the fill data in the design view By default, \u25e6 The IC\u00a0Validator tool assigns a data type of 0 to the fill shapes To use different data type values, set the  m x _fill_datatype and via x _fill_datatype parameters in the IC\u00a0Validator parameter file.\n \u25e6 The IC\u00a0Validator tool does not set mask constraints on the fill shapes If your block uses double-patterning technology, use the  -output_colored_fill true option to set mask constraints on the fill shapes.\n If your block uses double-patterning technology, use the  -output_colored_fill option to set mask constraints on the fill shapes.\n When you use this option, the IC\u00a0Validator tool assigns a data type of 235 for fill shapes with a  mask_one mask constraint and 236 for fill shapes with a  mask_two mask constraint.\n To assign different data types for the colored fill, set the following parameters in the IC\u00a0Validator parameter file:  m x _fill_datatype_color1, via x _fill_datatype_color1,  m x _fill_datatype_color2, and via x _fill_datatype_color2.\n \u25e6 The IC\u00a0Validator tool does not write exclude layers If your foundry uses exclude layers, define the data types for the exclude layers by setting the  m x _exclude_layer_datatype parameters in the IC\u00a0Validator parameter file.\n The IC\u00a0Validator tool outputs the exclude layers that have defined data types.\n For information about using an IC\u00a0Validator parameter file, see  Using an IC\u00a0Validator Parameter File.\n 7.\n Writes the result files to the run directory In addition to the standard output files generated by signoff metal fill insertion, when you perform track-based metal fill insertion, you can output detailed density and density gradient reports by using the  -report_density option.\n When you enable this option, the  signoff_create_metal_fill command writes the following report files: \u25e6 prefix _color_balance_and_density_report.txt \u25e6 prefix _fill_density_gradient_report.txt       You can specify either  on (in which case the tool uses \u201ctrack_fill\u201d as the prefix) or the prefix string.\n For example, to perform track-based metal fill insertion and use a prefix of my_prefix for the detailed density and density gradient reports, use the following command: fc_shell>\u00a0 signoff_create_metal_fill -track_fill true \\ -report_density my_prefix For information about the generated result files, see  Signoff Metal Fill Result Files.\n See Also \u2022 Timing-Driven Metal Fill Insertion"}
{"header": "How do I Typical Critical Dimension Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can customize the metal fill insertion by using an IC\u00a0Validator parameter file.\n \u2022 For pattern-based metal fill insertion, you pass the parameter file to the IC\u00a0Validator tool by setting the  signoff.create_metal_fill.user_defined_options application option.\n fc_shell>\u00a0 set_app_options \\ -name signoff.create_metal_fill.user_defined_options \\ -value {-D INDESIGN_USER_DEFINED_PARAM_FILE= file_name } \u2022 For track-based metal fill insertion, you pass the parameter file to the IC Validator tool by using the -track_fill_parameter_file option with the signoff_create_metal_fill command.\n fc_shell>\u00a0 signoff_create_metal_fill -track_fill true \\ -track_fill_parameter_file  file_name When you run track-based metal fill insertion, the IC\u00a0Validator tool writes a parameter file named  track_fill_params.rh into the run directory.\n This file contains the default settings for the supported parameters.\n You can modify this file as necessary and use it on subsequent  signoff_create_metal_fill runs.\n Note: In some cases, the IC Validator behavior can be controlled by either an IC Validator parameter or an application option.\n In these cases, if both are specified, the IC Validator parameter setting overrides the application option setting.\n Table\u00a050 shows the commonly used parameters supported in the parameter file.\n Unless otherwise specified, these parameters apply only to track-based metal fill insertion.\n The mx or  vx prefix in the parameters refers to the mask name, which can be found in the layer section of the technology file.\n       For example, if layer  M11 has the mask name  metal12 in the technology file, the prefix m12 would replace  mx in the parameters below.\n Therefore, the M11 layer would have the parameters  m12_spare_fill,  m12_fill_staggering, and so on.\n Table 50 IC\u00a0Validator Metal Fill Insertion Parameters Parameter Default Description Metal fill insertion mode parameters m x _sparse_fill     Note: -fill_all_tracks\u00a0true   m x _fill_staggering   m x _ignore_route_guide     m x _ignore_system_blockage    m x _via_enclosure  ContactCode    Fill size and spacing parameters m x _fill_width defaultWidth 9  m x _min_fill_length  minArea 9  m x _max_fill_length      m x _fill2fill_side_ spacing  m x _fill2route_side_ spacing   9.\n Attribute setting from the Layer section of the technology file       Table 50 IC\u00a0Validator Metal Fill Insertion Parameters (Continued) Parameter Default Description m x _fill2fill_end_\u00a0spacing   m x _fill2route_end_ spacing   m x _fill2Blockage_x m x _fill2Blockage_y   m x _fill2routeGuide_x m x _fill2routeeGuide_y   m x _fill2chipBoundary_x m x _fill2chipBoundary_y   m x _min_area_with_via   m x _EXCLUDED_CELLS_ OVERSIZE_VALUE   m x _EXCLUDED_CELLS   m x _EXCLUDED_CELLS   m x _EXCLUDED_CELLS_OVERSIZE_VALUE  v x _iso_via_distance    v x _min_spacing minSpacing 9      v x _per_metal         Exclude layer parameters       Table 50 IC\u00a0Validator Metal Fill Insertion Parameters (Continued) Parameter Default Description m x _exclude_layer_ datatype     Fill output mode parameters m x _compress_fill v x _compress_fill    Note: -mode\u00a0add    m x _fill_datatype v x _fill_datatype   output_colored_fill     Note: -output_colored_fill\u00a0true  m x _fill_datatype_\u00a0color1 v x _fill_datatype_\u00a0color1 m x _fill_datatype_\u00a0color2 v x _fill_datatype_\u00a0color2    Note:   Density calculation parameters exclude_bounding_box_ blockage_for_density_ computation   -excluded_coordinates   exclude_route_guides_ for_density_computation    exclude_system_metal_ blockages_for_density_ computation          Table 50 IC\u00a0Validator Metal Fill Insertion Parameters (Continued) Parameter Default Description m x _density_gradient_ window\u00a0 10 windowSize 9    signoff.report_metal_density.gradient_windo w_size  Note: windowSize   signoff.report_metal_density.gradient_wi ndow_size   m x _max_density_window    m x _max_open_area_rule 10    m x _min_density 10 minDensity 9    signoff.report_metal_density.min_density  Note: minDensity   signoff.report_metal_density.min_density   m x _min_density_window 10 windowSize 9    signoff.report_metal_density.density_window  Note: windowSize   signoff.report_metal_density.density_win dow   10.\n This parameter applies to timing-driven metal fill insertion, whether pattern-based or track-based.\n       Table 50 IC\u00a0Validator Metal Fill Insertion Parameters (Continued) Parameter Default Description m x _window_step_size        signoff.report_metal_density.density_window _step"}
{"header": "How do I Timing-Driven Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Typical critical dimension (TCD) structures can improve yield for designs.\n These structures are made up of marker and fill layers, both of which are added to the block during TCD metal fill insertion.\n To enable TCD metal fill insertion, set the  signoff.create_metal_fill.tcd_fill application option to  true before running the  signoff_create_metal_fill command.\n By default, the command inserts TCD structures on all metal and via layers for the entire block.\n To modify the default behavior, use the following options: \u2022 -select_layers To restrict the layers on which to insert metal fill, use this option, as described in Specifying the Layers for Metal Fill Insertion.\n \u2022 -coordinates and  -excluded_coordinates To restrict the regions on which to insert metal fill, use these options, as described in Specifying the Regions for Metal Fill Insertion.\n Note: You cannot use timing-driven metal fill insertion with TCD metal fill insertion.\n See Also \u2022 Removing Metal Fill"}
{"header": "How do I Incremental Metal Fill Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Timing-driven metal fill insertion inserts metal and via fill in the specified regions of the block, except around timing-critical nets.\n Timing-driven metal fill insertion is supported       for both pattern-based and track-based metal fill insertion.\n By default, the tool does not perform timing-driven metal fill insertion.\n To perform timing-driven metal fill insertion, use one or both of the following options with the  signoff_create_metal_fill command: \u2022 -nets This option explicitly specifies the critical nets.\n \u2022 -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold.\n The unit for the slack threshold setting is the library time unit.\n Be careful when choosing the threshold value; using a large threshold value can result in too many critical nets, which could reduce the metal density and create large empty areas.\n During timing-driven metal fill insertion, the  signoff_create_metal_fill command 1.\n Performs timing analysis, including multicorner-multimode analysis, to minimize timing impact 2.\n Identifies timing-critical nets based on the options you specify 3.\n Removes existing metal and via fill By default, the command removes the metal and via fill from the entire block.\n For information about performing incremental metal fill insertion, see  Incremental Metal Fill Insertion.\n 4.\n Inserts metal and via fill in the empty regions for the specified regions, except in the areas around the critical nets To enable fill insertion for shielded timing-critical clock nets, set the signoff.create_metal_fill.fill_shielded_clock application option to  true.\n 5.\n Invokes the IC\u00a0Validator tool to perform metal fill insertion By default, the minimum spacing between the metal fill and the net shapes of the critical nets is two times the minimum spacing specified in the technology file.\n This spacing requirement also applies to the vertical extension of the critical net on the adjacent layers.\n To modify these requirements, set the appropriate application options, as described in  Specifying the Spacing Requirements for Timing-Driven Metal Fill Insertion.\n Note: You can restrict the regions in which to perform timing-driven metal fill insertion, as described in  Specifying the Regions for Metal Fill Insertion       and  Performing Metal Fill Insertion Only in Modified Regions ; however, you cannot specify the layers.\n When performing timing-driven metal fill insertion, the  signoff_create_metal_fill command inserts metal fill on all routing layers (or all changed layers, if you perform metal fill insertion only in the changed regions).\n 6.\n (Optional) Fixes density errors In some cases, the spacing requirements for timing-driven metal fill insertion might cause density errors.\n To fix these errors automatically during timing-driven metal fill insertion, set the  signoff.create_metal_fill.fix_density_errors application option to  true (the default is  false ).\n For information about the density design rules, see  Defining the Density Design Rules.\n 7.\n Stores the metal fill data as fill cell objects in the design view 8.\n Writes the result files to the run directory For information about the generated result files, see  Signoff Metal Fill Result Files.\n See Also \u2022 Pattern-Based Metal Fill Insertion \u2022 Track-Based Metal Fill Insertion Specifying the Spacing Requirements for Timing-Driven Metal Fill Insertion By default, the minimum spacing between the metal fill and the net shapes of the critical nets is based on the minimum spacing specified in the technology file.\n \u2022 For metal fill on the same layer as the net shape, the default minimum spacing is two times the minimum spacing value specified for the layer in the technology file.\n \u2022 For metal fill on layers adjacent to the net shape, the default minimum spacing is the minimum spacing value specified for the layer in the technology file.\n For example, assume that the red rectangle in  Figure\u00a0149 is a critical net shape.\n The yellow regions indicate where fill cannot be inserted and the gray regions indicate the inserted fill.\n Figure 149 Minimum Spacing From Metal Fill to Critical Net Shape       To override the default spacing requirements for timing-driven metal fill insertion, set the following application options: \u2022 signoff.create_metal_fill.space_to_nets This application option defines the same-layer minimum spacing requirements between metal fill and a net shape of a timing-critical net.\n \u2022 signoff.create_metal_fill.space_to_clock_nets This application option defines the same-layer minimum spacing requirements between metal fill and a net shape of a user-defined clock net that is specified in the  -nets option.\n \u2022 signoff.create_metal_fill.space_to_nets_on_adjacent_layer This application option defines the adjacent-layer minimum spacing requirements between metal fill and a net shape of a timing-critical net.\n \u2022 signoff.create_metal_fill.space_to_clock_nets_on_adjacent_layer This application option defines the adjacent-layer minimum spacing requirements between metal fill and a net shape of a user-defined clock net that is specified in the -nets option.\n For each of these application options, use the following syntax to specify the spacing to use for each layer: {\u00a0{ layer 1 value 1 }\u00a0...\n { layer n value n }\u00a0} You can specify the spacing value either as a multiple of the minimum spacing ( n x) or a distance in microns.\n For example, to set the minimum spacing between metal fill and a timing-critical net on the same layer to four times the minimum spacing for the M2 and M3 layers, use the following command: fc_shell>\u00a0 set_app_options \\ -name signoff.create_metal_fill.space_to_nets \\ -value {{M2 4x} {M3 4x}} To set the minimum spacing between metal fill and a timing-critical net on the same layer to 0.125 microns for the M2 layer and 0.133 microns for the M3 layer, use the following command: fc_shell>\u00a0 set_app_options \\ -name signoff.create_metal_fill.space_to_nets \\ -value {{M2 0.125} {M3 0.133}}       Defining the Density Design Rules The IC\u00a0Validator tool can check and fix the following density design rules: \u2022 Minimum density, which specifies the minimum percentage of metal allowed in the density checking window This rule is checked when you enable density error fixing by setting the signoff.create_metal_fill.fix_density_errors application option to  true.\n By default, the IC\u00a0Validator tool uses the setting defined for the  minDensity attribute in the  DensityRule sections of the technology file.\n If this attribute is not defined for a layer, the IC\u00a0Validator tool uses a default of 10 percent.\n To override the default, define the  m x _min_density parameter in the IC\u00a0Validator parameter file.\n \u2022 Density gradient, which specifies the maximum percentage difference between the fill density of adjacent density checking windows This rule is checked if it is defined in the technology file and you enable density error fixing by setting the  signoff.create_metal_fill.fix_density_errors application option to  true.\n The IC\u00a0Validator tool uses the setting defined for the  maxGradientDensity attribute in the  DensityRule sections of the technology file.\n If this attribute is not defined for a layer, the IC\u00a0Validator tool does not check this rule.\n \u2022 Maximum open area, which specifies the maximum size of a square area that contains no polygons and does not interact with any polygons This rule is checked if it is defined.\n The maximum open area rule is defined in an IC\u00a0Validator parameter file.\n Use the following syntax to define the maximum open area rule for each metal layer: m n _max_open_area_rule\u00a0=\u00a0 value ; where  n is the metal layer number and  value is the side length of the square in microns.\n For more information about the IC\u00a0Validator parameter file, see  Using an IC\u00a0Validator Parameter File.\n For more information about the technology file, see the  Synopsys Technology File and Routing Rules Reference Manual."}
{"header": "How do I Foundry Fill and Track Fill Combined for Different Flows of", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If you have already used the  signoff_create_metal_fill command to performed metal fill insertion on a block, you can use incremental metal fill insertion to perform the following tasks: \u2022 Insert additional metal and via fill to specific layers or regions, as described in  Adding to Existing Metal and Via Fill.\n \u2022 Replacing existing metal and via fill in specific locations, as described in  Replacing Existing Metal and Via Fill.\n \u2022 Replacing existing metal and via fill in modified regions, as described in  Performing Metal Fill Insertion Only in Modified Regions.\n Adding to Existing Metal and Via Fill To insert metal and via fill without first removing the existing metal fill, use the  -mode\u00a0add option with the  signoff_create_metal_fill command.\n When you use this mode, you can control where the metal fill insertion occurs by using one or more of the following options: \u2022 -select_layers, which restricts the layers on which to perform metal fill insertion, as described in  Specifying the Layers for Metal Fill Insertion \u2022 -coordinates or  -excluded_coordinates, which restrict the regions on which to perform metal fill insertion, as described in  Specifying the Regions for Metal Fill Insertion.\n When you use these options with the  -mode\u00a0add option, the tool does not fix density errors regardless of the setting of the signoff.create_metal_fill.fix_density_errors application option.\n See Also \u2022 Pattern-Based Metal Fill Insertion \u2022 Track-Based Metal Fill Insertion Replacing Existing Metal and Via Fill To remove and insert metal and via fill only for the specified locations, use the  -mode replace option with the  signoff_create_metal_fill command.\n You would typically       use this mode after ECO changes.\n When you use this mode, you must also specify one or more of the following options: \u2022 -select_layers, which restricts the layers on which to perform metal fill insertion For example, to remove all metal fill on the M1 and M3 layers and refill those two layers without affecting the metal fill on other layers, use the following command: fc_shell>\u00a0 signoff_create_metal_fill -mode replace \\ -select_layers {M1 M3} For more information about this option, see  Specifying the Layers for Metal Fill Insertion.\n \u2022 -coordinates or  -excluded_coordinates, which restrict the regions on which to perform metal fill insertion For more information about these options, see  Specifying the Regions for Metal Fill Insertion.\n \u2022 -nets or  -timing_preserve_setup_slack_threshold, which restricts the nets on which to perform metal fill insertion For more information about these options, see  Timing-Driven Metal Fill Insertion.\n See Also \u2022 Pattern-Based Metal Fill Insertion \u2022 Track-Based Metal Fill Insertion \u2022 Timing-Driven Metal Fill Insertion Performing Metal Fill Insertion Only in Modified Regions If you have previously run the  signoff_create_metal_fill command on a block, you can use the  -auto_eco\u00a0true option to restrict the metal fill insertion to those regions of the block that have been modified since the last run.\n Note: You can use this option only if the percentage of change to the block since the previous  signoff_create_metal_fill run is less than the change threshold.\n The default change threshold is 20 percent; to modify the change threshold, set the  signoff.create_metal_fill.auto_eco_threshold_value application option.\n When you use the  -auto_eco\u00a0true option, the tool automatically determines the modified regions and layers, and then removes the existing metal fill and redoes metal fill insertion only in those locations; all other existing metal fill is retained.\n       By default, the tool compares the current block to the version used for the previous signoff_create_metal_fill run.\n To compare the current block to a different block, use the  -pre_eco_design option to specify the comparison block.\n Note: A change on a metal layer triggers metal fill removal and insertion on the adjacent via layers to ensure that no floating or hanging vias remain when the metal shapes are removed from the ECO area.\n If a cell instance changes, the tool takes a conservative approach and considers changes on all layers.\n For example, to remove the metal fill from the regions modified since the last time you ran the  signoff_create_metal_fill command and then fill only those regions using the pattern-based mode, use the following command: fc_shell>\u00a0 signoff_create_metal_fill -auto_eco true You can use the  -select_layers option to specify the layers on which to perform metal fill insertion; however, the tool performs metal fill insertion on a specified layer only if it is one of the automatically detected changed layers.\n You cannot use the  -coordinates or -excluded_coordinates options to restrict the metal fill insertion regions.\n When you use the  -auto_eco\u00a0true option, \u2022 You cannot use the  -mode,  -all_runset_layers, and  -report_density options \u2022 The tool does not insert dense fill on the double-patterning layers regardless of the setting of the  -fill_all_tracks option \u2022 The tool does not fix density errors regardless of the setting of the signoff.create_metal_fill.fix_density_errors application option See Also \u2022 Pattern-Based Metal Fill Insertion \u2022 Track-Based Metal Fill Insertion \u2022 Timing-Driven Metal Fill Insertion"}
{"header": "How do I Signoff Metal Fill Result Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To support designs that require combined foundry fill and track fill in the Fusion Compiler tool, you can use the  -mode\u00a0add option with the  signoff_create_metal_fill command.\n fc_shell>\u00a0 signoff_create_metal_fill -mode add For a few advanced nodes, you can add foundry fill on top of track fill, which is the default methodology to create fill on some special layers.\n       You can use the  all_runset_layers option with the  signoff_create_metal_fill command.\n Set the  all_runset_layers option to  true to insert fill for all output fill layers defined in the runset settings.\n By default, this option is set to  false and inserts fill only for the routing layers (metal and via layers)."}
{"header": "How do I Querying Metal Fill", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  signoff_create_metal_fill command stores the output files in the run directory specified by the  signoff.create_metal_fill.run_dir application option (or the signoff_fill_run directory if you do not use this option).\n For each fill run, the command creates a subdirectory named icv_run_# that contains the files generated for that run.\n When you perform metal fill insertion, the tool writes the following files to the output directory: \u2022 block.LAYOUT_ERRORS, which contains details about the detected errors \u2022 block.RESULTS, which contains a summary of the run results \u2022 signoff_create_metal_fill.log, which contains a summary of the run environment \u2022 icv_config_out, which contains the paths to the top-level block and the cell libraries \u2022 layer.map, which contains the generated layer mapping file \u2022 metal_fill_params.rh, which contains the metal fill parameters and options that you specified \u2022 metal_fill_compress_params.rh, which contains the storage commands and indicates whether the compression mode was flat (NONE) or hierarchical (AUTO) \u2022./run_details directory, which contains all the data generated by the IC\u00a0Validator tool for the metal fill insertion run"}
{"header": "How do I Viewing Metal Fill in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Metal fill shapes are stored in fill cells, which use the following naming convention: FILL_INST_#.\n \u2022 To query the fill cells in the block, use the  get_fill_cells command.\n By default, this command reports only the fill cells in the top-level design.\n To report all of the fill cells in the hierarchy, use the  -hierarchical option.\n \u2022 To query the fill shapes, use the  get_shapes\u00a0-include_fill command.\n To return only the fill shapes associated with specific fill cells, use the  -of_objects option to specify the fill cells."}
{"header": "How do I Reporting the Metal Density", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To view the metal fill shapes in the layout view of the GUI, 1.\n Display the View Settings panel by clicking the View Settings icon ( ) in the panel area.\n \u25e6 Set the Level to 1.\n \u25e6 Select the Objects tab and enable visibility for Fill Cell objects and Area Fill metal shapes (if you do not see Area Fill in the object list, expand the Route object and Shape Use attribute).\n 2.\n Display the Hierarchy Settings panel by clicking the Hierarchy Settings icon ( ) in the View Settings panel or the menu bar.\n \u25e6 Set the \u201cView level\u201d to 1.\n \u25e6 Select \u201cFill Cell\u201d in the \u201cExpanding cell types\u201d section.\n Figure\u00a0150 shows the View Settings and Hierarchy Settings panels with the required settings for displaying fill shapes.\n       Figure 150 Settings Used to Display Fill Shapes in the GUI"}
{"header": "How do I Viewing Density Heat Maps in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the metal density information, run the  signoff_report_metal_density command.\n       To calculate the metal density information for a metal layer, the tool requires the following information: \u2022 The density rule for the layer The tool determines the density rule for each layer by using the following settings, in order of priority: 1.\n The setting of the  m x _min_density parameter in the IC Validator parameter file specified by the  signoff.report_metal_density.user_defined_options application option 2.\n The setting of the  signoff.report_metal_density.min_density application option 3.\n The setting of the  minDensity attribute in the  DensityRule section of the technology file 4.\n 10 percent \u2022 The grid sizes for the layer The tool determines the grid sizes for each layer by using the following settings, in order of priority: 1.\n The setting of the  m x _min_density_window or  m x _density_gradient_window parameter in the IC Validator parameter file specified by the signoff.report_metal_density.user_defined_options application option 2.\n The setting of the  signoff.report_metal_density.density_window or signoff.report_metal_density.gradient_window_size application option 3.\n The setting of the  windowSize attribute in the  DensityRule section of the technology file 4.\n 50 microns For information about defining the metal density and density gradient rules in the technology file, including the  windowSize attribute, see the  Synopsys Technology File and Routing Rules Reference Manual.\n By default, the  signoff_report_metal_density command \u2022 Uses the fill data for the metal density calculation \u25e6 To use the design view if its timestamp is newer than the fill data, set the signoff.report_metal_density.fill_view_data application option to read_if_uptodate.\n \u25e6 To use the design view regardless of its timestamp, set the signoff.report_metal_density.fill_view_data application option to  discard.\n       \u2022 Creates the density and gradient windows starting from the lower-left corner of the chip boundary using a step size of half the window size \u25e6 To change the starting point for creating the windows, use the  -starting_point option with the  signoff_report_metal_density command.\n \u25e6 To change the step size, set the signoff.report_metal_density.density_window_step application option or the m x _window_step_size parameter in the IC Validator parameter file specified by the signoff.report_metal_density.user_defined_options application option.\n If you specify both, the IC Validator parameter overrides the application option.\n \u2022 Computes the metal density for the entire block To compute the metal density for specific regions, use the  -coordinates option with the  signoff_report_metal_density command.\n When you use this option, the command combines the specified regions when reporting the metal density; it does not report the metal density individually for each specified region.\n To specify the coordinates, use the following format: {{x 1 y 1 }\u00a0{x 2 y 2 }\u00a0...\n {x n y n }} Note that there must be a space between each set of coordinates.\n \u2022 Computes the metal density for each metal layer from the minimum routing layer to the maximum routing layer To compute the metal density for specific layers, use the  -select_layers option with the  signoff_report_metal_density command.\n \u2022 Does not generate heat maps To generate heat maps to enable viewing of the metal density information in the GUI, set the  signoff.report_metal_density.create_heat_maps application option to true.\n For information about viewing the heat maps, see  Viewing Density Heat Maps in the GUI.\n \u2022 Writes the report files to a directory named signoff_report_metal_density_run under the current working directory To change the name of the IC\u00a0Validator working directory, set the signoff.report_metal_density.run_dir application option.\n By default, the report files are named report_metal_density.txt and gradient_density_report.txt.\n To change the file names, use the  -output option with the signoff_report_metal_density command.\n When you use this option, the density report has the specified file name, while the gradient density report adds a.gradient file extension.\n For example, if you specify - output\u00a0density.rpt, the density report is named density.rpt and the gradient density report is named density.rpt.gradient.\n       The  signoff_report_metal_density command uses the options that you specify to generate the command line to invoke the IC\u00a0Validator tool.\n You can specify additional options for the IC\u00a0Validator command line by setting the signoff.report_metal_density.user_defined_options application option.\n The string that you specify in this option is added to the command line used to invoke metal density reporting in the IC\u00a0Validator tool.\n The Fusion Compiler tool does not perform any checking on the specified string.\n See Also \u2022 Using an IC\u00a0Validator Parameter File"}
{"header": "How do I Removing Metal Fill", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After running the  signoff_report_metal_density command, you can view heat maps in the GUI for both the minimum density and gradient density reports.\n Note: The  signoff_report_metal_density command generates the heat maps only when the  signoff.report_metal_density.create_heat_maps application option is set to  true.\n \u2022 To display the minimum density heat map, choose  View > Map > ICV Metal Fill Density.\n Figure\u00a0151 shows a minimum density heat map.\n In this heat map, each colored tile corresponds in size to the density window step.\n To customize or standardize the density values in the heat map, set the bin range, which is indicated by a red oval in the figure.\n       Figure 151 Minimum Density Heat Map \u2022 To display the density gradient heat map, choose  View > Map > ICV Metal Fill Gradient.\n       Figure\u00a0152 shows a density gradient heat map.\n In this heat map, each colored bar corresponds in size to the gradient window size.\n Figure 152 Density Gradient Heat Map"}
{"header": "How do I Removing Metal Fill With the IC\u00a0Validator Tool", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The method you use to remove metal fill depends on the extent of the metal fill removal: \u2022 To remove all metal fill from a block, specific layers of a block, or specific regions of a block, use the  signoff_create_metal_fill command with the  -mode\u00a0remove option.\n This command uses the IC\u00a0Validator tool to remove metal fill from the current block, as described in  Removing Metal Fill With the IC\u00a0Validator Tool.\n \u2022 To remove specific fill shapes, use the  remove_shapes or  remove_fill_cells commands.\n You would typically use this method when manually fixing DRC violations related to the metal fill.\n You might also be able to fix the DRC violation by modifying the metal fill shapes, as described in  Modifying Metal Fill."}
{"header": "How do I ECO-Aware Removal of Track Based Metal Fill Shapes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, when you use the  signoff_create_metal_fill\u00a0-mode\u00a0remove command, the IC\u00a0Validator tool removes all metal and via fill from the current block, including the typical critical dimension (TCD) structures.\n \u2022 To remove the metal fill only from specific regions, use the  -coordinates option, as described in  Specifying the Regions for Metal Fill Insertion.\n \u2022 To remove the metal fill only from specific layers, use the  -select_layers option, as described in  Specifying the Layers for Metal Fill Insertion.\n By default, when you use this option, the IC\u00a0Validator tool does not remove the TCD structures.\n To remove the TCD structures in addition to the metal and via fill, set the signoff.create_metal_fill.tcd_fill application option to  true before running the signoff_create_metal_fill command.\n \u2022 To remove the metal fill only over critical nets, use one or both of the  -nets and -timing_preserve_setup_slack_threshold options to identify the critical nets.\n Note: The existing fill is not considered when determining the critical nets for pattern-based metal fill, but not for track-based metal fill.\n \u2022 To honor certain rules when removing the metal fill, use the  -remove_by_rule option.\n You can specify one or more of the following rules: \u25e6 Nondefault routing rules ( ndr ) This rule applies to both pattern-based and track-based metal fill.\n \u25e6 Maximum density rules ( max_density_threshold ) This rule applies only to track-based metal fill.\n When you enable this rule, metal fill removal honors the maximum density threshold set by the signoff.create_metal_fill.max_density_threshold application option.\n For example, to honor nondefault routing rules during fill removal, use the following command: fc_shell>\u00a0 signoff_create_metal_fill -mode remove \\ -remove_by_rule {ndr} See Also \u2022 Specifying the Layers for Metal Fill Insertion \u2022 Specifying the Regions for Metal Fill Insertion"}
{"header": "How do I Modifying Metal Fill", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To automatically remove track based metal fill shapes that are causing DRC violations after ECO, use the  -remove_by_rule\u00a0drc_auto option with the signoff_create_metal_fill command.\n This action removes DRC violating track based metal fill shapes or vias from design, including any floating connections created due to removal of DRC violating shape.\n For example, fc_shell>\u00a0 signoff_create_metal_fill -remove_by_rule drc_auto"}
{"header": "How do I Performing Real Metal Fill Extraction", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes.\n \u2022 To change the boundary of a metal fill shape, use the  set_attribute command to modify its  bbox attribute.\n \u2022 To add a metal fill shape in the top-level fill cell, use the  create_shape\u00a0-shape_use area_fill command.\n \u2022 To add a metal fill shape in a specific fill cell, use the  create_shape\u00a0-fill_cell command.\n \u2022 To remove a metal fill shape, use the  remove_shapes command.\n You can also modify metal fill shapes in the GUI.\n To select or modify fill shapes in the GUI, 1.\n Select \u201cMultiple Levels Active\u201d ( ) in the View Settings panel.\n 2.\n In the \u201cHierarchy Settings\u201d panel, set \u201cView level\u201d to a minimum of 2 and select \u201cFill Cell\u201d in \u201cExpanding cell types.\u201d"}
{"header": "How do I Automatically Fixing Isolated Vias", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To enable metal fil extractionreal real metal fill extraction, 1.\n Associate non-emulation TLUPlus files with the timing corners by using the set_parasitic_parameters command, as described in the  Fusion Compiler Timing Analysis User Guide.\n 2.\n Enable real metal fill extraction by using the following command: fc_shell>\u00a0 set_extraction_options \\ -real_metalfill_extraction floating For more information about performing extraction in the Fusion Compiler tool, see the Fusion Compiler Timing Analysis User Guide."}
{"header": "How do I Setting Options for Fixing Isolated Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "An isolated via is a via that does not have neighboring vias close enough to meet the requirements of the technology.\n To check for and fix isolated vias, 1.\n Set up the IC\u00a0Validator environment as described in  Setting Up the IC\u00a0Validator Environment.\n 2.\n (Optional) Enable distributed processing by using the  set_host_options command, as described in  Enabling IC\u00a0Validator Multicore Processing.\n 3.\n Set the application options for fixing isolated vias.\n At a minimum, you must define the maximum distance within which a neighboring via must exist so that a via is not considered an isolated via.\n To define this information for each via layer, set the  signoff.fix_isolated_via.isolated_via_max_range application option, which has the following syntax: {\u00a0{ via_layer 1 distance 1 }\u00a0...\n { via_layer n distance n }\u00a0} where the  via_layer argument uses the mask names, such as via1, and the  distance argument is in microns.\n For information about the options available for fixing isolated vias, see  Setting Options for Fixing Isolated Vias.\n 4.\n Run isolated via checking and fixing by using the  signoff_fix_isolated_via command as described in  Running the signoff_fix_isolated_via Command."}
{"header": "How do I Running the signoff_fix_isolated_via Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run the  signoff_fix_isolated_via command, configure the run by setting the application options shown in  Table\u00a051.\n To set the application options, use the set_app_options command.\n To see the current settings, use the  report_app_options command.\n       Table 51 Application Options for Signoff Isolated Via Fixing Application option Default Description signoff.\n fix_isolated_via.\n isolated_via_max_range           signoff.\n fix_isolated_via.\n avoid_net_types {clock\u00a0pg}    clock pg none signoff.\n fix_isolated_via.\n run_dir    signoff_fix_isolated_via      signoff.\n fix_isolated_via.\n user_defined_options"}
{"header": "How do I Checking for Isolated Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can use the  signoff_fix_isolated_via command either to check for isolated vias only, or to check for and fix the isolated vias."}
{"header": "How do I Checking and Fixing Isolated Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To check for isolated vias without fixing them, run the  signoff_fix_isolated_via command with the  -check_only\u00a0true option.\n fc_shell>\u00a0 signoff_fix_isolated_via -check_only true       When run you run the  signoff_fix_isolated_via command in check-only mode, it generates a summary report that specifies the number of isolated vias detected on each via layer."}
{"header": "How do I 9", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "By default, the  signoff_fix_isolated_via command both checks for and fixes isolated vias.\n The command performs the following tasks: 1.\n Checks for isolated vias by using the ranges defined in the signoff.fix_isolated_via.isolated_via_max_range application option 2.\n (Optional) Performs track-based metal fill insertion to insert dummy fill shapes within the specified range around each detected isolated via \u25e6 By default, the  signoff_fix_isolated_via command ignores the existing fill data and performs track-based metal fill insertion to insert the fill shapes to use for fixing the isolated vias.\n The fill shapes are inserted on-track following the design rules defined in the technology file.\n Some foundries have additional design rules, which you enable by setting the appropriate  TRACK_FILL_FOUNDARY_ name IC\u00a0Validator variable.\n To set this variable, set the  signoff.create_metal_fill.user_defined_options application option, as shown in the following example: fc_shell>\u00a0 set_app_options \\ -name signoff.create_metal_fill.user_defined_options \\ -value {-D TRACK_FILL_FOUNDARY_ name } \u25e6 If you have already performed track-based metal fill insertion, you can use the existing fill shapes to fix isolated vias by using the  -update_track_fill\u00a0true option.\n When you use this option, you must use the  -track_fill_runset_include_file option to specify the parameter file used for the initial track-based metal fill insertion.\n This parameter file is named track_fill_params.rh and is located in the run directory for the initial run.\n For example, if the run directory for the initial track-based metal fill insertion run is named init_fill, use the following command to fix isolated vias using the existing fill shapes: fc_shell>\u00a0 signoff_fix_isolated_via -update_track_fill true \\ -track_fill_runset_include_file init_fill/track_fill_params.rh For information about performing track-based metal fill insertion, see  Track-Based Metal Fill Insertion.\n       3.\n Inserts fixing vias within the specified range by using one of the following methods, in order of priority: a.\n Inserting a via between an existing non-wide net shape and a fill shape b.\n Extending the line end of an existing non-wide net shape and inserting a via between the extension and a fill shape c.\n Inserting a via between a wide metal shape and a fill shape When inserting the fixing vias, the tool considers the routing rules, including double- patterning rules and nondefault spacing rules, to prevent the introduction of DRC violations.\n Note: If the block is either very congested or very sparse, the signoff_fix_isolated_via command might not be able to fix all isolated vias.\n 4.\n Removes the unused dummy fill shapes 5.\n (Optional) Saves the updated block to disk \u25e6 By default, the  signoff_fix_isolated_via command does not save the updated block to disk.\n After running the command, you must use the  save_block command to save the updated block to disk.\n \u25e6 To save the block at the end of the  signoff_fix_isolated_via run, use the -save_design\u00a0true option with the  signoff_fix_isolated_via command.\n 6.\n Saves the results to disk The  signoff_fix_isolated_via command generates the following results files: \u25e6 A summary report This report specifies the number of isolated vias for each via layer before and after fixing.\n \u25e6 An error data file By default, the error data generated by the  signoff_fix_isolated_via command is saved in a file named signoff_fix_isolated_via.err.\n To specify the name for the error data file, use the  -error_data option.\n To report or display the information in the error data file, use the error browser, as described in the  Fusion Compiler Graphical User Interface User Guide."}
{"header": "How do I Using Custom Router in the Fusion Compiler", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Custom Router is a shape-based router that supports gridded or gridless routing for custom digital, mixed signal, and analog routing needs.\n In the Fusion Compiler environment, you can use Custom Router to create interconnects (or routes) for critical signals between blocks and continue with the Fusion Compiler tool to complete the physical implementation.\n You can also preroute critical signals or clock nets by using a set of custom routing constraints.\n In the Fusion Compiler environment, Custom Router provides the following features: \u2022 Prerouting in the batch mode \u2022 Tcl-based routing constraint management \u2022 Automatic routing with custom routing constraints \u2022 Hybrid flow for prerouting \u2022 Double Data Rate (DDR) net routing flow Custom Router is fully integrated with the Fusion Compiler tool, and supports advanced design rules for 20 nm and below technologies.\n To learn about using Custom Router in the Fusion Compiler environment, see the following topics: \u2022 Using Custom Router in the Fusion Compiler Tool \u2022 Before Using Custom Router \u2022 Defining Routing Constraints \u2022 Managing Constraint Groups \u2022 Using Custom Routing Application Options \u2022 Routing With the Custom Router \u2022 Shielding the Nets \u2022 Checking the Routing Results       \u2022 Using a Hybrid Routing Flow \u2022 Using a DDR Routing Flow These topics describe how to use Custom Router to create custom routes in the Fusion Compiler environment.\n For detailed information about Custom Router, see the  Custom Compiler Custom Router User Guide."}
{"header": "How do I Before Using Custom Router", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides a set of Tcl commands to run Custom Router in the Fusion Compiler environment.\n These commands define routing constraints for adding wires on one or more nets at the block level or adding differential pair routing, bus routing, shielding, and other routing features.\n A set of application options is also available for specifying the parameters for performing custom routing.\n For more information about how to define routing constraints and application options, see  Defining Routing Constraints and  Using Custom Routing Application Options.\n The route_custom command uses the specified routing constraints, as well as information from the technology file and the design, to perform automatic routing using the Custom Router.\n For more information about using the  route_custom command, see  Routing With the Custom Router.\n Custom Router supports the following constraints: \u2022 Net shielding and differential pairs \u2022 Matched length \u2022 Variable width and space \u2022 Pin width matching and tapering Custom Router supports the following Fusion Compiler nondefault routing rules: \u2022 Routing layers and vias \u2022 Routing width and spacing \u2022 Routing grids \u2022 Inter- and intra-group spacing \u2022 Taper halo \u2022 Routing blockage       \u2022 Routing corridors \u2022 Shielding Figure\u00a0153 shows the basic Custom Router flow.\n Figure 153 Basic Custom Router Flow Define routing constraints Perform custom routing Block with routed power nets and unrouted clock trees Technology file with design rule definitions Perform postroute optimization Analyze routing results"}
{"header": "How do I Defining Routing Constraints", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run Custom Router, you must \u2022 Ensure the necessary design rules are correctly defined in the technology file, such as layer and via definitions.\n For more information, see the  Synopsys Technology File and Routing Rules Reference Manual.\n \u2022 Check the connectivity information and look for pin blockages in the design.\n For more information, see the \"Reviewing the Design\" topic in the  Custom Compiler Custom Router User Guide.\n \u2022 Ensure sure that the power and ground nets in the block have been routed.\n       For more information, see the  Fusion Compiler Design Planning User Guide.\n \u2022 Check the routability of the placement as explained in  Checking Routability."}
{"header": "How do I Defining the Bus Routing Style", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides a set of application options to control custom routing results.\n The application options are applied globally.\n See  Using Custom Routing Application Options.\n You can also define net-specific routing constraints that override the routing application options.\n Routing constraints provide guidance during routing.\n In the Fusion Compiler environment, Custom Router honors both the Custom Router constraints and the Fusion Compiler nondefault routing rules.\n Note: You must apply net-specific routing constraints to physical nets.\n When specifying nets that will be constrained, use the  get_nets\u00a0-physical_context command to ensure the physical net is returned.\n For example: fc_shell>\u00a0 create_net_shielding \\ -for [get_nets -physical_context pr*]\\ -disabled_layers {M5 M6} -sharing true \\ -layer_gaps {M2 3 M3 5} {shielding_4} Table\u00a052 lists the commands to define the Custom Router constraints by creating constraint groups.\n For information about the supported Fusion Compiler nondefault routing rules, see  Using Nondefault Routing Rules.\n To check or remove the created constraint groups, use the  report_constraint_groups or  remove_constraint_groups command.\n For more information about checking or removing constraint groups, see  Managing Constraint Groups.\n Table 52 Commands to Define Custom Router Routing Constraints Command Description create_bus_routing_style    create_differential_group         Table 52 Commands to Define Custom Router Routing Constraints (Continued) Command Description create_wire_matching    create_length_limit    create_net_shielding   create_net_priority"}
{"header": "How do I Creating Differential Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To route a collection of nets or bundles as a single bus structure (trunk), create a constraint group that defines the bus routing style by using the create_bus_routing_style command.\n You need to specify the following information: \u2022 The name of the constraint group If you do not specify a name, the command names the constraint group bus_style_ n, where  n is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the  -force option.\n \u2022 The nets, bundles, and topology edges to which the constraint group applies To specify the objects that constitute the constraint group, use the  -for option.\n \u2022 The constraints To specify the constraints that are applied per layer to the trunk and override any settings on the individual bits, use the options listed in  Table\u00a053.\n       Table 53 Bus Routing Style Constraints Option Description -valid_layers    -layer_spacings  {M1\u00a05.0\u00a0M2\u00a06.0} -layer_widths  {M1\u00a05.0\u00a0M2\u00a06.0} -shield_placement  \u25e6 default  custom.route.bus_intra_shield_placement \u25e6 double_interleave \u25e6 half_interleave \u25e6 interleave  \u25e6 outside:   -corner_type   \u25e6 auto   \u25e6 cross \u25e6 river   -gap   The following example creates a bus routing constraint group for the nets that match the pattern pr*.\n The command names the constraint group bus_style_1, because no name is assigned to the constraint group.\n The shield placement is interleave.\n The minimum spacing is 3 microns for the M2 layer and 5 microns for the M3 layer.\n fc_shell>\u00a0 create_bus_routing_style \\ -for [get_nets -physical_context pr*] \\ -shield_placement interleave \\ -layer_spacings {M2 3 M3 5} {bus_style_1}"}
{"header": "How do I Inserting Shields on the Nets", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create a differential group or a differential pair for the nets, bundles, or topology edges, use the  create_differential_group command.\n Custom Router pairs the closest pins, one from each net, and routes from a common gather point between the pins.\n The tool routes the net pair the closest to each other with the most similar routing patterns.\n You need to specify the following information: \u2022 The name of the constraint group If you do not specify a name, the command names the constraint group differential_pair_ n or differential_group_ n, where  n is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the  -force option.\n \u2022 The nets in the differential group To specify the nets included in the created group, use the  -for option.\n If you specify two nets, the nets form a differential pair.\n If you specify three nets, the nets form a differential group.\n \u2022 The constraints for the differential group To define the constraints that are applied per layer to the trunks and override any settings on the individual bits, use the options listed in  Table\u00a054.\n Table 54 Differential Group Constraints Option Constraint -twist_style  \u25e6 diagonal \u25e6 none  \u25e6 orthogonal -twist_interval  -twist_offset   -valid_layers  -layer_spacings  -layer_widths        Option Constraint -shield_placement    \u25e6 double_interleave \u25e6 half_interleave  \u25e6 interleave  \u25e6 outside\u00a0(default):    -gap   The following example creates a differential pair for the prn and prp nets.\n The command names the differential pair differential_pair_0, because there is no name assigned to the different pair.\n No twist style is specified and the shield placement is set to  default.\n fc_shell>\u00a0 create_differential_group \\ -for [get_nets -physical_context {prn prp}] \\ -shield_placement default {differential_pair_0}"}
{"header": "How do I Defining the Net Priority", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add shielding on the selected nets to reduce crosstalk or parasitic effects, run the create_net_shielding command.\n You need to specify the following information: \u2022 The name of the constraint group If you do not specify a name, the command names the constraint group shielding_ n, where  n is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the  -force option.\n \u2022 The nets, bundles, and topology edges to which the constraint group applies Use the  -for option.\n \u2022 The constraints for shielding styles and layer-specific requirements To define the net shielding constraints that are applied per layer to the trunk and override any settings on the individual bits, use the options listed in  Table\u00a055.\n       Table 55 Net Shielding Constraints Option Description -shield_net    -shield_net_2    -via_defs   -gap   -max_gap   -width  -layer_gaps   -layer_max_gaps   -layer_widths  -min_segment  -sharing  unset,\u00a0true\u00a0and\u00a0false -group_shield   -enclose_pins  -enclose_pins  -group_shield  unset,\u00a0true,\u00a0and\u00a0false -enclose_vias  unset,\u00a0true,\u00a0and\u00a0false -disabled_layers        The following example creates a constraint group and specifies constraints for adding shields on the nets whose names start with pr.\n The minimum spacing is 3 microns for the M2 layer and 5 microns for the M3 layer.\n All constituent objects can share the shield; the M5 and M6 layers cannot be used for shielding.\n fc_shell>\u00a0 create_net_shielding \\ -for [get_nets -physical_context pr*] \\ -disabled_layers {M5 M6} -sharing true -layer_gaps {M2 3 M3 5} {shielding_4}"}
{"header": "How do I Defining Minimum Wire Lengths", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the net priority constraint to define the routing order for specific nets.\n Nets with a higher priority are routed first.\n To define the priority for a collection of nets or bundles, create a constraint group by using the  create_net_priority command.\n You need to specify the following information: \u2022 The name of the constraint group If you do not specify a name, the command assigns a name.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the  -force option.\n \u2022 The nets, bundles, and topology edges to which the constraint group applies Use the  -for option.\n \u2022 The net priority To specify the priority, use the  -priority option.\n You can specify an integer between -128 and 128, inclusive.\n The following example creates a constraint group named abc for the nets and bundles that match the pattern pr*.\n The net priority is set to 15.\n fc_shell>\u00a0 create_net_priority abc \\ -for [get_nets -physical_context pr*] \\ -priority 15 {abc}"}
{"header": "How do I Defining Matching Wire Lengths", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define different minimum wire lengths for each object in a group of nets or pin-to- pin connections, use the  create_length_limit command.\n Use this feature to perform length-limit routing on the nets with a single driver and multiple receivers, and run point-to- point routing between the drivers, steiners, and receivers.\n The Custom Router generates the steiner nodes in the background when the  create_length_limit command is       executed.\n Each of the receivers has either a  matched length constraint or an independent length constraint from the driver.\n Figure\u00a0154 shows an example of a single driver with multiple receivers, where each receiver has an individual length constraint.\n Figure 154 Receivers With Individual Wire Length Constraints From Driver D Syntax: fc_shell>\u00a0 create_length_limit - for objects [ -min_value float ] [ -exclude pins or ports ] [ -driver pin or port ] [ -force ] [ intent_name ] Command or Options Description create_length_limit  -for   -min_value  -exclude   -driver  -force   intent_name    -force        In  Example\u00a031, the commands create five wire-length constraints, one for each of the receivers shown in  Figure\u00a0154.\n Example 31 Five Wire-Length Constraints for the Five Receivers Connected to Driver D fc_shell>\u00a0 create_length_limit -for [get_nets -physical_context $net] \\ -driver [get_pins -physical_context D/o1] fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context R1/a] \\ -min_value 38.0 fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context R2/a] \\ -min_value 40.0 fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context R3/a] \\ -min_value 45.0 fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context R4/a] \\ -min_value 42.0 fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context R5/a] \\ -min_value 41.0 In  Example\u00a032, the command creates a constraint group named abc for the nets and bundles that match the pattern pr*.\n The minimum wire length is set to 10, so the length for each of the wires in the group is at least 10 microns.\n See  Figure\u00a0155.\n Example 32 Minimum Wire Length Constraint for pr* Nets fc_shell>\u00a0 create_length_limit abc -for [get_nets -physical_context pr*] \\ -min_value 10 {abc} Figure 155 Minimum Wire Length Constraint for pr* Nets In  Example\u00a033, the command creates a constraint group named gcr_length_limit_a2 for the a2/A pin.\n The minimum wire length is set to 2000.\n See  Figure\u00a0156.\n Example 33 Minimum Wire Length Constraint for the a2/A Pin fc_shell>\u00a0 create_length_limit -for [get_pins -physical_context a2/A] \\ -min_value 2000.0 -force gcr_length_limit_a2       Figure 156 Minimum Wire Length Constraint for the a2/A Pin"}
{"header": "How do I Managing Constraint Groups", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a group of nets or pin-to-pin connections that must have the same wire length, use the  create_wire_matching command.\n By matching wire lengths, you can minimize clock skews and timing violations.\n Two types of length-matching methods are available: \u2022 Pin-based: Wire lengths between pins must match.\n Figure\u00a0157 and  Figure\u00a0158 show examples of pin-based wire length matching.\n In both examples, all the receivers have a matched length constraint from driver D.\n \u2022 Net-based: Total length of wires of specified nets must match.\n Figure\u00a0159 shows an example of net-based wire length matching.\n In the example, the total wire length of nets pr1 and pr2 are within the specified 10-um tolerance.\n Figure 157 Receivers With Matched Wire Length From Driver D       Figure 158 Receivers With Matched Wire Length From Driver D' Figure 159 Net-Based Wire Length Matching Syntax: fc_shell>\u00a0 create_wire_matching -for objects -tolerance float [ -match_type type ] [ -exclude objects ] [ -relative ] [ -driver pin or port ] [ -force ] [ intent_name ] Command or Options Description create_wire_matching  -for    -tolerance   -relative  -relative -tolerance  the -tolerance        Command or Options Description -match_type  \u2022  length   \u2022  length_per_layer -exclude   -driver  -force   intent_name      -force  After routing, a matched-length summary report is generated.\n You can use the report to troubleshoot and resolve the lengths that do not meet the set tolerance.\n The content of the report depends on the  -for option that you specified: \u2022 If the  -for option specifies pin-based length matching, a Length Constraint Report is generated.\n See  Figure\u00a0160.\n \u2022 If the  -for option specifies net-based length matching, a Routed Length report is generated.\n See  Figure\u00a0161.\n Figure 160 Pin-Based Length Matching Report       Figure 161 Net-Based Length Matching Report In  Example\u00a034, the commands create wire matching constraints for the scenario shown in Figure\u00a0157.\n All receivers (R) have a matched length constraint from the balanced driver (D).\n Example 34 Wire Matching Constraints for All Receivers to Driver D fc_shell>\u00a0 create_wire_matching -for [get_nets -physical_context $net] \\ -relative -tolerance 0.01 -driver [get_pins -physical_context D/o1]  fc_shell>\u00a0 create_wire_matching -for [get_pins \\ -physical_context {R1/a R2/a R3/a}] -tolerance 0.01 -relative In  Example\u00a035, the commands create wire matching constraints for the example in Figure\u00a0158.\n Example 35 Wire Matching Constraints for Receivers Connected to Driver D' fc_shell>\u00a0 create_wire_matching -for [get_nets -physical_context $net] \\ -tolerance 0.01 -relative -driver $driver_full_name  fc_shell>\u00a0 create_wire_matching \\ -for [get_pins -physical_context -of_objects $net] \\ -exclude $driver_full_name -tolerance 0.01 -relative In  Example\u00a036, the command creates a constraint group named abc for the nets and bundles that match the pattern pr*.\n An absolute tolerance of 10 um is set to match the length of each object in the constraint group.\n See  Figure\u00a0159.\n Example 36 Wire Matching Constraints for pr* Nets fc_shell>\u00a0 create_wire_matching abc \\ -for [get_nets -physical_context pr*] \\ -tolerance 10 {abc} In  Example\u00a037, the command creates a constraint group named def for the nets and bundles that match the pattern pr*.\n A tolerance of 10 percent is set to match the length of each object in the constraint group.\n       Example 37 Wire Matching Constraints for pr* Nets With Percent Tolerance fc_shell>\u00a0 create_wire_matching def \\ -for [get_nets -physical_context pr*] \\ -tolerance 0.10 -relative {def} In  Example\u00a038, the command creates a wire matching constraint named clk_match for the clk net.\n Each of the endpoints that connect to the clk net has an individual matching constraint.\n Example 38 Wire Matching Constraints for the clk Net fc_shell>\u00a0 create_wire_matching -for [get_pins -physical_context \\ -of_objects [get_nets -physical_context {clk}]] \\ -tolerance 0.01 -match_type length_per_layer -relative \\ -force clk_match In  Example\u00a039, the command creates a wire matching constraint named clk_match2 for all the nets in the block, except the pins whose names match the keyword u1/a.\n Example 39 Wire Matching Constraints With Exclusions fc_shell>\u00a0 create_wire_matching -for $nets -tolerance 0.05 \\ -exclude [get_pins -physical_context u1/a] -force clk_match2 In  Example\u00a040, the script creates a net-based wire matching constraint for the scenario shown in  Figure\u00a0162.\n The cell instance has an o1 terminal that servers as an inverter pin, driving signals on net1 and net1p to the pins.\n The I2 and I3 pins are excluded from the length matching constraint.\n Example 40 Net-Based Wire Matching Constraints With Pin Exclusions #\u00a0set\u00a0nets\u00a0to\u00a0match\u00a0length set\u00a0nets\u00a0[get_nets\u00a0-physical_context\u00a0{net1\u00a0net1p}] #\u00a0set\u00a0allowed\u00a0layers set_routing_rule\u00a0-min_routing_layer\u00a0m7\u00a0-max_routing_layer\u00a0m8\u00a0\\ -min_layer_mode\u00a0allow_pin_connection\u00a0-max_layer_mode\u00a0hard\u00a0$nets #\u00a0setup\u00a0Custom\u00a0Router\u00a0wire\u00a0match\u00a0constraint set\u00a0exclude_pin_names\u00a0[get_pins\u00a0-physical_context\u00a0{i2/a\u00a0i3/a}] create_wire_matching\u00a0-for\u00a0$nets\u00a0-tolerance\u00a00.01\u00a0-relative\u00a0\\ -exclude\u00a0$exclude_pin_names #\u00a0run\u00a0Custom\u00a0Router route_custom\u00a0-nets\u00a0$nets       Figure 162 Net-Based Wire Matching Constraints With Pin Exclusions"}
{"header": "How do I Using Custom Routing Application Options", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can report or remove the constraint groups that you create when specifying the routing constraints.\n To report the created constraint groups, use the  report_constraint_groups command and specify the constraint types to report by using the  -type option.\n By default, all constraint types are reported.\n To specify the number of objects to report, use the  -count option.\n The supported constraint types are: \u2022 bus_style, which is specified by the  create_bus_routing_style command \u2022 differential_group, which is specified by the  create_differential_group command \u2022 differential_pair, which is specified by the  create_differential_group command \u2022 matched_wire, which is specified by the  create_wire_matching command \u2022 net_priority, which is specified by the  create_net_priority command \u2022 shielding, which is specified by the  create_net_shielding command \u2022 wire_length_limit, which is specified by the  create_length_limit command       The following example shows the default output of the  report_constraint_groups command: fc_shell>\u00a0 report_constraint_groups **************************************** Report\u00a0:\u00a0report_constraint_groups Design\u00a0:\u00a0top_new Version: Date\u00a0\u00a0\u00a0: ****************************************  ------------------------------------------------------------------------ Name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Type\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Objects ------------------------------------------------------------------------ NDR_bus\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bus_style\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bus1 NDR_diff\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0differential_pair\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0clk0\u00a0clk1 shield_diff\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0shielding\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0clk0\u00a0clk1 matchL_con\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0matched_wire\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0match1 To remove the created constraint groups, use the  remove_constraint_groups command and specify the constraint groups to remove.\n To remove all the constraint groups, use the  -all option.\n The command disassociates the constituent objects from the removed constraint groups, and reports the number of the groups that are removed.\n For example, fc_shell>\u00a0 report_constraint_groups {shield_1}\u00a0{shield_2} fc_shell>\u00a0 remove_constraint_groups $a"}
{"header": "How do I Bus Routing Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool provides a set of application options to control custom routing results.\n The application options are applied globally.\n To define net-specific routing constraints to override the routing applications options, see  Defining Routing Constraints.\n To list all application options that are available for custom routing, use the following command: fc_shell>\u00a0 report_app_options custom.route.* To use the hybrid flow for custom routing, set the  custom.route.hybrid_flow application option to  on.\n This sets the values for each of hybrid flow related application options automatically.\n Table\u00a056 lists the application options for custom routing.\n       Table 56 Application Options for Running Custom Routing Application option Description custom.route.bus_corner_type custom.route.bus_intra_shield_placement custom.route.bus_pin_trunk_offset custom.route.bus_split_even_bits custom.route.bus_split_ignore_width custom.route.bus_tap_off_enable custom.route.bus_tap_off_shielding   custom.route.match_box    custom.route.layer_grid_mode      custom.route.diffpair_twist_jumper_enable custom.route.diffpair_twist_jumper_interval custom.route.diffpair_twist_jumper_offset custom.route.diffpair_twist_jumper_style    custom.route.net_min_layer_mode custom.route.net_min_layer_mode_soft_cost custom.route.net_max_layer_mode custom.route.net_max_layer_mode_soft_cost     custom.route.routing_area      custom.route.shield_connect_mesh_overlap custom.route.shield_connect_route custom.route.shield_connect_to_supply custom.route.shield_min_open_loop custom.route.shield_min_shield_seg custom.route.shield_min_signal_seg custom.route.shield_net custom.route.shield_second_net         Table 56 Application Options for Running Custom Routing (Continued) Application option Description custom.route.single_loop_match custom.route.single_loop_match_max_spacing custom.route.single_loop_match_min_spacing custom.route.single_loop_match_offset_layer     custom.route.skip_connect_pin_type  custom.route.distance_to_net_pin  skip_connect_pin_type    distance_to_net_pin distance_to_net_pin   netName distance custom.route.balance_mode"}
{"header": "How do I Corner Type", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Custom Router bus routing application options allow you to specify: \u2022 Corner Type \u2022 Intra-shield Placement \u2022 Pin-Trunk Offset \u2022 Trunk Splitting \u2022 Tapoffs"}
{"header": "How do I Intra-shield Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  custom.route.bus_corner_type application option specifies how the tool routes the bus trunks at corners.\n Valid values are: Valid Value Description auto         Valid Value Description cross  river"}
{"header": "How do I Pin-Trunk Offset", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  custom.route.bus_intra_shield_placement application option specifies how the bus trunk will be shielded.\n Valid values are: Valid Value Description double_interleave  half_interleave  interleave  outside"}
{"header": "How do I Trunk Splitting", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  custom.route.bus_pin_trunk_offset application option changes the default spacing between the bus trunk and the bus bit pins."}
{"header": "How do I Tapoffs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split.\n \u2022 custom.route.bus_split_ignore_width \u2022 custom.route.bus_split_even_bits The  custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section.\n The  custom.route.bus_split_even_bits application option requires that you set the  custom.route.bus_split_ignore_width application option.\n If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes).\n In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set.\n The spacing between the power and ground rails can accommodate three bits only.\n  Figure\u00a0163 a shows the two possible results when the  custom.route.bus_split_even_bits application option is turned off.\n  Figure\u00a0163 b shows the result when the  custom.route.bus_split_even_bits application option is turned on.\n Figure 163 Splitting Bus Trunk to Route Through Power and Ground Rails"}
{"header": "How do I Track Adherence Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Two Custom Router application options allow you to control tapoff operations: \u2022 custom.route.bus_tap_off_enable \u2022 custom.route.bus_tap_off_shielding The  custom.route.bus_tap_off_enable application option connects pins to the bus trunk.\n If the  custom.route.bus_tap_off_enable application option is turned on, you can use the  custom.route.bus_tap_off_shielding application option to add shielding to the bus tapoffs."}
{"header": "How do I Differential-Pair Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify whether the route and corresponding parallel shields, jumpers for parallel shields, and bus shields will snap to the wire tracks or the routing grid, use the custom.route.layer_grid_mode application option.\n Specify the application option with a list of paired values.\n The syntax for each pair of values is as follows: {{ layerName mode }} where layerName is the name of the layer.\n To include all layers, specify  All.\n mode is one of the following: \u2022 on : Snaps routes and shields to tracks.\n If the layer does not have tracks, the routes and shields will snap to the routing grid.\n \u2022 off : Does not snap routes and shields to tracks or grids.\n Choose this option for gridless routing.\n \u2022 off_cost\u00a0<costValue> : Snaps routes and shields to tracks when possible.\n The value you specify determines the adherence of routes to tracks.\n The higher the value, the more likely the route will remain on the track or grid.\n If tracks and routing grids are not defined and you specify  on, the Custom Router uses an internally determined grid.\n The grid pitch is route width + minSpacing between shapes.\n The grid offset is 0 or pitch/2, whichever permits more pins on the grid.\n Example 41 Layer and Cost Specification for Track Adherence {{M2\u00a0off}\u00a0{M3\u00a0off_cost\u00a04}}"}
{"header": "How do I Shielding Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following Custom Router application options allow you to control differential-pair routing: Application Option Description custom.route.diffpair_twist_jumper_enable  custom.route.diffpair_twist_jumper_interval   custom.route.diffpair_twist_jumper_offset    custom.route.diffpair_twist_jumper_style   \u2022  diagonal  \u2022  none   \u2022  orthogonal"}
{"header": "How do I Single-Loop Matching", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following Custom Router shielding application options allow you to control shielding: Application Option Description custom.route.shield_connect_mesh_overlap        custom.route.shield_connect_route      custom.route.shield_connect_to_supply         Application Option Description custom.route.shield_min_open_loop      custom.route.shield_min_shield_seg   custom.route.shield_min_signal_seg   custom.route.shield_net     custom.route.shield_second_net"}
{"header": "How do I Balance Mode Option", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create single-loops to extend wires for length matching, use the Custom Router single- loop matching application options.\n Single-loop matching is typically used in  DDR routing flows.\n Figure 164 Adding Single Loops to Extend Wires Application Option Description custom.route.single_loop_match        Application Option Description custom.route.single_loop_match_max_spacing   custom.route.single_loop_match_min_spacing   custom.route.single_loop_match_offset_layer"}
{"header": "How do I Routing With the Custom Router", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You use the  custom.route.balance_mode application option in interposer designs to reduce the skews caused by wire length and via cut count differences.\n This topic describes how to set the  custom.route.balance_mode application option and provides examples to demonstrate its use.\n To route using the balance mode: \u25baSet the  custom.route.balance_mode application option to true.\n set_app_options\u00a0-name\u00a0custom.route.balance_mode\u00a0-value\u00a0true When  custom.route.balance_mode is true: \u2022 The Custom Router creates feedthrough routes between two \u03bcbumps and a C4 bump on the same net.\n \u2022 The wire lengths between the \u03bcbumps and the C4 bump are equal.\n \u2022 The number of via cuts is the same in all related \u03bcbump-C4 bump connections.\n Example 1 shows how the  custom.route.balance_mode option is used when routing \u03bcbumps to a C4 bump.\n The designated routing layers are M1 through M5.\n The M2 and M4       layers are used for horizontal connections; and the M1, M3, and M5 layers are used for vertical connections.\n The number of via cuts and the array dimensions are also defined.\n Example 42 Routing with custom.route.balance_mode turned on create_routing_rule\u00a0skew\u00a0-widths\u00a0{M1\u00a06\u00a0M2\u00a06\u00a0M3\u00a06\u00a0M4\u00a06\u00a0M5\u00a025}\u00a0-vias {{VIA12_1cut\u00a03x3\u00a0R}\u00a0{VIA23_1cut\u00a03x3\u00a0R}\u00a0{VIA34_1cut\u00a03x3\u00a0R}\u00a0{VIA45_1cut 2x5\u00a0R}} set_routing_rule\u00a0$nets_to_route\u00a0-rule\u00a0skew\u00a0-max_routing_layer\u00a0M5 -min_routing_layer\u00a0M1 set_attribute\u00a0[get_layers\u00a0\"M2\u00a0M4\"]\u00a0routing_direction\u00a0horizontal set_attribute\u00a0[get_layers\u00a0\"M1\u00a0M3\u00a0M5\"]\u00a0routing_direction\u00a0vertical set_ignored_layers\u00a0-min_routing_layer\u00a0M1\u00a0-max_routing_layer\u00a0M5 set_app_options\u00a0-list\u00a0{custom.route.balance_mode\u00a0true} route_custom\u00a0-nets\u00a0$nets_to_route The results from the example show that the wire lengths and the number of vias are the same in each of the four \u03bcbump-to-C4 bump connections."}
{"header": "How do I Shielding the Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before performing custom routing on your block, you need to define routing constraints by using the commands described in  Defining Routing Constraints, and setting the appropriate application options.\n To perform custom routing with Custom Router in the Fusion Compiler environment, run the  route_custom command.\n By default, the tool routes all nets in the block.\n To route specific nets, use the  -nets option.\n By default, the tool removes the configuration data when the command run is complete.\n To keep the data in the cache for running other Custom Router commands in the current session, set the  -keep_session option to  true.\n The default is  false.\n The following example specifies the bus routing style and then performs bus routing.\n fc_shell>\u00a0 create_bundle -name Bus1 {net0 net1} fc_shell>\u00a0 create_bus_routing_style -for {Bus1} \\ -valid_layers {M5 M6} \\       -layer_widths {M5 0.4 M6 0.44} -force bus1 fc_shell>\u00a0 create_net_shielding -for {Bus1} -shield_net VSS \\ -layer_gaps 0.21 -layer_widths 0.2 -sharing true -force sh1 fc_shell>\u00a0 set_app_options -name custom.route.bus_corner_type \\ -value river fc_shell>\u00a0 set_app_options \\ -name custom.route.bus_intra_shield_placement -value interleave fc_shell>\u00a0 route_custom -nets {net0 net1} The following example creates a constraint group and then performs routing on the nets with the same length.\n fc_shell>\u00a0 set matchNets {net1 net2 net3 net4} fc_shell>\u00a0 create_bundle -name MatchL1 $matchNets fc_shell>\u00a0 create_wire_matching -for MatchL1s \\ -match_type length -tolerance 1 \\ -force matchL1_con fc_shell>\u00a0 route_custom -nets {net1 net2 net3 net4} The following example creates a differential group and then performs custom routing.\n fc_shell>\u00a0 create_differential_group -for {net1 net2} \\ -valid_layers {M3 M4} -layer_widths {M3 0.4 M4 0.4} \\ -layer_spacings {M3 0.4 M4 0.4} \\ -twist_style diagonal -twist_interval 80.0 -force Diff fc_shell>\u00a0 set_app_options\\ -name custom.route.diffpair_twist_jumper_offset -value 10 fc_shell>\u00a0 route_custom -nets {net1 net2}"}
{"header": "How do I Checking the Routing Results", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Shielding is needed around sensitive nets to reduce noise and crosstalk.\n When you perform custom routing by using the route_custom command, the tool automatically creates shields for the nets based on the constraints you specify by using the create_net_shielding command.\n To add shielding to the selected nets in a separate run, use the  create_custom_shields command.The following example creates shields for net1 and net2.\n fc_shell>\u00a0 create_custom_shields -nets {net1 net2} To remove the shielding created by the  create_custom_shields command, use the remove_custom_shields command.\n Doing this also removes the shielding created by the route_custom command."}
{"header": "How do I Using a Hybrid Routing Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After running Custom Router to perform custom routing on the nets, you can check the routing results by reporting the routing results, generating a congestion map, running DRC checks, and so on.\n For more information about the tasks to check the routing results, see  Analyzing the Routing Results."}
{"header": "How do I Using a DDR Routing Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the hybrid flow, Custom Router is used to perform trunk routing without completing some pin connections, and then Zroute is used to complete the pin connections.\n This flow enables the use of Custom Router for prerouting while avoiding or reducing inconsistency and DRC violations associated with differences in the pin connection behavior between the two tools.\n To enable the hybrid routing flow, set the  custom.route.skip_connect_pin_type application option to one or more of the following values, depending on your routing requirements.\n By default, this application option is set to  none, which disables the hybrid routing flow.\n \u2022 auto Custom Router identifies the routability of the pins in the block, and then completes the pin connections for the pins that can be connected.\n \u2022 all Custom Router does not complete the pin connections for all pins in the block.\n \u2022 stdcell Custom Router completes the pin connections for all pins in the block, except for standard cell pins.\n \u2022 io Custom Router completes the pin connections for all pins in the block, except for I/O cell pins.\n \u2022 macro Custom Router completes the pin connections for all pins in the block, except for macro pins.\n By default, when the hybrid flow is enabled, Custom Router determines how much space to leave between a route and an unconnected pin.\n To specify the maximum distance,       use the  custom.route.distance_to_net_pin application option.\n Set the value in the following format:  { net_name distance }.\n The following script uses Custom Router for trunk routing and Zroute for all pin connections.\n set_app_options -name custom.route.skip_connect_pin_type -value all route_custom -nets {net1 net2} route_eco -nets {net1 net2} remove_redundant_shapes -nets {net1 net2} route_detail -incremental true The following script uses Custom Router for trunk routing and pin connections except standard cell pins, and then uses Zroute for standard cell pin connections.\n set_routing_rule -min_routing_layer m3 \\ -max_routing_layer m9 \\ -min_layer_mode allow_pin_connection \\ -max_layer_mode hard {net1 net2} set_app_options -name custom.route.skip_connect_pin_type \\ -value stdcell set_app_options -name custom.route.distance_to_net_pin \\ -value {{{net1 5.0} {net2 3.0}}} route_custom -nets {net1 net2} route_eco -nets {net1 net2} remove_redundant_shapes -nets {net1 net2} route_detail -incremental true"}
{"header": "How do I 10", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "This topic describes how to use Custom Router to perform routing on a double data rate (DDR) design.\n Figure\u00a0165 illustrates the basic steps to create interconnects (routes) between a DDR net and the core.\n       Figure 165 A Basic DDR Flow Prepare input data Run custom routing Insert buffer cells Run ECO routing Define single-loop lengthening Trimming Define net bundles Define and apply routing rules route_custom -nets Set the length match route_custom -nets add_buffer_on_route route_eco -nets route_detail -incremental remove_redundant_shapes create_bundle create_routing_rule set_routing_rule Run custom routing create_wire_matching To perform routing on a DDR design with Custom Router, 1.\n Before you run Custom Router to perform routing on a DDR design, \u25e6 Group the nets as a bundle for length matching.\n fc_shell>\u00a0 create_bundle -name GRP1 [get_nets $nets] \u25e6 Create and apply the routing rules for the DDR nets.\n fc_shell>\u00a0 create_routing_rule DDR -widths { layer value  \u2026} \\ -spacings { layer value  \u2026 } fc_shell>\u00a0 set_routing_rule -rule DDR -min_routing_layer M4 \\ -max_routing_layer M5 $all_ddr_nets       Set two or more layers for initial routing and length matching.\n For postroute length matching, you should include two additional layers.\n For example, if you use the M4 and M5 layers for initial routing, set the M3, M4, M5, and M6 layers for postroute length matching.\n \u25e6 Add routing blockages as needed.\n Add routing blockages to prevent Custom Router from routing in the area that is covered by placement blockages.\n This helps avoid possible unplaceable buffers during buffer insertion.\n 2.\n Create routes for the DDR nets by running the  route_custom command.\n fc_shell>\u00a0 route_custom -nets $all_ddr_nets 3.\n Define the routing constraints.\n \u25e6 Use the following application options to set the single-loop constraints.\n fc_shell>\u00a0 set_app_options \\ -name custom.route.single_loop_match -value true fc_shell>\u00a0 set_app_options \\ -name custom.route.single_loop_match_min_spacing -value 0.75 fc_shell>\u00a0 set_app_options \\ -name custom.route.single_loop_match_max_spacing -value 10.0 fc_shell>\u00a0 set_app_options \\ -name custom.route.single_loop_match_offset_layer -value true \u25e6 Set the wire matching constraint for the group.\n fc_shell>\u00a0 create_wire_matching -for [get_bundles GRP1] \\ -match_type length -tolerance 20 -force match1 fc_shell>\u00a0 create_wire_matching -for [get_bundles GRP2] \\ -match_type length -tolerance 20 -force match2 \u25e6 Set the bounding box for the wire matching routing constraint.\n fc_shell>\u00a0 set_app_options -name custom.route.match_box \\ -value {{1000 1000} {1500 1500}} By default, the bounding box coordinates are set to {{0 0} {0 0}}.\n When set to other values, the router limits matching routes to the area inside the box, which might result in connections that do not meet the matching constraint.\n The matching box should cover the entire available channel space.\n 4.\n Perform custom routing with length matching.\n fc_shell>\u00a0 route_custom -nets [get_bundles {GRP1}]       If you define multiple matching boxes at step 3, you need to run the  route_custom command on each matching box.\n 5.\n Report the list of mismatching nets.\n %\u00a0 grep \"Mismatch\"  log_file 6.\n Reduce the number of the mismatched nets (if any) by using one of the following methods: \u25e6 Rebalance the net routing of one or more groups in the same channel among the available routing layers by a.\n Resetting the routing layers.\n For example, - Set the routing layers for route group A to the M3 and M4 layers, and for group B to the M5 and M6 layers, or - Set the routing layers for route groups A and B to the M3 and M4 layers, and route all mismatched nets on the M5 and M6 layers.\n b.\n Rerunning initial routing with the rebalanced routing layer settings.\n \u25e6 Set a larger value for the  custom.route.\n single_loop_match_max_spacing application option.\n \u25e6 Allow different layers for the single loop.\n fc_shell>\u00a0 set_app_options \\ -name custom.route.single_loop_match_offset_layer -value true 7.\n Insert buffer cells on the routed DDR net.\n In the following example, ddr_BUF is used as the prefix for the names of the added ECO nets and buffers for easy identification.\n The buffer cells are added at an interval that is 20 percent of the total net length.\n fc_shell>\u00a0 set ddr_buf \"BUF001\" fc_shell>\u00a0 add_buffer_on_route -net_prefix ddr_BUF \\ -cell_prefix ddr_BUF \\ -repeater_distance_length_ratio 0.2 \\ -respect_blockages [get_nets $ddr_nets] $ddr_BUF 8.\n Perform legalization and verify that the placement is legal.\n fc_shell>\u00a0 legalize_placement -cells $ddr_BUF fc_shell>\u00a0 check_legality -cells $ddr_BUF       Note: Using the  -cells option with the  legalize_placement and check_legality commands is supported only in the standard legalizer.\n 9.\n Preserve the route shapes of the clock nets by setting the  shape_use attribute of the clock nets to  user_route.\n fc_shell>\u00a0 set_attribute [get_shapes -of_object $all_nets] \\ shape_use \"user_route\" fc_shell>\u00a0 set_attribute [get_vias -of_object $all_nets] \\ shape_use \"user_route\" 10.\n Limit rerouting to minor changes by setting the  physical_status attribute on the nets to  minor_change.\n fc_shell>\u00a0 set_attribute [get_shapes -of_object $all_nets] \\ physical_status \"minor_change\" fc_shell>\u00a0 set_attribute [get_vias -of_object $all_nets] \\ physical_status \"minor_change\" 11.\n Run ECO routing to reconnect the nets by using the  route_eco command.\n fc_shell>\u00a0 route_eco -nets $all_nets -reroute modified_nets_only 12.\n Run incremental detail routing to fix the DRC violations by running the  route_detail -incremental\u00a0true command.\n After routing is complete, clean up the routed nets by running the  remove_redundant_shapes command.\n fc_shell>\u00a0 set_attribute \\ [get_shapes -of_object $all_nets] shape_use \"detail_route\" fc_shell>\u00a0 set_attribute  \\ [get_vias -of_object $all_nets] shape_use \"detail_route\" fc_shell>\u00a0 route_detail -incremental true fc_shell>\u00a0 remove_redundant_shapes -nets $all_nets 13.\n Check the routing results by using one of the following methods: \u25e6 Check for DRC violations.\n fc_shell>\u00a0 check_routes By default, the tool checks for DRC violations between signal shapes.\n To check for DRC violations between signal shapes and user shapes, use the following command: fc_shell>\u00a0 check_routes -check_from_user_shapes true \u25e6 View the ECO nets and buffers in the GUI.\n \u25e6 Report the lengths of the DDR nets and the ECO nets."}
{"header": "How do I Introduction to Physical Datapath With Relative Placement", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The physical datapath with relative placement capability provides a way for you to create structures in which you specify the relative column and row positions of instances.\n During placement and legalization, these structures, which are placement constraints called relative placement structures, are preserved and the cells in each structure are placed as a single entity.\n Relative placement is also called physical datapath and structured placement.\n The concepts and tasks necessary for doing relative placement are described in these sections: \u2022 Introduction to Physical Datapath With Relative Placement \u2022 Relative Placement Flow \u2022 Creating Relative Placement Groups \u2022 Adding Objects to a Group \u2022 Specifying Options for Relative Placement Groups \u2022 Changing the Structures of Relative Placement Groups \u2022 Generating Relative Placement Groups for Clock Sinks \u2022 Performing Placement and Legalization of Relative Placement Groups \u2022 Analyzing Relative Placement Groups \u2022 Saving Relative Placement Information \u2022 Summary of Relative Placement Commands"}
{"header": "How do I Benefits of Relative Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Relative placement is usually applied to datapaths and registers, but you can apply it to any cell in your design, controlling the exact relative placement topology of gate-level logic groups and defining the circuit layout.\n You can use relative placement to explore QoR benefits, such as shorter wire lengths, reduced congestion, better timing, skew control, fewer vias, better yield, and lower dynamic and leakage power.\n       The relative placement constraints that you create and annotate implicitly generate a matrix structure of the instances and control the placement of the instances.\n You use the resulting annotated netlist for physical optimization, during which the tool preserves the structure and places it as a single entity or group, as shown in  Figure\u00a0166.\n Figure 166 Relative Placement in a Floorplan Relative placement groups can be floating or fixed.\n Obstructions Relative placement cells Macro Relative placement groups Standard cells"}
{"header": "How do I Relative Placement Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Along with being technology-independent and having the ability to improve routability, relative placement provides the following benefits: \u2022 Reduces the placement search space in critical areas of the design, which improves the predictability of QoR (wire length, timing, power, area) and congestion.\n \u2022 Maintains relative placement during placement, optimization, clock tree synthesis, and routing.\n \u2022 Provides a method for maintaining structured placement for legacy or intellectual property (IP) designs.\n       \u2022 Handles flat and hierarchical designs.\n \u2022 Allows sizing of relative placement cells while maintaining relative placement."}
{"header": "How do I Creating Relative Placement Groups", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The relative placement flow consists of the following steps: 1.\n Prepare the design as described in  Preparing the Design.\n 2.\n Specify placement constraints as described in  Setting Up Multivoltage Designs.\n 3.\n Define the relative placement constraints and settings.\n a.\n Create the relative placement groups by using the  create_rp_group command, as described in  Creating Relative Placement Groups.\n b.\n Add relative placement objects to the groups by using the  add_to_rp_group command.\n See  Adding Objects to a Group.\n c.\n Specify options for the relative placement groups by using the set_rp_group_options command, as described in  Specifying Options for Relative Placement Groups.\n 4.\n Perform placement and optimization.\n 5.\n Analyze the relative placement results as described in  Analyzing Relative Placement Groups.\n If the relative placement is not what you want, modify the relative placement group or the constraints and settings, and rerun placement and optimization."}
{"header": "How do I Adding Objects to a Group", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "A relative placement group is an association of cells, other relative placement groups, and blockages.\n A group is defined by the number of rows and columns it uses.\n Use the  create_rp_group command to create a relative placement group.\n When you do so, you must specify a name for the relative placement group by using the  -name option.\n You can specify the number of columns and rows for the relative placement group by using the  -columns and  -rows options.\n If you do not do so, the tool create a relative placement group with one row and column.\n       For example, to create a relative placement group named RP1 that has six columns and six rows, use the following command: fc_shell>\u00a0 create_rp_group -name RP1 -columns 6 -rows 6 Figure\u00a0167 shows the relative placementpositions for data positions of columns and rows in a relative placement group.\n Figure 167 Relative Placement Column and Row Positions 0 5 0 4 0 2 1 5 1 4 1 3 3 5 3 4 3 3 4 5 2 5 3 2 2 3 4 2 0 0 1 0 3 0 4 0 2 0 5 5 5 4 5 2 5 0 2 4 5 3 0 1 1 1 3 1 2 1 5 1 col 0 row 0 row 2 row 4 row 5 row 3 row 1 col 1 col 2 col 4 col 5 col 3 1 2 2 2 4 4 4 3 For the relative placement group in  Figure\u00a0167, \u2022 The column count begins from column 0 (the leftmost column).\n \u2022 The row count begins from row 0 (the bottom row).\n \u2022 The width of a column is the width of the widest cell in that column.\n \u2022 The height of a row is the height of the tallest cell in that row.\n \u2022 All positions in the structure are not used.\n For example, positions 0 3 (column 0, row 3) and 4 1 (column 4, row 1) are not used.\n By default, the tool creates the relative placement group in the current design.\n You can create it in a different design by specifying its name using the  -design option.\n If you create a relative placement group in a design that has multiple instantiations in a top-level design, the changes you make to the relative placement group in one instance is reflected in all its instances.\n To remove relative placement groups, use the  remove_rp_groups command."}
{"header": "How do I Adding Leaf Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you create a relative placement group by using the  create_rp_group command, you can add the following types of objects to it by using the  add_to_rp_group command: \u2022 Leaf cells, as described in  Adding Leaf Cells \u2022 Leaf cells, as described in  Adding Hard Macro Cells \u2022 Relative placement groups, as described in  Adding Relative Placement Groups \u2022 Blockages, as described in  Adding Blockages When you add an object to a relative placement group, \u2022 The relative placement group to which you are adding the object must exist.\n \u2022 The object must be added to an empty location in the relative placement group.\n \u2022 Only one object can be added in one location of relative placement group.\n To remove objects from a relative placement group, use the  remove_from_rp_group command.\n You can remove leaf cells ( -cells ), relative placement groups ( -rp_group ), and blockages ( -blockage ).\n When you remove objects from a group, the space previously occupied by the removed objects is left unoccupied."}
{"header": "How do I Specifying Orientations for Leaf Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add leaf cells, including physical only cells, to a relative placement group, use the -cells option with the  add_to_rp_group command.\n Specify the column and row position within the relative placement group at which to add the cell by using the  -column and  -row options.\n In a relative placement group, a leaf cell can occupy multiple column positions or multiple row positions, which is known as leaf cell straddling.\n To specify the number of columns and rows the cells occupies, use the  -num_columns and  -num_rows options respectively.\n If you do not set these options, the default is 1 for both the number of columns and rows.\n For example, to add a leaf cell that occupies two columns and one row at position (0,0), use fc_shell>\u00a0 add_to_rp_group rp1 -cells U23 \\ -column 0 -row 0 -num_columns 2 -num_rows 1 Straddling is for leaf cells only, and not for hierarchical groups or blockages."}
{"header": "How do I Adding Hard Macro Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can specify orientations for leaf cells when you add them to a relative placement group.\n If you do not specify a leaf cell orientation, the tool automatically assigns a legal orientation for the leaf cells.\n To specify the orientation for leaf cells, use one of the following two methods: \u2022 Use the  -orientation option with a list of possible orientations when you add the cells to the group with the  add_to_rp_group command.\n \u2022 Set the  rp_orientation attribute on leaf cells by using the  set_attribute command.\n physopt_rp_enable_orient_opt variablevariablesphysopt_rp_enable_orient_opt The tool chooses one legal orientation from the list of orientations that you provide."}
{"header": "How do I Adding Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  add_to_rp_group command supports hard macro cells.\n When you add macro cells to a relative placement group, you cannot specify \u2022 A pin name with which to align the macro cell by using the  -pin option \u2022 An orientation for the macro cells by using the  -orientation option When you add hard macro cells, use the following steps: 1.\n Create the relative placement groups, add the cells, including the hard macro cells, and specify the relative placement options and settings.\n 2.\n Place the design by using the  create_placement\u00a0-floorplan command.\n 3.\n Fix the placement of the hard macro cells in the relative placement groups by using the set_placement_status\u00a0fixed command.\n Before you can perform further placement and optimization, \u25e6 The hard macro cells in the relative placement groups must be placed and fixed \u25e6 The other cells in the relative placement groups that contain hard macro cells must be placed 4.\n Perform further placement and optimization."}
{"header": "How do I Creating Hierarchical Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Hierarchical relative placement allows relative placement groups to be embedded within other relative placement groups.\n The embedded groups then are handled similarly to leaf cells.\n       You can use hierarchical relative placement to simplify the expression of relative placement constraints.\n With hierarchical relative placement, you do not need to provide relative placement information multiple times for a recurring pattern.\n Using hierarchical relative placement provides these benefits: \u2022 Allows you to organize your relative placement in a manner that is easier to maintain and understand.\n For example, you can create the relative placement group to parallel your Verilog or VHDL organization.\n \u2022 Allows reuse of a repeating placement pattern, such as an adder.\n \u2022 Can reduce the number of lines of relative placement information you need to write.\n \u2022 Allows integrating blocks.\n \u2022 Provides flexibility for the configuration you want."}
{"header": "How do I Using Hierarchical Relative Placement for Straddling", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create a hierarchical relative placement group by adding a group to another group, use the  -rp_group option with the  add_to_rp_group command.\n Specify the column and row position within the relative placement group by using the  -column and  -row options.\n The group you specify with the  -rp_group option must be in the same design as the hierarchical group in which you are including it.\n When you include a relative placement group in a hierarchical group, it is as if the included group is directly embedded within its parent group.\n An included group can be used only in a group of the same design and only one time.\n However, a group that contains an included group can be further included in another group in the same design or can be instantiated in a group of a different design.\n The script in  Example\u00a043 creates a hierarchical group (rp4) that contains three included groups (rp1, rp2, and rp3).\n Groups rp1, rp2, rp3, and rp4 are all in the design top.\n The contents of groups rp1, rp2, and rp3 are treated as leaf cells when they are included in group rp4.\n You can further include group rp4 in another group in the design top, or you can instantiate group rp4 in a group of a different design.\n The resulting hierarchical relative placement group is shown in  Figure\u00a0168.\n Example 43 Including Groups in a Hierarchical Group create_rp_group\u00a0-name\u00a0rp1\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U4\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp2\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0U2\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0U5\u00a0-column\u00a01\u00a0-row\u00a00        create_rp_group\u00a0-name\u00a0rp3\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U3\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U6\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp4\u00a0-columns\u00a01\u00a0-rows\u00a03 add_to_rp_group\u00a0rp4\u00a0 -rp_group rp1 \\ -column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp4\u00a0 -rp_group rp2 \\ -column\u00a00\u00a0-row\u00a01 add_to_rp_group\u00a0rp4\u00a0 -rp_group rp3 \\ -column\u00a00\u00a0-row\u00a02 Figure 168 Including Groups in a Hierarchical Group rp3 rp2 rp1 U3 U2 U4 U5 U6 U1 rp4 rp1 U4 U1 U3 U6 rp2 U2 U5 rp3 col 0 col 1 col 0 col 1 col 0 col 1 row 0 row 0 row 0 row 2 row 0 row 1 col 0"}
{"header": "How do I Using Hierarchical Relative Placement for Compression", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A cell can occupy multiple column positions or multiple row positions, which is known as straddling.\n For more information about leaf cell straddling, see  Adding Leaf Cells.\n Figure\u00a0169 shows a relative placement group in which cells straddle columns (instance U2) and rows (instance U7).\n Figure 169 Hierarchical Relative Placement Group With Straddling U3 U4 U6 U1 U2 U7       Figure\u00a0170 shows the process of using hierarchical relative placement to build this structure.\n First, define relative placement groups that contain the leaf cells: rp1 contains U1 and U4, rp2 contains U2, and rp3 contains U3 and U6.\n Then define a group (rp4) that contains these groups.\n Finally, define a group (rp5) that contains the hierarchical group rp4 and the leaf cell U7.\n The resulting group includes both the column and the row straddle.\n Example\u00a044 shows the commands used in this process.\n Figure 170 Straddling With Hierarchical Relative Placement rp3 rp2 rp1 U3 U2 U4 U7 U6 U1 rp4 U4 U1 U2 U3 U6 rp1 rp2 rp3 rp5 U4 U1 U2 U3 U6 col 0 col 1 row 0 col 0 col 1 col 0 col 1 row 0 row 0 row 2 row 1 row 0 col 0 row 2 row 1 row 0 col 0 col 1 U7 col 1 row 2 row 1 row 0 rp4 Example 44 Straddling With Hierarchical Relative Placement create_rp_group\u00a0-name\u00a0rp1\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U4\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp2\u00a0-columns\u00a01\u00a0-rows\u00a01 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0U2\u00a0-column\u00a00\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp3\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U3\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U6\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp4\u00a0-columns\u00a01\u00a0-rows\u00a03 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp2\u00a0-column\u00a00\u00a0-row\u00a01 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp3\u00a0-column\u00a00\u00a0-row\u00a02  create_rp_group\u00a0-name\u00a0rp5\u00a0-columns\u00a02\u00a0-rows\u00a01       add_to_rp_group\u00a0rp5\u00a0-rp_group\u00a0rp4\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp5\u00a0-cells\u00a0U7\u00a0-column\u00a01\u00a0-row\u00a00"}
{"header": "How do I Adding Blockages", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, construction for relative placement aligns cells from their bottom-left corner.\n Compression removes empty space in rows to create a more compact structure.\n The columns are no longer aligned, and utilization is higher in the area of the compressed cells.\n Figure\u00a0171 shows the same cells aligned with and without compression.\n To create the compressed structure shown in this example, first create three relative placement groups, rp1, rp2, and rp3, that contains a row of leaf cells.\n Then create a group, rp4, that contains all these groups.\n  Example\u00a045 shows the commands used to build the compressed structure.\n Figure 171 Bottom-Left Alignment Construction and Compression rpA rpB rpC Without compression With compression U3 U6 U2 U5 U1 U4 U1 U2 U3 U6 U5 U4 rp3 rp2 rp1 rp4 Example 45 Compression With Hierarchical Relative Placement create_rp_group\u00a0-name\u00a0rp1\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U4\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp2\u00a0\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0U2\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0U5\u00a0-column\u00a01\u00a0-row\u00a00  create_rp_group\u00a0-name\u00a0rp3\u00a0-columns\u00a02\u00a0-rows\u00a01 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U3\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp3\u00a0-cells\u00a0U6\u00a0-column\u00a01\u00a0-row\u00a00        create_rp_group\u00a0-name\u00a0rp4\u00a0-columns\u00a01\u00a0-rows\u00a03 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp2\u00a0-column\u00a00\u00a0-row\u00a01 add_to_rp_group\u00a0rp4\u00a0-rp_group\u00a0rp3\u00a0-column\u00a00\u00a0-row\u00a02 Alternatively, you can apply compression in the horizontal direction by using the -tiling_type option with the  set_rp_group_options command, as described in Controlling the Tiling Within Relative Placement Groups."}
{"header": "How do I Adding Cells Within a Predefined Relative Placement Area", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add a blockage within relative placement groups, use the  -blockage option with the add_to_rp_group command.\n When you add a blockage using this command, you can specify \u2022 The column and row position within the relative placement group by using the  -column and  -row options.\n If you do not specify a position, the tool adds the blockage to position (0,0).\n \u2022 The size of the blockage by using the  -height and  -width options.\n If you do not specify the  -height or  -width option, the tool determines the size based on the tiling type of the relative placement group as follows: \u25e6 For a tiling type setting of  bit_slice, the height default to the height of site row and the width to width of the column.\n \u25e6 For a tiling type setting of  compression, the height default to the height of site row and the width to the width of one site.\n \u2022 That the blockages can overlap with other relative placement blockages or other objects that are not relative placement cells by using the  -allow_overlap option.\n The following example adds a blockage named gap1 to the rp1 relative placement group at position (0,2) that is one site row high and five site rows wide: fc_shell>\u00a0 add_to_rp_group rp1-blockage gap1 \\ -column 0 -row 2 -width 5 -height 1"}
{"header": "How do I Specifying Options for Relative Placement Groups", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add cells anywhere within a predefined area of a relative placement group, use the -free_placement option with the  add_to_rp_group command.\n With this option, you must specify \u2022 The origin of the placement area by using the  -column and  -row options \u2022 The height and width of the placement area by using the  -height and  -width options \u2022 The number of columns and rows the cells occupy by using the  -num_columns and -num_rows options For example, to add a leaf cell that occupies two columns and two rows to a placement area with a height of 4 and a width of 5 and is at position (0,0), use fc_shell>\u00a0 add_to_rp_group rp2 -cells U41 -free_placement \\ -column 0 -row 0 -height 4 -width 5 -num_columns 2 -num_rows 2"}
{"header": "How do I Anchoring Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify properties of relative placement groups, use the  set_rp_group_options command as described in  Table\u00a057.\n Table 57 Specifying Relative Placement Group Properties To do this Use this option   -x_offset -y_offset -x_offset  -y_offset   -anchor_corner   -alignment   -pin_name   -tiling_type   -group_orientation  -utilization       Table 57 Specifying Relative Placement Group Properties (Continued) To do this Use this option   -place_around_fixed_cells    -optimization_restriction    -move_effort To remove relative placement group option settings, use the  remove_rp_group_options command.\n You must specify the group name and at least one option; otherwise, this command has no effect."}
{"header": "How do I ...", "size": 21.973588943481445, "font": "Helvetica", "flags": 4, "text": "By default, the Fusion Compiler tool can place a relative placement group anywhere within the core area.\n You can control the placement of a top-level relative placement group by anchoring it.\n To anchor a relative placement group, use the  set_rp_group_options command with the -x_offset and  -y_offset options.\n The offset values are float values, in microns, relative to the lower-left corner in the core area.\n If you specify both the x- and y-coordinates, the group is anchored at that location.\n If you specify only one coordinate, the Fusion Compiler tool determines the placement by maintaining the specified coordinate and sliding the group along the line passing through the unspecified coordinate.\n To specify a corner of relative placement group to anchor it by, use the  -anchor_corner option.\n The tool places the relative placement group such that the corner specified by this option is placed on the anchor point specified by the  -x_offset and  -y_offset options.\n The settings for the  -anchor_corner option are as follows, and are shown in  Figure\u00a0172 : \u2022 bottom_left The anchor point of the relative placement group is set to its bottom-left corner.\n The default is the bottom-left corner.\n \u2022 bottom_right The anchor point of the relative placement group is set to its bottom-right corner.\n       \u2022 top_left The anchor point of the relative placement group is set to its top-left corner.\n \u2022 top_right The anchor point of the relative placement group is set to its top-right corner.\n \u2022 rp_location The anchor point of the relative placement group is the element in the relative placement group at the position specified by the  -anchor_row and  -anchor_column options.\n When you use the  -anchor_corner\u00a0rp_location setting, the position specified with the  -anchor_row and  -anchor_column options must contain a cell, keepout, or a relative placement hierarchy.\n Figure 172 Bottom-Left, Bottom-Right, Top-Left and Top-Right Anchor Corners Bottom-left anchor corner Bottom-right anchor corner Top-left anchor corner Top-right anchor corner For example, to anchor a relative placement by its bottom let corner at location (100, 100), as shown  Figure\u00a0173, use the following command: fc_shell>\u00a0 set_rp_group_options misc1 -anchor_corner bottom_left \\ -x_offset 100 -y_offset 100       Figure 173 Anchored Relative Placement Group I33 I32 I34 misc1 I30 I31 I35 I43 I42 I44 I40 I41 I45 I53 I52 I54 I50 I51 I55 (100,100)"}
{"header": "How do I Aligning Leaf Cells Within a Column", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following example specifies that relative placement cell at column 1, row 2 of the RP1 relative placement group should be anchored at location (100, 100).\n fc_shell>\u00a0 set_rp_group_options RP1 \\ -anchor_corner rp_location -anchor_column 1 -anchor_row 2 \\ -x_offset 100 -y_offset 100 Figure 174 Using an Object Within the Relative Placement Group for Anchoring The relative placement group is anchored by placing the cell at column 1 row 2 at location (100, 100) 0 0 1 1 2 3 3 4 2 4"}
{"header": "How do I Aligning by the Left Edges", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can align the leaf cells in a column of a relative placement group by using the following alignment methods: \u2022 Left alignment (default) \u2022 Right alignment \u2022 Pin alignment Controlling the cell alignment can improve the timing and routability of your design."}
{"header": "How do I Aligning by the Right Edges", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the Fusion Compiler tool aligns the leaf cells by aligning the left edges.\n To explicitly specify this alignment method, use the  -alignment\u00a0left option of the set_rp_group_options command.\n Figure\u00a0175 shows cells that are left aligned.\n Figure 175 Bottom-Left-Aligned Relative Placement Group U4 U3 U2 U1 row 3 row 2 row 1 row 0 col 0"}
{"header": "How do I Aligning by Pin Location", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To align a group by aligning the right edges, use the  -alignment\u00a0right option of the set_rp_group_options command.\n Note: For hierarchical relative placement groups, the bottom-right alignment does not propagate through the hierarchy.\n Figure\u00a0175 shows cells that are right aligned.\n       Figure 176 Bottom-Right-Aligned Relative Placement Group U4 U3 U2 U1 row 3 row 2 row 1 row 0 col 0"}
{"header": "How do I Overriding the Alignment When Adding Objects", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To align a group by pin location, use the  -alignment\u00a0pin and  -pin_name options with the set_rp_group_options command.\n The tool looks for the specified alignment pin in each cell in the column.\n If the alignment pin exists in a cell, the cell is aligned by using the pin location.\n If the specified alignment pin does not exist in a cell, the cell is aligned by the left edge, and the tool issues an information message.\n If the specified alignment pin does not exist in any cell in the column, the Fusion Compiler tool issues a warning message.\n The script in  Example\u00a046 creates a relative placement group rp1, adds cells to it, and specifies that the cells are aligned by pin A.\n Example 46 Definition for Relative Placement Group Aligned by Pins create_rp_group\u00a0-name\u00a0rp1\u00a0-columns\u00a01\u00a0-rows\u00a04 set_rp_group_options\u00a0-alignment\u00a0pin\u00a0-pin_name\u00a0A add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U1\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U2\u00a0-column\u00a00\u00a0-row\u00a01 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U3\u00a0-column\u00a00\u00a0-row\u00a02 add_to_rp_group\u00a0rp1\u00a0-cells\u00a0U4\u00a0-column\u00a00\u00a0-row\u00a03 When aligning by pins, the tool tries different orientations for the cells and selects the orientation for each cell that gives the minimum column width.\n For example, changing the orientation of cell U2, as shown in  Figure\u00a0177, reduces the width of column 0.\n However, if you specify an orientation when adding a cell to a relative placement group by using the -cells and  -orientation options with the  add_to_rp_group command, the tool honors the orientation you specify.\n       Figure 177 Minimizing the Column Width of a Relative Placement Group Aligned by Pins U4 U3 U2 U1 row 3 row 2 row 1 row 0 column 0 Pin A U4 U3 U2 U1 row 3 row 2 row 1 row 0 column 0 When you specify an alignment pin for a group, the pin applies to all cells in the group.\n You can override the group alignment pin for specific cells in the group by specifying the -pin_name option when you use the  add_to_rp_group command to add the cells to the group.\n The script in  Example\u00a047 defines relative placement group rp2, and specified pin A as the group alignment pin.\n However, instances I5 and I6 use pin B as their alignment pin, rather than the group alignment pin.\n The resulting structure is shown in  Figure\u00a0178.\n Example 47 Definition for Aligning a Group and Leaf Cells by Pins create_rp_group\u00a0-name\u00a0rp2\u00a0-columns\u00a01\u00a0-rows\u00a06 set_rp_group_options\u00a0rp2\u00a0-alignment\u00a0pin\u00a0-pin_name\u00a0A add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I3\u00a0-column\u00a00\u00a0-row\u00a00 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I4\u00a0-column\u00a00\u00a0-row\u00a01 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I5\u00a0-column\u00a00\u00a0-row\u00a02\u00a0-pin_name\u00a0B add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I6\u00a0-column\u00a00\u00a0-row\u00a03\u00a0-pin_name\u00a0B add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I7\u00a0-column\u00a00\u00a0-row\u00a04 add_to_rp_group\u00a0rp2\u00a0-cells\u00a0I8\u00a0-column\u00a00\u00a0-row\u00a05       Figure 178 Relative Placement Group Aligned by Different Pins I5 I4 I3 row 3 row 2 row 1 row 0 col 0 I6 I7 I8 row 4 row 5 Pin A Pin B"}
{"header": "How do I Controlling the Tiling Within Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you add an object to a relative placement group by using the  add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the  -override_alignment option.\n However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option.\n The following example creates a relative placement group named rp1 that is right aligned.\n It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell>\u00a0 create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell>\u00a0 set_rp_group_options rp1 -alignment right fc_shell>\u00a0 add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell>\u00a0 add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell>\u00a0 add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell>\u00a0 add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement.\n       Figure 179 Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}
{"header": "How do I Applying Compression to Groups With Straddling Leaf Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To control the tiling of objects within a relative placement group, use the set_rp_group_options\u00a0-tiling_type command with the settings shown in the following table.\n Table 58 Controlling Placement With the set_rp_group_options -tiling_type Command To do this Use this setting   \u2022  \u2022  bit_slice    horizontal_compression   vertical_compression       Figure 180 Bit-Slice Placement Versus Horizontal or Vertical Compression 4 3 2 1 0 0 1 3 4 2 Bit-slice placement 4 3 2 1 0 0 1 3 4 2 4 3 2 1 0 0 1 3 4 2 Vertical compression Horizontal compression The setting of the  -tiling_type option is not propagated from a parent group to child groups."}
{"header": "How do I Specifying the Orientation of Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can apply compression to a relative placement group with cells that straddle multiple rows or columns, as shown in the following example: fc_shell>\u00a0 add_to_rp_group rp -cells U5 \\ -column 0 -row 0 -num_columns 1 -num_rows 2 fc_shell>\u00a0 set_rp_group_options rp -tiling_type horizontal_compression Figure\u00a0181 shows the placement of the relative placement group in the previous example.\n Figure 181 Compression of a Relative Placement Group With a Cell That Straddles Multiple Rows 4 3 2 1 0 0 1 3 4 2 Cell U5 straddles two rows For information about adding cells that straddle multiple rows or columns to a relative placement group, see  Adding Leaf Cells."}
{"header": "How do I Specifying a Keepout Margin", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports the following orientations for relative placement groups: \u2022 R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top.\n \u2022 R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom.\n \u2022 MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation.\n \u2022 MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation.\n Figure\u00a0182 shows how the column and row positions in a relative placement group are placed for the four orientations.\n       Figure 182 Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length.\n You can also choose to set the orientation of relative placement groups by using the  set_rp_group_options command.\n For example, the following command sets the relative placement group orientation to MY.\n fc_shell>\u00a0 set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy.\n       Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}
{"header": "How do I Handling Fixed Cells During Relative Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To prevent other relative placement groups from being placed close to a specific relative placement group, you can specify a keepout margin that applies only to other relative placement groups.\n To do so, use the  -rp_only_keepout_margin option with the set_rp_group_options command.\n You can specify a different margin for the left, bottom, right, and top sides of the group.\n The following command applies a margin of 15 on the left and right and a margin of 10 on the top and bottom of the relative placement group named rp1: fc_shell>\u00a0 set_rp_group_options rp1 \\ -rp_only_keepout_margin {15 10 15 10}"}
{"header": "How do I Allowing Nonrelative Placement Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To specify how to handle fixed cells in the floorplan during legalization of relative placement groups, use the  -place_around_fixed_cells option with the set_rp_group_options command.\n  Table\u00a059  shows the different settings you can specify for the  -place_around_fixed_cells option.\n Table 59 Settings for the -place_around_fixed_cells Option To do this Use this setting   standard   physical_only   all  none For hierarchical relative placement groups, you can use the  set_rp_group_options -place_around_fixed_cells command and specify different settings for the top-level and the lower-level relative placement groups.\n If you do not specify a setting for the lower- level placement groups, the value of the top-level relative placement group is used for the lower-level relative placement groups.\n       Assume a hierarchical relative placement group named top-rp contains three lower-level relative placement groups named rp1, rp2, and rp3.\n The following example specifies a less restrictive setting for the top level and a more restrictive setting for the lower-level group named rp1.\n It also specifies that the setting for the rp1 lower-level group overrides the top- level setting when legalizing the cells in the rp1 group.\n fc_shell>\u00a0 set_rp_group_options top-rp \\ -place_around_fixed_cells physical_only fc_shell>\u00a0 set_rp_group_options rp1 \\ -place_around_fixed_cells none fc_shell>\u00a0 set_app_options -name set_rp_group_options -value true"}
{"header": "How do I Controlling the Optimization of Relative Placement Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, nonrelative placement cells are \u2022 Not allowed within relative placement groups during coarse placement \u2022 Allowed within relative placement groups during optimization and legalization To reduce congestion and improve QoR, you can allow the tool to place nonrelative placement cells within the unused areas of a specific relative placement group by using the  -allow_non_rp_cells option with the  set_rp_group_options command.\n You can add blockages to relative placement group by using the  -blockage option with the  add_to_rp_group command.\n By default, no cells are allowed within these blockages during placement, optimization, and legalization.\n To allow nonrelative placement cells within relative placement blockages and unused areas of a specific relative placement group, use the  -allow_non_rp_cells_on_blockages option with the set_rp_group_options command.\n The following example allows nonrelative placement cells within the unused areas of the RP1 relative placement group: fc_shell>\u00a0 set_rp_group_options rp1 \\ -allow_non_rp_cells The following example allows nonrelative placement cells within the blockages and unused areas of the RP2 relative placement group: fc_shell>\u00a0 set_rp_group_options rp2 \\ -allow_non_rp_cells_on_blockages"}
{"header": "How do I Controlling Movement When Legalizing Relative Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed.\n When a relative placement cell is removed during optimization, the relative       placement information of the instance is also removed, disrupting the relative placement structure.\n To preserve the relative placement structures during various postplacement optimization processes, use the  -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table\u00a060.\n Table 60 Settings for the -optimization_restriction Option To do this Use this setting  all_opt  size_only  size_in_place  no_opt For a hierarchical relative placement group, the  -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}
{"header": "How do I Handling Tap Columns and Relative Placement Group Overlaps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can control the movement of a relative placement group during legalization by using the  -move_effort option of the  set_rp_group_options command.\n During coarse placement, the tool estimates an initial location for every top-level relative placement group.\n The  -move_effort option controls the extent to which a relative placement group can be moved from its initial location to preserve the relative placement without violating relative placement constraints.\n When you change the option setting from a higher effort level to a lower effort level, you reduce the size of the region searched for placement of a relative placement group."}
{"header": "How do I Changing the Structures of Relative Placement Groups", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the  place.coarse.no_split_rp_width_threshold application option.\n The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns.\n This application option helps the relative placement engine know about the distance between the tap columns.\n       This helps in better placement and structures of relative placement groups in the design.\n You must use this application option for n5 and older technical nodes.\n For n3 and beyond designs, the distance between tap columns is calculated automatically.\n place.coarse.no_split_rp_width_threshold\u00a0<value> For\u00a0example, place.coarse.no_split_rp_width_threshold\u00a046"}
{"header": "How do I Generating Relative Placement Groups for Clock Sinks", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To modify the structures of existing relative placement groups, use the  modify_rp_groups command as follows: \u2022 To add a row or column to a relative placement group, use the  -add_rows or -add_columns option respectively.\n \u2022 To remove a row or column, use the  -remove_rows or  -remove_columns option respectively.\n \u2022 To flip a row or column, use the  -flip_row or  -flip_column option respectively.\n \u2022 To swap two rows or columns, use the  -swap_rows or  -swap_columns option respectively.\n For example, to swap the first and third columns of the my_rp_group relative placement group, as shown in  Figure\u00a0183, enter fc_shell>\u00a0 modify_rp_groups [get_rp_groups my_rp_group] \\ -swap_columns {0 2} Figure 183 Swapping Columns of a Relative Placement Group Col 0 Col 1 Col 2 Col 0 Col 1 Col 2 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 C00 C01 C02 C21 C20 C22 C20 C21 C22 C01 C00 C02       To flip the second column of the my_rp_group relative placement group, as shown in Figure\u00a0184, enter fc_shell>\u00a0 modify_rp_groups [get_rp_groups my_rp_group] \\ -flip_column 1 Figure 184 Flipping a Column of a Relative Placement Group Col 0 Col 1 Col 2 Col 0 Col 1 Col 2 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 C10 C11 C12 C12 C11 C10"}
{"header": "How do I Performing Placement and Legalization of Relative Placement", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can generate a relative placement group for clock sinks and their drivers in a placed design by using the  create_clock_rp_groups command.\n When you run placement and optimization, the tool places the clocks sinks and their drivers based on their relative placement constraints it generated.\n This can improve routability and reduce dynamic power.\n You can control the sinks being considered for relative placement groups as follows: \u2022 Specify the minimum and maximum of sinks that should be driven by a single driver to be considered by using the  -min_sinks and  -max_sinks options.\n The default minimum is 2 sinks and the default maximum is 128 sinks.\n \u2022 Exclude timing critical sinks by using the  -timing_driven option.\n By default, the tool excludes all sinks with a negative slack.\n \u2022 Specify the cells to consider by using the  -cells option.\n B default, the tool considers all the sinks.\n       You can control the size and shape of the relative placement group by using one of the following methods: \u2022 Specify the maximum allowed Manhattan distance between the sinks in one relative placement group by using the  -distance option.\n If the Manhattan distance between sinks is more than the specified distance, they are put into separate relative placement groups.\n The default distance is 100 microns.\n \u2022 Specify a maximum number of rows by using the  -max_rp_rows option.\n The default is 32.\n \u2022 Allow the tool to decide the number of rows and columns based on the distribution of the cells by using the  -auto_shape option.\n Before you run the  create_clock_rp_groups command, the block must be placed.\n After you create the clock relative placement groups, reset the placement of the block by using the  reset_placement command, and rerun placement and optimization by using the place_opt command."}
{"header": "How do I Relative Placement in a Design Containing Obstructions", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics provide information related to the placement and legalization of relative placement groups: \u2022 Relative Placement in a Design Containing Obstructions \u2022 Legalizing Relative Placement Groups in a Placed Design \u2022 Creating New Relative Placement Groups in a Placed Design"}
{"header": "How do I Legalizing Relative Placement Groups in a Placed Design", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During placement, relative placement groups avoid placement blockages (obstructions) that are defined in the DEF file or created by the  create_placement_blockage command.\n A relative placement group can be broken into pieces that straddle obstructions, yet maintain the relative placement structure.\n If the height of the obstruction is below a certain threshold, the relative placement cells are shifted vertically; otherwise, the relative placement column is shifted horizontally.\n Figure\u00a0185 shows the placement of relative placement cells in a design containing obstructions that are either defined in the DEF file or created by create_placement_blockage.\n The obstruction in columns one and two is below the       threshold, so the tool shifts the cells vertically.\n The obstruction in column four is greater than the threshold, so the tool shifts all the cells of the column horizontally.\n Figure 185 Relative Placement in a Design Containing Obstructions 0 4 0 0 4 4 4 3 4 1 4 2 0 1 4 0 col 0 row 0 row 2 row 4 row 3 row 1 col 1 col 2 col 4 col 3 0 3 0 2 1 4 1 3 1 0 1 1 1 2 2 4 2 3 2 0 2 2 2 1 3 4 3 3 3 1 3 2 3 0 Obstruction Obstruction"}
{"header": "How do I Creating New Relative Placement Groups in a Placed Design", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can improve the placement of relative placement groups in a placed design by legalizing only the relative placement groups.\n To legalize the placement of only the relative placement groups, but not nonrelative placement cells, use the  legalize_rp_groups command.\n You can also specify a list of relative placement groups to be legalized.\n To perform a fast legalization of the relative placement groups, use the  -prototype option.\n When you use this option, the tool does not ensure that all legalization constraints are met.\n Therefore, use it during the prototyping stages of the design flow when you are developing relative placement groups.\n To specify that relative placement groups can overlap with each other, use the -legalize_over_rp option.\n For example, the following command legalizes the RP3 relative placement group over the RP1 and RP2 relative placement groups.\n fc_shell>\u00a0 legalize_rp_groups -legalize_over_rp RP3 Figure\u00a0186 shows the placement before and after running the command.\n       Figure 186 Legalizing the RP3 Relative Placement Group Over Other Groups RP1 RP2 RP1 RP2 RP3 After you legalize one or more relative placement groups by using the legalize_rp_groups command, there might be overlaps with cells in other relative placement groups or cells that are not in relative placement groups.\n Use the  check_legality command to identify any cell overlaps and use the legalize_placement command to resolve any remaining cell overlaps."}
{"header": "How do I Analyzing Relative Placement Groups", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create a new relative placement group of cells in a placed design and relative placementincremental relative placement place the relative placement groups incrementally by using the  place_opt\u00a0-from\u00a0final_place command.\n If you select cells that are placed far apart in the initial placement for the same relative placement group, performing incremental relative placement might degrade the QoR.\n The following example shows how to add a new relative placement group to a design that is already placed and optimized, and performs incremental placement and optimization: fc_shell>\u00a0 create_rp_group -name new_rp -columns 1 -rows 2 fc_shell>\u00a0 add_to_rp_group new_rp -cells U1 -column 0 -row 0 fc_shell>\u00a0 add_to_rp_group new_rp -cells U2 -column 0 -row 1...\n fc_shell>\u00a0 place_opt -from final_place For a placed design, if you create a new relative placement group and specify an anchor location by using the  -x_offset and  -y_offset options with the  set_rp_group_options command, you can use the  legalize_rp_groups command to legalizes the newly created group anchored by the specified x- and y-coordinates.\n Using the       legalize_rp_groups command for incremental relative placement groups reduces the turnaround time."}
{"header": "How do I Checking Relative Placement Groups Before Placement", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following sections explain methods for analyzing your relative placement groups: \u2022 Checking Relative Placement Groups Before Placement \u2022 Analyzing the Placeability of a Relative Placement Group \u2022 Reporting Relative Placement Constraint Violations \u2022 Querying Relative Placement Groups \u2022 Analyzing Relative Placement in the GUI"}
{"header": "How do I Analyzing the Placeability of a Relative Placement Group", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run placement and optimization, you can check the relative placement constraints for issues that might lead to critical or noncritical failures after placement by using the  check_rp_constraints command.\n The following example checks for possible relative placement constraint violation in the group named rp_volt1: fc_shell>\u00a0 check_rp_constraints rp_volt1  ********************************************************************** *** Report\u00a0:\u00a0Relative\u00a0Placement\u00a0Summary Total\u00a0number\u00a0of\u00a0specified\u00a0top\u00a0level\u00a0relative\u00a0placement\u00a0groups:\u00a01 Total\u00a0number\u00a0of\u00a0relative\u00a0placement\u00a0groups\u00a0which\u00a0may\u00a0not\u00a0honor\u00a0its constraints:\u00a01 ************************************************************************* RP\u00a0Group:\u00a0rp_volt1 ------------------------------------------------------------------------- Warning:\u00a0The\u00a0height\u00a0of\u00a0relative\u00a0placement\u00a0group\u00a0'rp_volt1'\u00a0is\u00a0more\u00a0than the\u00a0height\u00a0of\u00a0voltage\u00a0area\u00a0or\u00a0exclusive\u00a0move\u00a0bound.\n (RPGP-018)"}
{"header": "How do I Reporting Relative Placement Constraint Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you run placement and optimization, you can check if a specific relative placement group can be placed by using the  check_rp_constraints\u00a0-analyze_placement command.\n \u2022 To limit the analysis to a specific region or a specific number of random sites of the core area, use the  -region or  -trials option, respectively.\n \u2022 To ignore physical design constraints, advanced design rules, or relative placement constraints during placement analysis, use the  -no_pdc,  -no_adv, or -no_rp_constraints option, respectively.\n \u2022 To report only the relative placement groups that do not meet a specific threshold, use the  -threshold option.\n The tool reports a group only if the percentage of sites the group can be placed, relative to the total number of sites analyzed, is less than the specified threshold."}
{"header": "How do I Querying Relative Placement Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you run placement and optimization, use the  report_rp_groups command to identify placement issues and relative placement violations.\n You must either specify which relative placement groups to analyze or specify the  -all option to analyze all relative placement groups.\n By default, the command reports the following types of relative placement groups: \u2022 Placed groups that do not have constraint violations \u2022 Placed groups that have constraint violations that are not critical \u2022 Failed groups that have constraint violations that are critical \u2022 Groups that have not yet been placed You can modify the default behavior by using the options described in  Table\u00a061.\n Table 61 The report_rp_groups Command Options To do this Use this option   -critical   -non_critical   -unplaced       Table 61 The report_rp_groups Command Options (Continued) To do this Use this option  -verbose You can also run this command before you run placement and optimization and identify the unplaced groups in the design."}
{"header": "How do I Analyzing Relative Placement in the GUI", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To query relative placement groups that contain specific objects or attribute values, use the  get_rp_groups command.\n For example, the following command returns a collection consisting of all the relative placement groups: fc_shell>\u00a0 get_rp_groups {RP_TA\u00a0RP_TCO\u00a0RP_HO_1\u00a0RP_HO_2\u00a0RP_HO_3\u00a0RP_HO_4\u00a0RP_THO} The following command returns only the top-level relative placement groups: fc_shell>\u00a0 get_rp_groups -top {RP_TA\u00a0RP_TCO\u00a0RP_THO} The following command returns the relative placement group that contains the leaf cell named U129: fc_shell>\u00a0 get_rp_groups -of_objects U129 {RP_HO_4}"}
{"header": "How do I Saving Relative Placement Information", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler GUI provides tools to help you visualize and analyze the relative placement groups in your design: \u2022 Relative Placement (RP) Groups Visual Mode \u2022 Relative Placement (RP) Net Connection Visual Mode For more information about analyzing relative placement groups in the GUI, see the  Using Map and Visual Modes topic in the  Fusion Compiler Graphical User Interface User Guide."}
{"header": "How do I Summary of Relative Placement Commands", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The relative placement information is automatically saved in the design library database when you save the design by using the  save_lib command.\n You can also save the relative placement information to a file that contains Tcl commands that re-creates the relative placement groups, their objects, and their settings.\n To do so, use the  write_rp_groups\u00a0-file_name command.\n You must either specify which relative placement groups to write commands for or specify the  -all option to write commands for all relative placement groups.\n By default, the  write_rp_groups command writes out commands for creating the specified relative placement groups and to add leaf cells, hierarchical groups, and blockages to these groups.\n The commands for generating subgroups within hierarchical groups are not written.\n You can modify the default behavior by using the options described in  Table\u00a062.\n Table 62 The write_rp_groups Command Options To do this Use this option    -hierarchical create_rp_group  -create add_to_rp_group\u00a0-cells  -cell add_to_rp_group\u00a0-rp_group  -rp_group add_to_rp_group\u00a0-blockage  -blockage"}
{"header": "How do I 11", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "Table\u00a063 shows some of the key commands used to perform relative placement.\n Table 63 Relative Placement Commands Command Described in section create_rp_group  remove_rp_groups  add_to_rp_group  remove_from_rp_group        Table 63 Relative Placement Commands (Continued) Command Described in section set_rp_group_options  remove_rp_group_options  modify_rp_groups  legalize_rp_groups  check_rp_constraints  report_rp_groups  get_rp_groups  write_rp_groups"}
{"header": "How do I Performing Hierarchical Synthesis Using Abstracts", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following topics describe how to perform synthesis, placement, optimization, clock tree synthesis, routing, and postroute optimization on hierarchical designs.\n \u2022 Performing Hierarchical Synthesis Using Abstracts \u2022 Performing Hierarchical Synthesis Using ETMs \u2022 Performing Prechecks for Hierarchical Synthesis Flows \u2022 Providing Block-Level Test Models \u2022 Specifying Block-Level Power Intent \u2022 Overview of Abstract Views \u2022 Creating Abstract Views \u2022 Reporting Abstract Inclusion Reasons \u2022 Making Changes to a Block After Creating an Abstract \u2022 Creating a Frame View \u2022 Linking to Abstract Views at the Top-Level \u2022 Changing the Block From Abstract to Design View \u2022 Linking to Subblocks With Multiple Labels \u2022 Specifying the Editability of Blocks From the Top-Level \u2022 Preparing for Top-Level Closure With Abstracts \u2022 Checking Designs With Abstracts for Top-Level-Closure Issues \u2022 Performing Top-Level Closure With Abstract Views \u2022 Creating ETMs and ETM Cell Libraries \u2022 Linking to ETMs at the Top Level \u2022 Performing Top-Level Closure With ETMs \u2022 Transparent Hierarchy Optimization"}
{"header": "How do I Partitioning and Planning the Full Chip Design", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The hierarchical synthesis flow using abstracts consists of the following major steps: 1.\n Partition the design at the top-level and generate the design libraries for the lower-level blocks as described in  Partitioning and Planning the Full Chip Design.\n 2.\n Synthesize each lower-level block and generate the block-level information required for top-level synthesis as described in  Synthesizing a Subblock.\n 3.\n Synthesize the top-level as described in  Synthesizing the Top-Level.\n See Also \u2022 Overview of Abstract Views \u2022 Creating Abstract Views \u2022 Creating a Frame View"}
{"header": "How do I Hierarchical Synthesis Flow When Floorplans are not Available", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The hierarchical synthesis flow using abstracts includes the following two cases: \u2022 Floorplans of subblock and top-level design are not available \u2022 Floorplans of subblock and top-level design are available"}
{"header": "How do I Hierarchical Synthesis Flow When Floorplans are Available", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To partition and plan the top-level design and create the lower-level blocks for subsequent bottom-up synthesis, when the floorplans of subblock and top-level design are not available, perform the following steps: Figure 187 Hierarchical Synthesis Flow When Floorplans are not Available 1.\n Read in the full chip design and apply constraints as shown in the following example: fc_shell>\u00a0 set REF_LIBS \"stdcell.ndm macro.ndm\" fc_shell>\u00a0 create_lib TOP -technology techfile \\ -ref_libs $REF_LIBS fc_shell>\u00a0 analyze -format verilog $rtl_files fc_shell>\u00a0 elaborate TOP fc_shell>\u00a0 set_top_module TOP  fc_shell>\u00a0 load_upf fullchip.upf fc_shell>\u00a0 read_sdc fullchip.sdc 2.\n Identify the design partitions and split the constraints as shown in the following example: fc_shell>\u00a0 set_budget_options -add_blocks {BLOCK1 BLOCK2} fc_shell>\u00a0 split_constraints 3.\n Create the subblock design libraries with design information and enable block-specific reference library setup as shown in the following example: fc_shell>\u00a0 copy_lib -to_lib BLOCK1.nlib -no_design fc_shell>\u00a0 copy_lib -to_lib BLOCK2.nlib -no_design       fc_shell>\u00a0 set_attribute -objects BLOCK1.nlib \\ -name use_hier_ref_libs -value true fc_shell>\u00a0 set_attribute -objects BLOCK2.nlib \\ -name use_hier_ref_libs -value true fc_shell>\u00a0 save_lib -all 4.\n Create the subblock design partitions as shown in the following example: fc_shell>\u00a0 commit_block -library BLOCK1.nlib BLOCK1 fc_shell>\u00a0 commit_block -library BLOCK2.nlib BLOCK2 fc_shell>\u00a0 save_lib -all 5.\n Load the UPF and SDC constraints for the unmapped subblocks and the top-level, which are generated by the  split_constraints command earlier as shown in the following example: fc_shell>\u00a0 set_constraint_mapping_file./split/mapfile fc_shell>\u00a0 load_block_constraints -all_blocks -type SDC  \\ -type UPF -type CLKNET fc_shell>\u00a0 save_lib -all 6.\n Run the  compile_fusion command until logic optimization with auto floorplanning for sub blocks is complete as shown in the following example: fc_shell>\u00a0 compile_fusion -to logic_opto 7.\n Run the  compile_fusion command until technology mapping for the top-level design is complete as shown in the following example: fc_shell>\u00a0 compile_fusion -to initial_map 8.\n Perform design planning operations starting from floorplan initialization, subblock and voltage area shaping, hard macro and standard cell placement, power network creation until pin assignment.\n 9.\n Run the  compile_fusion command until logic optimization for the top-level design is complete as shown in the following example: fc_shell>\u00a0 compile_fusion -from logic_opto -to logic_opto 10.\n Perform incremental top-level only standard cell placement as shown in the following example: fc_shell>\u00a0 create_placement -floorplan -use_seed_locs 11.\n Perform timing estimation and budgeting steps to generate the block budgets needed for block level implementation.\n 12.\n After completing the design planning operations, rebuild the subblock and top-level design by opening the elaborated RTL NDM, loading floorplan, feedthroughs and budgets."}
{"header": "How do I Synthesizing a Subblock", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To partition and plan the top-level design and create the lower-level blocks for subsequent bottom-up synthesis, when the floorplans of subblock and top-level design are available, perform the following steps: Figure 188 Hierarchical Synthesis Flow When Floorplans are Available 1.\n Read in the full chip design and apply constraints as shown in the following example: fc_shell>\u00a0 set REF_LIBS \"stdcell.ndm macro.ndm\" fc_shell>\u00a0 create_lib TOP -technology techfile \\ -ref_libs $REF_LIBS fc_shell>\u00a0 analyze -format verilog $rtl_files fc_shell>\u00a0 elaborate TOP fc_shell>\u00a0 set_top_module TOP  fc_shell>\u00a0 load_upf fullchip.upf fc_shell>\u00a0 read_sdc fullchip.sdc 2.\n For the design partitions, split the constraints as shown in the following example: fc_shell>\u00a0 set_budget_options -add_blocks {BLOCK1 BLOCK2} fc_shell>\u00a0 split_constraints 3.\n Create the subblock design libraries with design information and enable block-specific reference library setup as shown in the following example: fc_shell>\u00a0 copy_lib -to_lib BLOCK1.nlib -no_design fc_shell>\u00a0 copy_lib -to_lib BLOCK2.nlib -no_design fc_shell>\u00a0 set_attribute -objects BLOCK1.nlib \\       -name use_hier_ref_libs -value true fc_shell>\u00a0 set_attribute -objects BLOCK2.nlib \\ -name use_hier_ref_libs -value true fc_shell>\u00a0 save_lib -all 4.\n Create the subblock design partitions as shown in the following example: fc_shell>\u00a0 commit_block -library BLOCK1.nlib BLOCK1 fc_shell>\u00a0 commit_block -library BLOCK2.nlib BLOCK2 fc_shell>\u00a0 save_lib -all 5.\n Load the UPF and SDC constraints for the unmapped subblocks as well as the top- level, which are generated by the  split_constraints command earlier as shown in the following example: fc_shell>\u00a0 set_constraint_mapping_file./split/mapfile fc_shell>\u00a0 load_block_constraints -all_blocks -type SDC  \\ -type UPF -type CLKNET fc_shell>\u00a0 save_lib -all 6.\n Load the floorplan for the subblocks and top-level design.\n 7.\n Run the  compile_fusion command until logic optimization for the subblocks and top- level design is complete as shown in the following example: fc_shell>\u00a0 compile_fusion -to logic_opto 8.\n Perform standard cell placement followed by the pin assignment, timing estimation and budgeting.\n 9.\n After completing the design planning operations, rebuild the subblock and top-level design by opening the elaborated RTL NDM, loading floorplan, feedthroughs and budgets.\n Note: For details about each of the design planning operation, see the  Design Planning User Guide."}
{"header": "How do I Synthesizing the Top-Level", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1.\n Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design.\n 2.\n Apply any block-specific constraints and settings required for synthesizing the block.\n       3.\n Apply DFT settings by using commands such as  set_dft_signal, set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command.\n 4.\n Insert DFT logic and synthesize the block by using the following commands: fc_shell>\u00a0 compile_fusion -to logic_opto fc_shell>\u00a0 insert_dft fc_shell>\u00a0 compile_fusion -from initial_place 5.\n Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell>\u00a0 create_abstract -read_only fc_shell>\u00a0 create_frame fc_shell>\u00a0 write_test_model BLOCK1.ctl fc_shell>\u00a0 save_block -as BLOCK1/PostSynthesis"}
{"header": "How do I Performing Hierarchical Synthesis Using ETMs", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To synthesize the top-level, perform the following steps: 1.\n Read in the top-level design generated after the rebuild step as described in Partitioning and Planning the Full Chip Design.\n 2.\n Set appropriate settings and link the top-level design as shown in the following example: fc_shell>\u00a0 set_label_switch_list \\ -reference {BLOCK1 BLOCK2} PostCompile fc_shell>\u00a0 set_attribute -objects {BLOCK1.nlib BLOCK2.nlib} \\ -name use_hier_ref_libs -value true fc_shell>\u00a0 set_top_module TOP When a subblock has been saved in the design library using labels, use the set_label_switch_list command to specify which label to link to.\n The set_top_module command links the specified top-level module.\n 3.\n Apply any block-specific constraints and settings required for synthesizing the top block and read in the test models for the subblocks as shown in the following example: fc_shell>\u00a0 read_test_model BLOCK1.ctl fc_shell>\u00a0 read_test_model BLOCK2.ctl fc_shell>\u00a0 create_test_protocol 4.\n Insert DFT logic and synthesize the top-level design by using the following commands: fc_shell>\u00a0 compile_fusion -to initial_opto fc_shell>\u00a0 insert_dft fc_shell>\u00a0 compile_fusion -from initial_place"}
{"header": "How do I Running the Hierarchical Synthesis Feasibility Analysis Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the hierarchical flow, block designs are represented as a macro with a frame view, and the implemented blocks are modeled as extracted timing models (ETMs) for the top- level implementation of the design.\n An extracted timing model (ETM) is a Liberty model representation of a design that is generated by the  extract_model command in the PrimeTime tool.\n The command captures the timing and power information of the design using relevant Liberty attributes, as shown in the following example.\n library(\"block1\")\u00a0{...\n comment\u00a0:\u00a0\"PrimeTime\u00a0Extracted\u00a0Model.\"\u00a0; voltage_map(\"nom_voltage\",\u00a01.08); voltage_map(\"VDD\",\u00a01.08);...\n cell(\u00a0block1\u00a0)\u00a0{ timing_model_type\u00a0:\u00a0\"extracted\";...\n pg_pin(\"VDD\")\u00a0{ voltage_name\u00a0:\u00a0\"VDD\"; pg_type\u00a0:\u00a0primary_power; }...\n Topics in this section \u2022 Running the Hierarchical Synthesis Feasibility Analysis Flow Using ETMs \u2022 Running the Hierarchical Synthesis Flow Using ETMs \u2022 Example Script of Hierarchical Synthesis Using ETMs See Also \u2022 SolvNet article 2284429, \"Top-level Closure Flow With Extracted Timing Models (ETMs)\" \u2022 Creating ETMs and ETM Cell Libraries \u2022 Linking to ETMs at the Top Level"}
{"header": "How do I Running the Hierarchical Synthesis Flow Using ETMs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To minimize the number of iterations and obtain optimal results, you can perform feasibility analysis before running hierarchical synthesis, as shown in  Figure\u00a0189.\n The hierarchical synthesis feasibility flow uses the following block-level information generated post  compile_fusion : \u2022 Floorplanning information to generate the ETM in step 2 \u2022 Power intent and test model (CTL) information for top-level synthesis in step 4       Figure 189 Hierarchical Synthesis Feasibility Analysis 1.\n  Synthesize the block in the front- end tool compile_fusion RTL Block UPF (front end) Block CTL (front end) UPF SDC, floorplan SDC Design (ndm) Netlist UPF \u2019 CTL SPEF Design (frame) 2.\n  Create an ETM in the front-end tool extract_model Block_ETM (ndm) 3.\n  Synthesize the top-level design in the front-end tool compile_fusion RTL Top-level UPF SDC, floorplan"}
{"header": "How do I Example Script of Hierarchical Synthesis Using ETMs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To run hierarchical synthesis flow, follow the steps described in  Figure\u00a0190.\n In contrast to the feasibility flow, the hierarchical synthesis flow uses the following block-level information generated post place and route: \u2022 Floorplanning information to generate the ETM in step 3 \u2022 Power intent and test model (CTL) information for top-level synthesis in step 5       Figure 190 Hierarchical Synthesis Flow 1.\n  Synthesize the block in the front-end tool compile_fusion RTL Block UPF (back end) Block CTL (back end) UPF SDC, floorplan Design (ndm) 3.\n  Create an ETM in the back-end tool extract_model Block_ETM (ndm) 4.\n  Synthesize the top-level design in the front-end tool compile_fusion RTL Top-level UPF SDC, floorplan SDC Netlist UPF \u2019\u2019 CTL Design (frame) 2.\n  Implement the block design in the back-end tool SPEF (back end or StarRC)"}
{"header": "How do I Performing Prechecks for Hierarchical Synthesis Flows", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The following script shows an example of the hierarchical synthesis flow: #\u00a0Specify\u00a0reference\u00a0libraries set\u00a0REF_LIBS\u00a0${std_cell}.ndm lappend\u00a0REF_LIBS\u00a0${block_design}_etm.ndm create_lib\u00a0-tech\u00a0${TECH_FILE}\u00a0-ref_libs\u00a0$REF_LIBS\u00a0${DESIGN_NAME}  #\u00a0Read\u00a0the\u00a0RTL\u00a0design analyze\u00a0-format\u00a0verilog\u00a0[list\u00a0$rtl_list] elaborate\u00a0${DESIGN_NAME}  #ETM.ndm\u00a0in\u00a0ref_lib\u00a0is\u00a0used\u00a0to\u00a0link\u00a0cell\u00a0instances set_top_module\u00a0${DESIGN_NAME}  #\u00a0Load\u00a0UPF\u00a0for\u00a0ETM\u00a0cell\u00a0instance load_upf\u00a0${block_design}.upf\u00a0-scope\u00a0cell_instance  #\u00a0Read\u00a0test\u00a0model\u00a0for\u00a0ETM\u00a0cell\u00a0instance read_test_model\u00a0${block_design}.mapped.ctl...\n compile_fusion\u00a0-to\u00a0initial_opto  #\u00a0Query\u00a0commands #\u00a0List\u00a0all\u00a0macro\u00a0cell\u00a0instances get_cells\u00a0-hierarchical\u00a0-filter\u00a0\"is_hard_macro\u00a0==\u00a0true\" #\u00a0ref\u00a0view\u00a0name\u00a0is\u00a0\"timing\"\u00a0for\u00a0cell\u00a0instances\u00a0bound\u00a0to\u00a0ETM get_attribute\u00a0${CELL}\u00a0is_etm_moded_cell"}
{"header": "How do I Providing Block-Level Test Models", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To check the readiness for the hierarchical synthesis flow, use the following commands: \u2022 check_design\u00a0-checks\u00a0block_ready_for_top Run this command after block synthesis to check whether the synthesized block is ready for the top-level synthesis.\n \u2022 check_design\u00a0-checks\u00a0hier_pre_compile Run this command before top-level synthesis to check whether the subblocks and top- level design are ready for the hierarchical flow."}
{"header": "How do I Specifying Block-Level Power Intent", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can provide test model of the subblocks for the top-level design implementation when running hierarchical synthesis.\n To do so, generate the test model for the mapped block       design during block-level synthesis and then annotate the test model to the subblock during top-level synthesis.\n For example, \u2022 Generating the test model during block-level synthesis #\u00a0Read\u00a0block\u00a0RTL\u00a0and\u00a0constraints #\u00a0Specify\u00a0DFT\u00a0configuration set_dft_signal\u00a0...\n set_scan_configuration\u00a0...\n create_test_protocol...\n compile_fusion\u00a0-to\u00a0initial_opto insert_dft write_test_model -output block_des.mapped.ctl \u2022 Running top-level synthesis with the block-level test model #\u00a0Read\u00a0RTL\u00a0and\u00a0constraints #\u00a0Specify\u00a0DFT\u00a0configuration  read_test_model block_des.mapped.ctl set_dft_signal\u00a0...\n set_scan_configuration\u00a0...\n create_test_protocol...\n compile_fusion\u00a0-to\u00a0initial_opto insert_dft"}
{"header": "How do I Overview of Abstract Views", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You must provide power intent of the subblock for the top-level design implementation when running hierarchical synthesis.\n To do so, you can provide full block-level UPF for the tool to automatically extract power intent interface.\n The following figure shows a subblock named U1, and the top-level power intent script loads the block-level power intent by using the  load_upf command.\n Note: The block-level power intent specification is required only for hierarchical synthesis using ETMs.\n In the abstract flow, the UPF constraints are handled automatically by the tool.\n       \u2022 U1 as an ETM in the PD_Top design \u2022 Top-Level power intent create_power_domain\u00a0PD_TOP\u00a0-include_scope create_supply_net\u00a0VDD_AO...\n load_upf block.upf -scope U1...\n connect_supply_net\u00a0VDD_AO\u00a0-port\u00a0U1/VDD_AO \u2022 Block-level power intent: block.upf create_power_domain\u00a0PD_BLK\u00a0-include_scope create_power_switch\u00a0sw1\u00a0-domain\u00a0PD_BLK\u00a0\\ -input_supply_port\u00a0{in\u00a0VDD_AO}\u00a0\\ -output_supply_port\u00a0{out\u00a0VDD_SW}\u00a0...\n...\n add_port_state\u00a0sw1/out\u00a0-state\u00a0{ON\u00a01.08}\u00a0-state\u00a0{OFF\u00a0off}...\n create_pst\u00a0pst\u00a0-supplies\u00a0{VDD_SW\u00a0...}"}
{"header": "How do I Creating Abstract Views", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In an abstract view, the gate-level netlist for the block is modeled by a partial gate- level netlist that contains only the required interface logic of the block.\n All other logic is removed.\n Figure\u00a0191 shows a block and its abstract view, where the logic is preserved between \u2022 The input port and the first register of each timing path \u2022 The last register of each timing path and the output port       Logic associated with pure combinational input-port-to-output-port timing paths (A to X) is also preserved.\n Clock connections to the preserved registers are kept as well.\n The register-to-register logic is discarded.\n Figure 191 A Block and Its Abstract View A B CLK X Y Block A B CLK X Y Abstract View The interface logic of an abstract view consists of the following: \u2022 All cells, pins, and nets in timing paths from input ports to registers or output ports \u2022 All cells, pins, and nets in timing paths to output ports from registers or input ports \u2022 Any logic in the connection from a master clock to generated clocks \u2022 The clock trees that drive interface registers, including any logic in the clock tree \u2022 The longest and shortest clock paths from the clock ports \u2022 All pins with timing constraints that are part of the interface logic In addition to the interface logic, an abstract view contains the following information associated with the interface logic: \u2022 Placement information \u2022 Timing constraints \u2022 Clock tree exceptions \u2022 Parasitic information \u2022 Transition and case values of dangling pins \u2022 Power management cells and UPF constraints \u2022 Nondefault routing rule association and minimum and maximum layer constraints, if any, for the nets that are retained in the abstract view"}
{"header": "How do I Creating Abstracts With Power Information", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the Fusion Compiler tool, you can create an abstract view for a block at various stages of the design flow, such as, after synthesis, placement, optimization, clock tree synthesis, routing, and so on.\n Before you create the abstract view, ensure that the scenarios needed at the top level have been created and are active.\n To create an abstract view for top-level closure, use the  create_abstract command.\n \u2022 To control the amount of timing information in the abstract view, use the -timing_level option with the following settings: \u25e6 To create an abstract that contains only the boundary cells (one level of logic) connected to each boundary port, use the  boundary setting.\n Such an abstract also contains feedthrough data paths, feedthrough combinational clock paths, and internal clock logic driving output ports.\n You can use this type of abstract to fix DRC violations at the top level.\n \u25e6 To create a compact abstract that contains the timing information for only the critical setup and hold timings paths of the interface logic, use the  compact setting.\n This is the default setting, and is preferred for top-level design closure.\n \u25e6 To create an abstract with timing information for all the interface logic, use the full_interface setting.\n A  full_interface abstract might be required for multiply-instantiated blocks (MIBs) when the constraints for MIB instances are different at the top-level.\n \u2022 To create the abstracts for lower-level blocks of the current block, use one of the following methods: \u25e6 Create abstracts for specific lower-level blocks by using the  -blocks option and specify the names of the blocks.\n \u25e6 Create abstracts for all lower-level blocks by using the  -all_blocks option.\n When you use the  -blocks or  -all_blocks option, if a specified block has an abstract view, by default, the tool does not re-create it.\n To force the tool to re-create the abstract, use the  -force_recreate option.\n \u2022 To include specific nets, ports, hierarchical pins, or leaf pins in a placement or timing abstract, use the  -include_objects option.\n       \u2022 To create a read-only abstract, use the  -read_only option.\n By default, the tool creates an editable abstract that you can modify in the context of a parent block.\n However, the tool makes the design view of the block read-only, preventing any changes from being made to the block.\n When you create the abstract view as read-only, the design view of the block is editable, and you can make changes to it.\n \u2022 To flatten the physical hierarchy and retain only the relevant logic of the lower-level blocks, use the  -preserve_block_instances\u00a0false option.\n \u2022 To specify if the abstract is going to be used for design planning or top-level implementation, use the  -target_use\u00a0planning or  -target_use\u00a0implementation option.\n Based on the intended usage, the tool applies appropriate internal settings to the abstract.\n \u2022 To specify host options for distributed processing, use  -host_options option and specify the appropriate settings.\n You can use this option to reduce the runtime when you create more than one abstract view by using the  -blocks or  -all_blocks option."}
{"header": "How do I Creating Abstracts for Signal Electromigration Analysis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create an abstract that contains power information of the corresponding block, use the following steps at the block level: 1.\n Activate the scenarios for which you want to perform power analysis by using the -active\u00a0true option of the  set_scenario_status command and enable them for power analysis by using the following options: \u25e6 -dynamic_power\u00a0true for dynamic power analysis \u25e6 -leakage_power\u00a0true for leakage power analysis Power information is stored only for active scenarios that are enabled for dynamic or leakage power.\n 2.\n (Optional) Apply switching activity by either reading in a SAIF file with the  read_saif command or annotating the switching activity information on the nets with the set_switching_activity command.\n For more information about applying switching activity, see  Annotating the Switching Activity.\n       3.\n Store the power information in the abstract by setting the  abstract.annotate_power application option to  true.\n 4.\n Create the abstract for the block by using the  create_abstract command.\n When you create an abstract with power information, the tool stores the power information only for the logic that is removed.\n When you instantiate such an abstract and perform power analysis at the top level, the tool \u2022 Recomputes the power for the interface logic in the abstract, in context, based on the switching activity and loading seen at the top level \u2022 Uses the stored power in the abstract for the logic that was removed when the abstract was created To report the power information in an abstract instantiated at the top level, use the report_power\u00a0-blocks command.\n If there are multiple levels of physical hierarchy, to specify the number of level for which you want to report, use the  -levels option."}
{"header": "How do I Handling Multiple Levels of Physical Hierarchy", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create an abstract that can be used for signal electromigration analysis at the top-level, set the  abstract.enable_signal_em_analysis application option to  true before you run the  create_abstract command."}
{"header": "How do I Creating Abstracts for Minimum Pulse Width Analysis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For designs with multiple levels of physical hierarchy, before you create an abstract for a block with an abstract instantiated in it, \u2022 Bind the lower-level blocks that you want represented by abstracts to the specific abstracts For example, assume you have a design with multiple levels of physical hierarchy as shown in the following figure.\n Figure 192 A Design With Multiple Levels of Physical Hierarchy BOT MID TOP       To create an abstract for the block named BOT, use the following commands: fc_shell>\u00a0 open_block BOT fc_shell>\u00a0 create_abstract To create an abstract for the block named MID, use the following commands: fc_shell>\u00a0 open_block MID fc_shell>\u00a0 change_abstract -view abstract -references BOT fc_shell>\u00a0 create_abstract By default, the  create_abstract command preserves all levels of the physical hierarchy.\n To flatten the physical hierarchy and retain only the relevant logic of the lower-level blocks, use the  -preserve_block_instances\u00a0false option, as shown in the following example: fc_shell>\u00a0 open_block MID fc_shell>\u00a0 create_abstract -preserve_block_instances false Use flattened abstracts in top-level implementation flows where the lower-level blocks are treated as read-only.\n Using flattened abstracts reduces the netlist size at the top level.\n It also simplifies data management because you do not need to include the lower-level blocks in the reference library list of the top level."}
{"header": "How do I Reporting Abstract Inclusion Reasons", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations.\n The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation.\n You can use the following application options to: \u2022 Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to  true.\n The data paths to these registers are not retained.\n By default, this application is set to false.\n \u2022 Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack.\n This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}
{"header": "How do I Making Changes to a Block After Creating an Abstract", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the Fusion Compiler tool, the  create_abstract command includes netlist objects such as the cells, nets, and pins in the abstract view at both the top-level and block-level.\n This command reports the reasons for the inclusion of netlist objects.\n       To report the reasons for including specific netlist objects in the abstract view, you can use the  report_abstract_inclusion_reason command for objects across all hierarchies in the abstract.\n For each reason reported, a reason code is displayed.\n These reason codes correspond to the valid reasons for inclusion in the abstract.\n There can be multiple reasons for the same netlist object.\n Note: The  report_abstract_inclusion_reason command does not report reasons for the hierarchical cells or pins on hierarchical cells.\n You can perform reason reporting from the top-level design, where the abstract is instantiated, without having the abstract as the current block.\n The following example reports the reasons for abstract inclusion for the pins in abstract view: fc_shell>\u00a0report_abstract_inclusion_reason\u00a0[get_pins\u00a0-of_object [get_cells\u00a0-filter\u00a0\"is_hierarchical==false\"\u00a0-hierarchical\u00a0*]]  Legend mv\u00a0-\u00a0MV\u00a0Logic comp\u00a0-\u00a0Compact\u00a0interface\u00a0logic cell\u00a0-\u00a0Cell\u00a0inclusion -------------------------------------------------------------------- Pin\u00a0name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Reason(s)\u00a0for\u00a0inclusion -------------------------------------------------------------------- AINV_P_260/I\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0comp,\u00a0cell AINV_P_260/VDD\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cell AINV_P_260/VSS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cell AINV_P_260/ZN\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0comp,\u00a0cell AINV_P_262/I\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0comp,\u00a0cell AINV_P_262/VDD\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cell AINV_P_262/VSS\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0cell AINV_P_262/ZN\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0comp,\u00a0cell AINV_P_263/I\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0mv,\u00a0comp,\u00a0cell A legend is displayed at the beginning of the report for the queried objects, specifying the detailed reason for each reason code."}
{"header": "How do I Creating a Frame View", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you create an abstract view for a block with the  create_abstract command, by default, the tool saves both the abstract and design views of the block and changes the design view to read-only.\n       You can open a read-only block and make changes to it in-memory, but you cannot save these changes by using the  save_block or  save_lib command.\n To save the change you make to a read-only block, use one of the following methods: \u2022 Save it as a different block by using the  save_block\u00a0-as command.\n \u2022 Re-create an abstract for the block by using the  create_abstract command.\n The tool then automatically saves the design view.\n \u2022 Remove the abstract by using the  remove_abstract command, if you no longer need the abstract.\n This changes the design view from being read-only to editable, and you can save the block by using the  save_block or  save_lib command.\n If you create a read-only abstract by using the  create_abstract\u00a0-read_only command, the tool does not make the design view of the block read-only and you can save any subsequent changes to the block by using the  save_block or  save_lib command, as shown in the following example: fc_shell>\u00a0 create_abstract -read_only fc_shell>\u00a0 change_link [get_cells U25] AND2 fc_shell>\u00a0 save_block"}
{"header": "How do I Linking to Abstract Views at the Top-Level", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform top-level routing, including virtual routing, every abstract view must have a corresponding frame view.\n To create a frame view, use the  create_frame command, which extracts the blockage, pin, and via information from the design view.\n After you create the frame view, save the design library by using the  save_lib command."}
{"header": "How do I Changing the Block From Abstract to Design View", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "For a top-level design to link to an abstract view of a lower-level block, the design library containing the abstract view of the lower-level block must be one of the reference libraries of the top level.\n For example, assume you have a top-level design named TOP with two lower-level blocks named BLK1 and BLK2, as shown in the following figure.\n       Figure 193 Top-Level Design With Instantiated Blocks BLK1 TOP BLK2 To link to the abstracts of the BLK1 and BLK2 blocks, the design libraries containing the abstract views of these block must be reference libraries of the TOP design.\n If not, you can add it to the reference libraries of the TOP design by using the  set_ref_libs\u00a0-add command as shown in the following example: current_block\u00a0TOP set_ref_libs\u00a0-add\u00a0../BLK1/BLK1.nib set_ref_libs\u00a0-add\u00a0../BLK2/BLK2.nib To report the reference libraries for the current design, use the  report_ref_libs command.\n When you link a top-level design, if an abstract view for a lower-level block is available, the tool links to that abstract view by default.\n The default precedence of the different views used when linking lower-level blocks is as follows: 1.\n Abstract view 2.\n Design view 3.\n Frame view 4.\n Outline view"}
{"header": "How do I Linking to Subblocks With Multiple Labels", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To change a block from its abstract to its design view, use the  change_abstract command and specify the view you are changing to by using the  -view option.\n When you change a block from its abstract view to its design view, remove the existing constraints and apply full-chip timing constraints.\n The following example changes the BLK1 block from its abstract view to its design view and applies full-chip timing constraints.\n 1.\n Remove any existing timing constraints: fc_shell>\u00a0 remove_scenarios -all fc_shell>\u00a0 remove_modes -all fc_shell>\u00a0 remove_corners -all       2.\n Use the  change_abstract command to change from the abstract view to the design view: fc_shell>\u00a0 change_abstract -view design -references BLK1 3.\n Apply the full-chip scenario creation script: fc_shell>\u00a0 source full_chip_scenario_creation.tcl If the abstract view for a block has changed in its design library, you can reload the new abstract view by using the  change_abstract\u00a0-reload command.\n To report the abstract views the design is linking to, use the  report_abstracts command.\n More information about specifying reference libraries and linking to abstract views at the top level, see  SolvNet article 2436119, Setting Up Designs for Hierarchical Place and Route."}
{"header": "How do I Specifying the Editability of Blocks From the Top-Level", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When saving a block at different stages of an implementation flow, you can use the  -as blockName / labelName or  -label\u00a0 labelName option with the  save_block command to specify a unique label for each version of the block you save.\n By default, during linking, the top-level block links to lower-level blocks with the same label.\n If a subblock has been saved with multiple labels, you can specify which label the top level should link to by using the  set_label_switch_list command.\n The command specifies a precedence-ordered list of labels to use during linking.\n By default, the command applies to all subblocks; to specify a different block or blocks, use the -reference option.\n   The following example specifies that the top level should link to the PostCompile label of the BLOCK1 and BLOCK2 subblocks: fc_shell>\u00a0 set_label_switch_list \\ -reference {BLOCK1 BLOCK2} PostCompile The following example specifies that the PostCompile label has a higher priority than the PreCompile label when linking any subblock at the top level.\n fc_shell>\u00a0 set_label_switch_list {PostCompile PreCompile}       You can use the  set_label_switch_list command again to update the block\u2019s label switch list and then relink the block using the  link_block\u00a0-rebind command.\n Note the following when relinking a block: \u2022 If none of the labels in the switch list are available in a subblock, or if you specify an empty switch list, the tool links the subblock to the label it was previously linked to \u2022 If you have removed all the labels for a subblock, the tool links the subblock to the label of its parent block"}
{"header": "How do I Preparing for Top-Level Closure With Abstracts", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "For designs with physical hierarchy, you can specify if changes can be made to lower-level blocks by using the  set_editability command at the top level.\n You can change the editability of \u2022 Specific blocks by using the  -blocks option \u2022 All blocks starting from a specific level of the physical hierarchy by using the -from_level option \u2022 All blocks up to a specific level of the physical hierarchy by using the  -to_level option For top-level implementation flows with read-only abstracts, after you link the design, explicitly set the lower-level blocks as read-only by using the following command: fc_shell>\u00a0 set_editability -blocks [get_blocks -hierarchical] \\ -value false By default, if you change a library or block name with one of the following commands, the tool does not propagate the editability settings from the old reference to the new reference: \u2022 change_abstract\u00a0-lib \u2022 link_block\u00a0-rebind\u00a0-force \u2022 set_reference To retain the editability settings, set the  design.preserve_reference_editability application option to  true before you change a library or block name.\n When you save the hierarchical design with the  save_block command, the editability settings are saved."}
{"header": "How do I Checking Designs With Abstracts for Top-Level-Closure Issues", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you can perform synthesis, placement, optimization, clock tree synthesis, and routing at the top level, you must perform the following tasks: \u2022 Apply the top-level-timing constraints and settings.\n You can split the chip-level constraints in to separate top- and block-level constraints by using the  split_constraints command.\n \u2022 Review and specify the relationship between the top- and block-level modes, corners, and clocks by using the  set_block_to_top_map command.\n \u2022 If the pre-clock tree implemented blocks, which have undergone CCD optimization, are used for top-level placement and optimization, then the ideal clock latencies adjusted dynamically by different engines such as CCD and clock-gate estimation on the clock pins of registers or integrated clock gating (ICG) cells inside the blocks might not be seen at the top-level leading to timing inaccuracies at the top-level.\n Promote these clock latency constraints from block-level to the top-level by using the promote_clock_data\u00a0-latency_offset\u00a0-auto_clock\u00a0connected command.\n \u2022 Apply the top-level clock tree synthesis settings and exceptions.\n \u25e6 If the top-level exceptions do not include the balance points on the pins within lower-level blocks, promote the balance points from the lower levels by using the promote_clock_data\u00a0-auto_clock\u00a0connected\u00a0-balance_points command.\n \u25e6 If concurrent clock and data (CCD) optimization is performed at the block level, the tool derives median clock latencies for the block-level clock ports, which accounts for the latency adjustments that were derived for the block-level registers during concurrent clock and data optimization.\n Promote these block-level clock latencies as clock balance point delays for the block-level clock pins by using the promote_clock_data\u00a0-auto_clock\u00a0connected\u00a0-port_latency command.\n \u25e6 If the lower-level blocks contain clock-meshes, promote the mesh annotations (annotated transitions and delays) by using the  promote_clock_data -mesh_annotations command.\n \u2022 If you need to promote clock data for a specific top-level clock, use the promote_clock_data\u00a0-clocks\u00a0{top_clock}\u00a0-port_latency command.\n The command also promotes clock-independent exceptions.\n If any of the given top-level clocks has no mapping to any block-level clock in any mode, the tool issues a warning.\n \u2022 If there are any active modes, corners, or clocks at the top-level, which cannot be mapped to corresponding modes, corners, or clocks in the block-level, you can still promote the clock data for other mapped modes, corners, or clocks using the promote_clock_data\u00a0-balance_points\u00a0-force command.\n This command issues errors for the unmapped modes, or corners, or clocks.\n       \u2022 Apply the top-level UPF constraints, which you can create from the full-chip UPF constraints by using the  split_constraints command.\n The tool promotes the required UPF constraints from the lower-level blocks to the top level."}
{"header": "How do I Handling Design Data Using the Early Data Check Manager", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can check a hierarchical design that contains abstracts for possible issues such as the application option consistency issues and the design issues related to top-level closure by using the  check_hier_design command.\n Identifying issues and fixing them before you perform top-level closure can help reduce turnaround time.\n When you use the  check_hier_design command, you can specify \u2022 The references to check by using the  -reference option.\n If you do not specify this option, the command checks all the references in the physical hierarchy.\n \u2022 The type of checks to perform by using the  -stage option as follows: \u25e6 Use the  -stage\u00a0timing option to perform timing related checks.\n If you do not specify the  -stage option, by default, the tool performs timing related checks.\n \u25e6 Use the  -stage\u00a0pre_placement to perform both timing and preplacement related checks.\n The  check_hier_design command can check the consistency between the top-level constraints and the constraints of every lower-level instance linked to an abstract.\n To enable this feature, set the  abstract.check_constraints_consistency application option to  true before you run the  check_hier_design command.\n The tool saves the settings of the predetermined list of timer application options during the create_abstract command.\n At the top-level design, the  check_hier_design command compares these timer application option settings with those of the block-level design.\n The following application options are automatically saved during the  create_abstract command and verified by the  check_hier_design command: \u2022 time.case_analysis_propagate_through_icg \u2022 time.case_analysis_sequential_propagation \u2022 time.clock_gating_propagate_enable \u2022 time.clock_gating_user_setting_only       \u2022 time.clock_marking \u2022 time.clock_reconvergence_pessimism \u2022 time.create_clock_no_input_delay \u2022 time.crpr_remove_clock_to_data_crp \u2022 time.delay_calc_waveform_analysis_mode \u2022 time.delay_calculation_style \u2022 time.disable_case_analysis_ti_hi_lo \u2022 time.disable_clock_gating_checks \u2022 time.disable_cond_default_arcs \u2022 time.disable_internal_inout_net_arcs \u2022 time.disable_recovery_removal_checks \u2022 time.edge_specific_source_latency \u2022 time.enable_auto_mux_clock_exclusivity \u2022 time.enable_ccs_rcv_cap \u2022 time.enable_clock_propagation_through_preset_clear \u2022 time.enable_clock_propagation_through_three_state_enable_pins \u2022 time.enable_clock_to_data_analysis \u2022 time.enable_non_sequential_checks \u2022 time.enable_preset_clear_arcs \u2022 time.enable_si_timing_windows \u2022 time.gclock_source_network_num_master_registers \u2022 time.special_path_group_precedence \u2022 time.use_lib_cell_generated_clock_name \u2022 time.use_special_default_path_groups For more information about the issues the  check_hier_design command identifies and how to fix them, see the man page for the corresponding message ID.\n In addition to generating a report, the  check_hier_design command generates an enhanced messaging system (EMS) database that you can view by using the message       browser in the Fusion Compiler GUI.\n Create the EMS database before you run the check_hier_design command, as shown in the following example: fc_shell>\u00a0 create_ems_database check_hier.ems fc_shell>\u00a0 check_hier_design -stage timing fc_shell>\u00a0 save_ems_database In the Fusion Compiler GUI message browser, you can sort, filter, and link the messages to the corresponding man page, as shown in the following figure.\n Figure 194 Viewing the EMS Database in the Message Browser You can also output the information in the EMS database in ASCII format by using the report_ems_database command.\n The checks performed by the  check_hier_design command are also available in the check_design command.\n You can perform \u2022 Timing checks specific to top-level closure by using the  check_design\u00a0-checks hier_timing command \u2022 All timing checks, including those specific to top-level closure, by using the check_design\u00a0-checks\u00a0timing command \u2022 Preplacement checks specific to top-level closure by using the  check_design -checks\u00a0hier_preplacement command \u2022 All preplacement checks, including those specific to top-level closure, by using the check_design\u00a0-checks\u00a0preplacement command       You can generate an EMS database for the  check_design command and view it in the GUI, similar to the  check_hier_design command."}
{"header": "How do I Prerequisites for Handling Early Design Data", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "While you identify the issues related to top-level closure and fix them, the tool enables you to explore the top-level flow in the presence of design data violations.\n The hierarchical checks can detect different types of mismatched, incomplete, and inconsistent data in designs.\n You can configure the following policies for the hierarchical checks to manage the design data violations: \u2022 Error: When you apply this policy, the tool does not mitigate the violation, but issues an error message.\n \u2022 Tolerate: When you apply this policy, the tool makes predictable and explainable assumptions to continue with the flow.\n No changes are made to the design or setup.\n \u2022 Repair: When you apply this policy, the tool mitigates the violation using one or more repair strategies and records it.\n Repair can include changes in design and setup.\n \u2022 Strict: When you apply this policy, depending on the policy supported by the check, the tool applies the policies in this order \u2013 error, tolerate, repair.\n \u2022 Lenient: When you apply this policy, depending on the policy supported by the check, the tool applies the policies in this order \u2013 repair, tolerate, error.\n Note: \u2022 Quality of results of the top-level flow might get impacted due to the toleration and repair of errors.\n Error toleration and repair is mainly provided for managing data violations during the early design exploration phases.\n In the implementation flow, you should use the strict policy for all checks."}
{"header": "How do I Early Data Checks, Policies, and Strategies", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool performs the repairs and saves the records in the subblocks within the check_hier_design command itself.\n For the repairs, which need frame recreation, you need to run the  save_lib command to save the frame on disk.\n \u2022 To save the repair and its record to the subblock successfully, the following setup is required: 1.\n Enable the reference libraries, containing the subblocks, for edit open_lib\u00a0top.nlib\u00a0-ref_libs_for_edit       2.\n Enable editability on the subblocks, on which repair has to be performed set_editability\u00a0-blocks\u00a0<>\u00a0-value\u00a0true The  check_hier_design command checks for the required editability settings, if repair has to be performed.\n If the required editability settings are not performed,then the check_hier_design command issues  TL-170 error message.\n Note: The tool supports the repairs on subblocks, which are linked to the  read_only abstracts rather than editable abstracts because managing the mismatched design data mechanism only aims to continue the top-level flow for exploration and as such no repair work performed on the subblock abstracts should get merged with the actual design view.\n If the top-level uses editable design views, the repair work still continues."}
{"header": "How do I Setting the Policy for Early Data Checks", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool can identify issues and violations in data during the early stages of design.\n You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data.\n  Table\u00a064 describes the predefined checks for top-level closure.\n Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view        error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location           error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary              error, tolerate, repair MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort           error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame     error,\u00a0tolerate TOP hier.block.inst ance_with_desig n_type_macro     error,\u00a0tolerate TOP hier.top.estima ted_corner     error,\u00a0tolerate TOP hier.block.miss ing_leaf_cell_l ocation             error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary              error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion                  error, tolerate, repair MID       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary               error, tolerate, repair MID hier.block.port _mismatch_betwe en_views             error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs     error,\u00a0tolerate MID BOT hier.block.inst ance_unlinked           error TOP hier.block.abst ract_type_non_t iming    error MID BOT hier.block.abst ract_target_use _non_implementa tion     error MID BOT hier.block.miss ing_core_area     error MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic     error MID BOT Where \u2022 BOT signifies bottom level design.\n \u2022 MID signifies intermediate level design, which instantiates BOT.\n \u2022 TOP signifies the top-level design, which instantiates MID."}
{"header": "How do I Reporting Early Data Check Records", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set or modify the policy for all the checks, or modify the policy settings for data checks, use the  set_early_data_check_policy command.\n Use the following options to configure the policy: \u2022 -checks : Specifies a predefined list of data checks.\n It supports an asterisk wildcard character (*) as the name of a check.\n \u2022 -policy : Specifies the type of policy depending on what is supported by the check.\n This can be \u25e6 error : The tool issues an error message if the check does not support  error as a policy.\n \u25e6 tolerate : The tool issues an error message if the check does not support tolerate as a policy.\n \u25e6 repair : The tool issues an error message if the check does not support  repair as a policy.\n \u25e6 strict : The tool sets the first matching policy in the following order: 1.\n  error 2.\n  tolerate 3.\n  repair For example, when a check supports the  error and  tolerate policies, and you select  strict as the policy type, the  error policy type is set.\n       \u25e6 lenient : The tool sets the first matching policy in the following order: 1.\n  repair 2.\n  tolerate 3.\n  error For example, when a check supports the  error and  tolerate policies, and you select  lenient as the policy type, the  tolerate policy type is set.\n Note: If you specify both the checks and policies, the configuration supports all the policies described in this section, depending on what the application-specific check supports.\n However, if you specify only the policies, but not the checks, the configuration supports only the  strict and  lenient policies.\n \u2022 You can also use the  if_not_exists keyword with the  -policy option to set a policy on the current design only if the design does not already have a policy set.\n \u2022 -strategy : Specifies the strategy to apply for a check.\n Note: -strategy is not applicable for the hierarchical checks.\n \u2022 -references : Specifies the policy and strategy for reference subdesigns."}
{"header": "How do I Generating a Report of Early Data Check Records", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can report the policy set for all checks or for a specific set of checks by using the report_early_data_checks command.\n Use the following options to configure the report: \u2022 -policy : Reports configuration details for all checks.\n It shows the selected policy and strategy for each check.\n Using the  -hierarchical option with the  -policy option reports the configuration of the subblocks.\n \u2022 -checks : Reports the current policy, supported policies, strategies, and help text for each check.\n It supports an asterisk wildcard character (*) as the name of a check.\n Using the  -hierarchical option with the  -checks option reports the checks of the subblocks.\n \u2022 -verbose : Reports a summary of all failed checks, policies, strategies applied, and checked objects with comments.\n Using the  -hierarchical option with the  -verbose       option reports the records of all failed checks, policies, strategies applied, and checked objects from the subblocks.\n \u2022 -hierarchical : Traverses the hierarchy and reports the check, policy, strategy, and fail count for each design in the hierarchy.\n In the following example, the  report_early_data_checks\u00a0-hierarchical\u00a0-policy command reports the policy settings for the hierarchical checks set on the top-level design and the block-level designs: fc_shell>\u00a0 report_early_data_checks -policy **************************************** Report\u00a0:\u00a0report_early_data_checks Design\u00a0:\u00a0top Version:\u00a0R-2020.09 Date\u00a0\u00a0\u00a0:\u00a0Thu\u00a0Aug\u00a020\u00a023:53:54\u00a02020 **************************************** Design\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Check\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Policy Strategy --------------------------------------------------------------------------------- ------- unit_des.nlib:top.design\u00a0hier.block.instance_bound_to_frame\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error  unit_des.nlib:top.design\u00a0hier.block.instance_unlinked\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error  unit_des.nlib:top.design\u00a0hier.block.instance_with_design_type_macro\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error  unit_des.nlib:top.design\u00a0hier.top.estimated_corner\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error --------------------------------------------------------------------------------- ------ blk\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hier.block.abstract_missing_design_view\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error  blk\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hier.block.abstract_target_use_non_implementation\u00a0error  blk\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hier.block.abstract_type_non_timing\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error  blk\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hier.block.leaf_cell_outside_boundary\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0error --------------------------------------------------------------------------------- ----- In the following example, the  report_early_data_checks\u00a0-hierarchical\u00a0-verbose command reports the repair performed on the checked object and also provides the details of policies, strategies applied, and checked objects on the subblocks.\n fc_shell>\u00a0 report_early_data_checks -hierarchical -verbose ****************************************************** Design\u00a0Check\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Policy\u00a0Strategy\u00a0Checked\u00a0\u00a0Comment Object ------------------------------------------------------------------------------------ blk\u00a0\u00a0hier.block.missing_leaf_cell_location\u00a0repair\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0eco_cell\u00a0Instance\u00a0location updated\u00a0to X:150145\u00a0Y:69620 ------------------------------------------------------------------------------------- While running the top-level early flow, you might run into top-level errors or warnings because of the design data violations in the subblocks or top-level design.\n To use the data checks and policies capability for exploring early flows, you need to know       the check name corresponding to the top-level errors seen on the design.\n The report_hier_check_description command provides the required information about the checks associated with each top-level error.\n The following example shows the report generated by the  report_hier_check_description command: fc_shell>\u00a0 report_hier_check_description ********************************************* Report\u00a0:\u00a0Hier\u00a0check\u00a0description Design\u00a0:\u00a0top Version:\u00a0R-2020.09 Date\u00a0\u00a0\u00a0:\u00a0Fri\u00a0Aug\u00a021\u00a000:08:32\u00a02020 *********************************************  Legend E\u00a0-\u00a0error R\u00a0-\u00a0repair T\u00a0-\u00a0tolerate TOP\u00a0-\u00a0Top-Design BLK\u00a0-\u00a0Respective\u00a0Block-Ref  -------------------------------------------------------------------------------------- --------------------------- Check\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Error\u00a0\u00a0Tolerate\u00a0Repair\u00a0Allowed\u00a0\u00a0Allowed Description ID\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ID\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ID\u00a0\u00a0\u00a0\u00a0Policies\u00a0References -------------------------------------------------------------------------------------- --------------------------- hier.block.missing_frame_view\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TL-101\u00a0\u00a0TL-401\u00a0\u00a0TL-501\u00a0\u00a0E|R|T\u00a0\u00a0\u00a0\u00a0\u00a0BLK Missing\u00a0frame\u00a0view hier.block.abstract_missing_design_view\u00a0\u00a0\u00a0\u00a0TL-101\u00a0\u00a0TL-401\u00a0\u00a0N/A\u00a0\u00a0\u00a0\u00a0\u00a0E|T\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0BLK Missing\u00a0design\u00a0view\u00a0for\u00a0abstract hier.block.reference_missing_port_location\u00a0TL-126\u00a0\u00a0TL-426\u00a0\u00a0TL-526\u00a0\u00a0E|R|T\u00a0\u00a0\u00a0\u00a0\u00a0BLK Missing\u00a0location\u00a0of\u00a0physical  hierarchy\u00a0boundary\u00a0pin hier.block.reference_port_outside_boundary\u00a0TL-127\u00a0\u00a0TL-427\u00a0\u00a0TL-527\u00a0\u00a0E|R|T\u00a0\u00a0\u00a0\u00a0\u00a0BLK Location\u00a0of\u00a0physical\u00a0hierarchy\u00a0boundary  pin\u00a0outside\u00a0physical\u00a0hierarchy\u00a0boundary"}
{"header": "How do I Performing Top-Level Closure With Abstract Views", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can generate a report of check records from a design by using the get_early_data_check_records command.\n Using the  -hierarchical option with this command enables to you get check records for all subblocks.\n The report generated is in the following format: check_name @ object For example, fc_shell>\u00a0 get_early_data_check_records -hierarchical {hier.block.missing_leaf_cell_location@eco_cell} You can use the  -filter option to filter the results of this command by various parameters such as object class and check name.\n       For example, fc_shell>\u00a0 get_early_data_check_records \\ -filter \"checked_object_class==port\" {place.port_type_mismatch@clk\u00a0route.missing_layer_direction@feed_in route.layer_name_mismatch@out}"}
{"header": "How do I Creating ETMs and ETM Cell Libraries", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can perform top-level closure by implementing the blocks first, and then implementing the top level, as shown in the following flow diagram: Figure 195 Top-Level Implemented After Blocks are Completed Abstract and frame views for each block Clock Tree Synthesis Routing Postroute Optimization Postroute Optimization Synthesis, Placement and Optimization Synthesis, Placement and Optimization Clock Tree Synthesis Routing Block-level flow Top-level flow       Alternatively, you can implement the blocks and top-level in parallel, as shown in the following flow diagram: Figure 196 Top and Block Levels Implemented in Parallel Clock Tree Synthesis Routing Postroute Optimization Postroute Optimization Synthesis, Placement and Optimization Synthesis, Placement and Optimization Clock Tree Synthesis Routing Block-level flow Top-level flow Abstract and frame views for each block When using abstracts at the top-level, you can perform top-level synthesis, placement, optimization, clock tree synthesis, routing, and postroute optimization using the commands supported at the block level.\n Currently the tool does not make changes within the abstracts during top-level closure.\n Therefore, you can create and use read-only abstracts."}
{"header": "How do I Creating ETMs and ETM Cell Libraries in the Fusion Compiler", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To create ETMs and ETM cell libraries in the Fusion Compiler tool, see the  Creating ETMs and ETM Cell Libraries in the Fusion Compiler Tool topic.\n To create ETMs and ETM cell libraries in the PrimeTime and the Library Manager tools respectively, see the following topics: \u2022 Creating ETMs in the PrimeTime Tool \u2022 Creating ETM Cell Libraries in the Library Manager Tool"}
{"header": "How do I Creating ETMs in the PrimeTime Tool", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Rather than creating an ETM for each mode and corner combination using the extract_model command in the PrimeTime tool and then using the Library Manager tool to combine the ETMs with the corresponding physical information to create a cell library, you can perform both steps together by using the  extract_model command directly in the Fusion Compiler tool.\n The following Fusion Compiler script creates an ETM for every mode and corner of the design and then combines them with the corresponding physical information and creates the corresponding cell library: #\u00a0Open\u00a0the\u00a0design,\u00a0create\u00a0a\u00a0frame\u00a0view,\u00a0and\u00a0set\u00a0the\u00a0PrimeTime\u00a0options open\u00a0block.nlib:block.design create_frame\u00a0<options>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0;#\u00a0extract_model\u00a0needs\u00a0Frame\u00a0for\u00a0library preparation set_pt_options\u00a0-pt_exec_path\u00a0<>\u00a0-work_dir\u00a0ETM_work_dir\u00a0\\ -post_link_script\u00a0<tcl\u00a0script\u00a0with\u00a0extract_model* variables>\u00a0\\  #\u00a0To\u00a0use\u00a0StarRC\u00a0for\u00a0Parasitic\u00a0extraction set_app_options\u00a0-name\u00a0extract.starrc_mode\u00a0-value\u00a0true set_starrc_options\u00a0-config\u00a0<starrc_config_file>  #\u00a0Create\u00a0the\u00a0ETM\u00a0and\u00a0generate\u00a0the\u00a0ETM\u00a0cell\u00a0library extract_model By default, the Fusion Compiler tool writes out the generated ETM library into \u2022 [pwd]/ETM_Lib_work_dir/block_name/label_name/ for labelled blocks \u2022 [pwd]/ETM_Lib_work_dir/block_name/ for non-labelled blocks"}
{"header": "How do I Creating ETM Cell Libraries in the Library Manager Tool", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create an ETM for design by using the  extract_model command in the PrimeTime tool.\n For multicorner-multimode designs, you must create an ETM for each scenario by applying the appropriate corner and mode constraints for each scenario.\n The following PrimeTime script creates an ETM for the S3 scenario, which consists of the m1 mode and c3 corner, of the AMS_BLK design: #Read\u00a0in\u00a0the\u00a0design read_verilog\u00a0./AMS_BLK.v link  #\u00a0Apply\u00a0parasitics read_parasitics\u00a0./AMS_BLK.spef        #For\u00a0multivoltage\u00a0designs,\u00a0apply\u00a0UPF\u00a0data\u00a0and\u00a0settings load_upf\u00a0./AMD_BLK.upf set\u00a0extract_model_include_upf_data\u00a0true  #\u00a0Apply\u00a0the\u00a0mode\u00a0(m1)\u00a0and\u00a0corner\u00a0(c3)\u00a0constraints\u00a0for\u00a0the\u00a0scenario\u00a0(S3) source\u00a0m1_constraints.tcl source\u00a0c3_constraints.tcl  #\u00a0Enable\u00a0clock\u00a0latencies\u00a0for\u00a0designs\u00a0with\u00a0synthesized\u00a0clock\u00a0trees set\u00a0extract_model_with_clock_latency_arcs\u00a0true set\u00a0extract_model_clock_latency_arcs_include_all_registers\u00a0false  #\u00a0Create\u00a0the\u00a0ETM extract_model\u00a0-library_cell\u00a0-format\u00a0db\u00a0-output\u00a0AMS_BLK_m1_c3 For more information about creating ETMs in the PrimeTime tool, see the Extracted Timing Models chapter in the  PrimeTime User Guide."}
{"header": "How do I Linking to ETMs at the Top Level", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you create an ETM for each mode and corner combination, use the Library Manager tool to combine the ETMs with the corresponding physical information and create a cell library.\n For more information, see the  Library Manager User Guide.\n The following Library Manager scripts combine the ETMs created for every mode and corner of the AMS_BLK design with the corresponding physical information and creates the corresponding cell library: #\u00a0Create\u00a0a\u00a0library\u00a0work\u00a0space create_workspace\u00a0-flow\u00a0etm_moded\u00a0AMS_BLK  #\u00a0Read\u00a0the\u00a0physical\u00a0data\u00a0(frame\u00a0view) read_ndm\u00a0-views\u00a0frame\u00a0AMS_BLK.ndm  #\u00a0Read\u00a0the\u00a0ETMs\u00a0for\u00a0every\u00a0scenario read_db\u00a0-mode_label\u00a0m1\u00a0AMS_BLK_m1_c1.db read_db\u00a0-mode_label\u00a0m1\u00a0AMS_BLK_m1_c2.db read_db\u00a0-mode_label\u00a0m1\u00a0AMS_BLK_m1_c3.db read_db\u00a0-mode_label\u00a0m2\u00a0AMS_BLK_m2_c1.db read_db\u00a0-mode_label\u00a0m2\u00a0AMS_BLK_m2_c2.db read_db\u00a0-mode_label\u00a0m2\u00a0AMS_BLK_m2_c3.db   #\u00a0Check\u00a0the\u00a0compatibility\u00a0of\u00a0the\u00a0libraries\u00a0you\u00a0read\u00a0in check_workspace  #\u00a0Generate\u00a0cell\u00a0library commit_workspace\u00a0-output\u00a0AMS_BLK_ETM.ndm When you create a cell library for an ETM, you can use one of the following methods to obtain the physical data: \u2022 Read the frame view of the corresponding block by using the  read_ndm\u00a0-views\u00a0frame command.\n \u2022 Read a LEF file for the block by using the  read_lef command.\n \u2022 Read a GDSII file for the block by using the  read_gds command \u2022 Read an OASIS file for the block by using the  read_oasis command."}
{"header": "How do I Performing Top-Level Closure With ETMs", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To link to ETMs at the top level, add the ETM libraries to the reference library list before you create the top-level design library, as shown in the following example: fc_shell>\u00a0 lappend nt_ref_lib \"AMS_BLK_ETM.ndm\" fc_shell>\u00a0 create_lib -technology tech.tf -ref_libs $nt_ref_lib TOP An ETM that contains multiple modes is called a moded ETM.\n For a cell instance that links to a moded ETM, you must specify the required mode by using the  set_cell_mode command, as shown in the following example: fc_shell>\u00a0 current_mode m1 fc_shell>\u00a0 set_cell_mode m1 U1 For a cell instance that links to a moded ETM, if you do not specify a mode, the tool does not activate the timing arcs, timing checks, generated clocks, and case values.\n To report the cell modes for specific cell instances, use the  report_cell_modes command.\n To switch a cell instance from its abstract view to its ETM or vice versa, use the set_reference command.\n The following example switches the UI cell instance from its abstract view to its ETM: fc_shell>\u00a0 set_reference -block AMS_BLK_ETM.ndm:AMS_BLK.timing U1 The following example switches the UI cell instance from its ETM to its abstract view: fc_shell>\u00a0 set_reference -block AMS_BLK.ndm:AMS_BLK.abstract U1 When you switch between ETMs and abstract views, reapply the top-level timing constraints."}
{"header": "How do I Transparent Hierarchy Optimization", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before you can use the ETMs at the top level, you must perform the following tasks: \u2022 Apply the top-level-only timing constraints and settings.\n If the cell instances represented by ETMs have internal clocks, you must reapply these clock definition from the top level.\n Avoid cross-boundary timing exceptions that refer to objects inside the blocks.\n \u2022 To apply the UPF constraints and settings, you must: 1.\n Generate the block-level UPF from each of the block-level designs using the save_upf command.\n 2.\n At the top level, load the block UPF for each of the block instances that are represented by an ETM and the top only UPF: load_upf\u00a0-scope\u00a0<instance_name>\u00a0block.upf load_upf\u00a0top.upf \u2022 Apply top-level placement constraints and settings such as hard keepout margins.\n When using ETMs at the top-level, you can perform synthesis, top-level placement, optimization, clock tree synthesis, routing, and postroute optimization using the commands supported at the block level."}
{"header": "How do I Accessing Libraries", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Transparent hierarchy optimization (THO) enables the tool to transparently optimize hierarchical designs.\n THO enables you to optimize the top and subblocks concurrently while honoring the physical block boundaries, and at the same time using all advanced optimization techniques such as CCD, AWP, PrimeTime delay calculation, and so on.\n During THO, the tool optimizes the top-level and specific subblocks (design views) in the context of top-level timing.\n THO does not change the subblock shape and physical hierarchy.\n By default, the tool honors the pin locations, but provides an option to reassign pin locations to improve QoR.\n You can continue your signoff flow with hierarchical blocks because you do not have to flatten the design.\n Signoff extraction and PrimeTime STA can be run hierarchically.\n In addition, any late ECOs can be easier to implement as well.\n THO is available during  compile_fusion in the  final_place and  final_opto stages, as well as during  route_opt and  hyper_route_opt.\n       Figure 197 Transparent Hierarchy Optimization Flow THO Flow open_block -ref_libs_for_edit (Blocks linked with design view) Enable THO settings compile_fusion -from final_place route_opt OR hyper_route_opt T H O The following example flow shows the usage of THO in the overall implementation flow.\n In this example, the THO operations are run as an additional incremental optimization step on top of the typical hierarchical optimization flow.\n       The THO flow includes the following steps: \u2022 Accessing Libraries \u2022 Setting up Transparent Hierarchy Optimization \u2022 Performing THO During compile_fusion final_place Stage \u2022 Performing THO During compile_fusion final_opto Stage \u2022 Rebudgeting After compile_fusion \u2022 Performing THO During route_opt or hyper_route_opt"}
{"header": "How do I Setting up Transparent Hierarchy Optimization", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before enabling the THO settings, you must ensure that: \u2022 All the subblock libraries are opened in edit mode.\n You must open the parent library using the  -ref_libs_for_edit option with the  open_lib command.\n \u2022 The design view of the blocks is editable."}
{"header": "How do I Performing THO During compile_fusion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform THO, you need to have design views.\n You might be linking to abstract views at the top.\n Use the instructions in the  Changing the Block From Abstract to Design View section to switch the blocks you want to optimize to design views.\n Perform the following steps to set up THO: 1.\n To perform THO after block-level  compile_fusion, you must propagate the CCD useful skew balancing offsets and latency offsets for integrated clock gating cells to the top-level timing context using the following commands: fc_shell>\u00a0 promote_clock_data -auto_clock all -latency_offset fc_shell>\u00a0 promote_clock_data -auto_clock all -balance_points 2.\n To enable and perform THO on the blocks, ensure that the blocks you want to optimize with THO are enabled for editing: fc_shell>\u00a0 set_editability -blocks {list of blocks} -value true 3.\n To verify block editability, use the following command: fc_shell>\u00a0 report_editability -blocks [get_blocks -hierarchical] 4.\n During THO, operations such as congestion updates and route-driven estimation (RDE) calculations inside subblocks as well as ECO-routing can be run using distributed processing.\n Use the following commands to perform the setup.\n You must specify your own queue parameters such as the  qsub parameters as shown in the following example: Note: If host options are not specified, the tool runs the operations for the subblocks serially in the main process.\n fc_shell>\u00a0 set_host_options -name for_tho -num_processes 4 -max_cores 16 -submit_command [list  qsub -P queue -pe mt 16 -l mem_free=100G -cwd ] fc_shell>\u00a0 set_hierarchy_options -host_option for_tho -blocks {list of blocks} 5.\n To enable THO, use the  init_hier_optimization command.\n Depending on the stage, you must use different options as shown in the following sections."}
{"header": "How do I Performing THO During compile_fusion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the  final_place stage of  compile_fusion, placement can be performed transparently across the top and blocks.\n Placement occurs within the boundaries of the       respective blocks, but it is global at the same time, ignoring pin locations to get straight paths.\n Placement can be wire length, timing, and congestion driven.\n THO provides an option to refine pin locations based on global placement.\n Pin locations can be refined for the specified set of blocks during coarse placement steps of the THO.\n 1.\n To refine pin locations and enable pin movement, use the following command: fc_shell>\u00a0 set_hierarchy_options -enable_pin_movement true -blocks {list of blocks} 2.\n To report the settings applied with the  set_hierarchy_options command, use the report_hierarchy_options command.\n 3.\n To run the  final_place stage with THO, use the following commands: fc_shell>\u00a0 init_hier_optimization -flow pre_route fc_shell>\u00a0 compile_fusion -from final_place -to final_place fc_shell>\u00a0 commit_hier_optimization The  init_hier_optimization command issues messages similar to the following message to confirm which blocks are available for optimization: Information:\u00a0Sub-block\u00a0u1/a/i1\u00a0(Reference:\u00a0ablock.design)\u00a0is\u00a0treated as\u00a0modifiable.\n (HOPT-001) After global placement, THO calls the  place_pins command to create the new pin placement."}
{"header": "How do I Rebudgeting After compile_fusion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool performs transparent hierarchical optimization during the final_opto stage, which ensures that all interblock and block-top paths are optimized as if the design were flat.\n In this manner, CCD optimizations can address any violations on these paths completely.\n fc_shell>\u00a0 init_hier_optimization -flow pre_route fc_shell>\u00a0 compile_fusion -from final_opto -to final_opto fc_shell>\u00a0 commit_hier_optimization"}
{"header": "How do I Performing THO During route_opt or hyper_route_opt", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After running the  compile_fusion command with THO, the block interface timing changes as compared to when the blocks were implemented individually.\n Because the blocks are now optimized based on the top-level timing picture, you must create updated timing constraints for the blocks before you continue with the  clock_opt command for the blocks.\n The CCD useful skew balance point offsets might have been modified during THO.\n These offsets need to also be made block-context-specific so that the clock tree synthesis step can take them into account.\n This example shows how you can perform budgeting: fc_shell>\u00a0 set budget_instances  \"u1/a/i1 u1/b/i2 \u2026\" fc_shell>\u00a0 set_budget_options -reset -all fc_shell>\u00a0 set_budget_options -add_blocks  $budget_instances fc_shell>\u00a0 set_app_options -list { plan.budget.use_ccd_latency true } fc_shell>\u00a0 set_app_options -list { plan.budget.write_hold_budgets false } fc_shell>\u00a0 set_app_options -list { plan.budget.estimate_timing_mode false } fc_shell>\u00a0 compute_budget_constraints -setup_delay -latency_targets actual -balance false -boundary fc_shell>\u00a0 write_budgets -output budgets-post-compile -force -nosplit -include_balance_points -include_pin_latency"}
{"header": "How do I 12", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "By performing THO at the end of the implementation flow, you have the best optimization potential because you optimize the complete design.\n The  route_opt and hyper_route_opt commands perform postroute optimization on the top and blocks together.\n ECO routing after optimization is performed on all subblocks that are open for editing.\n       THO optimization is completely integrated with the  route_opt and  hyper_route_opt commands.\n Follow this example to use the  hyper_route_opt or  route_opt command on a single host: fc_shell>\u00a0 init_hier_optimization -flow post_route fc_shell>\u00a0 route_opt or\u00a0 hyper_route_opt fc_shell>\u00a0 commit_hier_optimization When using the  route_opt command, it is possible to perform the ECO routing operations, which have to occur after each  route_opt command in parallel, reducing overall runtime.\n You must set up the host options as shown in the  Setting up Transparent Hierarchy Optimization section.\n The  hier_route_eco command performs the ECO routing in the blocks as shown in the following example.\n fc_shell>\u00a0 init_hier_optimization -flow post_route -detached_hier_route_eco fc_shell>\u00a0 route_opt fc_shell>\u00a0 hier_route_eco fc_shell>\u00a0 commit_hier_optimization Note: When the  hyper_route_opt command is used in this way, the tool ignores the setting and does not distribute the ECO routing."}
{"header": "How do I Running Rail Analysis Using RedHawk-SC Fusion", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The RedHawk\u2122 and RedHawk-SC\u2122 power integrity solution is integrated with the implementation flow through the RedHawk Fusion and RedHawk-SC Fusion interface.\n You can use the RedHawk Fusion and RedHawk-SC Fusion feature for rail analysis at different points in the physical implementation flow after power planning and initial placement are completed.\n This enables you to detect potential power network issues before you perform detail routing and thus significantly reduce the turnaround time of the design cycle.\n When placement is complete and the PG mesh is available, use RedHawk Fusion or RedHawk-SC Fusion to perform voltage drop analysis on the power and ground network to calculate power consumption and to check for voltage drop violations.\n You can perform voltage drop analysis at other stages in the design flow, such as after detail routing.\n When chip finishing is complete, use RedHawk Fusion or RedHawk-SC to perform PG electromigration analysis to check for current density violations.\n This chapter describes how to use the RedHawk Fusion or RedHawk-SC Fusion feature to perform rail analysis in the environment.\n For a detailed description about the RedHawk or RedHawk-SC analysis flows and commands, see the  RedHawk User Manual or RedHawk-SC User Manual.\n This chapter includes the following topics: \u2022 Running Rail Analysis Using RedHawk-SC Fusion \u2022 An Overview for RedHawk Fusion and RedHawk-SC Fusion \u2022 Setting Up the Executables \u2022 Specifying RedHawk and RedHawk-SC Working Directories \u2022 Preparing Design and Input Data for Rail Analysis \u2022 Specifying Ideal Voltage Sources as Taps \u2022 Missing Via and Unconnected Pin Checking \u2022 Running Rail Analysis with Multiple Rail Scenarios \u2022 Performing Voltage Drop Analysis \u2022 Performing PG Electromigration Analysis       \u2022 Performing Minimum Path Resistance Analysis \u2022 Performing Effective Resistance Analysis \u2022 Performing Distributed RedHawk Fusion Rail Analysis \u2022 Voltage Driven Power Switch Cell Sizing \u2022 Working With Macro Models \u2022 Performing Signoff Analysis \u2022 Writing Analysis and Checking Reports \u2022 Displaying Maps in the GUI \u2022 Displaying ECO Shapes in the GUI \u2022 Voltage Hotspot Analysis \u2022 Querying Attributes"}
{"header": "How do I An Overview for RedHawk Fusion and RedHawk-SC Fusion", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Similar to the RedHawk Fusion capability, RedHawk-SC Fusion supports gate-level rail analysis and checking capabilities in the Fusion Compiler environment.\n To enable the RedHawk-SC Fusion capability, you need to enable the  rail.enable_redhawk_sc application option and disable the  rail.enable_redhawk application option at the same time.\n For more information about RedHawk-SC Fusion, see  Setting Up the Executables and Specifying RedHawk and RedHawk-SC Working Directories.\n RedHawk Fusion and RedHawk-SC share the same set of analysis and checking commands for rail analysis, and the same GUI for examining the analysis results, except for some limitations.\n  Table\u00a065 compares the  analyze_rail options that are supported in either or both of RedHawk Fusion and RedHawk-SC Fusion.\n Table 65 Comparing Analysis Features Between RedHawk Fusion and RedHawk-SC Fusion RedHawk Fusion RedHawk-SC Fusion -redhawk_script_file   -voltage_drop   -switching_activity         Table 65 Comparing Analysis Features Between RedHawk Fusion and RedHawk-SC Fusion (Continued) RedHawk Fusion RedHawk-SC Fusion -electromigration   -power_analysis   -result_name   -script_only   -bg   -min_path_resistance   -voltage_drop  -effective_resistance   -voltage_drop  -check_missing_via   -voltage_drop     -extra_gsr_option_file   -multiple_script_files   -submit_to_other_machines   Before performing rail analysis using the RedHawk-SC Fusion capability, you must specify the location of the libraries and the required input files as described in  Preparing Design and Input Data for Rail Analysis.\n The following two application options are available only in RedHawk-SC Fusion: rail.toggle_rate : Specify toggle rates for different cell types for rail analysis.\n For example: fc_shell>\u00a0 set_app_options -name rail.toggle_rate  \\ -value {clock 2.0 data 0.2 combinational 0.15 \\ sequential 0.15}       rail.em_only_tech_file : Specify the electromigration rule file for performing PG electromigration analysis.\n Use this option when the electromigration rule information is defined in a separate technology file other than the one specified by the  rail.tech_file application option.\n For example, fc_shell>\u00a0 set_app_options -name rail.em_only_tech_file \\ -value EM_ONLY.rule"}
{"header": "How do I RedHawk Fusion and RedHawk-SC Fusion Data Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Both RedHawk Fusion and RedHawk-SC Fusion support gate-level rail analysis capabilities, including static and dynamic rail analysis.\n You can use RedHawk Fusion and RedHawk-SC Fusion to perform the following types of checking and analysis in the Fusion Compiler environment: \u2022 Missing via and unconnected pin shape checking To check for missing vias or unconnected pin shapes in the design, you first configure the checking-related settings by using the  set_missing_via_check_options command, and then perform the check by using the  analyze_rail -check_missing_via command.\n For more information, see  Missing Via and Unconnected Pin Checking.\n \u2022 Voltage drop analysis To perform voltage drop analysis, use the  analyze_3d_rail\u00a0-voltage_drop -electromigration command.\n To perform voltage drop analysis, use the  analyze_rail\u00a0-voltage_drop command or choose Rail > Analyze Rail and select \u201cVoltage drop analysis\u201d in the GUI.\n Set the  -voltage_drop option to  static,  dynamic,  dynamic_vcd, or dynamic_vectorless to choose the type of analysis you want to perform.\n For more information, see  Performing Voltage Drop Analysis.\n \u2022 PG electromigration analysis To perform PG electromigration analysis, use the  analyze_rail\u00a0-electromigration command.\n For more information, see  Performing PG Electromigration Analysis.\n       \u2022 Minimum path resistance analysis To perform minimum path resistance analysis, use the  analyze_rail -min_path_resistance command.\n In the RedHawk-SC analysis flow, you must use the  -voltage_drop option together with the  -min_path_resistance option for minimum path resistance analysis.\n For more information, see  Performing Minimum Path Resistance Analysis.\n Depending on the type of analysis you run, the tool generates visual displays (maps) of the results that you can view in the Fusion Compiler GUI, as well as error data that you can display in the Fusion Compiler error browser.\n These maps and error data help you discover problem areas and determine corrective action without leaving the Fusion Compiler environment.\n Note: RedHawk Fusion in the Fusion Compiler tool does not support RedHawk signoff analysis features, such as hierarchical analysis or dynamic analysis with lumped or SPICE packages.\n For more information, see  Preparing Design and Input Data for Rail Analysis.\n By default, RedHawk Fusion analyzes only the current design scenario when analyzing a multicorner-multimode design.\n For more information about how to create and specify a rail scenario for rail analysis, see  Running Rail Analysis with Multiple Rail Scenarios.\n Figure\u00a0198 shows where you would use these analysis capabilities in a typical design flow.\n Figure 198 Using RedHawk Fusion in the Fusion Compiler Design Flow Find missing vias Design planning place_opt Initial placement Static voltage clock_opt Static voltage Filler cell insertion drop analysis drop analysis Power-switch cell insertion Dynamic voltage drop analysis route_opt PG electromigration analysis and fixing"}
{"header": "How do I RedHawk/RedHawk-SC Fusion Analysis Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The RedHawk/RedHawk-SC Fusion feature allows you to perform rail analysis during the implementation stage.\n With the required input files, the Fusion Compiler tool creates the RedHawk run script and the Global System Requirements (GSR) configuration file for invoking the RedHawk tool (or the RedHawk-SC Python script for invoking the RedHawk-SC tool) to run PG net extraction, power analysis, voltage drop analysis, and PG electromigration analysis.\n When analysis is complete, the Fusion Compiler tool generates analysis reports and maps using the results calculated by the RedHawk or RedHawk-SC tool.\n You can then check for hotspots graphically in the Fusion Compiler GUI.\n Error data and ASCII reports are also available to check for locations where limits are violated.\n Figure\u00a0199 illustrates the data flow when using RedHawk Fusion or RedHawk-SC Fusion to perform rail analysis in the Fusion Compiler environment.\n       Figure 199 RedHawk Fusion and RedHawk-SC Fusion Data Flow"}
{"header": "How do I Running RedHawk Fusion Commands in the Background", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you have specified the necessary input and design data, you can perform voltage drop and PG electromigration analyses on the design.\n Figure\u00a0200 illustrates the steps in a basic static rail analysis flow.\n       Figure 200 Required Steps for a Basic Rail Analysis Using RedHawk and RedHawk-SC Fusion Run rail analysis analyze_rail -voltage_drop Run PG electromigration analysis Check current violations Check rail analysis results Set application options set_app_options Read design data open_lib,  open_block Specify ideal voltage sources create_taps analyze_rail -electromigration"}
{"header": "How do I Setting Up the Executables", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, when you execute the  analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished.\n You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished.\n To perform layout editing tasks while the tool is running in the background, run the analyze_rail\u00a0-bg command.\n When analysis is completed, run the  open_rail_result -back_annotate command to upload the analysis results to the rail database.\n By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed.\n However, when you specify the  -bg option with the analyze_rail command, you need to run the  open_rail_result\u00a0-back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results.\n       Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not.\n When opening rail results, the tool does not detect if the result is generated with or without the  -bg option.\n The command might not work correctly if you run the open_rail_result\u00a0-back_annotate command to open the rail result that is generated without the  -bg option, or vice versa.\n Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info:\u00a0Running\u00a0REDHAWK_BINARY\u00a0in\u00a0background\u00a0with\u00a0log\u00a0file:\u00a0LOG_FILE The LOG_FILE file is saved in the PWD directory.\n To check if the background  analyze_rail process is active, use the report_background_jobs command."}
{"header": "How do I Specifying RedHawk and RedHawk-SC Working Directories", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To run RedHawk Fusion or RedHawk-SC Fusion features, enable the features and specify the location of the RedHawk or RedHawk-SC executable by setting the  rail.product and  rail.redhawk_path application options.\n For example, fc_shell>\u00a0 set_app_options -name rail.product -value redhawk|redhawk_sc fc_shell>\u00a0 set_app_options -name rail.redhawk_path \\ -value /tools/RedHawk_Linux64e5_V19.0.2p2/bin You must ensure that the specified executable is compatible with the Fusion Compiler version that you are using.\n See Also \u2022 Specifying RedHawk and RedHawk-SC Working Directories"}
{"header": "How do I Preparing Design and Input Data for Rail Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During rail analysis, RedHawk/RedHawk-SC Fusion creates a working directory to store the generated files, including analysis logs, scripts, and various output data.\n By default,       the RedHawk or RedHakw-SC working directory is named RAIL_DATABASE.\n To use a different name for the working directory, use the  rail.database application option.\n The following figure shows the data structures: \u2022 RAIL_CHECKING_DIR: The directory where RedHawk Fusion saves report files on the missing information during rail analysis.\n For example, the tool generates the following report files in the RAIL_CHECKING_DIR directory when static rail analysis is run: \u25e6 libcell.apl_current \u25e6 libcell.apl_cap \u25e6 libcell.missing_liberty \u2022 RAIL_DATABASE: The directory where the tool saves and retrieves results and log files that are generated during power calculation and rail analysis.\n This directory contains the following sub-directories: \u25e6 in-design.redhawk or in-design.redhawk_sc: The directory that contains the following sub-directory: design_name.result: The directory where RedHawk or RedHawk-SC saves the analysis result files.\n \u25e6 design_name : The directory where RedHawk or RedHawk-SC writes analysis results for the Fusion Compiler tool to retrieve for map display and data query.\n For example, running the  open_rail_result command loads the data in this design_name directory for displaying maps in the GUI.\n       If you finish the analysis and want to keep the data for later retrieval, you need to save the existing rail data to another working directory by using the  rail.database application option before proceeding to another  analyze_rail run.\n For example, fc_shell>\u00a0 set_app_options -name rail.database \\ -value RAIL_DATABASE_STATIC_RUN Otherwise, the RedHawk/RedHawk-SC tool overwrites the previously generated rail data with the new data, and issues the following warning message: Warning:\u00a0Rail\u00a0result\u00a0still\u00a0open!\n Will\u00a0be\u00a0overwritten!\n To avoid the warning message, run the  close_rail_result command to remove all rail data from memory before proceeding to another  analyze_rail command run."}
{"header": "How do I Generating Rail Analysis Script Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before analyzing voltage drop and current density violations in a design using the RedHawk/RedHawk-SC Fusion capability, use the  set_app_options command to specify the location of the libraries and the required input files.\n Table\u00a066 lists the application options for specifying design and input data for running RedHawk/RedHawk-SC rail analysis within the Fusion Compiler environment.\n Table 66 Application Options for Specifying Design and Input Data Application Option Description rail.lib_files   fc_shell>\u00a0 set_app_options \\ -name rail.lib_files \\ -value {test1.lib test2.lib} rail.tech_file    fc_shell>\u00a0 set_app_options \\ -name rail.tech_file \\ -value ChipTop.tech   fc_shell>\u00a0 set_app_options \\ -name rail.3dic_enable_die\\ -value {DIE1 true DIE2 true...}       Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description    fc_shell>\u00a0 set_app_options \\ -name rail.instance_power_file\\ -value {E1 FILE1 DIE2 FILE2...} rail.apl_files    fc_shell>\u00a0 set_app_options \\ -name rail.apl_files -value \\ {cell.current current \\ cell.cdev cap} rail.switch_model_files    fc_shell>\u00a0 set_app_options \\ -name rail.switch_model_files \\ -value {switch.model} rail.macro_models   fc_shell>\u00a0 set_app_options \\ -name rail.macro_models \\ -value {gds_cell1 mm_dir1 \\ gds_cell2 mm_dir2} rail.lef_files   rail.def_files   rail.pad_files   create_taps  rail.sta_file     rail.spef_files            Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.effective_resistance_ instance_file   rail.generate_file_type    \u2022  tcl  set_user_input.tcl \u2022  python input_files.py       fc_shell>\u00a0 set_app_options \\ -name rail.generate_file_type -value python rail.generate_file_variab les         \u2022 \u2022 \u2022 \u2022 \u2022  fc_shell>\u00a0 set_app_options \\ -name rail.generate_file_variables -value \\ {PLOC ploc LEF lef_files DEF def_files \\ SPEF spef_files TWF tw_files} rail.enable_new_rail_scena rio  false   rail.enable_parallel_run_r ail_scenario         Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.scenario_name        rail.dump_icc2_results_st yle\u00a0-value\u00a02.0"}
{"header": "How do I Supporting RedHawk-SC Customized Python Script Files", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can run the  analyze_rail\u00a0-script_only command to generate the settings required for running rail analysis based on the information in the design library without actually executing the analysis run.\n The  analyze_rail\u00a0-script_only command writes data to the working directory.\n The output files that are saved to the directory are Table 67 Output data when running analyze_rail -script_only File Name Description RedHawk RedHawk-SC             analyze_rail"}
{"header": "How do I Specifying Ideal Voltage Sources as Taps", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "RedHawk-SC Fusion provides application options and commands to read in user- customized python script files.\n The tool generates all design collaterals (including DEF, LEF, SPEF, TWF and PLOC) from the design library and adds them to the user-customized python script to run voltage drop analysis in a single iteration of analyze_rail.\n The user-customized python script file is supported in rail analysis with multiple rail scenarios, as well as other IR-driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n To use a customized python script file for RedHawk-SC Fusion rail analysis, 1.\n Set the type of script file to  python.\n fc_shell>\u00a0 set_app_options -name rail.generate_file_type -value  python 2.\n Set the  rail.generate_file_variables application option to specify the variables for generating the input files (including DEF, LEF, SPEF, TWF and PLOC files) to add to the user-customized python script file.\n You do not need to set this application option if the customized python script file uses the same values as in RedHawk-SC Fusion.\n DEF File LEF File SPEF File TWF File PLOC File   DEF LEF SPEF TWF PLOC     def_files lef_files spef_files tw_files ploc For example, if you specify a test_def_file for the DEF variable to match with the DEF file specified in the customized python script file, set the following: fc_shell>\u00a0 set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files} 3.\n Create and specify rail scenarios for generating the necessary input files to add to the customized python script.\n Run the  create_rail_scenario command to create a rail scenario and associate it with a design scenario in the current design.\n You can create multiple rail scenarios and associate them with the same scenario in the current design.\n Then run the  set_rail_scenario\u00a0-generate_file\u00a0{LEF\u00a0|\u00a0TWF\u00a0|\u00a0DEF\u00a0|\u00a0SPEF\u00a0| PLOC} command to specify the rail scenario and the type of input files to generate from the design library.\n       Note: When running rail analysis using multicorner-multimode technology, you must create rail scenarios using the  create_rail_scenario command before the  set_rail_scenario command.\n The following example creates the T_low and T_high rail scenarios and generates input files for them: fc_shell>\u00a0 create_rail_scenario -name  T_low  \\ -scenario func_cbest fc_shell>\u00a0 set_rail_scenario -name  T_low  \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py fc_shell>\u00a0 create_rail_scenario -name  T_high  \\ -scenario func_cbest fc_shell>\u00a0 set_rail_scenario -name  T_high  \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py You can then use the customized.py file for multi-rail-scenario rail analysis or other IR- driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n Examples The following example uses a customized python script for multi-rail-scenario rail analysis on a grid system.\n #Required.\n Specify\u00a0the\u00a0below\u00a0options\u00a0to\u00a0enable\u00a0multi-rail-scenario\u00a0rail analysis.\n set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true }  #Required.\n Set\u00a0the\u00a0type\u00a0of\u00a0the\u00a0script\u00a0file\u00a0to\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_type\u00a0-value\u00a0python  #Use\u00a0user-defined\u00a0test_def_files\u00a0for\u00a0DEF\u00a0variable\u00a0to\u00a0match #with\u00a0customized\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_variables\u00a0\\ -value\u00a0{DEF\u00a0test_def_files\u00a0}  create_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-scenario\u00a0func.ss_125c set_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-voltage_drop\u00a0dynamic  create_rail_scenario\u00a0-name\u00a0func.ff_125c_\u00a0-scenario\u00a0func.ff_125c set_rail_scenario\u00a0-name\u00a0func.ff_125c\u00a0\\ -generate_file\u00a0{PLOC\u00a0DEF\u00a0SPEF\u00a0TWF\u00a0LEF}\u00a0\\ -custom_script_file\u00a0./customized.py        set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub\u00a0-V\u00a0-notify\u00a0-b\u00a0y\u00a0\\ -cwd\u00a0-j\u00a0y\u00a0-P\u00a0bnormal\u00a0-l\u00a0mfree=16G}  analyze_rail\u00a0-rail_scenario\u00a0{func.ss_125c\u00a0func.ff_125c}\u00a0\\ -submit_to_other_machine The following example uses a customized python script for multi-rail-scenario rail analysis on a local machine.\n #Required.\n Specify\u00a0the\u00a0below\u00a0options\u00a0to\u00a0enable\u00a0multi-rail-scenario\u00a0rail analysis.\n set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true }  #Required.\n Set\u00a0the\u00a0type\u00a0of\u00a0the\u00a0script\u00a0file\u00a0to\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_type\u00a0-value\u00a0python  #Use\u00a0user-defined\u00a0test_def_files\u00a0for\u00a0DEF\u00a0variable\u00a0to\u00a0match #with\u00a0customized\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_variables\u00a0\\ -value\u00a0{DEF\u00a0test_def_files\u00a0}  create_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-scenario\u00a0func.ss_125c set_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-voltage_drop\u00a0dynamic  create_rail_scenario\u00a0-name\u00a0func.ff_125c_\u00a0-scenario\u00a0func.ff_125c set_rail_scenario\u00a0-name\u00a0func.ff_125c\u00a0\\ -generate_file\u00a0{PLOC\u00a0DEF\u00a0SPEF\u00a0TWF\u00a0LEF}\u00a0\\ -custom_script_file\u00a0./customized.py  set_host_options\u00a0-submit_command\u00a0{local}  analyze_rail\u00a0-rail_scenario\u00a0{func.ss_125c\u00a0func.ff_125c} The following example uses a customized python script for single-scenario rail analysis on a grid system.\n Required.\n Specify\u00a0the\u00a0below\u00a0options\u00a0to\u00a0enable\u00a0multi-rail-scenario\u00a0rail analysis.\n set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true }  #Required.\n Set\u00a0the\u00a0type\u00a0of\u00a0the\u00a0script\u00a0file\u00a0to\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_type\u00a0-value\u00a0python  #Use\u00a0user-defined\u00a0test_def_files\u00a0for\u00a0DEF\u00a0variable\u00a0to\u00a0match #with\u00a0customized\u00a0python.\n       set_app_options\u00a0-name\u00a0rail.generate_file_variables\u00a0\\ -value\u00a0{DEF\u00a0test_def_files\u00a0}  create_rail_scenario\u00a0-name\u00a0func.ff_125c_\u00a0-scenario\u00a0func.ff_125c set_rail_scenario\u00a0-name\u00a0func.ff_125c\u00a0\\ -generate_file\u00a0{PLOC\u00a0DEF\u00a0SPEF\u00a0TWF\u00a0LEF}\u00a0\\ -custom_script_file\u00a0./customized.py  set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub\u00a0-V\u00a0-notify\u00a0-b\u00a0y\u00a0\\ -cwd\u00a0-j\u00a0y\u00a0-P\u00a0bnormal\u00a0-l\u00a0mfree=16G}  analyze_rail\u00a0-rail_scenario\u00a0{func.ff_125c}\u00a0\\ -submit_to_other_machine The following example uses a customized python script for IR-driven placement on a grid system.\n Required.\n Specify\u00a0the\u00a0below\u00a0options\u00a0to\u00a0enable\u00a0multi-rail-scenario\u00a0rail analysis.\n set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true }  #Required.\n Set"}
{"header": "How do I Specifying Ideal Voltage Sources as Taps", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "the\u00a0type\u00a0of\u00a0the\u00a0script\u00a0file\u00a0to\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_type\u00a0-value\u00a0python  #Use\u00a0user-defined\u00a0test_def_files\u00a0for\u00a0DEF\u00a0variable\u00a0to\u00a0match #with\u00a0customized\u00a0python.\n set_app_options\u00a0-name\u00a0rail.generate_file_variables\u00a0\\ -value\u00a0{DEF\u00a0test_def_files\u00a0}  create_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-scenario\u00a0func.ss_125c set_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-voltage_drop\u00a0dynamic  create_rail_scenario\u00a0-name\u00a0func.ff_125c_\u00a0-scenario\u00a0func.ff_125c set_rail_scenario\u00a0-name\u00a0func.ff_125c\u00a0\\ -generate_file\u00a0{PLOC\u00a0DEF\u00a0SPEF\u00a0TWF\u00a0LEF}\u00a0\\ -custom_script_file\u00a0./customized.py  set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub\u00a0-V\u00a0-notify\u00a0-b\u00a0y\u00a0\\ -cwd\u00a0-j\u00a0y\u00a0-P\u00a0bnormal\u00a0-l\u00a0mfree=16G} # Enable IR-driven placement before running clock_opt -from final_opto set_app_options -name opt.common.power_integrity -value true  clock_opt -from final_opto The following example uses a customized python script for concurrent clock and data optimization on a multicorner and multimode design on a grid system.\n       #Required.\n Specify\u00a0the\u00a0below\u00a0options\u00a0to\u00a0enable\u00a0MCMM-based\u00a0optimization.\n set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true } set_app_options\u00a0-name\u00a0rail.generate_file_type\u00a0-value\u00a0python  #Use\u00a0user-defined\u00a0test_def_files\u00a0for\u00a0DEF\u00a0variable\u00a0to\u00a0match #with\u00a0customized\u00a0python set_app_options\u00a0-name\u00a0rail.generate_file_variables\u00a0\\ -value\u00a0{DEF\u00a0test_def_files\u00a0}  create_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-scenario\u00a0func.ss_125c set_rail_scenario\u00a0-name\u00a0func.ss_125c\u00a0-voltage_drop\u00a0dynamic  create_rail_scenario\u00a0-name\u00a0func.ff_125c_\u00a0-scenario\u00a0func.ff_125c set_rail_scenario\u00a0-name\u00a0func.ff_125c\u00a0\\ -generate_file\u00a0{PLOC\u00a0DEF\u00a0SPEF\u00a0TWF\u00a0LEF}\u00a0\\ -custom_script_file\u00a0./customized.py  set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub\u00a0-V\u00a0-notify\u00a0-b\u00a0y\u00a0-cwd\u00a0-j\u00a0y\u00a0\\ -P\u00a0bnormal\u00a0-l\u00a0mfree=16G} # Enable IR-driven CCD analysis before running route_opt set_app_options -name opt.common.power_integrity -value true route_opt See Also \u2022 Specifying RedHawk and RedHawk-SC Working Directories"}
{"header": "How do I Validating the Taps and Finding Invalid Taps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Taps are used to model the external voltage source environment in which the device under analysis operates; they are not part of the design itself, but can be thought of as virtual models of voltage sources.\n The locations of the ideal voltage sources and the ideal power supplies in the design are required to achieve accurate rail analysis results.\n To create a tap, use the  create_taps command.\n You can create multiple taps by running multiple  create_taps commands.\n To specify a name for the created tap, use the  -name option.\n If the specified name is already present in the design, the tool issues a warning message, and replaces the original tap with the new one.\n When you create multiple taps by a single invocation of the create_taps command, all of the created taps are named by using the  tap_name _NNN naming convention, where NNN is a unique integer identifier and  tap_name is the string argument to the  -name option.\n       You can create taps in any of the following ways: \u2022 Treating top-level PG pins as taps Use the  -top_pg option when the block does not have physical pad or bump information available.\n Use the  -supply_net option to explicitly associate a tap to the supply (either power or ground) net connected to the object from which the tap was defined.\n To implicitly associate a tap with the supply net, run the  create_taps command without the -supply_net option.\n The following example creates taps for all the top-level supply pins.\n fc_shell>\u00a0 create_taps -supply_net VDD -top_pg \u2022 Creating taps at absolute coordinates Use the  -layer and  -point options to create taps at the specified coordinates.\n If there is no supply net, supply pin, or via shape at the specified location, which means there is no conductive path to the supply network, the tap has no effect on rail analysis despite being present.\n If you define a tap in a location where a tap already exists, the tool issues a warning message and replaces the original tap with the new one.\n You must specify the supply net with which this tap is associated by using the -supply_net\u00a0 option.\n Note: When you use the  -point option with the  -of_objects option, the location is relative to the origin of the specified object.\n Otherwise, it is relative to the origin of the current top-level block.\n The following example creates a tap using absolute coordinates.\n The command checks whether the coordinate location touches any layout shape.\n fc_shell>\u00a0 create_taps -supply_net VDD \\ -layer 3 -point {100.0 200.0} Warning:\u00a0Tap\u00a0point\u00a0(100.0,\u00a0200.0)\u00a0on\u00a0layer\u00a03\u00a0for\u00a0net\u00a0VDD\u00a0does\u00a0not touch\u00a0any\u00a0polygon\u00a0(RAIL-305) \u2022 Using existing instances as taps To create taps on specified objects, use the  create_taps\u00a0-of_objects command.\n Each item in the object list can be a cell or a library cell, or a collection of cells and library cells.\n By default, the tool creates the taps on the power and ground pins of the objects.\n If you specify the  -point option, the tool creates the taps at the specified physical location relative to the origin of each object.\n       Use existing instances for creating taps when analyzing a top-level design where pad cells are instantiated physically.\n Use the  -supply_net option to explicitly associate a tap to the supply (either power or ground) net connected to the object from which the tap was defined.\n To implicitly associate a tap with the supply net, run the  create_taps command without the - supply_net option.\n The following example creates taps for each instance of the some_pad_cell library cell.\n The tool creates one tap per instance on the metal1 layer at a location of {30.4 16.3} relative to the origin of the cell instance.\n fc_shell>\u00a0 create_taps -of_objects [get_lib_cell */some_pad_cell]\\ -layer metal1 -point {30.4 16.3} The following example creates taps on all power and ground pins of all cell instances that match the *power_pad_cell* pattern.\n fc_shell>\u00a0 create_taps -of_objects [get_cells -hier \\ *power_pad_cell*] \u2022 Importing a tap file If you are working with a block that does not yet have pins defined, or if the location or design of the pad cells is not finalized, you can define tap locations, layer numbers, and supply nets in an ASCII file and then import it into the tool by using the  create_taps -import command.\n The supported tap file format is as follows: net_name layer_number [X-coord Y-coord] Lines starting with semicolon (;) or pound (#) symbols are treated as comments.\n The x- coordinate and y-coordinate values are specified in microns.\n For example, fc_shell>\u00a0 exec cat tap_file VDD\u00a03\u00a0500.000\u00a0500.000 VSS\u00a05\u00a0500.000\u00a0500.000 fc_shell>\u00a0 create_taps -import tap_file \u2022 Creating taps with packages A simple package RLC (resistance-inductance-capacitance) model provides a fixed set of electrical characteristics assigned to all power and ground pads.\n To use simple package RLC models for rail analysis, you need to specify the pad location file which defines the simple RLC model by using  rail.pad_files application option.\n       For a detailed description about simple package RLC models, see the related section in the  RedHawk User Manual.\n Note: Before creating taps with simple package RLC models, you must enable the RedHawk signoff license key using the rail.allow_redhawk_license_checkout application option."}
{"header": "How do I Tap Attributes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When creating taps, by default the  create_taps command verifies that the created taps are inserted in valid locations.\n The tool issues a warning message if the tap does not touch any layout shape.\n To place taps outside a shape without issuing a warning message, disable the checking by using the  -nocheck option.\n The following command creates a tap with the  -nocheck option enabled.\n No warning message is issued.\n fc_shell>\u00a0 create_taps -supply_net VDD -layer 3 \\ -point {100.0 200.0} -nocheck"}
{"header": "How do I Finding Invalid Taps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "During validation checking, the tool marks each inserted tap object with the is_valid_location attribute to indicate its validity.\n When validation checking is enabled, the attribute value is  true for the valid taps and  false for the invalid taps.\n When the -nocheck option is used, the attribute value is  unknown for all taps.\n The tool updates the tap attributes in subsequent voltage drop and minimum path resistance analyses.\n Each tap belonging to the PG nets is checked against the extracted shape.\n When the analysis is complete, the tool updates the tap validity status based on the rail analysis results.\n The following example first lists the attributes of tap objects that are added to the block in this command run, and then checks if the Tap_1437 tap passes the validation checking.\n fc_shell>\u00a0 list_attributes -application -class tap...\n Properties: A\u00a0-\u00a0Application-defined U\u00a0-\u00a0User-defined I\u00a0-\u00a0Importable\u00a0from\u00a0design/library\u00a0(for\u00a0user-defined) S\u00a0-\u00a0Settable B\u00a0-\u00a0Subscripted  Attribute\u00a0Name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Object\u00a0\u00a0\u00a0\u00a0\u00a0Type\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Properties\u00a0\u00a0Constraints ------------------------------------------------------------------------- -------       context\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0integrity, rail, session full_name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A is_valid_location\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0boolean\u00a0\u00a0\u00a0\u00a0A layer_name\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A layer_number\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0int\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0A net\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A object_class\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A parasitics\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A position\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0coord\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0A static_current\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0double\u00a0\u00a0\u00a0\u00a0\u00a0A type\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tap\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0string\u00a0\u00a0\u00a0\u00a0\u00a0A absolute_coord, auto_pg,\u00a0cell_coord,\u00a0cell_pg,\u00a0lib_cell_coord,\u00a0lib_cell_pg,\u00a0signal, terminal, top_pg fc_shell>\u00a0 get_attribute [get_taps Tap_1437] is_valid_location true"}
{"header": "How do I Finding Substitute Locations for Invalid Taps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To find taps that fail the validity checking, use the  get_taps command to report the taps that have  is_valid_location attribute set to  false.\n For example, fc_shell>\u00a0 get_attribute [ get_taps Tap_1437 ] is_valid_location false"}
{"header": "How do I Removing Taps", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If the specified location for a tap is invalid, use the  -snap_distance option of the create_taps command to find a substitute location for the tap.\n The command searches the nearby layout shapes within the specified snap distance both horizontally and vertically on the same layer as defined by the  -layer option.\n The tap is reinserted at the corner of a valid shape which is within the minimum distance to the specified location.\n Note: You can search for a substitute location only for the invalid taps that are specified by the  -point and  -layer options.\n For example, fc_shell>\u00a0 create_taps -point {50,50} -layer {M1} \\ -snap_distance 100 Snap\u00a0tap\u00a0point\u00a0from\u00a0original\u00a0location\u00a0(50.000,\u00a050.000)\u00a0to\u00a0new location\u00a0(90.000,\u00a065.910) As shown in  Figure\u00a0201, the specified tap location does not touch any layout shape.\n The red rectangle is the shape closest to the specified location and its lower-right corner has       the minimum distance among all the other rectangles.\n The tool reinserts the tap at the lower-right corner of the red rectangle.\n Figure 201 Finding a Substitute Location for an Invalid Tap Original {x,y} 100 100 100 100 Snapped tap"}
{"header": "How do I Missing Via and Unconnected Pin Checking", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove taps that were previously created using the  create_taps command, use the  remove_taps command.\n To remove specific taps, use the  -filter option with the get_taps command.\n The following example removes all the supply pin taps that are of the type top_pg: fc_shell>\u00a0 remove_taps [get_taps -filter type==top_pg] To remove all the taps in the block, run the following command: fc_shell>\u00a0 remove_taps"}
{"header": "How do I Setting Checking Options", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: Missing via and unconnected pin checking is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n Before you check for missing vias and unconnected pins, make sure you have the required input files as described in  Preparing Design and Input Data for Rail Analysis.\n Check for missing vias or unconnected pins in the block during voltage drop analysis or in a separate run.\n For example, you can perform the checking after completing the power       structure and before running the  place_opt command.\n This allows you to find power network errors in the design before rail analysis.\n By default, RedHawk/RedHawk-SC Fusion detects the following types of power network errors: \u2022 Unconnected pin shapes: Pin shapes that are not contiguously and physically connected to an ideal voltage source.\n \u2022 Missing vias: If two overlapping metal shapes do not contain a via within their overlapping area, it is considered a potential missing via error.\n To check for and fix missing vias or unconnected pins, 1.\n Define configuration options by using the  set_missing_via_check_options command, as described in  Setting Checking Options.\n 2.\n Save the block by using the  save_block command.\n 3.\n Perform the checking by using the  analyze_rail\u00a0-check_missing_via command, as described in  Checking Missing Vias and Unconnected Pins.\n In the RedHawk-SC Fusion flow, you must specify the  -check_missing_via option together with the -voltage_drop option.\n 4.\n Examine the checking results by opening the generated error files in the error browser or writing the checking results to an output file, as described in  Viewing Error Data and Writing Analysis and Checking Reports.\n 5.\n Insert PG vias to fix the reported missing vias, as described in  Fixing Missing Vias."}
{"header": "How do I Checking Missing Vias and Unconnected Pins", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Before checking for missing vias or unconnected pins in the design, use the set_missing_via_check_options command to specify the necessary options.\n To check or remove the option settings, use the  report_missing_via_check_options or remove_missing_via_check_options command, respectively.\n Table\u00a068 lists the commonly used options for the  set_missing_via_check_options command.\n For a detailed description about each option, see the man page.\n Table 68 Commonly Used Options for the set_missing_via_check_options Command Option Description -redhawk_script_file        Table 68 Commonly Used Options for the set_missing_via_check_options Command (Continued) Option Description exclude_stack_via   check_valid_vias  -exclude_cell -exclude_instance    -exclude_regions  sort_by_hot_inst   -threshold     -min_width  -pitch   -gds     -ignore_inter_met -toplayer -bottomlayer"}
{"header": "How do I Viewing Error Data", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  analyze_rail -check_missing_via command to check for missing vias and unconnected pins in the block based on the settings specified by the set_missing_via_check_options command.\n Use the  -voltage_drop option if you want to run missing via and unconnected pin checks together with voltage drop analysis.\n The tool then reports all missing vias found in the geometry with voltage values in the missing via report.\n To set a voltage threshold across layers for filtering the report, use the  -threshold option of the set_missing_via_check_options command.\n You can set multiple threshold values in a missing via check.\n       Note: In the RedHawk-SC Fusion flow, you must specify the  -check_missing_via option together with the  -voltage_drop option.\n In cases you want to report missing vias with and without setting a voltage threshold in one  analyze_rail run, first set the desired threshold value (for example, 0.001) and then reset the value to -1.\n Setting  -threshold option to -1 disables voltage checking.\n When the missing via check is completed, open the generated error data to examine the errors in the error browser.\n For details, see  Viewing Error Data.\n Example 48 fc_shell>\u00a0 set_missing_via_check_options -exclude_stack_via \\ -threshold 0.0001 fc_shell>\u00a0 analyze_rail -voltage_drop static -check_missing_via \\ -nets {VDD VSS} The above example sets the threshold value to 0.0001 and compares voltages across two ends of a via, excluding stack vias.\n It then runs the missing via check during static rail analysis.\n The RedHawk script file includes the following commands: perform\u00a0extraction\u00a0-power\u00a0-ground perform\u00a0analysis\u00a0-static mesh\u00a0vias\u00a0-report_missing\u00a0-exclude_stack_via\u00a0-threshold\u00a00.0001\u00a0\\ -o\u00a0apache.missingVias1 Example 49 fc_shell>\u00a0 set_missing_via_check_options -exclude_stack_via \\ -threshold -1 fc_shell>\u00a0 analyze_rail -voltage_drop -check_missing_via \\ -nets {VDD VSS} The above example sets the threshold value to -1 to disable the voltage checking, and runs the missing via check.\n The RedHawk script file includes the following commands: perform\u00a0extraction\u00a0-power\u00a0-ground mesh\u00a0vias\u00a0-report_missing\u00a0-exclude_stack_via\u00a0-threshold\u00a0-1\u00a0\\ -o\u00a0apache.missingVias1.nothreshold Example 50 fc_shell>\u00a0 set_missing_via_check_options -exclude_stack_via \\ -threshold 0.001 fc_shell>\u00a0 set_missing_via_check_options -exclude_stack_via \\ -threshold 0.002 fc_shell>\u00a0 set_missing_via_check_options -exclude_stack_via \\       -threshold -1 fc_shell>\u00a0 analyze_rail -voltage_drop static -check_missing_via \\ -nets {VDD VSS} fc_shell>\u00a0 report_rail_result -type missing_vias -supply_nets \\ {VDD VSS} rpt.missing_vias Information:\u00a0writing\u00a0rpt.missing_vias.no_threshold\u00a0done Information:\u00a0writing\u00a0rpt.missing_vias\u00a0done In the above example, three different threshold values are set for a missing via check.\n The tool generates two missing via reports: rpt.missing_vias.no_threshold includes all missing vias found in the geometry, while rpt.missing_vias includes the vias whose voltage difference across two ends is less than 0.001 and 0.002."}
{"header": "How do I Fixing Missing Vias", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "RedHawk or RedHawk-SC Fusion saves the checking error data file, named missing_via.\n supplyNetName.err, in the working directory.\n The tool generates one error data file for each supply net.\n Before you quit the current session, be sure to save the block to keep the generated error data in the block.\n To open an error data file in the error browser, choose File > Open...\n from the Error Browser dialog box, and then select the error data file to open in the Open Error Data dialog box (see  Figure\u00a0202 ).\n For more information about the error browser, see \u201cUsing the Error Browser\u201d in the  Fusion Compiler Graphical User Interface User Guide.\n       Figure 202 Opening Error Data from the Error Browser See Also \u2022 Specifying RedHawk and RedHawk-SC Working Directories"}
{"header": "How do I Running Rail Analysis with Multiple Rail Scenarios", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To fix the missing vias by inserting PG vias based on the specified DRC error objects written by the  analyze_rail command, use the  fix_pg_missing_vias command.\n When the tool inserts a PG via for a missing via error object, it sets the status of the error object to  fixed in the error browser (see  Figure\u00a0203 ).\n This allows you to quickly check if all the missing vias are fixed.\n       Figure 203 Error Status After Inserting PG Vias for Missing Vias The tool marks the error object as fixed The following example inserts PG vias for all error objects of the VDD nets reported by the analyze_rail\u00a0-check_missing_via command: fc_shell>\u00a0 set errdm [open_drc_error_data rail_miss_via.VDD.err] fc_shell>\u00a0 set errs [get_drc_errors -error_data $errdm] fc_shell>\u00a0 fix_pg_missing_vias -error_data $errdm $errs"}
{"header": "How do I Specifying a Design Scenario for Rail Analysis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To control scenarios for RedHawk Fusion or RedHawk-SC Fusion rail analysis: \u2022 Use the  rail.scenario_name application option to specify a different design scenario for rail analysis.\n For details, see  Specifying a Design Scenario for Rail Analysis.\n       \u2022 You can create rail scenarios and associate them with a design scenario in the current design.\n This allows you to identify possible power integrity issues by running optimization and rail analysis on one or more rail scenarios.\n For details, see  Creating and Specifying Rail Scenarios for Rail Analysis."}
{"header": "How do I Creating and Specifying Rail Scenarios for Rail Analysis", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, RedHawk or RedHawk-SC Fusion analyzes only the current design scenario for a multicorner-multimode design.\n To specify a different design scenario for rail analysis, use the  rail.scenario_name application option.\n The tool honors the specified design scenario for the IR-driven features in power integrity flow, such as IR-driven placement, IR- driven concurrent clock and data optimization, and IR-driven optimization.\u200b Here is a script example: open_lib open_block  set_app_option\u00a0-name\u00a0rail.technology\u00a0-value\u00a07 set_app_options\u00a0-name\u00a0rail.tech_file\u00a0-value\u00a0\u00a0./Apache.tech set_app_options\u00a0-name\u00a0rail.lib_files\u00a0-value\u00a0{\\ A.lib\u00a0\\ B.lib\u00a0} set_app_options\u00a0-name\u00a0rail.switch_model_files\u00a0-value {./switch_cells.txt\u00a0} source\u00a0./test_taps.tcl  current_scenario func_max set_app_options -name rail.scenario_name -value func_typ  analyze_rail\u00a0-voltage_drop"}
{"header": "How do I Performing Voltage Drop Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can create multiple rail scenarios and associate them with a design scenario in the current design.\n The created rail scenarios are saved in the design library.\n To run rail analysis on multiple rail scenarios: 1.\n Specify the following application options to enable multi-rail-scenario rail analysis: fc_shell>\u00a0 set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true }       2.\n Run the  set_scenario_status\u00a0-ir_drop command to enable rail analysis for the specified design scenario.\n fc_shell>\u00a0 set_scenario_status func_cbest -ir_drop true 3.\n Create a rail scenario and associate it with an existing design scenario.\n Specify rail attributes for the created rail scenario with the  set_rail_scenario command.\n You can create multiple rail scenarios for different purposes and associate them with an existing design scenario.\n fc_shell>\u00a0 create_rail_scenario -name  T_low  \\ -scenario func_cbest fc_shell>\u00a0 set_rail_scenario -name  T_low  \\ -voltage_drop dynamic -extra_gsr_option_file extra.gsr \\ -nets {VDD VSS} fc_shell>\u00a0 create_rail_scenario -name  T_high  \\ -scenario func_cbest fc_shell>\u00a0 set_rail_scenario -name  T_high  \\ -voltage_drop dynamic -extra_gsr_option_file extra2.gsr \\ -nets {VDD VSS} 4.\n Specify the multicore processing setting with the  set_host_options command.\n For example, to run rail analysis on a local host, use the following command: fc_shell>\u00a0 set_host_options -submit_command {local} To run analysis on a grid system, use the following command: fc_shell>\u00a0 set_host_options -submit_protocol sge \\ -submit_command {qsub -V -b y -cwd -P bnormal -l mfree=16G} 5.\n Run rail analysis with the  analyze_rail command.\n fc_shell>\u00a0 analyze_rail -rail_scenario {T_high T_low} \\ -submit_to_other_machines Note: To use the multi-rail-scenario rail analysis capability for IR-driven placement or IR-driven concurrent clock and data optimization, you must set the following application option before the  clock_opt\u00a0-from\u00a0final_opto or  route_opt command: fc_shell>\u00a0 set_app_options \\ -name opt.common.power_integrity -value true For more information about power integrity analysis, see the  Enabling the Power Integrity Features section.\n       Examples The following example runs rail analysis on multiple rail scenarios.\n #\u00a0Specify\u00a0options\u00a0for\u00a0multi-rail-scenario\u00a0rail\u00a0analysis set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true }  set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub\u00a0-V\u00a0-notify\u00a0-b\u00a0y\u00a0-cwd\u00a0-j\u00a0y\u00a0\\ -P\u00a0bnormal\u00a0-l\u00a0mfree=16G}  #\u00a0Custom\u00a0RedHawk-SC\u00a0Fusion\u00a0python\u00a0script\u00a0to\u00a0specify\u00a0user-defined #\u00a0toggle\u00a0rate\u00a0for\u00a0scenario\u00a0T_custom create_rail_scenario\u00a0-name\u00a0T_custom\u00a0-scenario\u00a0func_cbest set_rail_scenario\u00a0-name\u00a0T_custom\u00a0-custom_script_file\u00a0custom_sc.py  #\u00a0Default\u00a0RedHawk-SC\u00a0Fusion\u00a0toggle\u00a0rate\u00a0for\u00a0scenario\u00a0T_def create_rail_scenario\u00a0-name\u00a0T_def\u00a0-scenario\u00a0func_cbest set_rail_scenario\u00a0-name\u00a0T_def\u00a0-voltage_drop\u00a0dynamic\u00a0-nets\u00a0{VDD\u00a0VSS}  #\u00a0Run\u00a0RedHawk-SC\u00a0Fusion\u00a0rail\u00a0analysis\u00a0on\u00a0the\u00a0specified\u00a0rail\u00a0scenario analyze_rail\u00a0-rail_scenario\u00a0{T_custom\u00a0T_def}\u00a0-submit_to_other_machines  #\u00a0(Optional)\u00a0Open\u00a0and\u00a0examine\u00a0the\u00a0generated\u00a0rail\u00a0results open_rail_result\u00a0{T_custom\u00a0T_def} The following example runs multi-rail-scenario rail analysis in the power integrity flow.\n ##\u00a0Specify\u00a0RedHawk/RedHawk-SC\u00a0based\u00a0options set_app_options\u00a0-name\u00a0rail.enable_redhawk\u00a0-value\u00a0true set_app_options\u00a0-name\u00a0rail.enable_redhawk_sc\u00a0-value\u00a0false set_app_options\u00a0-name\u00a0rail.redhawk_path\u00a0-value\u00a0/test/bin set_app_options\u00a0-name\u00a0rail.tech_file\u00a0-value\u00a0design_data/tech/rh.tech set_app_options\u00a0-name\u00a0rail.lib_files\u00a0-value\u00a0{ inputs/test/CCSP_test.lib } set_host_options\u00a0-submit_protocol\u00a0sge\u00a0-submit_command\u00a0{qsub\u00a0-V\u00a0\\ -notify\u00a0-b\u00a0y\u00a0-cwd\u00a0-j\u00a0y\u00a0-P\u00a0bnormal\u00a0-l\u00a0mfree=16G}  ##\u00a0Specify\u00a0options\u00a0for\u00a0running\u00a0optimization\u00a0\u00a0on\u00a0multiple\u00a0rail\u00a0scenarios set_app_options\u00a0-list\u00a0{ rail.enable_new_rail_scenario\u00a0true rail.enable_parallel_run_rail_scenario\u00a0true } ##\u00a0Enable\u00a0IR\u00a0drop\u00a0flag\u00a0for\u00a0a\u00a0given\u00a0scenario set_scenario_status\u00a0[current_scenario]\u00a0-ir_drop\u00a0true ##\u00a0Create\u00a0a\u00a0rail\u00a0scenario\u00a0and\u00a0specify\u00a0associated\u00a0options create_rail_scenario\u00a0-name\u00a0T_low\u00a0-scenario\u00a0func_cbest set_rail_scenario\u00a0-name\u00a0T_low\u00a0-voltage_drop\u00a0dynamic\u00a0\\       -extra_gsr_option_file\u00a0extra.gsr\u00a0-nets\u00a0{VDD\u00a0VSS}  create_rail_scenario\u00a0-name\u00a0T_high\u00a0-scenario\u00a0func_cbest set_rail_scenario\u00a0-name\u00a0T_high\u00a0-voltage_drop\u00a0dynamic\u00a0\\ -extra_gsr_option_file\u00a0extra2.gsr\u00a0-nets\u00a0{VDD\u00a0VSS}  ##\u00a0Enable\u00a0power\u00a0integrity\u00a0flow set_app_options\u00a0-name\u00a0opt.common.power_integrity\u00a0-value\u00a0true"}
{"header": "How do I Viewing Voltage Drop Analysis Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: Before running the  analyze_rail command to calculate voltage drops and current violations, ensure you have provided the input files required by each analysis mode.\n For more information about preparing input files, see  Preparing Design and Input Data for Rail Analysis.\n Voltage drop analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n To invoke the RedHawk/RedHawk-SC tool for calculating voltage drops of the specified power and ground networks, use the  analyze_rail command with the following options: \u2022 Use the  -voltage_drop option to specify the analysis mode.\n \u25e6 static : Performs static voltage drop analysis.\n \u25e6 dynamic : Performs dynamic voltage drop analysis.\n \u25e6 dynamic_vectorless : Performs dynamic voltage drop analysis without Verilog Change Dump (VCD) inputs.\n \u25e6 dynamic_vcd : Performs dynamic voltage drop analysis with VCD inputs.\n When enabled, use the  -switching_activity option to specify a switching activity file.\n \u2022 Use the  -nets option to specify the power and ground supply nets to analyze.\n The tool considers all the switched or internal power nets of the specified power nets in the analysis.\n You do not need to explicitly specify the internal power nets.\n \u2022 (Optional) Use the  -switching_activity option to specify a switching activity file.\n The supported file formats are:  VCD,  SAIF, and  ICC_ACTIVITY.\n When not specified, by default the tool uses the toggle rate for rail analysis.\n       Note: If you are using the dynamic vector-free mode, you do not need to provide switching activity information.\n To specify a switching activity file, use the  -switching_activity option by using the following syntax: -switching_activity\u00a0{ type file_name [ strip_path ]\u00a0[ start_time end_time ]} \u25e6 VCD : Specifies a VCD file that is generated from a gate-level simulation.\n By default, rail analysis reads and uses all time values in the VCD file.\n To specify the time window to read from the VCD file, use the optional  start_time and  end_time arguments with the  -switching_activity option.\n When specified, the tool reads all time values from the VCD file, but uses only the specified time window for rail analysis.\n \u25e6 SAIF : Specifies one or more SAIF files generated from a gate-level simulation.\n \u25e6 icc_activity : Runs the Fusion Compiler write_saif command to generate a SAIF file that contains the user-annotated and simulated switching activity (including state-dependent and path-dependent information) for the complete design without running the propagation engine.\n The  strip_path argument removes the specified string from the beginning of the object names.\n Using this option modifies the object names in the VCD or SAIF file to make them compatible with the object names in the block.\n The  strip_path argument is case- sensitive.\n \u2022 (Optional) By default, the tool uses the RedHawk/RedHawk-SC power analysis feature to calculate the power consumption of the specified power and ground network.\n If you prefer having the Fusion Compiler tool generate the necessary power data for rail analysis, set the  -power_analysis option to  icc2.\n For a detailed description about how to run power analysis using the Fusion Compiler report_power command.\n \u2022 (Optional) By default, the  analyze_rail command automatically generates a GSR file for running RedHawk rail analysis.\n To specify an external GSR file to append to the GSR file generated in the current run, use the  -extra_gsr_option_file option.\n \u2022 (Optional) Use the  -redhawk_script_file option to specify an existing RedHawk script file generated in an earlier  analyze_rail run.\n When using an existing script file for rail analysis, the tool honors the settings in this file and ignores all other currently enabled options.\n For example, if you run the       analyze_rail\u00a0-voltage_drop\u00a0static -redhawk_script_file\u00a0myscript.tcl command, the tool ignores the  -voltage_drop option setting.\n When the  -redhawk_script_file option is not specified, you must specify the nets to analyze by using the  -nets option.\n The following example performs static voltage drop analysis on the VDD and VSS nets with the optional settings defined in a GSR configuration file.\n fc_shell>\u00a0 analyze_rail -voltage_drop static -nets {VDD VSS} \\ -extra_gsr_option_file add_opt.gsr"}
{"header": "How do I Performing PG Electromigration Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When analysis is complete, the tool saves the analysis results and logs in the working directory.\n For more information about the working directories, see  Specifying RedHawk and RedHawk-SC Working Directories.\n The  analyze_rail command generates the following files to invoke the RedHawk tool for running rail analysis: \u2022 The RedHawk run script (analyze_rail.tcl) \u2022 The RedHawk GSR configuration file (*.gsr) The  analyze_rail command generates the following file to invoke the RedHawk-SC tool for running rail analysis: \u2022 The RedHawk-SC Python script (analyze_rail.py) The RedHawk or RedHawk-SC tool generates the following files in the in- design.redhawk/ design_name.result (or in-design.redhawk_sc/ design_name.result in RedHawk-SC flow) directory when rail analysis is complete: \u2022 The RedHawk analysis log (analyze_rail.log.*) \u2022 Timing window file (*.sta) \u2022 Signal SPEF files (*.spef) \u2022 DEF/LEF files (*.def, *.lef) for the full-chip analysis When voltage drop analysis is complete, the tool saves the analysis results (*.result) in the  design_name directory under the working directory.\n The rail analysis results are used to display maps and query attributes to determine the problem areas with large voltage drops.\n       \u2022 To reload the rail results for displaying maps in the GUI, use the  open_rail_result command.\n For example, fc_shell>\u00a0 open_rail_result REDHAWK_RESULT For more information about displaying maps, see  Displaying Maps in the GUI.\n \u2022 To write out the rail analysis results, use the  report_rail_result command.\n You must specify the result type with the  -type option.\n For example, to write out the voltage drop values for the current block, set the  -type option with the voltage_drop_or_rise argument.\n For more information, see  Writing Analysis and Checking Reports.\n \u2022 To query the results stored in the current rail results cache, use the  get_attribute commands.\n For more information, see  Querying Attributes.\n Note: RedHawk Fusion does not support results that are generated by the RedHawk tool outside of the Fusion Compiler environment.\n The RedHawk  dump icc2_result command works only within the Fusion Compiler session."}
{"header": "How do I Viewing PG Electromigration Analysis Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: PG electromigration analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n To analyze the current density on PG nets and identify the segments with potential electromigration issues, run the  analyze_rail\u00a0-electromigration command.\n The analysis results are saved in the working directory.\n To perform electromigration analysis, 1.\n Set the  rail.tech_file application option to specify the Apache technology file (*.tech) that defines the layer-by-layer current density limits.\n For example, fc_shell>\u00a0 set_app_options -name rail.tech_file \\ -value design_data/tech/test.tech       2.\n Run the  analyze_rail command with the following options: \u25e6 Use the  -voltage_drop and  -electromigration options to enable electromigration analysis.\n \u25e6 Use the  -nets option to specify the power and ground supply nets to analyze.\n The tool considers all the switched or internal power nets of the specified power nets in the analysis.\n You do not need to explicitly specify the internal power nets.\n \u25e6 (Optional) By default, the  analyze_rail command automatically generates a GSR file for running RedHawk rail analysis.\n To specify an external GSR file to append to the GSR file generated in the current run, use the  -extra_gsr_option_file option.\n \u25e6 (Optional) To specify an existing RedHawk script file that was generated in an earlier  analyze_rail run, use the  -redhawk_script_file option.\n When using an existing script file for rail analysis, the tool honors the settings in this script file and ignores all other currently enabled options.\n For example, if you run the  analyze_rail\u00a0-voltage_drop\u00a0static -redhawk_script_file myscript.tcl command, the tool ignores the  -voltage_drop option.\n When the  -redhawk_script_file option is not specified, you must specify the nets to analyze by using the  -nets option.\n 3.\n Check the analysis results, as described in  Viewing PG Electromigration Analysis Results."}
{"header": "How do I Displaying the PG Electromigration Map", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When PG electromigration analysis is complete, you can check for current violations by displaying a PG electromigration map or checking the generated errors in the error browser.\n \u2022 Displaying the PG Electromigration Map \u2022 Checking PG Electromigration Violations"}
{"header": "How do I Checking PG Electromigration Violations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "A PG electromigration map is a visual display of the color-coded electromigration values overlaid on the physical supply nets.\n For static analysis, the map displays average electromigration values.\n For dynamic analysis, the map displays average electromigration values, peak electromigration values, or root mean square electromigration values.\n Figure\u00a0204 shows an example of the electromigration map in which problem areas are highlighted in different colors.\n Use the options to investigate the problem areas by       selecting layers or nets to display.\n For example, to examine the current value of one specific net, deselect all the nets and then select the net to display from the list.\n To analyze only the shapes on a layer, select the layer from the list.\n For a detailed procedure about how to display an electromigration map, see  Displaying Maps in the GUI.\n Figure 204 Displaying a PG Electromigration Map"}
{"header": "How do I Performing Minimum Path Resistance Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When PG electromigration analysis is complete, you can check the generated error files in the error browser or write the generated errors to an output file.\n The tool does not write the generated errors to the working directory, meaning the error data is deleted if you exit the tool without saving the block.\n Ensure that you save the block to keep the generated error data if you want to examine the errors in another session.\n       You can examine the generated error files in the error browser or write the generated errors to an output ASCII file.\n \u2022 To examine the generated errors in the error browser, 1.\n Choose View > Error Browser from the GUI.\n 2.\n In the Open Error Data dialog box, select the errors to examine and click Open Selected.\n 3.\n Check the details of the errors in the Error Browser (see  Figure\u00a0205 ).\n       Figure 205 Opening Generated Errors in the Error Browser \u2022 To write errors to an ASCII file, use the following script: set\u00a0fileName\u00a0\"errors.txt\" set\u00a0fd\u00a0[open\u00a0$fileName\u00a0w] set\u00a0dm\u00a0[open_drc_error_data\u00a0rail_pg_em.VDD.err] set\u00a0all_errs\u00a0[get_drc_errors\u00a0-error_data\u00a0$dm\u00a0*] foreach_in_collection\u00a0err\u00a0$all_errs\u00a0{ set\u00a0info\u00a0[\u00a0get_attribute\u00a0$err\u00a0error_info]; puts\u00a0$fd\u00a0$info\u00a0} close\u00a0$fd       Here is an example of the output error file: M1\u00a0(414.000,546.584\u00a0414.344,546.584)\u00a0em\u00a0ratio\u00a023585.9%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024963 M1\u00a0(414.344,546.584\u00a0416.168,546.584)\u00a0em\u00a0ratio\u00a023401.3%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024768 M1\u00a0(416.168,546.584\u00a0416.776,546.584)\u00a0em\u00a0ratio\u00a023241.7%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024599 M1\u00a0(416.776,546.584\u00a0417.992,546.584)\u00a0em\u00a0ratio\u00a023082.2%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024430 M1\u00a0(417.992,546.584\u00a0419.208,546.584)\u00a0em\u00a0ratio\u00a022897.7%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024235 M1\u00a0(419.208,546.584\u00a0419.512,546.584)\u00a0em\u00a0ratio\u00a022731.1%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0024059 M1\u00a0(419.512,546.584\u00a0421.184,546.584)\u00a0em\u00a0ratio\u00a022564.4%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0023882 M1\u00a0(421.184,546.584\u00a0421.488,546.584)\u00a0em\u00a0ratio\u00a022349%\u00a0width\u00a00.06\u00a0blech length\u00a00.000\u00a0um\u00a0current\u00a00.0023654 M1\u00a0(421.488,546.584\u00a0423.160,546.584)\u00a0em\u00a0ratio\u00a022133.5%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0023426 M1\u00a0(423.160,546.584\u00a0423.616,546.584)\u00a0em\u00a0ratio\u00a021967.2%\u00a0width\u00a00.06 blech length\u00a00.000\u00a0um\u00a0current\u00a00.0023250"}
{"header": "How do I Viewing Minimum Path Resistance Analysis Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: Minimum path resistance analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n Perform minimum path resistance analysis to quickly detect power and ground network weaknesses in the design.\n The minimum path resistance value of a node is the resistance value on the smallest resistive path to the ideal voltage source locations (taps).\n The ideal voltage sources can be power or ground pins, user-defined taps, or packages.\n Because this value represents only the resistance on a single path, it is not necessarily same as the effective resistance value from the node to the supply or ground; instead, it represents an upper bound on the effective resistance of a node to the supply or ground.\n       To perform minimum path resistance analysis, run the  analyze_rail -min_path_resistance command.\n You must specify the power and ground nets to analyze by using the  -nets option.\n Note: In RedHawk-SC rail analysis flow, you must specify both the  -voltage_drop and  -min_path_resistance options for minimum path resistance calculation.\n You can perform minimum path resistance analysis before or during voltage drop analysis.\n When the analysis is completed, the tool writes the minimum path resistance values and the voltage drop results into the same rail result.\n The following example performs voltage drop analysis and minimum path resistance calculation at the same time.\n fc_shell>\u00a0 analyze_rail -nets {VDD VSS} \\ -min_path_resistance -voltage_drop static The following example performs only minimum path resistance analysis.\n fc_shell>\u00a0 analyze_rail -nets {VDD VSS} -min_path_resistance"}
{"header": "How do I Tracing Minimum Path Resistance Using the Mouse Tool", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When the analysis is complete, run the  report_rail_result\u00a0-type minimum_path_resistance command to display a minimum path resistance map, write the results to an output file, or query the attributes on the cell instances or pins.\n The following example writes the calculated minimum path resistances for the VDD net to an output file called minres.rpt.\n fc_shell>\u00a0 open_rail_result fc_shell>\u00a0 report_rail_result -type minimum_path_resistance \\ -supply_nets { vdd } minres.rpt fc_shell>\u00a0 sh cat minres.rpt FEED0_14/vbp\u00a0518.668 INV61/vdd\u00a0158.268 ARCR0_1/vbp\u00a0145.582 FEED0_5/vdd\u00a0156.228 INV11/vbp\u00a0518.669 The output minres.rpt report includes the entire resistance information.\n fc_shell>\u00a0 sh cat minres.rpt FEED0_14/vbp\u00a0518.668 INV61/vdd\u00a0158.268 ARCR0_1/vbp\u00a0145.582 FEED0_5/vdd\u00a0156.228 INV11/vbp\u00a0518.669       To write out a detailed minimum resistance path report for a cell instance, run the report_rail_minimum_path command and specify the net and the cell to report.\n To see the segment-by-segment resistance of that minimum resistance path shown in the GUI, use the  -error_cell option of the  report_rail_minimum_path command to save the geometries on the path of the minimum path resistance to an error cell.\n You can then open the error cell in an error browser and check the minimum resistance path from the pin of the cell to the nearest tap and trace each go-through geometries.\n In the following example, all geometries on the minimum resistance path are traced and written to the error cell named test.err.\n fc_shell>\u00a0 open_rail_result fc_shell>\u00a0 report_rail_minimum_path -cell U19 -net VDD -error_cell Shown in  Figure\u00a0206, each geometry is classified by layer in the error browser.\n Click a geometry to check for detailed information, such as IR drop, resistance, bounding box, and so on.\n In the GUI, the traced path is highlighted in yellow in the design layout (see Figure\u00a0207 ).\n Figure 206 Displaying Error Cells in the Error Browser       Figure 207 Traced Segment is Highlighted in the Design Layout See Also \u2022 Displaying Maps in the GUI \u2022 Writing Analysis and Checking Reports \u2022 Querying Attributes"}
{"header": "How do I Performing Effective Resistance Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the minimum path resistance (MPR) mouse tool to interactively trace the path with the least resistance from the specified power or ground net to the boundary nodes in the design.\n To trace the calculated minimum path resistance with the MPR interactive tracing tool, 1.\n In the GUI, choose Task > Rail and then select Analysis Tools from the task list to open the Task Assistant window (see  Figure\u00a0208 ).\n 2.\n In the Task Assistant - Rail window that opens, click MPR Mouse Tool.\n 3.\n Specify the nets to analyze.\n Click OK.\n       The MPR interactive mouse tool, which is shown in  Figure\u00a0209, provides the following features: \u2022 Zoom in and out to review the traces \u2022 Provide two operation modes: the Add mode to trace multiple paths in the map, and the Replace mode to trace one path at a time in the map \u2022 Use the standard query tool to show tracing information \u2022 Select a region to trace multiple cells at a time \u2022 Document the interactive actions by scripts Figure 208 Invoking the MPR Mouse Tool       Figure 209 Tracing the Path With the Least Resistance Click to hide all objects from showing in the map Then select Cell"}
{"header": "How do I Performing Distributed RedHawk Fusion Rail Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: Effective resistance analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n To calculate effective resistance for the specified power and ground nets, use the analyze_rail\u00a0-effective_resistance command.\n To specify a list of cell instances for effective resistance calculation, describe the target instances in a text file.\n Then specify this text file with the rail.effective_resistance_instance_file application option.\n For example, fc_shell>\u00a0 sh cat cell_list.txt u_GS_PRO_65 u_GS_PRO_64 ChipTop_U_compressor_mode/U3  fc_shell>\u00a0 set_app_options \\ -name rail.effective_resistance_instance_file \\ -value cell_list.txt fc_shell>\u00a0 analyze_rail -nets {VDD VSS} -effective_resistance You can perform effective resistance analysis before or during voltage drop analysis.\n When the analysis is completed, the tool writes the effective resistance values into the same rail result with the voltage drop results.\n Note: In the RedHawk-SC rail analysis flow, you must specify both the -effective_resistance and  -voltage_drop options for effective resistance calculation.\n When the calculation is complete, the tool saves the results in the working directory.\n To write the effective resistance values to a text file, use the  report_rail_result -type\u00a0effective_resistance command.\n To query the resistance value, use the get_attribute command.\n For example, fc_shell>\u00a0 get_attribute [get_pins u_GS_PRO_65/VDD] \\ effective_resistance       See Also \u2022 Specifying RedHawk and RedHawk-SC Working Directories \u2022 Writing Analysis and Checking Reports"}
{"header": "How do I Voltage Driven Power Switch Cell Sizing", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow.\n By default, the  analyze_rail command uses a single process to perform RedHawk rail analysis.\n To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run.\n You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session.\n This allows you to run multiple RedHawk analyses with only one Fusion Compiler license.\n Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key.\n To examine the generated analysis result, first run the  open_rail_result command to load the result that is saved in the directory you specify.\n You can then investigate the problematic areas in the map and check for violations in a text file or in an error view.\n You can open one result context at a time.\n To load the rail context generated in another analysis run, first close the current rail result using the  close_rail_result command, and then open the desired rail result (see  Displaying Maps in the GUI ).\n License Requirement By default, the number of required licenses is the number of script files or configurations specified with the  -multiple_script_files option during distributed processing mode.\n If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message.\n To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the  analyze_rail run, set the  rail.license_checkout_mode application option to wait.\n If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately.\n By default, the rail.license_checkout_mode application option is set to  nowait.\n When the analysis is finished, run the  remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses.\n fc_shell>\u00a0 remove_licenses SNPS_INDESIGN_RH_RAIL       In  Figure\u00a0210, the  rail.license_checkout_mode application option is set to wait.\n There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses.\n In this case, the tool first checks out two licenses and waits for other licenses to become available.\n When a script finishes the job, the tool reuses its license immediately to submit other scripts.\n Figure 210 Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke  analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6 1 3 5 2 4 6 Set  rail.license_checkout_mode  to  wait The tool first submits two scripts to the farm machines, because there are only two licenses available.\n 2 3...\n The tool checks for available licenses during the  analyze_rail  run.\n When a license becomes available, the tool reuses it.\n 1 Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1.\n Define the distributed processing configuration by using the  set_host_options command.\n You can specify one or more of the following options: Option Description -submit_protocol  rsh    -target  -timeout        Option Description -submit_command    -max_cores   2.\n Run the  analyze_rail command with the following options: Option Description -submit_to_other_machines  -multiple_script_files\\ directory_name script_name   Example 51 %>\u00a0rsh\u00a0myMachine\u00a0ls test1 CSHRC DESKTOP >\u00a0set_host_options\u00a0\"myMachine\"\u00a0-target\u00a0RedHawk\u00a0\\ -max_cores\u00a02\u00a0-timeout\u00a0100 >\u00a0analyze_rail\u00a0-submit_to_other_machines\u00a0\\ -voltage_drop\u00a0static\u00a0-nets\u00a0{VDD\u00a0VDDG\u00a0VDDX\u00a0VDDY\u00a0VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only.\n Timeout value is 100 and the number of cores to use is 2.\n Example 52 >\u00a0set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{\u00a0qsub\u00a0-P\u00a0normal\u00a0} >\u00a0analyze_rail\u00a0-submit_to_other_machines\u00a0-voltage_drop\u00a0\\ static\u00a0-nets\u00a0{VDD\u00a0VSS} The above example enables job submission to a machine on the SGE farm machine.\n Example 53 >\u00a0set_host_options\u00a0-submit_protocol\u00a0lsf\u00a0\\ -submit_command\u00a0{bsub} >\u00a0analyze_rail\u00a0-submit_to_other_machines\u00a0\\ -multiple_script_files\u00a0{{result1\u00a0RH1.tcl}\u00a0{result2\u00a0RH2.tcl}}  >\u00a0open_rail_result\u00a0result1       >\u00a0close_rail_result >\u00a0open_rail_result\u00a0result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2.\n Example 54 >\u00a0set_app_options\u00a0-name\u00a0rail.license_checkout_mode\u00a0\\ -value\u00a0wait >\u00a0set_host_options\u00a0-submit_protocol\u00a0sge\u00a0\\ -submit_command\u00a0{qsub} >\u00a0analyze_rail\u00a0-submit_to_other_machines\u00a0\\ -multiple_script_files\u00a0{{\u00a0result1\u00a0RH1.tcl}\u00a0{result2\u00a0RH2.tcl}\u00a0\\ {result3\u00a0RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the  analyze_rail run."}
{"header": "How do I Working With Macro Models", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool can resize power switch cells to reduce total power and to mitigate the voltage drop in the design.\n Power switch cells have different voltage thresholds (V T ) and are classified as high, standard, low, and ultra-low.\n For a power cell with high threshold voltage, the power consumption and leakage current is low, but the timing is also slow with a smaller drive strength.\n For a power cell with a low threshold voltage, the timing is faster but the power consumption and leakage current is high.\n With power switch cell sizing, the tool supports different drive strength and voltage threshold to reduce IR (voltage) drop in the design.\n Note: When the tool switches power cells (swapping), it can only swap cells with the same footprint but with different threshold voltages.\n This means, the cell cannot be swapped if the cell size and pin shapes are different.\n To perform power switch cell swapping, you can use the  size_power_switches command to set the maximum IR drop target.\n To meet this target when swapping power cells, the tool tries to find another cell with higher V T, but lower R ON value, so that it can reduce the IR drop.\n You can set the ON resistance (R ON ) value to be considered by the tool for swapping using the  set_power_switch_resistance command.\n Based on the IR drop target and the set R ON value of the power cell, the tool tries to replace power cells to meet the targeted voltage drop.\n       Note: If the tool does not find any suitable power cell that matches the targeted voltage drop and R ON value, it skips cell resizing.\n To perform voltage driven cell sizing, 1.\n Perform a voltage drop analysis using RH Fusion to get the maximum voltage drop of the cells driven by the power switch in question.\n Refer  Performing Voltage Drop Analysis for more information.\n 2.\n Set the RON value limit to be considered for cell switching using the set_power_switch_resistance command.\n Provide the following values as input, \u25e6 Lib cell name - specifies the name of the library cell.\n \u25e6 On resistance value - specifies the RON value limit to be considered for cell sizing.\n You can get this information from the switch model files.\n For example, fc_shell>\u00a0 set_power_switch_resistance saed32hvt_pg_ss0p_v125c/HEAD2X2_HVT 0.015 3.\n Run the  size_power_switches command to perform cell size switching.\n Provide the value for -max_irdrop option which specifies the allowed maximum effective voltage drop on supply nets for standard cells driven by switches.\n This is a mandatory input.\n For example, fc_shell>\u00a0 size_power_switches -max_irdop 0.05 For the other non-mandatory inputs to further refine the command action, see the man page for the  size_power_switches command.\n The tool also provides the following commands to further help with power switch resistance: \u2022 get_power_switch_resistance - This command fetches the R ON value of a power switch cell.\n \u2022 reset_power_switch_resistance - This command resets the R ON value specified for a power switch cell.\n \u2022 report_power_switch_resistance - This command reports all power switch library cells with a set R ON.\n Use the -verbose option with the command to display the group of cells with the same footprint, the R on value and the number of cells instantiated in the design.\n When using the  -verbose option, you can also use  -same_vt option to report power switch cells and their R ON value from current library with same VT but different driving strength cells."}
{"header": "How do I Generating Macro Models", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Memory and macro cells are used in designs with advanced process technologies to reduce memory usage and improve the rail analysis performance.\n Macro models are supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n To learn about working with macro models, see the following topics: \u2022 Generating Macro Models \u2022 Creating Block Contexts"}
{"header": "How do I Creating Block Contexts", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To consider current and power distribution inside the memory blocks when analyzing hierarchical designs, use the  exec_gds2rh command to generate RedHawk macro models for memory blocks.\n The command invokes the RedHawk  gds2rh utility under the hood and extracts power grids and current sources from the memory blocks with varying levels of abstraction\u2015from fully detailed models for accurate block-level analysis to abstract models for full-chip dynamic analysis.\n Note: To create RedHawk macro models using the RedHawk  gds2rh utility, you must specify the path to the RedHawk executable with the  rail.redhawk_path application option before running the  exec_gds2rh command.\n The generated macro models are saved in the current working directory or the one you specify in the configuration file.\n To run rail analysis with the generated macro models, set the  rail.macro_models\u00a0-value\u00a0{ cell1 path1 } application option before running the analyze_rail command.\n For more information about how to run the RedHawk  gds2rh utility, see the  RedHawk User Manual.\n Required Configuration File To generate a RedHawk macro model using the  gds2rh utility, you must provide a configuration file that includes the following information: \u2022 GDS II files \u2022 Top design name \u2022 Layer mapping file \u2022 Power and ground net names       Specify one configuration file per memory.\n Make sure the configuration file contains the correct syntax for macro model generation.\n Otherwise, the tool issues an error message and terminates the model generation process.\n The following is an example of the configuration file: LEF_FILE\u00a0{./lef/saed32sram.lef } GDS_FILE\u00a0./gds/SRAMLP2RW128x16.gds GDS_MAP_FILE\u00a0./redhawk.gdslayermap OUTPUT_DIRECTORY\u00a0SRAMLP2RW128x16_output  USE_LEF_PINS_FOR_TRACING\u00a0\u00a0\u00a01  VDD_NETS\u00a0{ VDD } GND_NETS\u00a0{ VSS } TOP_CELL\u00a0SRAMLP2RW128x16 Examples The following example generates RedHawk macro models for the SRAMLP2RW128x16, SRAMLP2RW32x4, SRAMLP2RW64x32 and SRAMLP2RW64x8 memories: ##\u00a0Specify\u00a0the\u00a0path\u00a0to\u00a0the\u00a0RedHawk\u00a0executable\u00a0## set_app_options\u00a0-name\u00a0rail.redhawk_path\u00a0-value\u00a0$env(REDHAWK_IMAGE)/bin  ##\u00a0Specify\u00a0one\u00a0configuration\u00a0file\u00a0per\u00a0memory\u00a0## exec_gds2rh\u00a0-config_file\u00a0SRAMLP2RW128x16.config exec_gds2rh\u00a0-config_file\u00a0SRAMLP2RW32x4.config exec_gds2rh\u00a0-config_file\u00a0SRAMLP2RW64x32.config exec_gds2rh\u00a0-config_file\u00a0SRAMLP2RW64x8.config The following example runs top-level rail analysis with the macro models that are generated in the previous example: ##\u00a0Run\u00a0rail\u00a0analysis\u00a0at\u00a0top\u00a0level\u00a0##  open_lib open_block\u00a0top link_block  ##\u00a0Specify\u00a0rail\u00a0analysis\u00a0setting\u00a0## create_taps set_app_options\u00a0-name\u00a0rail.tech_file\u00a0-value\u00a0test.tech set_app_options\u00a0-name\u00a0rail.lib_files\u00a0-value\u00a0test.lib \u2026 ##\u00a0Set\u00a0macro\u00a0model\u00a0file\u00a0## set_app_options\u00a0-name\u00a0rail.macro_models\u00a0\\       -value\u00a0{\u00a0SRAMLP2RW128x16\u00a0./data_\u00a0SRAMLP2RW128x16 SRAMLP2RW32x4\u00a0./data_SRAMLP2RW32x4 SRAMLP2RW64x32\u00a0./data_SRAMLP2RW64x32 SRAMLP2RW64x8\u00a0./data_\u00a0SRAMLP2RW64x8 }  ##\u00a0Run\u00a0rail\u00a0analysis\u00a0## analyze_rail\u00a0-voltage_drop\u00a0static\u00a0-all_nets  ##\u00a0Check\u00a0rail\u00a0results\u00a0## open_rail_result gui_start"}
{"header": "How do I Performing Signoff Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Macro models are used to reduce total turnaround time for designs with advanced process technology.\n When violations are reported in the macros during full-chip signoff voltage drop analysis, it might be time-consuming to fix the violations at the block level and then rerun full-chip analysis to verify the fix.\n To reduce the turnaround time, you can create a context model for the macro block.\n A context model depicts the relationship between the block and the full-chip design, including both physical and electrical information, and enables you to verify the fixes by running block-level analysis rather than full-chip analysis.\n To create a context model, use the  create_context_for_sub_block command.\n To run voltage drop analysis with the generated block contexts, set the  rail.pad_files and  rail.block_context_model_file application options before running the analyze_rail command.\n Note: Creating full-chip contexts for blocks is supported only in RedHawk Fusion.\n The following figure shows that a fix in the block can effectively improve the performance of the top design.\n       Figure 211 Fixing Violations in Block Contexts Content of Block Contexts The  create_context_for_sub_block command models the full-chip context of a block, including physical models and electrical models.\n \u2022 Physical model, which describes the locations of the connections between the block and full-chip design.\n These tap locations are derived by tracing the RedHawk parasitics data.\n The physical model is generated when the  create_context_for_sub_block command process is complete, in the.ploc format.\n \u2022 Electrical model, which is an effective resistance- and capacitance-based model.\n The tool uses the native resistance engine to calculate the effective resistance, which is used to calculate equivalent current during peak dynamic voltage drop analysis.\n By default, the tool models the full-chip context for the specified block.\n The capacitance data is derived by the RedHawk extraction engine.\n To create an electrical model for the specified block, specify the -electric_model_file option with the  create_context_for_sub_block command.\n The electrical model is written in the.context format.\n       Examples The following example creates a block context for the top/cell_inst_1 block.\n The generated physical and electrical models are block.ploc and block.context, respectively.\n ##Create\u00a0block\u00a0context\u00a0in\u00a0top\u00a0block\u00a0## open_block\u00a0top create_context_for_sub_block\u00a0\\ -block_instance\u00a0top/cell_inst_1\u00a0block.ploc\u00a0\\ -nets\u00a0{VDD_TOP\u00a0VSS_TOP}\u00a0\\ -electric_model_file\u00a0block.context close_block  ##Run\u00a0IR\u00a0analysis\u00a0with\u00a0block\u00a0context\u00a0information\u00a0in\u00a0block-level\u00a0design\u00a0## open_block\u00a0block set_app_options\u00a0-name\u00a0rail.pad_files\u00a0-value\u00a0block.ploc set_app_options\u00a0-name\u00a0rail.block_context_model_file\u00a0\\ -value\u00a0block.context analyze_rail\u00a0-nets\u00a0{VDD_BLOCK\u00a0VSS_BLOCK}\u00a0\\ -voltage_drop\u00a0static\u00a0-extra_gsr_option_file\u00a0extra.gsr...\n The following example creates only a physical model for the top/cell_inst_1 block.\n ##Create\u00a0block\u00a0context\u00a0in\u00a0top\u00a0block\u00a0## open_block\u00a0top create_context_for_sub_block\u00a0\\ -block_instance\u00a0top/cell_inst_1\u00a0block.ploc\u00a0\\ -nets\u00a0{VDD_TOP\u00a0VSS_TOP} close_block  ##Run\u00a0IR\u00a0analysis\u00a0with\u00a0block\u00a0context\u00a0information\u00a0in\u00a0block-level\u00a0design\u00a0## open_block\u00a0block set_app_options\u00a0-name\u00a0rail.pad_files\u00a0-value\u00a0block.ploc analyze_rail\u00a0-nets\u00a0{VDD_BLOCK\u00a0VSS_BLOCK}\u00a0\\ -voltage_drop\u00a0static\u00a0-extra_gsr_option_file\u00a0extra.gsr..."}
{"header": "How do I Writing Analysis and Checking Reports", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "RedHawk Fusion or RedHawk-SC Fusion does not support RedHawk signoff analysis capabilities, such as signal electromigration or inrush current analysis.\n If you have the RedHawk signoff licenses, you can enable the following RedHawk signoff analysis features in the Fusion Compiler environment by using the rail.allow_redhawk_license_checkout application option.\n Signoff analysis features not included in the following list can only be run with the RedHawk standalone tool.\n       \u2022 Dynamic analysis with custom macro models \u2022 Dynamic analysis with package models \u2022 Analysis with RTL-level VCD files To perform RedHawk signoff analysis, 1.\n Modify your GSR file or RedHawk run script to include the related configuration settings.\n 2.\n Set the following application option to enable the RedHawk signoff features: fc_shell>\u00a0 set_app_options \\ -name rail.allow_redhawk_license_checkout -value true Setting the  rail.allow_redhawk_license_checkout application option to  true allows the RedHawk tool to retrieve the related RedHawk licenses for performing signoff features inside the Fusion Compiler tool.\n The default is  off.\n 3.\n Run the  analyze_rail command with the  -extra_gsr_option_file or -redhawk_script_file option to perform the analysis defined in the GSR or RedHawk script file.\n Specify other settings as necessary.\n Note: You cannot display the RedHawk signoff analysis results in the Fusion Compiler GUI.\n 4.\n Proceed to other steps in the analysis flow.\n See Also \u2022 An Overview for RedHawk Fusion and RedHawk-SC Fusion"}
{"header": "How do I Displaying Block-Level Rail Results", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When the checking or analysis is complete, run the  report_rail_result command to write the analysis or checking results to a text file.\n The power unit in the report file is watts, the current unit is amperes, and the voltage unit is volts.\n To display block-level rail results from top-level RAIL_DATABASE for debugging purposes, use the -top_design and  -block_instance options.\n For more information, see  Displaying Block-Level Rail Results.\n To write rail results for the cells or geometries in the hotspot area only, use the get_instance_result and  get_geometry_result commands.\n For more information, see  Generating Instance-Based Analysis Reports and  Generating Geometry-Based Analysis Reports.\n       To specify the data or error types to report, use the  -type option.\n  Table\u00a069  lists the supported data and error types.\n To limit the number of the elements to report, use the  -limit option.\n Set the value to zero to write all elements to the output file in descending order.\n To filter the data to write to the report file, use the  -threshold option.\n The tool writes the data greater than the specified threshold to the output file.\n The option is valid only for the following data types: \u2022 pg_pin_power \u2022 voltage_drop_or_rise \u2022 effective_voltage_drop To restrict the report to the specified supply nets, use the  -supply_nets option.\n This option is valid only for the following data types: \u2022 effective_voltage_drop \u2022 instance_minimum_path_resistance \u2022 minimum_path_resistance \u2022 pg_pin_power \u2022 voltage_drop_or_rise Table 69 Supported Data and Error Types for report_rail_result Type Description effective_voltage_drop  effective_resistance  instance_minimum_path_resistance  instance_power  minimum_path_resistance   missing_vias   pg_pin_power  unconnected_instances         Table 69 Supported Data and Error Types for report_rail_result (Continued) Type Description voltage_drop_or_rise  In the output report file, the tool lists the data in different formats.\n For example: \u2022 For the  effective_voltage_drop type, \u25e6 When reporting the static analysis results, the format is cell_instance_pg_pin_name mapped_pg_pin_name supply_net_name effective_voltage_drop \u25e6 When reporting the dynamic analysis results, the format is cell_instance_pg_pin_name mapped_pg_pin_name supply_net_name average_effective_voltage_drop_in_tw max_effective_voltage_drop_in_tw min_effective_voltage_drop_in_tw max_effective_voltage_drop \u2022 For the  instance_minimum_path_resistance type, the result is sorted by the Total_R value in the following format: Supply_net Total_R(ohm) R_to_power(ohm) R_to_ground(ohm) Location Pin_name Instance_name \u2022 For the  minimum_path_resistance type, the format is full_path_cell_instance_name/pg_pin_name resistance \u2022 For the  missing_vias type, the format is net_name via_location_x_y top_metal_layer bottom_via_layer delta_voltage \u2022 For the  pg_pin_power type, the format is full_path_cell_instance_name pg_pin_name power \u2022 For the  voltage_drop_or_rise type, the format is full_path_cell_instance_name/pg_pin_name voltage \u2022 For the  unconnected_instances error type, the format depends on the error condition.\n \u25e6 When either or both of power and ground nets are physically disconnected from ideal voltage sources, the format is unconnected_type {net_names} instance_name instance bbox       \u25e6 When the power or ground nets are either floating or logically floating but physically connected to ideal voltage sources, the format is unconnected_type {net_names} instance_name:pin_name instance bbox The following example writes a file containing the top five PG pin power values to an output file called power.rpt.\n fc_shell>\u00a0 open_rail_result fc_shell>\u00a0 report_rail_result -type pg_pin_power -limit 5 \\ -supply_nets { VSS } power.rpt fc_shell>\u00a0 sh cat power.rpt FI2/vss\u00a04.81004e-06 FI6/vss\u00a04.80959e-06 FI3/vss\u00a04.79702e-06 FI4/vss\u00a04.79684e-06 FI1/vss\u00a04.79594e-06...\n The following example writes the calculated effective voltage drop values for the VDD and VSS nets to an output file called inst_effvd.rpt.\n fc_shell>\u00a0 open_rail_result fc_shell>\u00a0 report_rail_result -type effective_voltage_drop \\ -supply_nets { VDD VSS } inst_effvd.rpt fc_shell>\u00a0 sh cat inst_effvd.rpt  #cell_instance_pg_pin_name\u00a0mapped_pg_pin_name\u00a0supply_net_name #average_effective_voltage_drop_in_tw #max_effective_voltage_drop_in_tw\u00a0min_effective_voltage_drop_in_tw #max_effective_voltage_drop  S32_reg_14_/VDD\u00a0VSS\u00a0VDD\u00a0-7.750034332e-03\u00a0-1.017999649e-02 -5.850076675e-03\u00a0-1.029992104e-02  S32_reg_15_/VDD\u00a0VSS\u00a0VDD\u00a0-7.709980011e-03\u00a0-1.013994217e-02 -5.810022354e-03\u00a0-1.026010513e-02  S46_reg_8_/VDD\u00a0VSS\u00a0VDD\u00a0-7.179975510e-03\u00a0-9.490013123e-03\u00a0-5.330085754e-03 -1.021003723e-02...\n The following example writes the minimum path resistance values of cell instances to an output file called inst_minres.rpt.\n fc_shell>\u00a0 open_rail_result fc_shell>\u00a0 report_rail_result -type instance_minimum_path_resistance \\ -supply_nets { VDD VSS } inst_minres.rpt fc_shell>\u00a0 sh cat inst_minres.rpt  Rmax(ohm)\u00a0=\u00a0162.738       Rmin(ohm)\u00a0=\u00a04.418 ====================================================================== Supply_net\u00a0Total_R(ohm)\u00a0R_to_power(ohm)\u00a0R_to_ground(ohm) Location\u00a0Pin_name\u00a0Instance_name ====================================================================== VDD\u00a0162.738\u00a0152.686\u00a010.052\u00a0586.000, 496.235\u00a0VDDL\u00a0dataout_44_u VSS\u00a0156.266\u00a0137.963\u00a018.303\u00a0544.000, 613.235\u00a0VSS\u00a0GPRs/U2317 VDD\u00a0156.266\u00a0137.963\u00a018.303\u00a0544.000, 613.235\u00a0TVDD\u00a0GPRs/U2317 VDD\u00a0152.690\u00a0135.223\u00a017.467\u00a0602.400, 467.435\u00a0VDDL\u00a0dataout_33_u"}
{"header": "How do I Generating Instance-Based Analysis Reports", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you perform rail analysis on the top-level design, the tool saves the analysis results in the top-level rail database.\n To locate issues that are reported in a block-level design, run the  open_rail_result command with the  -top_design and  -block_instance options to excerpt block-level instance data from the top-level rail database.\n The tool then displays maps for the specified block instances based on the extracted block-level rail analysis data.\n Note: The excerpt of the block-level rail results is saved in memory and is deleted when you exit the current session.\n The following example opens the rail result named REDHAWK_RESULT in the./ RAIL_DATABASE directory; the result is the rail analysis result for the top design named bit_coin.\n The example then creates an excerpt of rail analysis data for the block instance slice_5.\n Note that in this example, the block design of instance slice_5 has to be opened, not the top-level design.\n fc_shell>\u00a0 open_lib block.nlib fc_shell>\u00a0 open_block block fc_shell>\u00a0 set_app_options -name rail.database -value RAIL_DATABASE fc_shell>\u00a0 open_rail_result REDHAWK_RESULT \\ -top_design bit_coin \\ -block_instance slice_5 fc_shell>\u00a0 report_rail_result"}
{"header": "How do I Generating Geometry-Based Analysis Reports", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  get_instance_result command to write the cell instances with rail data to an output text file, in the units defined with the  report_units command.\n       To specify which analysis or checking types to report, use the  -type option.\n The supported analysis types are:  effective_voltage_drop,  current,  effective_resistance, min_path_resistance, and  power.\n Here are commonly used options of the  get_instance_result command: Option Description -net   -touching  {{ x1 y1 }\u00a0{ x2 y2 }} -top\u00a0 value   -threshold    -percentage   voltage_drop   -histogram   -collection   Example The following example reports instance voltage drop results within the specified area: fc_shell>\u00a0 get_instance_result -net VDD -type voltage_drop \\ -touching {{1610 1968} {1620 1969}} Isw2/Isw2_pktpro/U179070\u00a0-0.053533 Isw2/Isw2_pktpro/U64076\u00a0-0.0535949 Isw2/Isw2_pktpro/U83035\u00a0-0.0535949 Isw2/Isw2_pktpro/U181017\u00a0-0.0535949 Isw2/Isw2_pktpro/U103335\u00a0-0.05366 Isw2/Isw2_pktpro/U181049\u00a0-0.05366 Isw2/Isw2_pktpro/U98988\u00a0-0.05366 Isw2/Isw2_pktpro/U201986\u00a0-0.053713 Isw2/Isw2_pktpro/U181064\u00a0-0.053719 Isw2/Isw2_pktpro/U79791\u00a0-0.053809 Isw2/Isw2_pktpro/U179052\u00a0-0.054007 Isw2/Isw2_pktpro/U4120\u00a0-0.054073 Isw2/Isw2_pktpro/U20408\u00a0-0.054287       See Also \u2022 Voltage Hotspot Analysis"}
{"header": "How do I Displaying Maps in the GUI", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  get_geometry_result command to write the geometry information with rail results to an output file, in the units defined with the  report_units command.\n You can specify one net at a time.\n When more than one net is specified, an error message is displayed.\n To specify which analysis or checking types to report, use the  -type option.\n The supported analysis types are:  voltage_drop and  min_path_resistance.\n The report is in the following format: geometry\u00a0bbox_value Here are commonly used options of the  get_geometry_result command: Option Description -layer   -touching {{ x1 y1 } { x2 y2 }}   -top\u00a0 value   -threshold   -percentage      -histogram   Example The following example writes geometry data with voltage drop values that are within the specified area: fc_shell>\u00a0 get_geometry_result -net VDD -type voltage_drop \\ -touching {{1610 1968} {1620 1969}}       {\u00a0{\u00a01616.475\u00a01967.000\u00a0}\u00a0{\u00a01617.525\u00a01969.800\u00a0}\u00a0}\u00a0metal5\u00a00.00448 {\u00a0{\u00a01608.810\u00a01946.000\u00a0}\u00a0{\u00a01611.190\u00a01974.000\u00a0}\u00a0}\u00a0metal7\u00a00.00446 {\u00a0{\u00a01608.000\u00a01946.000\u00a0}\u00a0{\u00a01612.000\u00a01974.000\u00a0}\u00a0}\u00a0metal9\u00a00.00446 See Also \u2022 Voltage Hotspot Analysis"}
{"header": "How do I Displaying ECO Shapes in the GUI", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When analysis is complete, the tool saves the design data and analysis results (*.result) in the in-design.redhawk/ design_name.result directory under the RedHawk working directory.\n You must run the  open_rail_result command to load the analysis results before displaying a map in the Fusion Compiler GUI.\n Table\u00a070 lists the map types that are supported in the RedHawk Fusion analysis flow.\n Table 70 Analysis Maps Supported in RedHawk Fusion Flow Map Type Description       Note:                                Table 70 Analysis Maps Supported in RedHawk Fusion Flow (Continued) Map Type Description                      To display maps in the Fusion Compiler GUI, 1.\n To load the rail analysis result using the GUI, choose  Task > Rail Analysis > 2D Rail Analysis.\n The Block Level 2D Rail Analysis window appears.\n In the window, click the open_rail_result link.\n Alternatively, run the  open_rail_result command to load the design data and analysis results (*.result) saved in the  design_name directory under the RedHawk working directory when analysis is complete.\n 2.\n In the GUI layout window, choose  View > Map and select the map to display.\n In the map, problem areas are highlighted in different colors.\n Move the pointer over an instance to view more information in the InfoTip.\n By default, the tool displays information for all instances in the block.\n To examine information of one specific instance, deselect all the instances and then select the instance to display from the list.\n Use the options in the map panel to change map display: \u25e6 Value: Sets the type of map to display \u25e6 Bins: Changes the number of unique bins used to display the map \u25e6 From: and To: Sets the range of density values displayed in the power density map \u25e6 Text: Displays the calculated values in the layout; if the values are not visible, zoom in to view them       Examples The following examples show how to display various types of maps in the GUI: Figure\u00a0212 shows how to display a rail instance effective voltage drop map and check for hotspots in the instance effective voltage drop map.\n Figure\u00a0213 shows how to display a rail map for the switch cells in the block and examine the voltage information of the selected switch cell.\n Figure\u00a0214 shows how to display a power density map for the block.\n       Figure 212 Displaying a Rail Instance Effective Voltage Drop Map Hover over the red spot to see the voltage drop number on the instance Select the instance to display Choose Rail Instance Effective Voltage Drop Click \u201cZoom to Critical\u201d to examine the critical area Histogram for the range of map values (in volts) Options for map display control       Figure 213 Displaying Maps for Switch Cells Choose Rail Instance Switch Cell.\n Select the instance to Choose the type of map to display The tool shows the switch cells display on the selected power domain in the map.\n In the map, hover over a switch cell to examine its voltage information       Figure 214 Displaying a Power Density Map Choose Rail Power Choose Density to display power density values See Also \u2022 Specifying RedHawk and RedHawk-SC Working Directories"}
{"header": "How do I Voltage Hotspot Analysis", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you use the RedHawk  mesh\u00a0add command to add virtual PG meshes in the top block for the current subblock, by default the virtual PG meshes created by the RedHawk  mesh\u00a0add command are not shown as layout objects in the GUI.\n Therefore, these GUI shapes cannot be queried using layout object collection commands (such as, get_shapes ), and are not saved to the design library when you save the block.\n To save ECO shapes along with rail results and display them in the GUI, enable the rail.display_eco_shapes application option, like set_app_options\u00a0-name\u00a0rail.display_eco_shapes\u00a0-value\u00a0true Note: The  mesh\u00a0add command is available only in RedHawk, not in RedHawk SC.\n Therefore, the tool issues an error message when you enable both the rail.enable_redhawk_sc and  rail.display_eco_shapes application options.\n To display ECO shapes in GUI, you must first enable the RedHawk signoff license key by setting the  rail.allow_redhawk_license_checkout application option to  true.\n Otherwise, an error message is issued.\n To add virtual PG meshes and display the created ECO shapes in the GUI, 1.\n Prepare a script file (such as, mesh.tcl) that contains the  mesh\u00a0add command.\n 2.\n Run design setup with the mesh.tcl script file.\n fc_shell>\u00a0set_rail_command_options\u00a0-script_file\u00a0mesh.tcl\u00a0\\ -command\u00a0setup_design\u00a0-order\u00a0after_the_command The tool generates the RedHawk script file and sources the mesh.tcl file after design setup.\n 3.\n Perform rail analysis using the following command: fc_shell>\u00a0analyze_rail\u00a0-nets\u00a0-voltage_drop 4.\n Run the  open_rail_result command to load the design data and analysis results.\n 5.\n Run the  gui_start command to open the Fusion Compiler GUI.\n In the GUI layout window, choose View > Map and select the map to display.\n You can now display and query the ECO shapes that are created by the RedHawk mesh\u00a0add command in the GUI.\n Script Examples       The following script displays ECO shapes in the GUI by using the set_rail_command_option command.\n ##\u00a0Open\u00a0design\u00a0## open_block link_block ##\u00a0Specify\u00a0taps\u00a0## create_taps ##\u00a0Specify\u00a0RedHawk\u00a0Fusion\u00a0input\u00a0files\u00a0or\u00a0variables\u00a0## set_app_options\u00a0-name\u00a0rail.enable_redhawk\u00a0-value\u00a01 set_app_options\u00a0-name\u00a0rail.redhawk_path\u00a0-value set_app_options\u00a0-name\u00a0rail.disable_timestamps\u00a0-value\u00a0true set_app_options\u00a0-name\u00a0rail.display_eco_shapes\u00a0-value\u00a0true set_rail_command_options\u00a0-script_file\u00a0mesh.tcl\u00a0-command\u00a0\\ setup_design\u00a0...\n ##\u00a0Analyze## analyze_rail\u00a0-voltage_drop\u00a0...\n -nets\u00a0{VDD\u00a0VSS} ##\u00a0Check\u00a0GUI\u00a0## open_rail_result The following script displays ECO shapes in the GUI by using a RedHawk script.\n ##\u00a0Open\u00a0design\u00a0## open_block link_block ##\u00a0Specify\u00a0taps\u00a0## create_taps ##\u00a0Specify\u00a0RedHawk\u00a0Fusion\u00a0input\u00a0files\u00a0or\u00a0variables\u00a0## set_app_options\u00a0-name\u00a0rail.enable_redhawk\u00a0-value\u00a01 set_app_options\u00a0-name\u00a0rail.redhawk_path\u00a0-value set_app_options\u00a0-name\u00a0rail.disable_timestamps\u00a0-value\u00a0true set_app_options\u00a0-name\u00a0rail.display_eco_shapes\u00a0-value\u00a0true ##\u00a0Analyze\u00a0## analyze_rail\u00a0-voltage_drop\u00a0...\n -nets\u00a0{VDD\u00a0VSS}\u00a0-script_only ##\u00a0Modify\u00a0the\u00a0script.tcl\u00a0containing\u00a0mesh\u00a0add\u00a0command\u00a0## analyze_rail\u00a0-redhawk_script_file ##\u00a0Check\u00a0GUI\u00a0## open_rail_result"}
{"header": "How do I Generating Hotspots", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When rail analysis is complete, there might be hundreds to thousands of voltage drop violations reported in the analysis report, which might make it difficult to identify the root causes for the violations.\n Use the voltage hotspot analysis capability to generate hotspots for a power or ground net by dividing the whole chip into small grid boxes, and report rail-related information for the generated grid boxes.\n In addition, you can query cell- or geometry-based rail results only for the specific analysis type by using the  get_instance_result and get_geometry_result commands.\n       Hotspot analysis provides the following features: \u2022 Identify the root cause of aggressors with high voltage drop, such as large current from the aggressor itself or from the neighboring cells due to simultaneous switching by the overlapping timing windows.\n \u2022 Determine which design technique to use for fixing voltage violations based on the report, such as choosing a candidate reference cell for cell sizing replacement, moving or relocating cells to reduce voltage drops, or applying PG augmentation to solve a voltage drop issue.\n This section contains the following topics: \u2022 Generating Hotspots \u2022 Reporting Hotspots \u2022 Removing Hotspots \u2022 Voltage Hotspot Analysis Examples To write rail results only for the cell instances or geometries that reside in the hotspot area, use the  get_instance_result and  get_geometry_result commands.\n For more information, see  Generating Instance-Based Analysis Reports  and  Generating Geometry- Based Analysis Reports."}
{"header": "How do I Reporting Hotspots", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To generate voltage drop hotspots for a power or ground net, use the generate_hot_spots command.\n This command divides the whole chip area into multiple grids in terms of rows and columns, such as 100x100.\n The grid boxes are sorted by the maximum effective voltage drop value in each grid box and are indexed with an integer number starting from 0.\n To create rows based on standard cell site rows, and columns by using vertical PG straps on the lowest metal layers, use the  -site_row option.\n Alternatively, you can specify the number of rows and columns for dividing the whole region with the  -row and  -column options.\n The command creates error cells for the grids with voltage drop values greater than the specified percentage of the ideal voltage drop.\n The default is 0.1, meaning that error cells are created for the grids with voltage drop values greater than 10% of the ideal supply voltage.\n The error cell type is effective voltage drop.\n To examine the content of the generated error cells, open the error cells in the error browser.\n To examine the content of the grid box, use the  report_hot_spots command.\n To remove the generated voltage hotspot data from memory, use the  remove_hot_spots command.\n       Option Description -net   -percentage   -site_row\u00a0integer     -site_row  -site_row    -row  -column  See Also \u2022 Reporting Hotspots \u2022 Removing Hotspots \u2022 Voltage Hotspot Analysis Examples"}
{"header": "How do I Removing Hotspots", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you generate hotspots on the block using the  generate_hot_spots command, run the  report_hot_spots command to report cells with voltage-related cell attributes for a hotspot grid box.\n The voltage-related cell attributes are:  current,  overlap_current, effective_resistance,  timing_\u00a0window,  slack,  output_load and  static_power.\n Use these voltage-related cell attributes to identify root causes of voltage violations.\n For example, you can \u2022 Use the current and output loading capacitance information to determine if a cell\u2019s high peak is caused by too much load.\n If this is the case, splitting the output might be an effective approach to reduce high voltage drops.\n \u2022 Check and compare the timing windows in the current hotspot to those of the neighboring grids to determine if a cell can be moved to other grids (targets).\n Doing so reduces the voltage drop of the original grid without increasing the voltage drop of the target grid.\n       \u2022 Compare slew and load capacitance among all cells in the region to determine if high peak current is caused by sharp slew or large load capacitance.\n \u2022 Find cells that have overlapping timing windows to identify cells that might switch at the same time during dynamic rail analysis.\n Here are commonly used options of the  report_hot_spots command: Option Description -index  -summary     -object   -verbose  Listing Voltage Grid Boxes by Index By default, the tool searches three rows up and down and three columns left and right to determine the neighboring grids of the current one.\n Use the  -index option to specify the index used to report voltage hotspot grids.\n The grid box with the smallest index number has the highest effective voltage drop values.\n This allows you to determine the size of the hotspot area.\n For example, if all the surrounding grids have bigger index numbers and only a few central grids have much smaller numbers, this voltage drop hotspot is assumed to be an island.\n Accumulating Current For an instance in a grid box, the overlap current is estimated by accumulating the timing- window-based current across its neighboring cells.\n The command scans all timing windows from smallest to biggest, and accumulates current on the way as time passes by.\n Use the information to determine how many cells are switching simultaneously and how much time shift to apply when shifting timing windows for voltage drop reduction.\n       Assume the design has three instances with current as follows: As shown in the following report, the accumulated current on point 2.0 is from inst2 and inst3, and does not include the current from inst1.\n inst1\u00a0[0.0\u00a02.0]\u00a0current\u00a00.11 inst2\u00a0[1.0\u00a02.5]\u00a0current\u00a00.22 inst3\u00a0[2.0\u00a03.0]\u00a0current\u00a00.33 See Also \u2022 Generating Hotspots \u2022 Removing Hotspots \u2022 Voltage Hotspot Analysis Examples"}
{"header": "How do I Voltage Hotspot Analysis Examples", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The tool saves the generated hotspot data in memory.\n If you want to generate hotspots for other nets in another run, you need to remove the previously generated hotspot data from memory with the  remove_hot_spots command before proceeding to another hotspot analysis run.\n For example, if you have run the  generate_hot_spots command on the VDD net, you must first remove the hotspot data for the VDD net before generating hotspots for other nets.\n       See Also \u2022 Generating Hotspots \u2022 Reporting Hotspots \u2022 Voltage Hotspot Analysis Examples"}
{"header": "How do I Querying Attributes", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "This topic provides examples about how to use the hotspot analysis capability to identify the root cause of voltage violations.\n Cells with overlapping timing windows might switch at the same time, leading to high voltage drops.\n  Figure\u00a0215 shows how to identify if the cell has overlapping timing windows.\n       Figure 215 Checking High Voltage Drop Caused by Overlapping Timing Window (I) Next, run the  report_hot_spots command with the  -index option to find which grid has overlapping timing windows that contribute to large current.\n As shown in  Figure\u00a0216, when the  -index option is set to 5, the grid 5 is reported with small total current.\n When the  -index option is set to 2, the grid 2 is reported with large total current.\n In this case, overlapping time windows contribute to the high effective voltage drop in grid 2.\n       Figure 216 Checking High Voltage Drop Caused by Overlapping Timing Window (II) See Also \u2022 Generating Hotspots \u2022 Reporting Hotspots \u2022 Removing Hotspots"}
{"header": "How do I 13", "size": 30.0, "font": "ArialMT", "flags": 4, "text": "When rail analysis or missing via checking is complete, use the  get_attribute attribute to query the results stored in the RedHawk working directory.\n You can query the attributes shown in  Table\u00a071, which are specific to the rail analysis results.\n Table 71 Rail Result Object Attributes Object Attributes  static_power       Table 71 Rail Result Object Attributes (Continued) Object Attributes  static_current peak_current static_power switching_power leakage_power internal_power min_path_resistance voltage_drop average_effective_voltage_drop_in_tw max_effective_voltage_drop (=effective_voltage_drop) max_effective_voltage_drop_in_tw min_effective_voltage_drop_in_tw effective_resistance The following example retrieves the  effective_voltage_drop attribute for the cellA/VDD pin.\n fc_shell>\u00a0 get_attribute [get_pins cellA/VDD] effective_voltage_drop -0.02812498807907104 The following example retrieves the  static_power attribute for the cellA cell.\n fc_shell>\u00a0 get_attribute [get_cells cellA] static_power 2.014179968645724e-05"}
{"header": "How do I Generic ECO Flow for Timing or Functional Changes", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "An engineering change order (ECO) is an incremental change made to a complete or nearly complete design.\n You can use ECOs to fix functional, timing, noise, and crosstalk violations without synthesizing, placing and routing the entire design.\n You can also use ECOs to implement late-arriving design changes while maintaining design performance.\n The following topics describe the various ECO flows supported in the Fusion Compiler tool, and tasks you perform in these flows: \u2022 Generic ECO Flow for Timing or Functional Changes \u2022 Freeze Silicon ECO Flow \u2022 Signoff ECO Flow \u2022 Incremental Signoff ECO Flow \u2022 ECO Fusion Flow \u2022 ECO Fusion Power Integrity Flow \u2022 Manually Instantiating Spare Cells \u2022 Automatically Adding Spare Cells \u2022 Adding Programmable Spare Cells \u2022 Making ECO Changes Using the eco_netlist Command \u2022 Making ECO Changes Using Netlist Editing Commands \u2022 Resizing Cells \u2022 Adding Buffers on Nets \u2022 Adding Buffers on Routed Nets \u2022 Optimizing the Fanout of a Net \u2022 Reporting Available Sites for Placing ECO Cells \u2022 Identifying and Reverting Nonoptimal ECO Changes \u2022 Placing ECO Cells       \u2022 Placing and Mapping ECO Cells to Spare Cells \u2022 Updating Supply Nets for ECO Cells \u2022 Recording the Changes Made to a Layout \u2022 Performing Prerequisite Check for Group Repeater Insertion and Placement \u2022 Adding a Group of Repeaters \u2022 Querying Group Repeater \u2022 Swapping Variant Cell \u2022 Fixing Multivoltage Violations"}
{"header": "How do I Freeze Silicon ECO Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use this flow to incorporate timing or functional ECO changes when you have the flexibility to add new cells and move or delete existing cells.\n This flow is recommended if you have not taped out your design.\n The unconstrained ECO flow consists of the following steps: 1.\n Update the design with the ECO changes by using one of the following methods: \u25e6 Using the  eco_netlist command, as described in  Making ECO Changes Using the eco_netlist Command \u25e6 Using netlist editing Tcl commands, as described in  Making ECO Changes Using Netlist Editing Commands.\n 2.\n Update the placement by using the  place_eco_cells command, as described in Placing ECO Cells.\n 3.\n Add filler cells to the empty spaces in the site array, as described in  Inserting Filler Cells.\n To reduce runtime, use the  -post_eco option when you \u25e6 Insert metal filler cells with the  create_stdcell_fillers command, and the tool marks the inserted filler cells as post-ECO cells.\n \u25e6 Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post-ECO cells.\n 4.\n Update the routing by using the  route_eco command, as described in  Performing ECO Routing, or by manually rerouting the affected nets."}
{"header": "How do I Signoff ECO Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use this flow if your cell placement is fixed, and you can only change the metal and via mask patterns.\n This flow is recommended if you have taped out your design and you want to avoid the expense of generating a whole new mask set.\n To perform the freeze silicon ECO flow, your block must contain spare cells.\n You can add spare cells to a block, anytime during the design flow, by using one of the following methods: \u2022 Manually instantiate spare cells, as described in  Manually Instantiating Spare Cells.\n \u2022 Automatically add spare cells after placement by using the  add_spare_cells command, as described in  Automatically Adding Spare Cells.\n \u2022 Add programmable spare cells during the chip finishing stage by using the create_stdcell_fillers, as described in  Adding Programmable Spare Cells.\n The freeze silicon ECO flow consists of the following steps: 1.\n Enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to  true.\n 2.\n Update the design with the ECO changes by using one of the following methods: \u25e6 Using the  eco_netlist command, as described in  Making ECO Changes Using the eco_netlist Command \u25e6 Using netlist editing Tcl commands, as described in  Making ECO Changes Using Netlist Editing Commands.\n 3.\n Analyze the mapping of ECO cells to spare cells by using the  check_freeze_silicon command.\n 4.\n Automatically map all the ECO changes to spare cells by using the place_freeze_silicon command or manually map each ECO cell to a specific spare cell by using the  map_freeze_silicon command, as described in  Placing and Mapping ECO Cells to Spare Cells.\n 5.\n Update the routing by using the  route_eco command, as described in  Performing ECO Routing, or by manually rerouting the affected nets."}
{"header": "How do I Incremental Signoff ECO Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool.\n You can also perform power or area recovery in the PrimeTime tool.\n       If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in  Figure\u00a0217.\n Figure 217 Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations?\n PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1.\n Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands.\n 2.\n Update the placement by using the  place_eco_cells command as shown in the following example: place_eco_cells\u00a0-legalize_mode\u00a0minimum_physical_impact\u00a0\\ -eco_changed_cells\u00a0-legalize_only\u00a0-displacement_threshold\u00a010 For more information about the  place_eco_cells command, see  Placing ECO Cells.\n 3.\n Add filler cells to the empty spaces in the site array, as described in  Inserting Filler Cells.\n       To reduce runtime, use the  -post_eco option when you \u25e6 Insert metal filler cells with the  create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells \u25e6 Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4.\n Update the routing by using the  route_eco command, as described in  Performing ECO Routing, or by manually rerouting the affected nets."}
{"header": "How do I ECO Fusion Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you make ECO changes in the PrimeTime tool and incorporate these changes by performing the Fusion Compiler unconstrained ECO flow, it might be necessary to iterate multiple times between the tools to meet the required QoR goals.\n To reduce the overall turnaround time for the flow, you can reduce the runtime of each iteration by using the incremental signoff ECO flow.\n This flow generates incremental design data from the Fusion Compiler tool, which enables you to perform incremental extraction in the StarRC tool and incremental timing analysis and ECO in the PrimeTime tool, as shown in the following figure.\n       Figure 218 Incremental Signoff ECO Flow StarRC incremental parasitic extraction ECO change list file Fusion Compiler incremental signoff ECO flow PrimeTime timing ECO ECO change list file Incremental parasitics Incremental design data PrimeTime incremental timing analysis and ECO To perform the incremental signoff ECO flow within the Fusion Compiler tool, use the record_signoff_eco_changes command.\n This command incorporates the PrimeTime ECO into the design library, tracks all the changes made to the design, and generates the incremental files that are required to run StarRC incremental extraction and PrimeTime incremental timing analysis and ECO.\n The Fusion Compiler incremental signoff ECO flow consists of the following steps: 1.\n Open the design library by using the  open_block command.\n 2.\n Incorporate the PrimeTime ECO changes and begin tracking the ECO changes to the design by using the  record_signoff_eco_changes\u00a0-start\u00a0-input command as shown in the following example: fc_shell>\u00a0 record_signoff_eco_changes -start -input pt_eco.tcl 3.\n (Optional) Perform additional timing ECO changes to the design by using netlist editing commands.\n Do not perform functional ECO changes to the design.\n If you do so, the tool stops tracking the ECO changes being performed on the design.\n       4.\n Place the ECO cells by using the  place_eco_cells command.\n 5.\n Update the routing by using the  route_eco command, as described in  Performing ECO Routing, or by manually rerouting the affected nets.\n 6.\n Stop tracking the ECO changes and complete the incremental signoff ECO flow by using the  record_signoff_eco_changes\u00a0-stop command as shown in the following example: fc_shell>\u00a0 record_signoff_eco_changes -stop"}
{"header": "How do I ECO Fusion Power Integrity Flow", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler ECO Fusion flow allows you to use the PrimeTime physically aware ECO capabilities and the StarRC extraction capabilities (In-Design signoff extraction) within the Fusion Compiler tool.\n You can use this flow to fix timing and DRC violations and improve area and power QoR at the very late stages of the implementation flow.\n The Fusion Compiler ECO Fusion flow consists of the following steps: 1.\n Specify the settings required to run the PrimeTime ECO capabilities within the Fusion Compiler tool by using the  set_pt_options command.\n The following example specifies the path to the PrimeTime executable and the settings for distributed processing: fc_shell>\u00a0 set_host_options -name pteco_host_option \\ -submit_command \"/lsf/bin/bsub -R \\\"rusage\\[mem=$MEM\\]\\\"\" fc_shell>\u00a0 set_pt_options -pt_exec /snps_tools/PT/pt_shell \\ -host_option pteco_host_option If there is a.synopsys_pt.setup file in the current working directory, the Fusion Compiler tool uses the information in this file.\n However, you can specify additional PrimeTime settings by using the  -pre_link_script and  -post_link_script options of the  set_pt_options command.\n For more information, see the man page for the  set_pt_options command.\n 2.\n Set up StarRC extraction as follows: a.\n Ensure that StarRC extraction is enabled.\n StarRC extraction is controlled by the  extract.starrc_mode application option.\n The default is  fusion_adv.\n You can also set the value to  in-design or  none.\n To use the native extractor, set the value to  none.\n b.\n Specify a configuration file for running StarRC extraction by using the set_starrc_options\u00a0-config command.\n       3.\n Perform optimization by using the  eco_opt command.\n By default, the  eco_opt command fixes timing (setup and hold) and DRC violations, removes redundant buffers, and improves the total power QoR by using PrimeTime ECO capabilities.\n It then incorporates the ECO changes by using the Fusion Compiler ECO place and route capabilities.\n However, you can control the type of optimization by using the  -type option.\n The following example uses the  eco_opt command to fix only timing and DRC violations using exhaustive path-based analysis: fc_shell>\u00a0 eco_opt -pba_mode exhaustive -types {timing drc} The following example uses the  eco_opt command to improve the leakage power QoR.\n However, it does not incorporate the ECO changes.\n Instead, it generates a file containing the ECO changes.\n fc_shell>\u00a0 eco_opt -pba_mode exhaustive -types {timing drc} \\ -write_change_file_only For more information, see the man page for the  eco_opt command.\n 4.\n Analyze the PrimeTime QoR by using the  check_pt_qor command.\n For more information, see the man page for the  check_pt_qor command.\n Note: When you run the  eco_opt command, the Fusion Compiler tool specifies the PrimeTime settings based on the Fusion Compiler timing analysis settings, such as derating factors, on-chip-variation settings, and so on.\n Therefore, for optimal convergence, ensure that the Fusion Compiler timing analysis settings at the postroute stage are consistent with the PrimeTime timing analysis settings.\n You can identify the differences in the Fusion Compiler and PrimeTime settings by using the  check_consistency_settings command."}
{"header": "How do I Manually Instantiating Spare Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler ECO Fusion power integrity flow allows you to use the RedHawk Fusion rail analysis feature to identify power integrity issues and the PrimeTime physically aware ECO capabilities to fix them.\n       The Fusion Compiler ECO Fusion power integrity flow consists of the following steps: 1.\n Specify the path for saving the RedHawk Fusion rail analysis results by setting the rail.database application option.\n 2.\n Perform dynamic-vectorless or dynamic-vector-based voltage-drop analysis by using the  analyze_rail\u00a0-voltage_drop\u00a0dynamic_vcd or  analyze_rail\u00a0-voltage_drop dynamic_vectorless command.\n 3.\n Specify the settings required to run the PrimeTime ECO capabilities within the Fusion Compiler tool by using the  set_pt_options command.\n 4.\n Fix the identified power integrity issues by using the  eco_opt\u00a0-type power_integrity command.\n To fix power integrity (voltage drop) violations, the tool downsizes aggressor cells while considering the timing and DRC QoR.\n However, for this optimization to be effective, \u2022 The aggressor cells should not be timing- or DRC-critical \u2022 The cell library should have smaller versions of the aggressor cells without  dont_use or  dont_touch attribute settings.\n The following is an example script for running the ECO Fusion power integrity flow: set_app_options\u00a0-name\u00a0rail.database\u00a0-value\u00a0RAIL_DATABASE_BASELINE analyze_rail\u00a0-voltage_drop\u00a0dynamic_vcd\u00a0-all_nets\u00a0\\ -switching_activity\u00a0{VCD\u00a0./top.vcd\u00a0top} set_pt_options\u00a0-pt_exec\u00a0/snps_tools/PT/pt_shell eco_opt\u00a0-type\u00a0power_integrity"}
{"header": "How do I Automatically Adding Spare Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can manually instantiate spare cells in a block by using one of the following methods: \u2022 Instantiating them in the Verilog netlist \u2022 Adding them by using netlist editing commands such as  create_cell,  connect_pin s, and so on When manually instantiating spare cells, you should \u2022 Evenly distribute the spare cells through the logical hierarchy to better handle ECO changes anywhere in the block \u2022 Tie their inputs to power or ground, as appropriate, to prevent the spare cells from creating noise and consuming power       If a cell meets the following criteria, the tool automatically identifies it as a spare cell: \u2022 It is not a physical-only cell \u2022 All inputs except for the clock pin are unconnected or tied to a logic constant The clock pin of the spare cell, if any, can be connected to the clock network.\n \u2022 All outputs are unconnected If you instantiate the spare cells before you perform physical synthesis on a block, the tool places and legalizes the spare cells during the subsequent physical synthesis steps.\n However, if you instantiate the spare cells in a block that is optimized, placed and legalized, you must place and legalize the spare cells by using the following steps: 1.\n Spread the spare cells by using the  spread_spare_cells command.\n By default, this command distributes and places all the spare cells evenly throughout the core area.\n You can specify the spare cells to place by using one of the following two methods: \u25e6 To place specific spare cells, use the  -cells option.\n \u25e6 To place all the spare cells that belong to specific voltage areas, use the -voltage_areas option.\n You can control the placement of the spare cells as follows: \u25e6 Specify an area within which to place the spare cells by using the  -boundary option.\n \u25e6 Ignore specific types of placement blockages by using the -ignore_blockage_types option.\n By default, the  add_spare_cells command honors all placement blockage types.\n \u25e6 Ignore the current cell density and place the spare cells randomly by using the -random_distribution option.\n \u25e6 Specify a percentage of spare cells to be placed based on the cell density distribution by using the  -density_aware_ratio option.\n The rest of the spare cells are placed randomly throughout the design.\n By default, all the spare cells are placed based on the cell density distribution.\n For example, if you specify a setting of  -density_aware_ratio\u00a080, the tool places 80 percent of the spare cells based on the cell density distribution and 20 percent randomly across the design.\n 2.\n Legalize the spare cells by using the  place_eco_cells\u00a0-legalize_only\u00a0-cells command."}
{"header": "How do I Adding Programmable Spare Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "After placement and optimization, you can add spare cells and legalize them by using the following steps: 1.\n Add spare cells by using the  add_spare_cells command and specify the following information: \u25e6 A name prefix for the spare cells by using the  -cell_name option \u25e6 The type and number of spare cells to insert by using one of the following two methods: \u25aa Specify the library cells to use for the spare cell and the number of instances of each library cell by using the  -lib_cell and  -num_instances options For example, to insert 250 instances each of the AND2 and OR2 library cells, use the following command: fc_shell>\u00a0 add_spare_cells -cell_name spare \\ -lib_cell {AND2 OR2} -num_instances 250 \u25aa Specify the library cells and a different number of instances for each library cell by using the  -num_cells option For example, to insert 200 instances of the NAND2 library cell and 150 instances of the NOR2 library cell, use the following command: fc_shell>\u00a0 add_spare_cells -cell_name spare \\ -num_cells {NAND2 200 NOR 150} \u25e6 (Optional) A repetitive placement window in which to add the spare cells by using the  -repetitive_window option For example, to add 15 instances each of the AND2 and OR2 library cells in a 20 by 20 micron window that is repeated throughout the placement area, use the following command: fc_shell>\u00a0 add_spare_cells -cell_name spare \\ -lib_cell {AND2 OR2} -num_instances 15 \\ -repetitive_window {20 20} To add 20 instances of the NAND2 and 15 instances of the NOR2 library cells in a 25 by 20 micron window that is repeated throughout the placement area, use the following command: fc_shell>\u00a0 add_spare_cells -cell_name spare \\ -num_cells {NAND2 20 NOR 15} -repetitive_window {25 20}       By default, the  add_spare_cells command distributes the spare cells evenly throughout the entire design.\n To distribute the spare cells within a specific \u25e6 Hierarchical block, use the  -hier_cell option.\n When you use this option, the tool distributes the spare cells in a rectangular area that encloses all of the cells that belong to the specified hierarchical block.\n \u25e6 Bounding box, use the  -boundary option.\n \u25e6 Voltage areas, use the  -voltage_areas option.\n You can further control the placement of the spare cells as follows: \u25e6 Ignore specific types of placement blockages by using the -ignore_blockage_types option.\n By default, the  add_spare_cells command honors all placement blockage types.\n \u25e6 Ignore the current cell density and place the spare cells randomly by using the -random_distribution option.\n \u25e6 Specify a percentage of spare cells to be placed based on the cell density distribution by using the  -density_aware_ratio option.\n The rest of the spare cells are placed randomly throughout the design.\n By default, all the spare cells are placed based on the cell density distribution.\n For example, if you specify a setting of  -density_aware_ratio\u00a080, the tool places 80 percent of the spare cells based on the cell density distribution and 20 percent randomly across the design.\n \u25e6 Specify the type of connection for the input pins of the spare cells by using the -input_pin_connect_type option.\n The valid values are  tie_low,  tie_high, or open.\n 2.\n Legalize the spare cells by using the  place_eco_cells\u00a0-legalize_only\u00a0-cells command."}
{"header": "How do I Making ECO Changes Using the eco_netlist Command", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports programmable spare cells, also known as gate array filler cells, if they are provided by your vendor.\n These cells can be programmed by metal mask changes for ECO implementation, reducing mask costs and time-to-results.\n To insert programmable spare cells, use the following steps: 1.\n Specify the programmable spare cell that a standard cell can map to by setting the same  psc_type_id attribute setting on the corresponding library cell for the standard cell and the programmable spare cell.\n The following example specifies that \u25e6 The standard cells named BUF1 and INV1 can map to the programmable spare cell named fill1x by setting the  psc_type_id attribute to  1 for the corresponding library cells.\n \u25e6 The standard cells named NAND2 and NOR2 can map to the programmable spare cell named fill2x by setting the  psc_type_id attribute to  2 for the corresponding library cells.\n fc_shell>\u00a0 set_attribute [get_lib_cells fill_lib/fill1x] \\ psc_type_id 1 fc_shell>\u00a0 set_attribute [get_lib_cells stdcell_lib/BUF1] \\ psc_type_id 1 fc_shell>\u00a0 set_attribute [get_lib_cells stdcell_lib/INV1] \\ psc_type_id 1 fc_shell>\u00a0 set_attribute [get_lib_cells fill_lib/fill2x] \\ psc_type_id 2 fc_shell>\u00a0 set_attribute [get_lib_cells stdcell_lib/NAND2] \\ psc_type_id 2 fc_shell>\u00a0 set_attribute [get_lib_cells stdcell_lib/NOR2] \\ psc_type_id 2 2.\n Insert the programmable spare cells by using the  create_stdcell_fillers command.\n The following example inserts programmable spare cells named fill1x and fill2x: fc_shell>\u00a0 create_stdcell_fillers \\ -lib_cells {fill_lib/fill1x fill_lib/fill2x} During the ECO flow, the tool swaps an ECO cell with a programmable spare cell based on the  psc_type_id attribute setting, cell width, and voltage area.\n If the tool removes an ECO cell from the design, it can reuse the corresponding programmable spare cell."}
{"header": "How do I Making ECO Changes Using Netlist Editing Commands", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can make ECO changes to a block by using the  eco_netlist command.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the  design.eco_freeze_silicon_mode application option to  true, before you run the  eco_netlist command.\n When you use the  eco_netlist command, use one of the following two methods to make the ECO changes: \u2022 Specify a golden Verilog netlist that includes the ECO changes by using the -by_verilog_file option \u2022 Specify a golden block that includes the ECO changes by using the  -block option When you use the  -block option, by default, \u25e6 The tool assumes the golden block is in the current design library.\n To specify a different design library, use the  -golden_lib option.\n \u25e6 The tool makes the ECO changes to the current design.\n To make the ECO changes to a different design, use the  -working_block option.\n To specify the design library that contains the design specified by the -working_block option, use the  -working_lib option.\n The tool compares the working design to the input Verilog netlist or the golden design and generates a change file containing netlist editing Tcl commands that implements the functional changes.\n You must specify the name of the output file by using the -write_changes option.\n By default, the tool ignores the following: \u2022 Differences in the physical-only cells To consider the differences in the physical-only cells, use the -compare_physical_only_cells option.\n \u2022 Timing ECO changes, such as cells that are resized or repeaters that are added or removed.\n To consider the timing ECO changes, in addition to the functional ECO changes, use the  -extract_timing_eco_changes option.\n \u2022 Differences in power and ground objects.\n       To make the ECO changes to the working design, source the change file that the eco_netlist command generates, as shown in the following example: fc_shell>\u00a0 eco_netlist -by_verilog_file eco.v \\ -compare_physical_only_cells  -write_changes eco_changes.tcl fc_shell>\u00a0 source eco_changes.tcl"}
{"header": "How do I Using ECO Scripts for Netlist Editing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "If the ECO changes are minimal, you can update the design by using netlist editing commands given.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the  design.eco_freeze_silicon_mode application option to  true, before you run the netlist editing commands.\n For a list of netlist editing commands, see the  Common Design Objects topic in the  Fusion Compiler Data Model User Guide."}
{"header": "How do I Resizing Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "The Fusion Compiler tool supports using ECO scripts to make changes in the netlist during design planning.\n You can use the \u2022 write_split_net_eco command to push up the branching of a physical multiple- fanout net to the top level \u2022 write_push_down_eco command to push down a tree of standard cells one level \u2022 write_spare_ports_eco command to create spare ports and nets on a child block For more information, see the  Generating ECO Scripts for Netlist Editing topic in the Fusion Compiler Design Planning User Guide."}
{"header": "How do I Reverting Changes Made During Resizing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can resize a cell by using the  size_cell command, as shown in the following example: fc_shell>\u00a0 size_cell U21 -lib_cell AND2X4 If you enable the freeze silicon mode by setting the  design.eco_freeze_silicon_mode application option to  true, by default, the  size_cell command checks if a compatible       spare cell is available within a distance of five times the unit site height before sizing the cell.\n If a compatible spare cell is not available, the tool does not size the cell.\n \u2022 To control this distance, use the  -max_distance_to_spare_cell option.\n \u2022 To disable this feature, use the  -not_spare_cell_aware option."}
{"header": "How do I Adding Buffers on Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To revert the ECO changes made with the  size_cell command, use the revert_cell_sizing command.\n To include the sized cells that are adjacent to the specified cell in the same row, use the  -include_adjacent_sized_cells option.\n When you use this option, by default, the tool also reverts the cells that abut the specified cell on either side, if they are also sized cells.\n However, if you use the -adjacent_cell_distance option, the tool recursively reverts the sized cells that are adjacent to sized cells within the specified distance in the same row."}
{"header": "How do I Adding Buffers on Routed Nets", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers on nets connected to specified pins, use the  add_buffer command.\n Specify the following options when using the  add_buffer command: \u2022 -new_net_names : Specifies the names of the new nets to add.\n You must specify one net name per buffer when adding buffers, and two net names per inverter pair when adding inverter pairs.\n \u2022 -new_cell_names : Specifies the names of the new cells to be added.\n You must specify one cell name per buffer when adding buffers, and two cell names per inverter pair when adding inverter pairs.\n \u2022 -inverter_pair : Adds inverter pairs instead of buffer cells.\n If you specify this option, you must supply a library cell that has an inverting output.\n \u2022 -respect_voltage_areas : Inserts buffers within the hierarchy of the voltage area such that the buffer is physically in the layout.\n This option is mutually exclusive with the -snap option.\n \u2022 -no_of_cells : Specifies the number of buffer cells or inverter pairs to be inserted per net.\n \u2022 -object_list : Specifies a list of nets, pins, or ports that must be buffered.\n The new buffer cells or inverter pairs are placed close to the specified pins or ports if their cells are placed.\n       \u2022 -lib_cell : Specifies the library cell to be used as buffer.\n In this case, the object is either a named library cell or a library cell collection.\n This is a required option.\n This option is mutually exclusive with  buffer_lib_cell.\n \u2022 -snap : Puts the new buffer cells next to the target cell, then snaps the buffer cells to the closest site, and flips the buffer cells when needed."}
{"header": "How do I Specifying the Net Names, Buffers Types, and Their Locations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers or pairs of inverters on a fully routed net, use the  add_buffer_on_route command as described in the following topics: \u2022 Specifying the Net Names, Buffers Types, and Their Locations \u2022 Controlling How Buffers are Added \u2022 Specifying Settings for Multivoltage Designs \u2022 Specifying Settings for the Freeze Silicon ECO Flow"}
{"header": "How do I Adding Buffers in a Specified Configuration", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you use the  add_buffer_on_route command, you must specify the following: \u2022 The net on which to add buffers \u2022 The type of buffers to add and where to add them on the net by using one of the following methods: \u25e6 Adding Buffers in a Specified Configuration \u25e6 Adding Buffers at Specified Locations \u25e6 Adding Buffers at a Specified Interval \u25e6 Adding Buffers at an Interval That is a Ratio of the Net Length \u25e6 Adding Buffers on a Bus in a Specified Pattern"}
{"header": "How do I Adding Buffers at Specified Locations", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers in an exact configuration, specify the configuration of cells and their locations by using the  -user_specified_buffers option.\n With the  -user_specified_buffers option, you can add cells only on one net at a time.\n You can insert different types of buffers or inverter pairs by using this option, but you cannot combine both buffers and inverter pairs.\n For each cell you add, use the {instance_name library_cell_name x y layer_name...\n } format with the  -user_specified_buffers option to specify the \u2022 Instance name \u2022 Library cell to use \u2022 Coordinates of the exact location \u2022 Layer at that location with an existing routing shape to connect to Instead of specifying the routing layer, you can have the tool automatically detect the closest routing shape to that location by using the  -detect_layer option.\n The following example adds two cells named ECO1 and ECO2 on net n22.\n The ECO1 cell is of type BUF2, at location (100, 70), connecting to a routing shape on the M3 layer.\n The ECO2 cell is of type BUF4, at location (150, 70), also connecting to a routing shape on the M3 layer.\n fc_shell>\u00a0 add_buffer_on_route net22 \\ -user_specified_buffers {ECO1 BUF2 100 70 M3 ECO2 BUF4 150 70 M3}"}
{"header": "How do I Adding Buffers at a Specified Interval", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers at specific locations of a net, specify \u2022 A list of one or more library cells to select from by using the  -lib_cell option \u2022 The exact locations by using the  -location option With the  -location option, you must specify the x- and y-coordinates and a layer with an existing routing shape at that location by using the {x1 y1 layer1....} format.\n Instead of specifying the routing layer, you can have the tool automatically detect the closest routing shape to that location by using the  -detect_layer option.\n With this method, you can add cells only on one net at a time.\n The following example adds the BUF1 library cell on the net1 net at location (100, 200) and connects it to an existing route shape on the M4 layer.\n fc_shell>\u00a0 add_buffer_on_route net1 -lib_cell BUF1 \\ -location {100 200 M4}       By default, the tool uses eco_cell and eco_net as the name prefix of all new cells and nets.\n To specify a name prefix for the new cells and nets, use the  -cell_prefix and -net_prefix options, respectively."}
{"header": "How do I Adding Buffers at an Interval That is a Ratio of the Net Length", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers to one or more nets at a specified interval, specify \u2022 A list of one or more library cells to select from by using the  -lib_cell option \u2022 The distance between the driver of the net and the first buffer by using the -first_distance option \u2022 The distance between the load pin of the net and the last buffer by using the -last_distance option You must use the  -last_distance option with the  -repeater_distance option or the -repeater_distance_length_ratio option.\n You can also use the  -last_distance option with the  -first_distance option.\n However, you cannot use it with the following options: \u25e6 -location \u25e6 -user_specified_buffers \u25e6 -user_specified_bus_buffers Note: When you use the  -last_distance option, the value of the eco.add_buffer_on_route.min_distance_buffer_to_load application option is ignored.\n \u2022 The interval between the buffers by using the  -repeater_distance option Optionally, you can scale the distance between the buffers by \u25e6 Specifying a different scaling factor for each layer using the  -scaled_by_layer option \u25e6 Using the ratio between the default width for the layer and the actual route width as the scaling factor by specifying the  -scaled_by_width option The following example adds the BUF1 library cell on the nets n2 and n5 at an interval of 150 microns.\n The distance between the driver and the first repeater cell is 100 microns.\n fc_shell>\u00a0 add_buffer_on_route {n2 n5} -lib_cell BUF1 \\ -first_distance 100 -repeater_distance 150       The following example adds the BUF2 library cell on the net n1 at an interval of 100 microns.\n The distance between the driver and the first repeater cell is 50 microns and the last distance is 20 microns.\n fc_shell>\u00a0 add_buffer_on_route -repeater_distance 100 \\ -first_distance 50 -last_distance 20 net1 -lib_cell BUF2 By default, the tool uses eco_cell and eco_net as the name prefix of all new cells and nets.\n To specify a name prefix for the new cells and nets, use the  -cell_prefix and -net_prefix options, respectively."}
{"header": "How do I Adding Buffers on a Bus in a Specified Pattern", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers at an interval that is a ratio of the total net length, specify \u2022 A list of one or more library cells to select from by using the  -lib_cell option \u2022 The distance between the driver and the first buffer as a ratio of the total net length by using the  -first_distance_length_ratio option \u2022 The distance between the buffers as a ratio of the total net length by using the -repeater_distance_length_ratio option The following example adds the BUF1 library cell on the nets n3, n21, and n41 at an interval that is 20 percent of the total net length.\n The distance between the driver and the first repeater cell is 10 percent of the total net length.\n fc_shell>\u00a0 add_buffer_on_route {n3 n21 n41} -lib_cell mylib/BUF1 \\ -first_distance_length_ratio 0.1 \\ -repeater_distance_length_ratio 0.2 By default, the tool uses eco_cell and eco_net ad the name prefix of all new cells and nets.\n To specify a name prefix for the new cells and nets, use the  -cell_prefix and -net_prefix options, respectively."}
{"header": "How do I Controlling How Buffers are Added", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add buffers to the individual nets of a bus in a specific pattern, use the following steps: 1.\n Define buffer patterns for the nets of a bus by using the create_eco_bus_buffer_pattern command.\n This command allows you to define patterns for staggering buffers on bused nets, which prevent clumping and overlapping of buffers.\n Table 72 Commands Associated With Bus Patterns To do this Use this command  create_eco_bus_buffer_pattern       To do this Use this command  report_eco_bus_buffer_patterns  get_eco_bus_buffer_patterns  remove_eco_bus_buffer_patterns The following example creates the buffer pattern shown in  Figure\u00a0219 for a horizontal bus, where the first buffer is placed on the topmost net.\n The buffers are staggered by a distance of 2, starting from the left, and the pattern is repeated after every three buffers.\n fc_shell>\u00a0 create_eco_bus_buffer_pattern -name top_left \\ -first_buffer top -measure_from left -distance 2 -repeat_after 3 Figure 219 Buffer Patterns for a Horizontal Bus 2 2 First buffer The following example creates the buffer pattern shown in  Figure\u00a0220 for a vertical bus, where the first buffer is placed on the rightmost net.\n Starting from the top, the second buffer is staggered by a distance of 2 from the first, the third a distance of 3 from the second, and the fourth a distance 2 from the third.\n After that, the pattern is repeated.\n fc_shell>\u00a0 create_eco_bus_buffer_pattern -name right_top \\ -first_buffer right -measure_from top \\ -user_specified_distance {2 3 2}       Figure 220 Buffer Patterns for a Vertical Bus 2 3 First buffer 2 2.\n Add buffers on the nets of the bus by using the  add_buffer_on_route -user_specified_bus_buffers command.\n For each group of buffers that you add on the bused nets, use the {buffer_pattern_name library_cell_name x y....\n } format with the -user_specified_bus_buffers option to specify the \u25e6 Name of the buffer pattern that you defined using the create_eco_bus_buffer_pattern command \u25e6 Library cell to use \u25e6 Coordinates of the location of the first buffer in the pattern The following example adds a group of buffers of type BUF2 on the bus named data_A, using a buffer pattern named BP1.\n The first buffer of the pattern is placed at location (100, 70).\n fc_shell>\u00a0 add_buffer_on_route [get_net data_A*] \\ -user_specified_bus_buffers {BP1 BUF2 100 70}"}
{"header": "How do I Specifying Settings for Multivoltage Designs", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "By default, the  add_buffer_on_route command \u2022 Adds buffers over all placement blockages, soft macros, and hard macros.\n To prevent buffers from being placed over specific macro cells, use the -dont_allow_insertion_over_cell option.\n Alternatively, you can prevent the buffers from being placed over all blockages and macro cells by using the  -respect_blockages option.\n When you use this option, you can specify a list of macro cells over which buffers are allowed by using the -allow_insertion_over_cell option.\n \u2022 Adds buffers on both global routed and detail routed nets.\n To add buffers only on nets that are global routed only, without assigned tracks or detail routing, use the  -only_global_routed_nets option.\n \u2022 Adds buffers at the lowest common level of hierarchy of the pins being driven by the buffers.\n To add the buffers on the highest possible level of hierarchy, use the -on_top_hierarchy option.\n \u2022 Does not add buffers on a route segment if it is necessary to create new ports because of a difference in the logical and physical topology of the net.\n To add buffers on such route segments by creating new ports, use the  -punch_port option."}
{"header": "How do I Specifying Settings for the Freeze Silicon ECO Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For multivoltage designs, to \u2022 Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the  add_buffer_on_route command.\n \u2022 Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format.\n When you use this option, you must also use the  -lib_cell option.\n \u2022 Specify different single-rail and dual-rail library cells for different voltage areas, use the  -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format.\n       When you use this option, you must also use the  -lib_cell option.\n For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option.\n For the default voltage area, specify DEFAULT_VA as the voltage area name.\n \u2022 Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the  -allow_physical_feedthrough_buffer option.\n This option can only be used with the  -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area.\n After you run the  add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command.\n \u2022 Add cells within gas stations of specified supply nets, use the  -respect_gas_station option and specify the supply net.\n Gas stations are areas with a constant power supply.\n These areas used for buffering nets that go through power domains that are powered down.\n To specify the maximum allowed distance from the gas station to the added buffer, use the  -max_distance_route_to_gas_station option."}
{"header": "How do I Optimizing the Fanout of a Net", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When you set the  design.eco_freeze_silicon_mode application option to  true and run the  add_buffer_on_route command in the freeze silicon mode, the tool checks if a spare cell is available within a distance of five times the unit site height before adding a buffer.\n If a spare cell is not available, the tool does not add the buffer.\n \u2022 To control this distance, use the  -max_distance_to_spare_cell option.\n \u2022 To disable this feature, use the  -not_spare_cell_aware option."}
{"header": "How do I Reporting Available Sites for Placing ECO Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "During the timing ECO flow, you can add buffers to a net and optimize its fanout by using the  split_fanout command.\n With this command, you must specify \u2022 The net to optimize by specifying its name by using the  -net option or its driver by using the  -driver option \u2022 The library cell to use by using the  -lib_cell option       \u2022 The method in which to optimize the net by specifying one of the following: \u25e6 A maximum fanout constraints for the net by using the  -max_fanout option \u25e6 The load pins or ports to buffer by using the  -load option When you use this option, you can specify the logical hierarchy to add the buffer by using the  -hierarchy option.\n In addition, you can \u2022 Add the buffers on the existing route topology of the net by using the  -on_route option If you use this option with the  -load option, you cannot specify the  -hierarchy option.\n \u2022 Split the fanout of a routed net that is not fully connected to the terminals of the driver or loads of the net by specifying a maximum distance between terminals of the driver or load pins and the incomplete route using the  -max_distance_for_incomplete_route option.\n If the tool is unable to find a routed segment or finds more than one routed segment within the specified distance from the unconnected terminal, it issues an error message.\n \u2022 Avoid placement blockages and macro cells when placing buffers by using the -respect_blockages option \u2022 Specify a name prefix for the new cells and nets by using  -cell_prefix and -net_prefix options By default, the tool uses eco_cell and eco_net as the name prefix for the new cells and nets."}
{"header": "How do I Identifying and Reverting Nonoptimal ECO Changes", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can report sites available for placing ECO cells by using the report_cell_feasible_space command.\n By default, the tool reports the available sites in the entire block.\n You can restrict the report to specific voltage areas by using the  -voltage_areas option or to a specific rectangle or rectilinear area by using the -boundary option."}
{"header": "How do I Placing ECO Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can identify if ECO changes made with the  size_cell,  add_buffer, and add_buffer_on_route commands can cause large displacements during ECO placement and legalization by using the  report_eco_physical_changes command.\n       You can revert the nonoptimal ECO changes made by the  size_cell,  add_buffer, and add_buffer_on_route commands by using the  revert_eco_changes command.\n To specify the cells for which to revert the ECO changes, use the  -cells option."}
{"header": "How do I Controlling Placement When Using the place_eco_cells Command", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For the unconstrained ECO flow, place the ECO cells by using the  place_eco_cells command.\n This command derives the placement of each ECO cell based on the connectivity and the delays associated with the cell.\n The tool then legalizes each ECO cell to the closest unoccupied site.\n The existing cells are untouched to minimize the impact to their placement.\n To place \u2022 All unplaced cells, use the  -unplaced_cells option.\n \u2022 Specific cells, use the  -cells option.\n \u2022 Only the cells that have changed due to ECO operations, use the -eco_changed_cells option.\n A cell is considered changed if the  eco_change_status attribute of the cell has one of the following values: \u25e6 create_cell \u25e6 change_link \u25e6 add_buffer \u25e6 size_cell When you run the  eco_netlist command, the tool automatically sets the eco_change_status attribute on the changed cells.\n If you update the design without using the  eco_netlist command, you can manually set the  eco_change_status attribute by using the  set_attribute command."}
{"header": "How do I Controlling Legalization When Using the place_eco_cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  place_eco_cells command places and legalizes each ECO cell based on the connectivity and the delays associated with the cell.\n You can control the placement of the ECO cells as follows: \u2022 To use the channels areas between macro cells for ECO placement, use the -channel_aware option.\n By default, the command avoids channel areas during ECO placement.\n       \u2022 To place ECO cells closer to fixed points, such as I/O pads or macro cells, specify a weight for the nets connected to the fixed cells by using the -fixed_connection_net_weight option.\n By default, nets connected to fixed cells have a weight of one.\n To place ECO cells closer to fixed points, specify an integer value greater than one for the corresponding net.\n \u2022 To prioritize specific nets during ECO placement by specifying net weights, 1.\n Specify net weights by using the  set_eco_placement_net_weight command.\n 2.\n Specify that the tool honors the net weights by using the  -honor_user_net_weight option with the  place_eco_cells command.\n To report the net weights you specify, use the  report_eco_placement_net_weight command.\n \u2022 To create virtual connections for ECO cells and use them during ECO placement, instead of the actual connections, 1.\n Create virtual connections by using the  create_virtual_connection command 2.\n Use these virtual connections during ECO placement by using the -use_virtual_connection option with the  place_eco_cells command.\n The following example creates virtual connections for the inputs and output of the cell named ECO17 and performs ECO placement using these virtual connections: fc_shell>\u00a0 create_virtual_connection -name VC_0 \\ -pins {U1/Y ECO17/A} fc_shell>\u00a0 create_virtual_connection -name VC_1 \\ -pins {U2/Y ECO17/B} fc_shell>\u00a0 create_virtual_connection -name VC_2 \\ -pins {ECO17/Y D17_OUT} -weight 3 fc_shell>\u00a0 place_eco_cells -cells ECO17 -use_virtual_connection To remove virtual connections you have created, use the remove_virtual_connections command.\n To query virtual connections, use the get_virtual_connections command.\n \u2022 To ignore high-fanout nets connected to ECO cells that exceed a specific threshold, use the  -max_fanout option with the  place_eco_cells command.\n \u2022 To ignore the connections of specific pins on ECO cells, use the -ignore_pin_connection option with the  place_eco_cells command."}
{"header": "How do I Placing ECO Cells With Minimal Physical Impact (MPI)", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "After placing the ECO cells, the  place_eco_cells command legalizes each ECO cell to the closest unoccupied site.\n The existing cells are untouched to minimize the impact to their placement.\n You can control the legalization of the ECO cells by using one of the following methods: \u2022 To not legalize the cells after ECO placement, use the  -no_legalize option.\n \u2022 To perform legalization only, use the  -legalize_only option.\n \u2022 To specify the mode in which to legalize, use the  -legalize_mode option with one of the following settings: \u25e6 free_site_only When you specify this setting, the default, the tool legalizes the ECO cells on free sites without moving preexisting cells.\n An ECO cells can have a large displacement, if a free site is unavailable nearby.\n \u25e6 allow_move_other_cells When you specify this setting, the tool legalizes the ECO cells to the nearest legal location by moving preexisting cells.\n \u25e6 minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells the can be legalized to a free site nearby without moving preexisting cells.\n For the ECO cells that do not have a free site nearby, the tool legalizes them by moving preexisting cells.\n \u2022 To specify a displacement threshold for legalization, use the -displacement_threshold option.\n When you use the  -displacement_threshold option, you can also use the -max_displacement_threshold option to specify a second displacement threshold that is larger than the value specified with the  -displacement_threshold option.\n How the tool uses these displacement thresholds depends on the setting you use for the  -legalize_mode option as follows: \u25e6 free_site_only When you specify this setting, the tool legalizes the ECO cells that have available free sites within the specified displacement threshold.\n       If the displacement of an ECO cell exceeds this threshold, the tool does not legalize the cell.\n It creates a collection named epl_legalizer_rejected_cells that consists of such ECO cells that are not legalized.\n You can subsequently legalize the ECO cells in the epl_legalizer_rejected_cells collection by using the following command: fc_shell>\u00a0 place_eco_cells -legalize_mode allow_move_other_cells \\ -legalize_only -cells $epl_legalizer_rejected_cells This command moves existing cells to find legal locations for the ECO cells in the collection named epl_legalizer_rejected_cells.\n If you also specify the  -max_displacement_threshold option with -displacement_threshold option, the tool also creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n The collection epl_max_displacement_cells is a subset of the collection epl_legalizer_rejected_cells and its cells are also not legalized.\n You can use the  -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n \u25e6 allow_move_other_cells When you specify this setting, you cannot specify the  -displacement_threshold and  -max_displacement_threshold options.\n \u25e6 minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells that have available free sites within the specified displacement threshold.\n If the displacement of an ECO cell exceeds this threshold, the tool legalizes them by moving preexisting cells.\n If you also specify the  -max_displacement_threshold option, the tool does not legalize the cells that exceed this maximum displacement threshold specified with this option and the tool creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n You can use the  -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n \u2022 To specify the types of filler cells that can be removed during legalization, use the -remove_filler_references option.\n       When you use this option, the filler cells are removed if they do not have a fixed placement and they overlap with ECO cells.\n By default, the tool does not remove any filler cells when legalizing ECO cells.\n \u2022 To enable Advanced Legalizer and remove the filler cells that have violations, set the place.legalize.enable_advanced_legalizer application option to  true.\n When you specify this setting, the filler cells that have violations are removed after legalizing ECO cells.\n Using the  -remove_filler_references option with this application option set to  true results in the legalizer engine removing only those fillers that are specified by this option.\n The  -min_filler_distance option is ignored when you use the place.legalize.enable_advanced_legalizer application option."}
{"header": "How do I Placing and Mapping ECO Cells to Spare Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To minimize the disturbance to the existing placement during ECO placement, use the following options with the  place_eco_cells command: \u2022 -legalize_mode\u00a0minimum_physical_impact \u2022 -max_displacement_threshold \u2022 -remove_filler_references"}
{"header": "How do I Specifying Mapping Rules for Programmable Spare Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "For the freeze silicon ECO flow, place and map the ECO cells to spare cells by using the place_freeze_silicon command.\n By default, this command places and maps all ECO cells.\n To place and map specific ECO cells, use the  -cells option.\n The following example places and maps the ECO cells named ECO1, ECO2, and ECO3: fc_shell>\u00a0 place_freeze_silicon -cells {ECO1 ECO2 ECO3} This command places each ECO cell and maps it to the nearest matching spare cell.\n Cells that are deleted as a result of the ECO changes are not removed from the design.\n They are converted to spare cells and remain in the design.\n When you use the  place_freeze_silicon command, you can \u2022 Place the ECO cells by the target spare cells, but not map them to the spare cells, by using the  -no_spare_cell_swapping option This feature allows you to place the ECO cells and analyze the QoR before you map them.\n       \u2022 Map the spare cells that are already placed by the target spare cells by using the -map_spare_cells_only option.\n \u2022 Generate an ECO cell to spare cell mapping file by using the  -write_map_file command.\n You can edit the mapping file, if necessary, and map the ECO cells by using the map_freeze_silicon command.\n \u2022 Specify a minimum distance between ECO cells that are mapped to programmable filler cells by using the  -min_filler_distance option."}
{"header": "How do I Mapping ECO Cells to Specific Spare Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can define mapping rules for programmable spare cells to control the \u2022 Overlapping of spare cells and PG nets \u2022 Splitting of multiple-height and merging of single-height spare cells \u2022 Compatibility of the different types of spare cells To do so, use the  set_programmable_spare_cell_mapping_rule command before you run the  place_freeze_silicon command.\n To report or remove the mapping rules you specify, use the report_programmable_spare_cell_mapping_rule command."}
{"header": "How do I Mapping ECO Cells to Logically Equivalent Spare Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To map an ECO cell to a specific spare cell, use the  map_freeze_silicon command.\n Specify the ECO cell name and the corresponding spare cell name by using the -eco_cell and  -spare_cell options.\n The following example maps the ECO cell named ECO1 to the spare cell named spare_1: fc_shell>\u00a0 map_freeze_silicon -eco_cell ECO1 -spare_cell spare_1 You can specify the ECO cell to spare cell mapping by using a map file and specifying this map file name by using the  -map_file option with the  map_freeze_silicon command.\n The map file has the following format: ECO_cell_1   spare_cell_1 ECO_cell_2   spare_cell_2...\n     ..."}
{"header": "How do I Updating Supply Nets for ECO Cells", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "When the tool maps an ECO cell, it looks for a spare cell with the same library cell name.\n If it is unable to find such a spare cell, the ECO cells remains unmapped.\n To identify and map such ECO cells to logically equivalent (LEQ) spare cells, use the following steps: 1.\n Identify the ECO cells that do not have matching spare cells by using the check_freeze_silicon command.\n 2.\n Find logically equivalent spare cells for these ECO cells by using the create_freeze_silicon_leq_change_list command.\n Specify \u25e6 The names of the unmapped ECO cells by using the  -cells option \u25e6 A name for the output file by using the  -output option This output file is a Tcl script with netlist editing commands.\n The commands replace each ECO cell with logically equivalent spare cells, which can be a \u25aa Single spare cell with the same logical functionality, but a different library cell name \u25aa Combination of up to two spare cells that give the same logical functionality 3.\n View the output Tcl file to ensure that the ECO mapping is satisfactory, and edit it if necessary.\n 4.\n Source the Tcl file in the tool to replace the ECO cells with their logical equivalents."}
{"header": "How do I Recording the Changes Made to a Layout", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To update the supply nets for ECO cells, use the  eco_update_supply_net command.\n By default, it updates the supply nets for all cell added by using the following ECO commands: \u2022 size_cell in freeze-silicon mode \u2022 add_buffer \u2022 add_eco_repeater \u2022 split_fanout \u2022 add_buffer_on_route To update the supply nets for specific cells, use the  eco_update_supply_net\u00a0-cells command."}
{"header": "How do I Performing Prerequisite Check for Group Repeater Insertion and", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "You can record the changes you make to a layout and generate a Tcl file containing the changes by using the  record_layout_editing command, as shown in the following example: fc_shell>\u00a0 record_layout_editing -start fc_shell>\u00a0 remove_shapes RECT_32_0 fc_shell>\u00a0 record_layout_editing -stop -output layout_changes1.tcl You can make the following layout changes: \u2022 Create or remove layout objects by using Tcl commands \u2022 Set attributes by using the  set_attribute command \u2022 Move or resize objects by using the GUI With this feature, multiple users can make ECO changes to different parts of a layout in parallel.\n Each user can output a Tcl file that contains the layout changes they make by using the  record_layout_editing command, and all the Tcl files can be applied to the original layout."}
{"header": "How do I Adding a Group of Repeaters", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  -check_prerequisites option of the  place_group_repeaters or add_group_repeaters command to perform a prerequisite check for a design.\n This prerequisite check detects the design errors at the beginning of the command flow.\n \u2022 For the  place_group_repeaters command, use the  -check_prerequisites option with the following options to provide necessary information for the check: place_group_repeaters -cells\u00a0|\u00a0-repeater_groups [-lib_cell_input] [-lib_cell_output] -check_prerequisites \u2022 For the  add_group_repeaters command, use the  -check_prerequisites option with the following options to provide necessary information for the check: add_group_repeaters -nets\u00a0|\u00a0-bundles [-lib_cell_input] [-lib_cell_output] -check_prerequisites       \u2022 The prerequisite check validates the following in a design and search region: \u25e6 Site rows are present in the design.\n \u25e6 Each net has only one driver and can have multiple loads.\n \u25e6 Locations of pins or ports are assigned.\n \u25e6 For pins on standard cells, the standard cells are placed.\n \u25e6 Supernets must be routed.\n \u25e6 Route ends must not be more than 5 \u03bcm away from the driver, load pins, or ports in the search region.\n \u25e6 The routes are defined for a driver or load in the search region.\n \u25e6 Load is connected to a driver.\n \u25e6 When the end of a route is open, no other route of the same net is present in the vicinity of the pin or port.\n \u25e6 Routes must be assigned to the net of the supernet driver pin.\n \u25e6 Vias must be created for routes.\n \u25e6 Repeaters have a physical library cell.\n The following example shows the usage of  -check_prerequisites option using the add_group_repeaters command: fc_shell>\u00a0 add_group_repeaters -bundles bundle_wo_load \\ -lib_cell ref_lib1/libCell1 -lib_cell_input A -lib_cell_output X \\ -repeater_distance 10 -check_prerequisite Error:\u00a0The\u00a0net\u00a0net_wo_load\u00a0does\u00a0not\u00a0have\u00a0loads.\n (ECO-329) Error:\u00a0The\u00a0cell\u00a0driver1\u00a0of\u00a0the\u00a0pin\u00a0driver1/X\u00a0is\u00a0not\u00a0placed.\n (ECO-331) Error:\u00a00 Use\u00a0error_info\u00a0for\u00a0more\u00a0info.\n (CMD-013)"}
{"header": "How do I Defining a group of repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To add a group of repeaters, use the  add_group_repeaters command as described in the following sections: \u2022 Defining a group of repeaters \u2022 Grouping a list of repeaters \u2022 Setting Constraints for a Group of Repeaters \u2022 Adding Voltage Area Aware Group Repeaters       \u2022 Reporting the Constraints Assigned to a Group of a Repeaters \u2022 Removing Constraints for a Group of Repeaters \u2022 Placing Group Repeaters Before Routing \u2022 Performing On Route Placement of Repeaters \u2022 Placing Group Repeaters For Multibit Registers \u2022 Specifying Locations for Repeater Groups \u2022 Allowing Repeater Groups Over Macros \u2022 Specifying Cut Space and Cut Distance for Repeater Groups \u2022 Specifying Horizontal and Vertical Spacing for Repeater Groups \u2022 Specifying Library Cells as Repeaters \u2022 Avoiding Overlapping Repeaters With Existing Tap Cells \u2022 Avoiding Crosstalk During Group Repeater Insertion \u2022 Previewing Repeater Groups \u2022 Unplacing the Repeaters \u2022 Removing Repeater Groups"}
{"header": "How do I Grouping a list of repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define a group of repeaters for cutline support, use the  set_repeater_group or create_repeater_groups command.\n The following examples show the command usage.\n set_repeater_group -group_id  group_id  \\ -check_connection  \\ [-cells  cell_list ] \\ [-cutline  { {{x1 y} {x2 y}} | {{x y1} {x y2}} } ] \\ [-driver_group_id  group_id ] \\ [-path_drivers  pin_port_list ] \\ [-path_loads  pin_port_list ] \\ [-override] [-lib_cell_input  string ] [-lib_cell_output  string ] [-clear]"}
{"header": "How do I Setting Constraints for a Group of Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To automatically group a list of repeaters or repeaters of supernets, use the create_repeater_groups command.\n This command takes a list of repeaters, a list of supernets, or bundles of supernets and returns a list of repeater groups created by the  set_repeater_group command.\n The command supports both single load and multiple loads supernets.\n create_repeater_groups -supernets  supernet_list  | \\ -supernet_bundles  supernet_bundle_list  | \\ -cells  cell_list  \\ -lib_cells  lib_cell_list  \\ [-lib_cell_input  lib_pin ] \\ [-lib_cell_output  lib_pin ] \\ [-group_pin_spacing  spacing ] \\ [-ignore_pin_layers]"}
{"header": "How do I Adding Voltage Area Aware Group Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To define the constraints for a group of repeaters, use the set_repeater_group_constraints command.\n The  set_repeater_group_constraints command has a lower priority than the corresponding command options in the  add_group_repeaters and place_group_repeaters commands.\n set_repeater_group_constraints -type  type_list  \\ [-horizontal_repeater_spacing  spacing ] \\ [-vertical_repeater_spacing  spacing ] \\ [-layer_cutting_distance  layer_scale_list ]"}
{"header": "How do I Reporting the Constraints Assigned to a Group of a Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Voltage area aware group repeaters choose legal library cells for repeaters based on the corresponding voltage area and updates supply nets for repeaters to meet multivoltage constraints.\n You can use the  add_group_repeaters command with specific options to add voltage area aware group repeaters in three different ways, depending on the design methodology: \u2022 When the design is single-rail buffer only, use the  -va_aware option fc_shell>\u00a0 add_group_repeaters -lib_cell <lib_cell> -va_aware \u2022 When the design is single-rail buffer based on voltage area, use the -voltage_area_specific_lib_cell option       fc_shell>\u00a0 add_group_repeaters -lib_cell <default_lib_cell> \\ -voltage_area_specific_lb_cell {{VA1 libcell1}} {{VA2 libcell2}} \u2022 When the design is single- and dual-rail buffers, use the  -select_mv_buffer option fc_shell>\u00a0 add_group_repeaters -lib_cell <default_lib_cell> \\ -select_mv_buffer {{VA1 SingleRail1 DualRail1}} \\ {{VA1 SingleRail2 DualRail2}} Voltage area aware group repeaters help resolve multivoltage violations by choosing the library cell based on voltage area and repeater location."}
{"header": "How do I Removing Constraints for a Group of Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To report the constraints that were assigned to a group of repeaters using the  place_group_repeaters,  add_group_repeaters, or  set_repeater_group_constraints commands, use the report_repeater_group_constraints command.\n For example: fc_shell>\u00a0 report_repeater_group_constraints"}
{"header": "How do I Placing Group Repeaters Before Routing", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove the constraints that were assigned to a group of repeaters, use remove_repeater_group_constraints command.\n For example: fc_shell>\u00a0 remove_repeater_group_constraints -type  type_list"}
{"header": "How do I Performing On Route Placement of Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  preplace_group_repeaters command to place the group repeaters before the routing.\n This command places the group repeaters either in an ascending or descending order, default is ascending.\n The ascending order means that the command places the cells in a group from the lowest or left-most available track to the highest or right-most track.\n Note: A FAA-Base-Beta license is required to run the  preplace_group_repeaters command.\n You must specify either the cell collections or group IDs of the group repeaters.\n The following example places group repeaters when the cell collections are specified.\n fc_shell>\u00a0 preplace_group_repeaters     \\ -repeater_group_locations { { $cellGroup1, M2, {720 363.5}, \\ north, descending} {$cellGroup2, M2, {920 363.5}, east, ascending} \\       {$cellGroup3, M2, {1230 328.5}, east, ascending} \\ {$cellGroup4, M2, {1430 328.5}}, east} The following example places group repeaters when the group ID is specified.\n fc_shell>\u00a0 preplace_group_repeaters \\ -repeater_group_locations { { 1,M2, {720 363.5}, south, ascending} \\ {2, M2, {920 363.5},west, ascending} {3, M2, {1230 328.5}, \\ south, ascending} {4, M2, {1430 328.5}, west, descending}}"}
{"header": "How do I Placing Group Repeaters For Multibit Registers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command.\n place_group_repeaters \\ -cells  cell_list  | -repeater_groups  group_id_list  \\ [-lib_cell_input  pin_name ] \\ [-lib_cell_output  pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}
{"header": "How do I Specifying Locations for Repeater Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To place group repeaters for multibit registers, use the  create_repeater_groups command with the  -multi_bit option with the following command options: create_repeater_groups -cells\u00a0|\u00a0-supernet_bundles\u00a0|\u00a0-supernets -multi_bit -pin_mapping\u00a0{{lib_cell1\u00a0{inp1\u00a0outp1}\u00a0{inp2\u00a0outp2}\u2026} The  -multi_bit option determines the order of a multibit repeater based on the path driver and creates the repeater groups for the multibit repeaters.\n In a design, when a net has no route defined, this option places the group repeaters based on their location.\n To verify the support for multibit register placement, use the following command: fc_shell>\u00a0 preplace_group_repeater -repeater_group_locations  repeater_group_location_list The format for the  repeater_group_location_list argument is       {\u00a0{cell_collection,\u00a0layer,\u00a0location,\u00a0potential\u00a0routing\u00a0direction,\u00a0placing order}\u00a0...} or {\u00a0{group_id,\u00a0layer,\u00a0location,\u00a0potential\u00a0routing\u00a0direction,\u00a0placing order}\u00a0...}."}
{"header": "How do I Allowing Repeater Groups Over Macros", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use one of the following mutually exclusive options to control repeater group location: \u2022 -repeater_distance specifies the distance between repeater groups.\n This option supports the following additional options: \u25e6 -first_distance specifies the distance between the driver and the center of the first repeater group.\n \u25e6 -min_distance_repeater_to_load specifies the minimum distance between the last repeater group and the load.\n The default is one half of the value specified for the  -repeater_distance option.\n \u25e6 -tolerance specifies the maximum delta distance over the value specified for -repeater_distance.\n The default is 5 \u03bcm.\n \u2022 -relative_distance specifies the distance between the driver and the first repeater group, the distance between the first and second repeater groups, the distance between the second and third repeater group, and so on.\n \u2022 -location specifies the location of the center of each repeater group.\n \u2022 -number_of_repeater_groups specifies the total number of repeater groups to be inserted evenly along the route.\n \u2022 -cutlines specifies the location pairs that define the cutlines.\n Cutlines must be perpendicular to the routes and the repeater groups are centered around the cutlines."}
{"header": "How do I Specifying Cut Space and Cut Distance for Repeater Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  -allow_insertion_over_block option to allow repeater groups to be added on top of soft or hard macros.\n Note: If the repeater cell is an inverter, you are responsible for ensuring logical correctness."}
{"header": "How do I Specifying Horizontal and Vertical Spacing for Repeater Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use one of the following mutually exclusive options to control cutting for repeater groups: \u2022 -layer_cutting_spacing specifies the cut space of the routes to the driver pin.\n The cut starts from the driver side.\n \u2022 -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}
{"header": "How do I Specifying Library Cells as Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use one of the following mutually exclusive options to control spacing for repeater groups: \u2022 -horizontal_repeater_spacing specifies the horizontal spacing between repeaters by cell site width.\n \u2022 -vertical_repeater_spacing specifies the vertical spacing between repeaters by site row height."}
{"header": "How do I Avoiding Overlapping Repeaters With Existing Tap Cells", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  -lib_cell option to specify a library cell as a repeater.\n This option supports the following additional options: \u2022 -lib_cell_input specifies the input pin of the library cell to connect, if it has multiple inputs.\n \u2022 -lib_cell_output specifies the output pin of the library cell to connect, if it has multiple outputs."}
{"header": "How do I Avoiding Crosstalk During Group Repeater Insertion", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  -honor_special_cell option to avoid overlapping with existing tap cells when inserting repeaters."}
{"header": "How do I Previewing Repeater Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The crosstalk management is only supported in the  create_group_repeaters_guidance and  add_group_repeaters commands flow.\n       The flow to avoid crosstalk during group repeater insertion is as follows: 1.\n Use the following command to query interleaving groups: create_group_repeaters_guidance\u00a0-net -number_of_interleaving_groups\u00a0 number By default, the  number argument is set to 1.\n For example, if the value of the  number is 2, one net group is separated into two interleaving net groups.\n 2.\n Use the following command to manage crosstalk during group repeater insertion: add_group_releaters -nets\u00a0|\u00a0-bundles -first_distance_of_net_groups {\u00a0{group_id1\u00a0$first_dist1}\u00a0{group_id2 $first_dist2}\u00a0\u2026} -repeater_distance\u00a0$dist or add_group_releaters -nets\u00a0|\u00a0-bundles -cutlines_of_net_groups {\u00a0{group_id1\u00a0$cutline_list1}\u00a0{group_id2\u00a0$cutline_list2}\u00a0\u2026} \u25e6 If the option  -first_distance_of_net_groups is specified, the command groups the nets based on the existing group IDs on nets and inserts repeaters based on the specified first distance for the various net groups.\n The repeater distance is same for all net groups.\n \u25e6 If the option  -cutlines_of_net_groups is specified, the command groups the nets based on the existing group IDs of the nets and inserts repeaters based on the cutlines for the various net groups."}
{"header": "How do I Unplacing the Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  -preview option to preview repeater group locations before insertion.\n The repeaters are represented by annotation objects at the same locations where they are to be inserted, with the same width and height as a repeater lib cell, and with the group ID eco_preview_ id.\n Note: Before previewing the repeater groups again, you must first remove the annotation objects using either the  gui_remove_annotations or gui_remove_all_annotations command."}
{"header": "How do I Removing Repeater Groups", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To unplace the previous placement of repeaters, use the  unplace_group_repeaters command.\n unplace_group_repeaters \\ -cells  cell_list  | -repeater_groups  group_id_list  \\ [-lib_cell_input  pin_name ] \\ [-lib_cell_output  pin_name ]"}
{"header": "How do I Querying Group Repeater", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "To remove a group of repeaters, use the  remove_eco_repeater command.\n The nets are restored to their original names and routes shapes."}
{"header": "How do I Performing Auto Grouping Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The group repeater query commands provide improved ease of use for interconnect repeater while planning.\n The group repeater query \u2022 Provides capability to query group repeater path info \u2022 Supports cross-session query operation \u2022 Supports query operation before group repeater placement To query the group repeater during planning, you must be familiar with the following key information \u2022 Cells of a repeater group \u2022 Cutline of a repeater group \u2022 Group virtual connection If a group has either driver group or path drivers, then it is categorized as group virtual connection.\n Cell connection between groups depend on cell order in a group.\n The following topics describe the steps in this flow \u2022 Performing Auto Grouping Flow \u2022 Performing Manual Grouping Flow \u2022 Cell Input Mode"}
{"header": "How do I Performing Manual Grouping Flow", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Auto repeater group creation allows you to derive virtual connections for register paths.\n For repeater group input mode,  place_group_repeaters applies cutline based placement.\n You must specify cutline for each group.\n Repeaters are placed based on the intersection point between cutline and route.\n Build connectivity based on real connections for target cells.\n 1.\n To group a list of repeaters or repeaters of supernets, use the create_repeater_groups command.\n Also, specify the constraint option.\n The command automatically performs cell grouping and groups virtual connection with the following attributes: \u25e6 group_repeater_driver \u25e6 group_repeater_loads \u25e6 pin_pair \u25e6 group_id 2.\n Verify the path with the  get_attribute,  report_repeater_group, and get_repeater_path_info commands.\n The  get_attribute command reports the attributes of the  group_repeater_driver or  group_repeater_loads command.\n The command  report_repeater_groups reports group information for specified groups or all groups, and reports repeater paths for all groups if  -verbose is on.\n The get_repeater_paths_info command returns cells on repeater paths that include input cells.\n 3.\n Specify the cutline for a group manually with the  set_repeater_group\u00a0-group_id- cutline command.\n 4.\n Place interconnect repeaters on route with cutline for input repeater groups."}
{"header": "How do I Cell Input Mode", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Auto grouping is based on the  create_repeater_groups command.\n Use manual grouping in case the auto grouping command result does not meet the requirement.\n Check your target cell connection before placement.\n Perform the following steps for manual grouping: 1.\n Group your cells by -cells, cell order intends the cell connection.\n 2.\n Define group virtual connection by -driver_group_id or -path_drivers.\n 3.\n Specify the cutline by -cutline.\n       1.\n To define register path connections (virtual connection) for each set of repeater groups, use the  set_repeater_group command.\n \u25e6 To check cell connection before placement, use the  set_repeater_group -check_connection command.\n If the cell connection is not placed as expected, repeat a reset repeater group for desired cell connection.\n It also adds new options to record pin pair for the  -check_connection option.\n The  pin_pair option is used to find cell real connection based on specified lib cell pin name.\n 2.\n Verify the path with the  get_attribute,  report_repeater_group, and get_repeater_path_info commands.\n The  get_attribute command reports the attributes of the  group_repeater_driver or  group_repeater_loads commands.\n The report_repeater_groups command reports group information for specified groups or all groups, and reports repeater paths for all groups if  -verbose is on.\n The command get_repeater_paths_info returns cells on repeater paths that include input cells.\n 3.\n Check and report invalid paths based on real connection with the set_repeater_group\u00a0-check\u00a0connection command.\n 4.\n Place interconnect repeaters on route with cutline for input repeater groups."}
{"header": "How do I Swapping Variant Cell", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Cell input mode enables to set distance based on route placement.\n By default, repeaters are placed based on even distance on route for one repeater path.\n This mode allows you to set the  -first_distance or  -last_distance option to control the distance at driver side or load side.\n 1.\n Use the  place_group_repeaters\u00a0-cells\u00a0-blockage_aware command, to internally enable auto grouping.\n To internally enable auto grouping use the create_repeater_groups\u00a0-cells command and derive cutline based on distance.\n Then, define repeater group by using the  set_repeater_group\u00a0-group_id\u00a0-cutline command, After placing group repeaters, you can query repeater groups using the report_repeater_groups command and repeater paths info using the get_repeater_paths_info command.\n 2.\n To establish cell connection based on real connection and apply distance based placement, use the  place_group_repeaters\u00a0-cells command.\n No repeater group is created."}
{"header": "How do I Setting Constraints of Variant Cell", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  add_group_repeater and  place_group_repeater commands support variant cell in group repeater insertion and placement.\n       The following topics describe the steps in this flow \u2022 Setting Constraints of Variant Cell \u2022 Setting Application Option \u2022 Grouping Variant Cell \u2022 Running and Placing Group Repeaters \u2022 Troubleshooting"}
{"header": "How do I Setting Application Option", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set the constraints of variant cell: 1.\n Use the  set_repeater_group_constraints\u00a0-type\u00a0variant_cell_swapping command to set the variant for cell swapping.\n 2.\n Use the  report_repeater_group_constraints command to view the report of the repeater group constraint settings, after setting the variant for cell swapping.\n The report provides the \u25e6 Track pattern of the variant cell group \u25e6 Variant site ids \u25e6 Honor cell group not sharing timing \u25e6 First track alignment 3.\n Use the  remove_repeater_group_constraints command to remove the constraints and reset the settings based on the report."}
{"header": "How do I Grouping Variant Cell", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "To set application option before using the  add\u00a0group\u00a0repeaters and place_group_repeaters commands, use the  set_app_option\u00a0-name eco.placement.variant_cell_swapping\u00a0-value\u00a0true command.\n Based on the requirement, you can plan the variant cell flow.\n The rules of variant reference swapping differ in various variant cell flows.\n By default, the variant cell support in the eco_change_legal_reference command detects the variant mode and settings automatically.\n The  eco_change_legal_reference command checks whether the current reference of the cell is legal or illegal for the placed location.\n If it is illegal, the command attempts to find a legal reference from its variant cell group defined to swap with the illegal one.\n       To use the variant cell features directly for other cells, use the eco_change_legal_reference command.\n For complicated scenarios, you can switch the variant mode and tune the settings manually.\n Following are the new application options for variant cell support: \u2022 To set variant mode for different customers and different design flows, use the set_app_options\u00a0-name\u00a0eco.placement.variant_cell_group_mode\u00a0-value command.\n \u2022 To honor the variant cell groups, which are not sharing timing view, use the  set_app_options\u00a0-name eco.placement.honor_cell_group_not_sharing_timing\u00a0-value command."}
{"header": "How do I Running and Placing Group Repeaters", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "In the same variant cell group, the library cell variants differ from the master-variant only in mask color (or small geometry), while the timing data is same for these variants.\n The variant cell feature supports the following \u2022 track_pattern mode \u2022 siteId_based mode track_pattern mode To specify the first metal layer for track alignment checking in track_pattern mode, use the set_app_options\u00a0-name\u00a0eco.placement.first_track_alignment_layer\u00a0-value name command.\n Figure\u00a0221 shows the cell group with two variants.\n       Figure 221 Cell Group With Two Variants Based on the first track offset of library cells and the pitch value, you can define and derive the variant library cell types, which start from 0.\n Figure\u00a0222 shows variant type id definition.\n Figure 222 Variant Type id Definition       You can detect the variant type id for target cell current location.\n You can also check if the current reference is legal or illegal.\n If it is not legal, select the legal reference from cell group and swap it.\n Figure\u00a0223 shows the check and swap with legal reference for target cell.\n Figure 223 Check and Swap With Legal Reference for Target Cell.\n siteId_based mode The variant mapping and flipped mapping information are defined in the cell group.\n Following is an example of the  report_cell_groups command.\n Figure\u00a0224 shows the cell group definition for mapping id and flipped mapping id.\n       Figure 224 Cell Group Definition for Mapping id and Flipped Mapping id There are two sub flows for siteId_based mode: 2-Variants and N-Variant.\n Figure\u00a0225 shows the 2-Variants and N-Variants sub flows in siteId_based mode       Figure 225 2-Variants and N-Variants Sub Flows in siteId_based Mode Each variant reference has both legal mapping id and flipped mapping id.\n Figure\u00a0226 shows the variant mapping and flipped mapping id.\n       Figure 226 Variant Mapping and Flipped Mapping id For variant siteId, you can get the  cycle and  offset from site rows first, then use the cell placed location to do the calculation.\n Figure\u00a0227 shows the calculation for variant siteId       Figure 227 Calculation for Variant siteId"}
{"header": "How do I Troubleshooting", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Use the  add_group_repeaters and  place_group_repeaters commands to display the summary report for variant cell swapping in command cell collections."}
{"header": "How do I Fixing Multivoltage Violations", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Table\u00a073 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters.\n Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error:\u00a0The\u00a0repeater\u00a0group (%d)\u00a0is\u00a0invalid.\n    report_repeater_g roups        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning:\u00a0Failed\u00a0to connect\u00a0to\u00a0route\u00a0for\u00a0%d object:\u00a0{%s\u00a0}.\n       place_group_repeat ers ECO-224 Error:\u00a0The\u00a0option -repeater_groups cannot\u00a0be\u00a0used\u00a0when the\u00a0app\u00a0option eco.placement.eco_enable_ pipeline_register_placer is\u00a0false.\n       place_group_repeat ers ECO-227 Warning:\u00a0Failed\u00a0to\u00a0place %d\u00a0repeaters\u00a0for\u00a0%d drivers\u00a0in\u00a0collection (%s),\u00a0and\u00a0failed\u00a0cells are\u00a0in\u00a0collection\u00a0(%s).\n   query_objects get_ports get_pins  get_cells     place_group_repeat ers ECO-228 Warning:\u00a0Some\u00a0repeaters from\u00a0path\u00a0driver\u00a0(%s) have\u00a0same\u00a0repeater\u00a0group id.\n The\u00a0cells\u00a0belonging to\u00a0the\u00a0path\u00a0are\u00a0{%s}.\n          place_group_repeat ers ECO-229 Warning:\u00a0Failed\u00a0to\u00a0find intersection\u00a0of\u00a0cutline %s\u00a0and\u00a0route\u00a0for\u00a0cell {%s}.\n place_group_repeat ers ECO-231 Error:\u00a0The\u00a0repeater\u00a0group (%d)\u00a0has\u00a0no\u00a0cutline\u00a0or invalid\u00a0cutline.\n     set_repeater_gr oup        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error:\u00a0Cutline\u00a0{{%s} {%s}}\u00a0is\u00a0invalid.\n      place_group_repeat ers unplace_group_repeat ers ECO-233 Error:\u00a0The\u00a0cells\u00a0in collection\u00a0(%s)\u00a0are invalid\u00a0since\u00a0they\u00a0have no\u00a0target\u00a0input\u00a0pin\u00a0name (%s)\u00a0and\u00a0output\u00a0pin\u00a0name (%s).\n       -lib_cell_input  -lib_cell_output     -lib_cell_input   -lib_cell_output  place_group_repeat ers ECO-234 Warning:\u00a0There\u00a0is\u00a0no repeater\u00a0to\u00a0be\u00a0placed\u00a0for the\u00a0path\u00a0driver\u00a0(%s).\n place_group_repeat ers ECO-235 Warning:\u00a0There\u00a0is\u00a0no route\u00a0on\u00a0driver\u00a0net\u00a0(%s).\n place_group_repeat ers ECO-236 Warning:\u00a0There\u00a0is\u00a0no target\u00a0load\u00a0for\u00a0path driver\u00a0(%s).\n place_group_repeat ers ECO-237 Warning:\u00a0Some\u00a0cell\u00a0to\u00a0be placed\u00a0has\u00a0no\u00a0load\u00a0for path\u00a0driver\u00a0(%s).\n place_group_repeat ers ECO-239 Info:%s.\n                Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error:\u00a0The\u00a0option -cells\u00a0cannot\u00a0be\u00a0used when\u00a0the\u00a0app\u00a0option eco.placement.eco_enable_ virtual_connection\u00a0is true.\n    -repeater_groups    place_group_repeat ers ECO-241 Warning:\u00a0The\u00a0distance based\u00a0placement\u00a0does\u00a0not support\u00a0multi-fanout\u00a0path driver(%s).\n     place_group_repeat ers unplace_group_repeat ers ECO-242 Warning:\u00a0The\u00a0cell\u00a0(%s) has\u00a0no\u00a0driver\u00a0or\u00a0load (number\u00a0of\u00a0driver:\u00a0%d, number\u00a0of\u00a0load:\u00a0%d).\n place_group_repeat ers ECO-243 Error:\u00a0The\u00a0cells\u00a0in collection\u00a0(%s)\u00a0are invalid\u00a0since\u00a0they\u00a0have no\u00a0driver\u00a0or\u00a0load.\n       place_group_repeat ers ECO-244 Warning:\u00a0The\u00a0%s\u00a0%s\u00a0has\u00a0no shape.\n    place_group_repeat ers ECO-246 Warning:\u00a0Skip\u00a0the\u00a0path driver\u00a0(%s)\u00a0since\u00a0the driver\u00a0or\u00a0load\u00a0for\u00a0the path\u00a0has\u00a0no\u00a0shape.\n place_group_repeat ers ECO-251 Info:\u00a0Place\u00a0group repeaters\u00a0successfully.\n    place_group_repeat ers ECO-252 Warning:\u00a0Failed\u00a0to\u00a0place repeaters\u00a0for\u00a0repeater path\u00a0which\u00a0driver\u00a0is\u00a0%s.\n place_group_repeat ers ECO-253 Warning:\u00a0The\u00a0cutline information\u00a0%s\u00a0for\u00a0cell %s\u00a0is\u00a0not\u00a0on\u00a0valid\u00a0route.\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning:\u00a0Failed\u00a0to\u00a0cut route\u00a0for\u00a0cell\u00a0%s.\n    place_group_repeat ers ECO-255 Warning:\u00a0Gap\u00a0%s\u00a0between driver\u00a0and\u00a0nearest\u00a0route is\u00a0larger\u00a0than\u00a0placing distance\u00a0%s      place_group_repeat ers ECO-256 Warning:\u00a0The\u00a0first distance\u00a0(%s)\u00a0specified by\u00a0command\u00a0option\u00a0is shorter\u00a0than\u00a0the\u00a0gap\u00a0(%s) between\u00a0pin\u00a0and\u00a0route\u00a0for driver\u00a0(%s).\n (warning) The\u00a0last\u00a0distance\u00a0(%s) specified\u00a0by\u00a0command option\u00a0is\u00a0shorter\u00a0than the\u00a0gap\u00a0(%s)\u00a0between\u00a0pin and\u00a0route\u00a0for\u00a0load\u00a0(%s).\n  -first_distance -last_distance      place_group_repeat ers ECO-257 Warning:\u00a0Cannot\u00a0find cutline\u00a0information\u00a0for cell\u00a0%s.\n place_group_repeat ers ECO-258 Info:\u00a0The\u00a0app\u00a0option about\u00a0virtual\u00a0connection is\u00a0turned\u00a0on.\n Please make\u00a0sure\u00a0the\u00a0cells\u00a0in repeater\u00a0group\u00a0keep\u00a0in order.\n  eco.placement.eco _enable_virtual_c onnection   place_group_repea ters -repeater_groups  place_group_repeat ers unplace_group_repeat ers ECO-259 Warning:\u00a0The\u00a0number\u00a0of cells\u00a0from\u00a0repeater\u00a0group (%d)\u00a0is\u00a0not\u00a0consistent with\u00a0the\u00a0number\u00a0of drivers\u00a0from\u00a0driver\u00a0group (%s).\n place_group_repeat ers unplace_group_repeat ers ECO-260 Warning:\u00a0The\u00a0number\u00a0of cells\u00a0from\u00a0repeater\u00a0group (%d)\u00a0is\u00a0not\u00a0consistent with\u00a0the\u00a0number\u00a0of\u00a0loads from\u00a0load\u00a0group\u00a0(%s).\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning:\u00a0The\u00a0number\u00a0of path\u00a0loads\u00a0is\u00a0less\u00a0than the\u00a0number\u00a0of\u00a0cells\u00a0in group\u00a0(%d),\u00a0so\u00a0skip\u00a0these path\u00a0loads.\n place_group_repeat ers unplace_group_repeat ers ECO-262 Warning:\u00a0The\u00a0number\u00a0of path\u00a0loads\u00a0is\u00a0not\u00a0an integral\u00a0multiple\u00a0of\u00a0the number\u00a0of\u00a0cells\u00a0in\u00a0group (%d),\u00a0so\u00a0use\u00a0path\u00a0loads in\u00a0order.\n place_group_repeat ers ECO-265 Warning:\u00a0The\u00a0pin\u00a0shape {%s}\u00a0of\u00a0%s\u00a0(%s)\u00a0is projected\u00a0to\u00a0route\u00a0%s {%s}.\n       unplace_group_repeat ers ECO-266 Warning:\u00a0The\u00a0cells\u00a0in collection\u00a0%s\u00a0which are\u00a0not\u00a0placed\u00a0before cannot\u00a0be\u00a0unplaced\u00a0by unplace_group_repeaters.\n       add_group_repeat ers   placed_group_repe aters  unplace_group_rep eaters  unplace_group_repeat ers ECO-267 Error:\u00a0Input\u00a0and\u00a0output routes\u00a0are\u00a0not\u00a0merged after\u00a0unplacing\u00a0repeater %s\u00a0since\u00a0the\u00a0routes\u00a0are not\u00a0aligned\u00a0or\u00a0not\u00a0at\u00a0the same\u00a0layer."}
{"header": "How do I Fixing Multivoltage Violations", "size": 15.0, "font": "Arial-BoldMT", "flags": 20, "text": "Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-268 Error:\u00a0The\u00a0cells\u00a0in collection\u00a0(%s)\u00a0are invalid\u00a0since\u00a0they are\u00a0placed\u00a0before.\n Apply\u00a0the\u00a0command unplace_group_repeaters to\u00a0unplace\u00a0them.\n    add_group_repeat ers   place_group_repea ters  add_group_repeaters place_group_repeat ers ECO-269 Error:\u00a0Unable\u00a0to\u00a0check the\u00a0current\u00a0reference\u00a0of cell\u00a0'%s':\u00a0%s.\n           add_group_repeaters place_group_repeat ers ECO-270 Error:\u00a0Unable\u00a0to\u00a0find swappable\u00a0variant reference\u00a0for\u00a0cell\u00a0'%s': %s.\n     add_group_repeaters place_group_repeat ers ECO-271 Error:\u00a0Candidate reference\u00a0'%s'\u00a0and reference\u00a0(%s)\u00a0of\u00a0cell (%s)\u00a0are\u00a0not\u00a0in\u00a0the\u00a0same variant\u00a0cell\u00a0group.\n          unplace_group_repeat ers ECO-272 Error:\u00a0The\u00a0mixed input\u00a0cells\u00a0are\u00a0not supported,\u00a0which\u00a0includes the\u00a0cells\u00a0added\u00a0by add_group_repeaters and\u00a0the\u00a0cells\u00a0placed\u00a0by place_group_repeaters.\n unplace_group_repeat ers ECO-273 Error:\u00a0There\u00a0are\u00a0no placed\u00a0cells\u00a0to\u00a0be unplaced.\n Please\u00a0double check\u00a0the\u00a0cell\u00a0status.\n          Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips ECO-274 Warning:\u00a0You\u00a0are deleting\u00a0cell\u00a0%s\u00a0with eco_repeater_group_id\u00a0%d.\n     place_group_repeat ers ECO-275 Error:\u00a0Failed\u00a0to\u00a0traverse cutlines.\n The\u00a0nets\u00a0may have\u00a0too\u00a0many\u00a0blockages.\n      -repeater_group  add_group_repeaters ECO-276 Warning:\u00a0Unable\u00a0to\u00a0find free\u00a0area\u00a0for\u00a0repeater\u00a0on net\u00a0(%s)\u00a0at\u00a0location\u00a0(%s) within\u00a0range\u00a0{%s}.\n      set_repeater_group ECO-277 Warning:\u00a0You\u00a0are\u00a0trying to\u00a0override\u00a0cells\u00a0of repeater\u00a0group\u00a0%d.\n Use -override\u00a0if\u00a0you\u00a0have\u00a0to override\u00a0cells.\n    -override  create_repeater_gro ups ECO-278 Error:\u00a0Get\u00a00\u00a0transparent cells\u00a0from\u00a0all\u00a0supernets.\n     create_repeater_gro ups ECO-279 Error:\u00a0%s\u00a0has multiple(%lu)\u00a0inputs."}
{"header": "How do I Fixing Buffers", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "Design changes in the ECO flow sometimes result in isolation or voltage violations.\n The fix_mv_design command can identify and fix violations for buffer trees and diodes.\n You must use either the  -buffer or  -diode option with the  fix_mv_design command.\n For more information, see the following topics: \u2022 Fixing Buffers \u2022 Fixing Diodes       If the UPF has not already been committed, the  fix_mv_design command automatically commits the UPF before performing any operations.\n Netlist changes that the tool makes as a result of the  fix_mv_design command are not guaranteed to be placement or timing legal.\n You must check the design after running the fix_mv_design command."}
{"header": "How do I Fixing Diodes", "size": 14.0, "font": "Arial-BoldMT", "flags": 20, "text": "The  -buffer option of the  fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design.\n The command can perform the following changes: \u2022 Minimize the number of dual-rail buffers or inverters \u2022 Fix isolation violations in buffer trees \u2022 Fix buffers and inverters that have illegal settings, as follows: \u25e6 Process, voltage, and temperature settings \u25e6 Library cell purpose or subset settings \u25e6 Target library subset settings \u25e6 Bias voltages \u2022 Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: \u2022 Swap buffer library cells to fix illegal settings \u2022 Swap single-rail buffers for dual-rail buffers \u2022 Swap dual-rail buffers for single-rail buffers \u2022 Change the backup supplies of dual-rail buffers and inverters \u2022 Change the input or output supplies of level shifters \u2022 Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough \u2022 Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The  fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters.\n In addition,       the command only uses supplies that are available in the voltage area or voltage area region.\n The  fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations.\n Netlist changes caused by the command do not introduce new isolation or voltage violations.\n To specify a buffer tree, use the  -from option with the name of a net or driver pin.\n If you specify a net name, its driver pin is used.\n In both cases, the driver pin defines a full or partial buffer tree.\n Wildcards are supported.\n The  -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the  fix_mv_design command can use as replacement cells.\n By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations.\n However, if you also specify the  -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area.\n If the tool inserts a new library cell as a result of the  fix_mv_design command, the new cell is chosen according to the following rules, in priority order: \u2022 A cell from the same library as the original library cell \u2022 A cell from a library with a name similar to the original library \u2022 A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells.\n Specify the  -level_shifter option to allow the  fix_mv_design command to modify the input or output supplies of level-shifter cells.\n However, the command does not change level-shifter library cells.\n To report the changes that the tool recommends without making any netlist changes, use the  -report_only option."}
{"header": "How do I Fixing Diodes", "text": "The  -diode option of the  fix_mv_design command fixes mismatches between power domains and voltage areas for diodes throughout the design.\n The  fix_mv_design -diode command examines all diodes, including diodes inserted by the  create_cell, create_diodes, and  add_port_protection_diodes commands, as well as several routing commands that insert diodes to fix antenna violations.\n If a power domain and voltage area mismatch for a diode is found, the tool uses the voltage area to explicitly assign a corresponding power domain.\n If multiple power domains exist in a single voltage area, the tool picks one of the available power domains.\n Any of the available power domains is acceptable because all diode cells are single-rail cells and all power domains in the same voltage area have the same primary supply.\n       To obtain a report of the changes that the tool recommends without making any netlist changes, use the  -report_only option.\n To obtain detailed information in the report, use the  -verbose option.\n These are the only two options that you can use with the  -diode option."}
