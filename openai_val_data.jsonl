{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Command"}, {"role": "assistant", "content": "After placing the ECO cells, the place_eco_cells command legalizes each ECO cell to the closest unoccupied site.\n The existing cells are untouched to minimize the impact to their placement.\n You can control the legalization of the ECO cells by using one of the following methods: To not legalize the cells after ECO placement, use the -no_legalize option.\n To perform legalization only, use the -legalize_only option.\n To specify the mode in which to legalize, use the -legalize_mode option with one of the following settings: free_site_only When you specify this setting, the default, the tool legalizes the ECO cells on free sites without moving preexisting cells.\n An ECO cells can have a large displacement, if a free site is unavailable nearby.\n allow_move_other_cells When you specify this setting, the tool legalizes the ECO cells to the nearest legal location by moving preexisting cells.\n minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells the can be legalized to a free site nearby without moving preexisting cells.\n For the ECO cells that do not have a free site nearby, the tool legalizes them by moving preexisting cells.\n To specify a displacement threshold for legalization, use the -displacement_threshold option.\n When you use the -displacement_threshold option, you can also use the -max_displacement_threshold option to specify a second displacement threshold that is larger than the value specified with the -displacement_threshold option.\n How the tool uses these displacement thresholds depends on the setting you use for the -legalize_mode option as follows: free_site_only When you specify this setting, the tool legalizes the ECO cells that have available free sites within the specified displacement threshold.\n 975 Placing ECO Cells Feedback If the displacement of an ECO cell exceeds this threshold, the tool does not legalize the cell.\n It creates a collection named epl_legalizer_rejected_cells that consists of such ECO cells that are not legalized.\n You can subsequently legalize the ECO cells in the epl_legalizer_rejected_cells collection by using the following command: fc_shell> place_eco_cells -legalize_mode allow_move_other_cells \\ -legalize_only -cells $epl_legalizer_rejected_cells This command moves existing cells to find legal locations for the ECO cells in the collection named epl_legalizer_rejected_cells.\n If you also specify the -max_displacement_threshold option with -displacement_threshold option, the tool also creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n The collection epl_max_displacement_cells is a subset of the collection epl_legalizer_rejected_cells and its cells are also not legalized.\n You can use the -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n allow_move_other_cells When you specify this setting, you cannot specify the -displacement_threshold and -max_displacement_threshold options.\n minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells that have available free sites within the specified displacement threshold.\n If the displacement of an ECO cell exceeds this threshold, the tool legalizes them by moving preexisting cells.\n If you also specify the -max_displacement_threshold option, the tool does not legalize the cells that exceed this maximum displacement threshold specified with this option and the tool creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n You can use the -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n To specify the types of filler cells that can be removed during legalization, use the -remove_filler_references option.\n 976 Placing and Mapping ECO Cells to Spare Cells Feedback When you use this option, the filler cells are removed if they do not have a fixed placement and they overlap with ECO cells.\n By default, the tool does not remove any filler cells when legalizing ECO cells.\n To enable Advanced Legalizer and remove the filler cells that have violations, set the place.legalize.enable_advanced_legalizer application option to true When you specify this setting, the filler cells that have violations are removed after legalizing ECO cells.\n Using the -remove_filler_references option with this application option set to true results in the legalizer engine removing only those fillers that are specified by this option.\n The -min_filler_distance option is ignored when you use the place.legalize.enable_advanced_legalizer application option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Updating Via Ladders"}, {"role": "assistant", "content": "You can use the following methods to update existing via ladders in a design: Use the refresh_via_ladders command Automatic updates during the route_group route_auto, and route_eco commands is enabled by default by setting the route.auto_via_ladder.update_during_route application option to true Both of these methods perform the following tasks: Verifies the existing via ladders based on the current via ladder constraints Removes invalid via ladders Inserts via ladders where needed based on the settings of the route.auto_via_ladder application options By default, the tool Updates all pins with via ladder constraints, whether on signal nets or clock nets By default, during the route_group command, the via ladder updates is restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted about the pin layer be fully contained within the pin shape boundary, which includes 461 Inserting Via Ladders Feedback the pin shape and its extensions.\n To specify this requirement, set the following application options: route.auto_via_ladder.connect_within_metal This application option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join.\n To prevent changes to the pin shape boundary, set this application option to true route.auto_via_ladder.connect_within_metal_for_via_ladder This application option controls the via enclosures only for performance and electromigration via ladders.\n By default, the tool uses the global setting specified by the route.auto_via_ladder.connect_within_metal application option.\n To explicitly specify the behavior for performance and electromigration via ladders, set this application option to true or false Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion.\n In many cases, the via ladder rule specifies the maximum number of stagger tracks.\n To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, the route.auto_via_ladder.auto_stagger application option is set to true by default.\n Reports the via ladder insertion status for each target pin To limit the number of via ladders reported for each category to 40, set the route.auto_via_ladder.report_all_via_ladders application option to false See Also Inserting Via Ladders Verifying Via Ladders Querying Via Ladders Removing Via Ladders 462 Inserting Via Ladders Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Skew Groups"}, {"role": "assistant", "content": "During clock tree synthesis, you might want to balance a group of sinks only among each other, and not the rest of the sinks.\n To do so, define a skew group by using the create_clock_skew_group command.\n When you use this command, specify the sinks you want to group, by using the -objects option.\n Optionally, you can specify the following: A clock or generated clock for which to create the skew group by using the -clock option.\n A mode for which to create the skew group by using the -mode option.\n 364 Specifying the Clock Tree Synthesis Settings Feedback By default, the tool creates the skew group for the current mode.\n A name for the skew group by using the -name option.\n The following example creates a skew group named sg1 consisting of sinks reg1/CP, reg2/ CP, and reg3/CP: fc_shell> create_clock_skew_group -name sg1 \\ -objects {reg1/CP reg2/CP reg3/CP} To report skew groups, use the report_clock_skew_groups command.\n To remove skew groups, use the remove_clock_skew_groups command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Synthesizing a Subblock"}, {"role": "assistant", "content": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1.\n Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2.\n Apply any block-specific constraints and settings required for synthesizing the block.\n 822 Performing Hierarchical Synthesis Using Abstracts Feedback 3.\n Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command.\n 4.\n Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5.\n Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running RedHawk Fusion Commands in the Background"}, {"role": "assistant", "content": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished.\n You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished.\n To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command.\n When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database.\n By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed.\n However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results.\n 874 Setting Up the Executables Feedback Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not.\n When opening rail results, the tool does not detect if the result is generated with or without the -bg option.\n The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa.\n Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory.\n To check if the background analyze_rail process is active, use the report_background_jobs command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Signoff ECO Flow"}, {"role": "assistant", "content": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool.\n You can also perform power or area recovery in the PrimeTime tool.\n 950 Signoff ECO Flow Feedback If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in Figure 217 Figure 217 Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations?\n PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1.\n Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands.\n 2.\n Update the placement by using the place_eco_cells command as shown in the following example: place_eco_cells -legalize_mode minimum_physical_impact \\ -eco_changed_cells -legalize_only -displacement_threshold 10 For more information about the place_eco_cells command, see Placing ECO Cells 3.\n Add filler cells to the empty spaces in the site array, as described in Inserting Filler Cells 951 Incremental Signoff ECO Flow Feedback To reduce runtime, use the -post_eco option when you Insert metal filler cells with the create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4.\n Update the routing by using the route_eco command, as described in Performing ECO Routing, or by manually rerouting the affected nets."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing ECO Routing"}, {"role": "assistant", "content": "Whenever you modify the nets in your block, you need to run engineering change order (ECO) routing to reconnect the routing.\n To run ECO routing, use the route_eco command.\n The route_eco command sequentially performs global routing, track assignment, and detail routing to reconnect the routing.\n By default, the route_eco command Considers timing and crosstalk during routing, which means that the tool performs extraction and updates the timing before performing the routing.\n The extraction and timing update can be time consuming and might not be necessary for your block.\n To prevent the extraction and timing update, use the following commands to disable the timing-driven and crosstalk-driven modes: fc_shell> set_app_options \\ -name route.global.crosstalk_driven -value false fc_shell> set_app_options \\ -name route.global.timing_driven -value false fc_shell> set_app_options \\ -name route.track.crosstalk_driven -value false fc_shell> set_app_options \\ -name route.track.timing_driven -value false fc_shell> set_app_options \\ -name route.detail.timing_driven -value false 558 Performing ECO Routing Feedback Works on all open nets in the block To perform ECO routing only on specific nets, use the -nets option to specify the nets.\n Ignores existing global routes To honor the existing global routes and perform incremental global routing, set the -reuse_existing_global_route option to true Relieves congestion by reusing dangling wires instead of rerouting detail routed wires To disable the reuse of dangling wires, set the -utilize_dangling_wires option to false Performs a maximum of 40 detail routing iterations To change the maximum number of detail routing iterations, use the -max_detail_route_iterations option.\n Fixes hard DRC violations on the entire block by rerouting any wires, whether modified or not To fix DRC violations only in the neighborhood of the open nets, set the -open_net_driven option to true Note: When you use the -nets option to perform ECO routing on specific nets, Zroute fixes DRC violations only within the bounding box of the specified nets.\n In this case, Zroute ignores the setting of the -open_net_driven option.\n To change the scope of rerouting performed by the ECO router, use the -reroute option.\n To limit rerouting to modified wires, set this option to modified_nets_only To first attempt to fix DRC violations by rerouting modified nets and then reroute other nets if necessary, set this option to modified_nets_first_then_others A common use for this option is to route the clock nets affected by an ECO in a fully routed block.\n To enable the fixing of soft DRC violations, such as bridge rule violations, after the final detail routing iteration, set the route.common.post_eco_route_fix_soft_violations application option to true Zroute generates a DRC violations summary at the end of each detail routing iteration.\n Before reporting the final DRC violations, Zroute merges redundant violations.\n For more 559 Routing Nets in the GUI Feedback information about the DRC violations reported by Zroute, see Performing Design Rule Checking Using Zroute Zroute also reports the nets changed during ECO routing.\n By default, it reports the first 100 changed nets.\n You can use the -max_reported_nets option to set a different limit on the reported nets.\n To report all changed nets, set the -max_reported_nets option to -1.\n See Also Routing Nets in the GUI"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Naming Convention for Tool-Inserted Clock Gates"}, {"role": "assistant", "content": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs.\n The naming convention is as follows: prefix_base-name[_index] The prefix is clock_gate by default.\n To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option.\n The base name is the most frequent instance name among the registers gated by the clock gate.\n The base name does not include bus bit indexes.\n If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0.\n For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg.\n If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0.\n However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register.\n 288 Introduction to Clock Gating Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Troubleshooting"}, {"role": "assistant", "content": "Table 73 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters.\n Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error: The repeater group (%d) is invalid.\n Check if the input group id exists by running the report_repeater_g roups command.\n 999 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning: Failed to connect to route for %d object: {%s }.\n Check the pin shape of object and route shapes.\n The object as driver or load can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-224 Error: The option -repeater_groups cannot be used when the app option eco.placement.eco_enable_ pipeline_register_placer is false.\n Check the pin shape of object and route shapes.\n The object as driver or load can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-227 Warning: Failed to place %d repeaters for %d drivers in collection (%s), and failed cells are in collection (%s).\n Check the failed drivers by running the query_objects get_ports get_pins and get_cells commands.\n The driver can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-228 Warning: Some repeaters from path driver (%s) have same repeater group id.\n The cells belonging to the path are {%s}.\n Check if the group id of cells are on the same path.\n The command skips to place some repeaters.\n The group id of cells on one path should be different.\n place_group_repeat ers ECO-229 Warning: Failed to find intersection of cutline %s and route for cell {%s}.\n place_group_repeat ers ECO-231 Error: The repeater group (%d) has no cutline or invalid cutline.\n Check the right cutline for this group.\n Set right cutline for this group using the set_repeater_gr oup command.\n 1000 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error: Cutline {{%s} {%s}} is invalid.\n Check the format of the cutline.\n The valid format of cutline is {{x1 y} {x2 y}} or {{x y1} {x y2}}.\n place_group_repeat ers unplace_group_repeat ers ECO-233 Error: The cells in collection (%s) are invalid since they have no target input pin name (%s) and output pin name (%s).\n Check the input and output pin name.\n The input pin name and output pin name can be specified by using the -lib_cell_input and -lib_cell_output options if needed, or filter out invalid cells from input.\n The default value for -lib_cell_input is D.\n The default value for -lib_cell_output is Q.\n place_group_repeat ers ECO-234 Warning: There is no repeater to be placed for the path driver (%s).\n place_group_repeat ers ECO-235 Warning: There is no route on driver net (%s).\n place_group_repeat ers ECO-236 Warning: There is no target load for path driver (%s).\n place_group_repeat ers ECO-237 Warning: Some cell to be placed has no load for path driver (%s).\n place_group_repeat ers ECO-239 Info:%s.\n Check the place and connection mode.\n Show the place mode (cutline/distance) and connection mode (virtual connection/real connection) on this command.\n 1001 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error: The option -cells cannot be used when the app option eco.placement.eco_enable_ virtual_connection is true.\n Check the command for virtual connection.\n Specify the -repeater_groups command if you need to use virtual connection.\n place_group_repeat ers ECO-241 Warning: The distance based placement does not support multi-fanout path driver(%s).\n Check the cutline based placement for the multi-fanout path driver.\n place_group_repeat ers unplace_group_repeat ers ECO-242 Warning: The cell (%s) has no driver or load (number of driver: %d, number of load: %d).\n place_group_repeat ers ECO-243 Error: The cells in collection (%s) are invalid since they have no driver or load.\n Check for invalid cells.\n Ensure the cell that is placed has both driver and load.\n Else, remove such cells from input.\n place_group_repeat ers ECO-244 Warning: The %s %s has no shape.\n Check if the top port or macro pin has shape.\n place_group_repeat ers ECO-246 Warning: Skip the path driver (%s) since the driver or load for the path has no shape.\n place_group_repeat ers ECO-251 Info: Place group repeaters successfully.\n Check if all the input cells are placed successfully.\n place_group_repeat ers ECO-252 Warning: Failed to place repeaters for repeater path which driver is %s.\n place_group_repeat ers ECO-253 Warning: The cutline information %s for cell %s is not on valid route.\n 1002 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning: Failed to cut route for cell %s.\n Check if the command failed to cut route for cell.\n place_group_repeat ers ECO-255 Warning: Gap %s between driver and nearest route is larger than placing distance %s Check if the route to the nearest pin distance is larger than placing distance for driver or load.\n place_group_repeat ers ECO-256 Warning: The first distance (%s) specified by command option is shorter than the gap (%s) between pin and route for driver (%s).\n (warning) The last distance (%s) specified by command option is shorter than the gap (%s) between pin and route for load (%s).\n Check if the -first_distance or -last_distance option specified is shorter than the gap between pin and route for driver or load.\n place_group_repeat ers ECO-257 Warning: Cannot find cutline information for cell %s.\n place_group_repeat ers ECO-258 Info: The app option about virtual connection is turned on.\n Please make sure the cells in repeater group keep in order.\n Check if the eco.placement.eco _enable_virtual_c onnection option is set to true and the place_group_repea ters -repeater_groups option is specified.\n place_group_repeat ers unplace_group_repeat ers ECO-259 Warning: The number of cells from repeater group (%d) is not consistent with the number of drivers from driver group (%s).\n place_group_repeat ers unplace_group_repeat ers ECO-260 Warning: The number of cells from repeater group (%d) is not consistent with the number of loads from load group (%s).\n 1003 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning: The number of path loads is less than the number of cells in group (%d), so skip these path loads.\n place_group_repeat ers unplace_group_repeat ers ECO-262 Warning: The number of path loads is not an integral multiple of the number of cells in group (%d), so use path loads in order.\n place_group_repeat ers ECO-265 Warning: The pin shape {%s} of %s (%s) is projected to route %s {%s}.\n Check if the route is far away from driver or loads.\n The tool projects the closest pin shape to the route.\n unplace_group_repeat ers ECO-266 Warning: The cells in collection %s which are not placed before cannot be unplaced by unplace_group_repeaters.\n Check if the cells are not placed.\n The cells that are not placed cannot be unplaced.\n Also, only the cells added by the add_group_repeat ers command and placed by the placed_group_repe aters command can be unplaced by the unplace_group_rep eaters command.\n unplace_group_repeat ers ECO-267 Error: Input and output routes are not merged after unplacing repeater %s since the routes are not aligned or not at the same layer.\n Check if the routes are merged after unplacing repeaters.\n This error occurs when the routes are not aligned or not at the same layer since they are not"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Hierarchical Synthesis Flow When Floorplans are Available"}, {"role": "assistant", "content": "To partition and plan the top-level design and create the lower-level blocks for subsequent bottom-up synthesis, when the floorplans of subblock and top-level design are available, perform the following steps: Figure 188 Hierarchical Synthesis Flow When Floorplans are Available 1.\n Read in the full chip design and apply constraints as shown in the following example: fc_shell> set REF_LIBS \"stdcell.ndm macro.ndm\" fc_shell> create_lib TOP -technology techfile \\ -ref_libs $REF_LIBS fc_shell> analyze -format verilog $rtl_files fc_shell> elaborate TOP fc_shell> set_top_module TOP fc_shell> load_upf fullchip.upf fc_shell> read_sdc fullchip.sdc 2.\n For the design partitions, split the constraints as shown in the following example: fc_shell> set_budget_options -add_blocks {BLOCK1 BLOCK2} fc_shell> split_constraints 3.\n Create the subblock design libraries with design information and enable block-specific reference library setup as shown in the following example: fc_shell> copy_lib -to_lib BLOCK1.nlib -no_design fc_shell> copy_lib -to_lib BLOCK2.nlib -no_design fc_shell> set_attribute -objects BLOCK1.nlib \\ 821 Performing Hierarchical Synthesis Using Abstracts Feedback -name use_hier_ref_libs -value true fc_shell> set_attribute -objects BLOCK2.nlib \\ -name use_hier_ref_libs -value true fc_shell> save_lib -all 4.\n Create the subblock design partitions as shown in the following example: fc_shell> commit_block -library BLOCK1.nlib BLOCK1 fc_shell> commit_block -library BLOCK2.nlib BLOCK2 fc_shell> save_lib -all 5.\n Load the UPF and SDC constraints for the unmapped subblocks as well as the top- level, which are generated by the split_constraints command earlier as shown in the following example: fc_shell> set_constraint_mapping_file./split/mapfile fc_shell> load_block_constraints -all_blocks -type SDC \\ -type UPF -type CLKNET fc_shell> save_lib -all 6.\n Load the floorplan for the subblocks and top-level design.\n 7.\n Run the compile_fusion command until logic optimization for the subblocks and top- level design is complete as shown in the following example: fc_shell> compile_fusion -to logic_opto 8.\n Perform standard cell placement followed by the pin assignment, timing estimation and budgeting.\n 9.\n After completing the design planning operations, rebuild the subblock and top-level design by opening the elaborated RTL NDM, loading floorplan, feedthroughs and budgets.\n Note: For details about each of the design planning operation, see the Design Planning User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Saving Route Information"}, {"role": "assistant", "content": "To save the route information, use the write_routes command.\n This command generates a Tcl script that reproduces the metal shapes and vias for a block, including their attribute settings.\n Note that the write_routes command reproduces routes, but not routing blockages.\n To generate a Tcl script that reproduces routing blockages, use the write_floorplan command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing Buffers"}, {"role": "assistant", "content": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design.\n The command can perform the following changes: Minimize the number of dual-rail buffers or inverters Fix isolation violations in buffer trees Fix buffers and inverters that have illegal settings, as follows: Process, voltage, and temperature settings Library cell purpose or subset settings Target library subset settings Bias voltages Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: Swap buffer library cells to fix illegal settings Swap single-rail buffers for dual-rail buffers Swap dual-rail buffers for single-rail buffers Change the backup supplies of dual-rail buffers and inverters Change the input or output supplies of level shifters Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters.\n In addition, 1007 Fixing Multivoltage Violations Feedback the command only uses supplies that are available in the voltage area or voltage area region.\n The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations.\n Netlist changes caused by the command do not introduce new isolation or voltage violations.\n To specify a buffer tree, use the -from option with the name of a net or driver pin.\n If you specify a net name, its driver pin is used.\n In both cases, the driver pin defines a full or partial buffer tree.\n Wildcards are supported.\n The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells.\n By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations.\n However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area.\n If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order: A cell from the same library as the original library cell A cell from a library with a name similar to the original library A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells.\n Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells.\n However, the command does not change level-shifter library cells.\n To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up Multivoltage Designs"}, {"role": "assistant", "content": "The following topics describe the tasks you need to perform when setting up multivoltage designs: Applying the Multivoltage Power Intent Preparing the Power Network 113 Setting Up Multivoltage Designs Feedback Defining Voltage Areas Inserting Multivoltage Cells Controlling the Placement of Multivoltage Cells Enabling Improved Buffering for Multivoltage Nets Analyzing Multivoltage Information"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Advanced PG Net Checks"}, {"role": "assistant", "content": "For advanced technology nodes, such as 12 nanometer, 7 nanometer, or smaller technology nodes, you can enable advanced physical DRC checks between cells and prerouted PG nets by setting the place.legalize.enable_advanced_prerouted_net_check application option to true When you enable this feature, you can further control the accessibility checks performed for standard cell pins by using the place.legalize.advanced_layer_access_check and place.legalize.advanced_libpin_access_check application options.\n However, the default behavior of this feature is suitable for most designs.\n 163 Specifying Legalization Settings Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Self-Gating Options"}, {"role": "assistant", "content": "To specify self-gating settings, use the set_self_gating_options command with the following options: -min_bitwidth bitwidth Controls the minimum size for self-gating banks.\n The default is 4.\n -max_bitwidth bitwidth Controls the maximum size for self-gating banks.\n The default is 8.\n -interaction_with_clock_gating interaction_type Registers gated by user-instantiated clock-gating cells are candidates for self-gating.\n Valid arguments are none (skip registers gated by tool-inserted clock gates), insert (the default; insert self-gates on gated registers), and collapse (collapse tool-inserted clock gates if they are in the same hierarchy).\n -objects object_list Specifies that the options should be applied to the listed objects.\n Supported objects are hierarchical instances, power domains, and designs.\n By default, the settings apply to the entire design.\n -tree_type combinational_logic_type Uses the specified logic type to build the gated enable tree.\n Valid arguments are xor nand or, and auto (the default).\n 332 Self-Gating Optimization Feedback To report self-gating options, use the report_self_gating_options command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating a Report of Early Data Check Records"}, {"role": "assistant", "content": "You can generate a report of check records from a design by using the get_early_data_check_records command.\n Using the -hierarchical option with this command enables to you get check records for all subblocks.\n The report generated is in the following format: check_name object For example, fc_shell> get_early_data_check_records -hierarchical {hier.block.missing_leaf_cell_location@eco_cell} You can use the -filter option to filter the results of this command by various parameters such as object class and check name.\n 853 Performing Top-Level Closure With Abstract Views Feedback For example, fc_shell> get_early_data_check_records \\ -filter \"checked_object_class==port\" {place.port_type_mismatch@clk route.missing_layer_direction@feed_in route.layer_name_mismatch@out}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Configuring Distributed Processing"}, {"role": "assistant", "content": "Distributed processing performs tasks in parallel by using multiple machines; each process uses its own process memory image.\n When using distributed processing, each parallel task is called a process.\n For the best performance during distributed processing, you should limit the number of processes to the number of available cores, which is the sum of the number CPUs times the number of cores per CPU for each host machine.\n The following commands support distributed processing configured by the set_host_options command: analyze_rail create_placement -floorplan signoff_check_drc signoff_fix_drc signoff_create_metal_fill signoff_fix_isolated_via When you configure distributed processing, you can specify one or more of the following settings: The job submission command (the -submit_command option) If you do not specify this option, the tool uses the rsh command to submit the parallel processes.\n The list of host machines (the host_names argument) The maximum number of processes (the -num_processes option) By default, the tool assigns a name to each configuration you define with the set_host_options command.\n To specify the configuration name, use the -name option.\n You use the configuration name to select the configuration to use for specific commands and to remove a configuration.\n For example, to specify a distributed processing configuration that uses the qsub command to submit the parallel processes, use the following command: fc_shell> set_host_options -name dp_config \\ -submit_command [list qsub -P bnormal -cwd]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating Via Ladder Rules for Performance Via Ladders"}, {"role": "assistant", "content": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the setup_performance_via_ladder command to generate the via ladder rules and associations.\n By default, this command Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the -max_layer attribute.\n 451 Inserting Via Ladders Feedback The command uses information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file: The cut layers that connect the specified metal layers The cut names The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block.\n The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules.\n For details about these files, see Via Ladder Rule Files You can also generate these files by using the generate_via_rules_for_performance command.\n Associates via ladder rules with the pins of all library cells that do not have a dont_use attribute To include the pins of library cells that have a dont_use attribute, use the -dont_use option.\n To associate via ladder rules only with specific pins, use the -lib_pins option.\n The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations.\n For details about this file, see Via Ladder Association File You can also generate this file by using the associate_performance_via_ladder command.\n Runs the generated script files See Also Defining Via Ladder Rules Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization 452 Inserting Via Ladders Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Metal Fill Insertion"}, {"role": "assistant", "content": "You can use the signoff_create_metal_fill command to perform the following tasks: Pattern-Based Metal Fill Insertion Track-Based Metal Fill Insertion Using an IC Validator Parameter File Typical Critical Dimension Metal Fill Insertion Timing-Driven Metal Fill Insertion Incremental Metal Fill Insertion Foundry Fill and Track Fill Combined for Different Flows of Foundry"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing Secondary Power and Ground Pins"}, {"role": "assistant", "content": "To use Zroute to perform secondary power and ground pin routing, 1.\n Verify that the secondary power and ground pins have the appropriate attributes in the standard cell frame views.\n 2.\n Set the routing constraints for secondary power and ground pin routing.\n 3.\n Perform secondary power and ground pin routing by using the route_group command.\n The following topics describe these steps."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Clock-Gating Results"}, {"role": "assistant", "content": "After compiling your design, you can check the results using the report_clock_gating command.\n An example is shown in Figure 64 Figure 64 Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics.\n The term \"pre-existing clock gates\" refers to user-instantiated clock gates.\n The preexisting category also includes registers that are gated by a tool-inserted clock gate.\n This includes registers that are gated by both preexisting and tool-inserted clock-gating cells.\n By default, the tool reports multilevel statistics.\n This includes the maximum level of clock- gating cells in the design.\n Clock-gate levels are counted from the clock source toward the register.\n If multibit flip-flops are found in the design, multibit composition is automatically reported.\n 321 Reporting Clock-Gating Results Feedback Figure 65 Example of a Multibit Composition Report To report the details on ungated registers, use the -ungated option for report_clock_gating.\n For details on the gated registers, use the -gated option.\n 322 Reporting Clock-Gate Enable Signals Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Selecting and Multiplexing Logic"}, {"role": "assistant", "content": "The Fusion Compiler tool infers SELECT_OP cells for logic that selects data signals based on control signals.\n SELECT_OP cells are mapped to combinational logic.\n The following topics describe SELECT_OP inferences: Inferring SELECT_OPs Inferring SELECT_OPs HDL Compiler uses SELECT_OP components to implement conditional operations implied by if and case statements.\n An example of a SELECT_OP cell implementation for an 8-bit data signal is shown in Figure 31 227 Controlling Mapping and Optimization Feedback Figure 31 SELECT_OP Implementation for an 8-bit Data Signal Figure 32 Verilog Output\u2014SELECT_OP and Selection Logic 228 Controlling Mapping and Optimization Feedback Depending on the design constraints, Fusion Compiler implements the SELECT_OP with either combinational logic or multiplexer cells from the logic library.\n For more information on SELECT_OP inference, see the HDL Compiler documentation."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Transferring to Back End"}, {"role": "assistant", "content": "To transfer the clock latencies and balance points from the front-end tool to the back-end tool, use the write_ascii_files command.\n The command writes the design.MCMM directory, which contains timing contexts in Tcl files for.\n For example, The design.MCMM/scenario_ scenario.tcl file contains the following clock latency settings: set_clock_latency -clock [get_clocks {CLK}] -0.3 [get_pins {d_reg[4]/CP}] set_clock_latency -clock [get_clocks {CLK}] 0.1 [get_pins {d_reg[7]/CP}] The design.MCMM/mode_ mode.tcl file contains the following balance points: set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[4]/CP}] \\ -consider_for_balancing true \\ -rise -delay 0.3 -corners [get_corners {default}] set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[7]/CP}] \\ -consider_for_balancing true -rise -delay -0.1 -corners [get_corners {default}]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Deriving Routing Guides"}, {"role": "assistant", "content": "Routing guides provides routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic described how to derive the following types of routing guides: Deriving Pin Access Routing Guides Deriving Metal Cut Routing Guides See Also Defining Routing Guides 479 Routing Constraints Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Pin Tapering"}, {"role": "assistant", "content": "Pin tapering is the method used to connect wires with nondefault routing rules to pins.\n Zroute supports pin tapering for both hard and soft nondefault routing rules; the tapering implementation is the same for both types of nondefault routing rules.\n Note: By default, if a net has both a nondefault routing rule defined by the create_routing_rule command and voltage-based spacing rules defined in the technology file, Zroute performs pin tapering on that net based on the nondefault routing rule.\n To disable pin tapering on these nets, set the route.detail.enable_ndr_tapering_on_voltage_rule application option to false You can specify the method used for pin tapering and control the tapering width, as described in the following topics: Specifying the Tapering Method Controlling the Tapering Width 516 Routing Constraints Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Early Data Checks, Policies, and Strategies"}, {"role": "assistant", "content": "The tool can identify issues and violations in data during the early stages of design.\n You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data.\n Table 64 describes the predefined checks for top-level closure.\n Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view Checks whether the frame view is missing for a hierarchical block Re-create frame views from the bound view error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location Checks whether the location of a physical hierarchy boundary pin is missing Assign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary Checks whether the location of a physical hierarchy boundary pin is outside the physical hierarchy boundary Reassign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT 847 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort Checks whether a port is missing in the physical hierarchy reference Create missing ports in the reference block and update its location error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame Checks whether a physical hierarchy instance is bound to a frame view error, tolerate TOP hier.block.inst ance_with_desig n_type_macro Checks whether a physical hierarchy instance is bound to a macro error, tolerate TOP hier.top.estima ted_corner Checks whether the estimated corner is at top level error, tolerate TOP hier.block.miss ing_leaf_cell_l ocation Checks whether the location of a leaf cell of a physical hierarchy is missing Assign an approximate location inside the block boundary for the leaf cell (legality not considered) error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary Checks whether the location of a leaf cell of a physical hierarchy is outside the physical hierarchy boundary Reassign the leaf cell location to the nearest location inside the block boundary (legality not considered) error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion Checks whether the location of a child physical hierarchy instance is missing in the specified physical hierarchy Assign an approximate location for the lower-level subblock based on connectivity inside the block boundary (overlap removal not considered) error, tolerate, repair MID 848 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary Checks whether the location of a child physical hierarchy instance is outside the specified physical hierarchy boundary Move the subblock to the nearest location inside the block boundary (overlap removal not considered).\n error, tolerate, repair MID hier.block.port _mismatch_betwe en_views Checks whether there is a mismatch of ports between the views of a physical hierarchy Bound view is treated as golden and the frame view is recreated to match the bound view error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs Checks whether the design view for an abstract is missing error, tolerate MID BOT hier.block.inst ance_unlinked Checks whether the physical hierarchy reference is not linked properly to the top-level design due to a view change from frame or ETM to abstract or design error TOP hier.block.abst ract_type_non_t iming Checks whether the abstract type is not timing error MID BOT hier.block.abst ract_target_use _non_implementa tion Checks whether the target use of an abstract is not implementation error MID BOT hier.block.miss ing_core_area Checks whether the core area for a physical hierarchy is missing error MID BOT 849 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic Checks whether unmapped logic is present in the physical hierarchy error MID BOT Where BOT signifies bottom level design.\n MID signifies intermediate level design, which instantiates BOT.\n TOP signifies the top-level design, which instantiates MID."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Settings for Clock Latency Adjustments"}, {"role": "assistant", "content": "I/O ports are usually constrained using real or virtual clocks.\n After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate.\n When you run clock tree synthesis with the clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports.\n You can control these latency adjustments by using the set_latency_adjustment_options command.\n The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell> set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the synthesize_clock_trees command, the tool does not automatically update the clock latencies.\n To do so, use the compute_clock_latency command after clock tree synthesis.\n This command honors the settings you specify with the set_latency_adjustment_options command.\n 369 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Bus Routing Options"}, {"role": "assistant", "content": "The Custom Router bus routing application options allow you to specify: Corner Type Intra-shield Placement Pin-Trunk Offset Trunk Splitting Tapoffs"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Hierarchical Relative Placement for Straddling"}, {"role": "assistant", "content": "A cell can occupy multiple column positions or multiple row positions, which is known as straddling.\n For more information about leaf cell straddling, see Adding Leaf Cells Figure 169 shows a relative placement group in which cells straddle columns (instance U2) and rows (instance U7).\n Figure 169 Hierarchical Relative Placement Group With Straddling U3 U4 U6 U1 U2 U7 788 Adding Objects to a Group Feedback Figure 170 shows the process of using hierarchical relative placement to build this structure.\n First, define relative placement groups that contain the leaf cells: rp1 contains U1 and U4, rp2 contains U2, and rp3 contains U3 and U6.\n Then define a group (rp4) that contains these groups.\n Finally, define a group (rp5) that contains the hierarchical group rp4 and the leaf cell U7.\n The resulting group includes both the column and the row straddle.\n Example 44 shows the commands used in this process.\n Figure 170 Straddling With Hierarchical Relative Placement rp3 rp2 rp1 U3 U2 U4 U7 U6 U1 rp4 U4 U1 U2 U3 U6 rp1 rp2 rp3 rp5 U4 U1 U2 U3 U6 col 0 col 1 row 0 col 0 col 1 col 0 col 1 row 0 row 0 row 2 row 1 row 0 col 0 row 2 row 1 row 0 col 0 col 1 U7 col 1 row 2 row 1 row 0 rp4 Example 44 Straddling With Hierarchical Relative Placement create_rp_group -name rp1 -columns 2 -rows 1 add_to_rp_group rp1 -cells U1 -column 0 -row 0 add_to_rp_group rp1 -cells U4 -column 1 -row 0 create_rp_group -name rp2 -columns 1 -rows 1 add_to_rp_group rp2 -cells U2 -column 0 -row 0 create_rp_group -name rp3 -columns 2 -rows 1 add_to_rp_group rp3 -cells U3 -column 0 -row 0 add_to_rp_group rp3 -cells U6 -column 1 -row 0 create_rp_group -name rp4 -columns 1 -rows 3 add_to_rp_group rp4 -rp_group rp1 -column 0 -row 0 add_to_rp_group rp4 -rp_group rp2 -column 0 -row 1 add_to_rp_group rp4 -rp_group rp3 -column 0 -row 2 create_rp_group -name rp5 -columns 2 -rows 1 789 Adding Objects to a Group Feedback add_to_rp_group rp5 -rp_group rp4 -column 0 -row 0 add_to_rp_group rp5 -cells U7 -column 1 -row 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Self-Gating Flow"}, {"role": "assistant", "content": "Figure 68 illustrates the Fusion Compiler flow for inserting self-gates by using the compile_fusion command.\n 330 Self-Gating Optimization Feedback Figure 68 General Self-Gating Flow Fusion Compiler read_saif in.saif or set_switching_activity compile_fusion SAIF RTL/netlist Libraries Reports set_app_options -name compile.clockgate.self_gating -value true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up Libraries"}, {"role": "assistant", "content": "block is a container for physical and functional design data.\n A design library is a collection of related blocks, together with technology data that applies to the block collection.\n A chip design consists of one or more blocks, often stored in different design libraries.\n A design library uses instances of blocks defined in lower-level libraries, called reference libraries.\n A design library can serve as a reference library for another design library.\n To learn about setting up libraries, see the following topics: Working With Design Libraries Setting Up Reference Libraries Library Configuration Restricting Library Cell Usage Restricting the Target Libraries Used Specifying Library Subset Restrictions 73 Setting Up Libraries Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Pin Connections"}, {"role": "assistant", "content": "By default, Zroute connects a signal route to a pin by using wires or vias anywhere on the pin.\n To restrict the allowed types of pin connections on a per-layer basis, use the following 513 Routing Constraints Feedback syntax to set the route.common.connect_within_pins_by_layer_name application option: set_app_options -name route.common.connect_within_pins_by_layer_name -value { { layer mode }...\n } Valid values for the mode argument are off (the default) There are no restrictions on pin connections.\n via_standard_cell_pins Only the connections to standard cell pins by using a via are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to macro cell and pad cell pins by using a via or to any pins by using wires.\n via_wire_standard_cell_pins The connections to standard cell pins by using a via or a wire are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n via_all_pins The connections to any pins (standard cell, macro cell, or pad cell) by using a via are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to any pins by using wires.\n via_wire_all_pins The connections to any pins by using a via or a wire are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n For example, if you use the following command (or use the default settings), all of the connections shown in Figure 113 are valid and no DRC violations are reported: fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 off}} 514 Routing Constraints Feedback Figure 113 Unrestricted Pin Connections If you set the mode for M1 to via_all_pins, as shown in the following example, the via enclosures must be inside the pin shape.\n The connections shown on the left side of Figure 114 are valid; however, the connections on the right side of the figure cause DRC violations.\n fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_all_pins}} Figure 114 Restricted Via-to-Pin Connections No DRC Violations DRC Violations If you set the mode for M1 to via_wire_standard_cell_pins, as shown in the following example, both the via enclosures and wires must be inside the pin shape.\n The connections 515 Routing Constraints Feedback shown on the left side of Figure 115 are valid; however the connections on the right side of the figure cause DRC violations.\n fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_wire_standard_cell_pins}} Figure 115 Restricted Via-to-Pin and Wire-to-Pin Connections DRC Violations No DRC Violations"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Mapping of Synchronous Reset or Preset Registers"}, {"role": "assistant", "content": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default.\n To infer registers with synchronous reset or preset pins, use the sync_set_reset Synopsys compiler directive in the RTL.\n HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible.\n To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: The sync_set_reset directive Specify the //synopsys sync_set_reset directive in the RTL.\n The hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to true.\n The default is false 233 Controlling Mapping and Optimization Feedback During compile, the tool performs the following mapping based on the registers in your library: The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin.\n The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin.\n The tool also attempts to map the logic as close as possible to the data pin.\n This figure shows examples of mapping to registers with and without a synchronous reset pin.\n ___ RST Using a reset pin ___ RST Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible.\n To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to true Note: Synchronous reset and preset signals are not inferred for level-sensitive latches.\n A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins.\n Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must Describe the registers correctly in the RTL Ensure the library contain the corresponding cells Ensure the hdlin.elaborate.ff_infer_async_set_reset application option is set to true (the default) 234 Controlling Mapping and Optimization Feedback If the library does not contain this type of registers, the tool leaves the cells unmapped."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Overriding the Alignment When Adding Objects"}, {"role": "assistant", "content": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option.\n However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option.\n The following example creates a relative placement group named rp1 that is right aligned.\n It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement.\n 799 Specifying Options for Relative Placement Groups Feedback Figure 179 Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Constructing Faster Clock Tree to Specific Endpoints"}, {"role": "assistant", "content": "The Fusion Compiler tool enables you to construct a faster clock tree to specified endpoints without any additional detouring or delay balancing.\n This improves clock latency to the specified endpoints.\n To achieve a faster clock tree to specific endpoints, you must create a user skew group for the required endpoints.\n To create a skew group for a specific endpoint, use the following command before running the synthesize_clock_tree or the build_clock stage of the clock_opt command: fc_shell> create_clock_skew_group -objects <endpoints> Note: If there is a balancing requirement between the fast endpoints, you must put them in the same skew group.\n If there is no balancing requirement between the endpoints, you must create separate skew groups for each endpoint.\n The upstream clock logic of the required skew group endpoints is shared with the endpoints of the default group or other user skew groups.\n This leads to detouring for balancing among the endpoints of the default group or other user skew group.\n 366 Specifying the Clock Tree Synthesis Settings Feedback Figure 79 Faster Clock Tree to Specific Endpoints If a gate drives both skew group and non-skew group endpoints, the skew group endpoints might be delayed due to the balancing requirements of the non-skew group endpoints.\n In such cases, in addition to creating skew groups, you must also completely isolate the skew group endpoints from the rest of the clock tree by cloning the gates along the path to these endpoints.\n To create a separate clock path from the clock source to the required endpoints, use the -to option with the split_clock_cells command before clock tree synthesis, that is, before using the synthesize_clock_trees or the build_clock stage of the clock_opt command.\n fc_shell> split_clock_cells -to $endpoints The Fusion Compiler tool enables you to construct a faster clock tree by identifying the optimal cloning solution to achieve the best latency for the group of specified sinks.\n To achieve a fast clock tree to certain endpoints, use the split_clock_cells -to < $sinks> -latency_driven command.\n The endpoints must also be created as part of the user skew group using the create_clock_skew_group command.\n 367 Specifying the Clock Tree Synthesis Settings Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Modifying Metal Fill"}, {"role": "assistant", "content": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes.\n To change the boundary of a metal fill shape, use the set_attribute command to modify its bbox attribute.\n To add a metal fill shape in the top-level fill cell, use the create_shape -shape_use area_fill command.\n To add a metal fill shape in a specific fill cell, use the create_shape -fill_cell command.\n To remove a metal fill shape, use the remove_shapes command.\n You can also modify metal fill shapes in the GUI.\n To select or modify fill shapes in the GUI, 1.\n Select \"Multiple Levels Active\" ( ) in the View Settings panel.\n 2.\n In the \"Hierarchy Settings\" panel, set \"View level\" to a minimum of 2 and select \"Fill Cell\" in \"Expanding cell types.\""}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Guided Power Grid Augmentation"}, {"role": "assistant", "content": "Guided power grid augmentation inserts PG augmentation shapes only near cells with IR violations.\n For each candidate cell, guided PG augmentation inserts PG augmentation shapes in the region from the cell to its tap with the minimum path resistance.\n Because the shapes are added only in specific regions, guided PG augmentation inserts fewer metal shapes and uses less routing area, which decreases the coupling capacitance impacts.\n To perform guided power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop and minimum path resistance analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis and Performing Minimum Path Resistance Analysis The IC Validator tool uses the results of these analyses to drive the power grid augmentation.\n 3.\n Set up the IC Validator environment as described in Setting Up the IC Validator Environment 4.\n (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 5.\n Save the block to disk.\n When you run the fix_pg_wire command, the IC Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the save_block command to save the current state of the block before running the fix_pg_wire command.\n 705 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback 6.\n Perform guided power grid augmentation by using the fix_pg_wire command with one or both of the following options: -number_pins This option specifies the number of worst IR-drop violators for which to perform PG augmentation.\n -voltage_drop_threshold This option enables the tool to automatically determine the cells to process based on a voltage drop threshold.\n In addition, you must specify The power and ground nets on which to perform PG augmentation by using the -supply_nets option The technology node for which to perform the augmentation by using the -node option For information about the fix_pg_wire command, see the man page.\n 7.\n Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n See Also Standard Power Grid Augmentation Timing-Driven Power Grid Augmentation Removing PG Augmentation Shapes"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Associating Checkpoints and Checkpoint Behaviors"}, {"role": "assistant", "content": "After defining checkpoints with the eval_checkpoint command and checkpoint behaviors with the create_checkpoint_* command, you must associate the two so that the tool executes the behaviors when it encounters the checkpoints in a run, as described in the following topics: Associating Checkpoints With Checkpoint Reports Associating Checkpoints With Checkpoint Actions See Also Defining Checkpoints Defining Checkpoint Behaviors Associating Checkpoints With Checkpoint Reports To associate a checkpoint report with one or more checkpoints, use the associate_checkpoint_report command in your checkpoint.config.tcl file.\n 56 Adding Changes to a Script With Checkpoints Feedback Specify the checkpoint report name with the -enable option.\n To enable the report to run before one or more checkpoints, specify the checkpoint names with the -before option.\n To enable the report to run after one or more checkpoints, specify the checkpoint names with the -after option.\n When associating a report with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined three checkpoints in your script named remove_buffers, place_opt_to_initial_opto, and place_opt_to_final_opto using the eval_checkpoint command, and two checkpoint reports named timing and app_options using the create_checkpoint_report command.\n To enable your timing report to run after the place_opt_to_initial_opto and place_opt_to_final_opto checkpoints, use the following command: associate_checkpoint_report -enable timing \\ -after { place_opt_to_initial_opto place_opt_to_final_opto } To enable your app_options report to run before all the checkpoints in your script, use the following command: associate_checkpoint_report -enable app_options -before * You can also add the command like this, which enables the report to run before the remove_buffers checkpoint and any checkpoints beginning with the phrase place_opt: associate_checkpoint_report -enable app_options -before remove_buffers place_opt* The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in the run.\n The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the app_options report, configured to run before each checkpoint The code identifies the timing report, configured to run after the place_opt_to_final_opto checkpoint 57 Adding Changes to a Script With Checkpoints Feedback Associating Checkpoints With Checkpoint Actions To associate a checkpoint action with one or more checkpoints, use the associate_checkpoint_action command in your checkpoint.config.tcl file.\n Specify the checkpoint action name with the -enable option.\n To enable the action to run before one or more checkpoints, specify the checkpoint names with the -before option.\n To enable the action to run after one or more checkpoints, specify the checkpoint names with the -after option.\n To enable the action to run instead of the code block enwrapped by the checkpoint, specify the checkpoint names with the -replace option.\n When associating an action with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined two checkpoints in your script named place_opt_to_initial_drc and incr_placement with the eval_checkpoint command, and two checkpoint actions named gropto and placer_high_effort_cong with the create_checkpoint_action command.\n To enable your gropto action to run before the place_opt_to_initial_drc checkpoint, use the following command: associate_checkpoint_action -enable gropto \\ -before place_opt_to_initial_drc 58 Adding Changes to a Script With Checkpoints Feedback To enable your placer_high_effort_cong action to run instead of the code block enwrapped by the incr_placement checkpoint, use the following command: associate_checkpoint_action -enable placer_high_effort_cong \\ -replace incr_placement The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in a run.\n The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the gropto action, configured to run before the place_opt_to_initial_drc checkpoint The code identifies the placer_high_effort_cong action, configured to run in place of the code block enwrapped by the incr_placement checkpoint 59 Adding Changes to a Script With Checkpoints Feedback Associating a Checkpoint With Multiple Behaviors When you associate a checkpoint with multiple behaviors, the tool executes those behaviors in the following order: Any reports configured to run before the checkpoint Any actions configured to run before the checkpoint The checkpointed code block, or any actions configured to replace it Any actions configured to run after the checkpoint Any reports configured to run after the checkpoint If multiple reports or multiple actions are configured to run at the same position ( -before -after, or -replace ) in the same checkpoint, the tool executes them in the order in which they were associated with the checkpoint with the associate_checkpoint_* commands.\n For example, suppose you define a timing report before an area report.\n If you associate the area report to run after a checkpoint before you associate the timing report to run after the same checkpoint, the tool runs the area report first when it encounters the checkpoint.\n See Also Defining Checkpoints Defining Checkpoint Behaviors Querying Checkpoints and Checkpoint Behaviors"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Wire Length Aware Power-Driven Relocation"}, {"role": "assistant", "content": "The Fusion Compiler tool supports improved activity driven clock gate relocation by controlling the amount of wire length degradation and considering the power impact before performing the clock gate relocation.\n To enable activity driven clock gate relocation, set the cts.compile.power_opt_mode application option to all or gate_relocation The clock gates are not relocated or moved if: Relocating an integrated clock gate (ICG) has a minor power benefit or degrades power while degrading wire length.\n Moving the clock gate has a significant wire length impact for a less power benefit."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Analyzing and Fixing Signal Electromigration Violations"}, {"role": "assistant", "content": "Signal electromigration problems result from an increase in current density caused by the use of smaller line widths and higher operational speeds in IC designs.\n Electromigration can lead to shorts or opens due to metal ion displacement caused by the flow of electrons.\n The more frequently a net switches, the more susceptible it is to electromigration.\n To analyze and fix signal electromigration violations in a detail routed block, 1.\n Apply the signal electromigration constraints by using the read_signal_em_constraints command.\n For more information, see Loading the Signal Electromigration Constraints 2.\n Apply switching activity by either reading in a SAIF file with the read_saif command or annotating the switching activity information on the nets with the set_switching_activity command.\n For more information, see Annotating the Switching Activity 3.\n Report the signal electromigration information by using the report_signal_em command.\n For more information, see Analyzing Signal Electromigration 4.\n Fix any signal electromigration violations by using the fix_signal_em command.\n For more information, see Fixing Signal Electromigration Violations The following example script shows the signal electromigration flow.\n # Open the block and apply the signal electromigration constraints open_block block1_routed read_signal_em_constraints em.itf # Load switching information read_saif block1.saif # Perform signal electromigration analysis report_signal_em -violated -verbose > block1.signal_em.rpt # Fix signal electromigration violations fix_signal_em 554 Analyzing and Fixing Signal Electromigration Violations Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Sequential Mapping"}, {"role": "assistant", "content": "The sequential mapping phase consists of two steps: register inferencing and technology mapping.\n The term register refers to both edge-triggered registers and level-sensitive latches.\n Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN.\n SEQGENs are created during elaboration and are usually mapped to flip-flops during compile.\n Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library.\n Both of these steps are performed by the compile_fusion command.\n 230 Controlling Mapping and Optimization Feedback Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable QN SEQGEN This table lists the pins of a SEQGEN cell.\n Only a subset of these pins is used depending on the type of cell that is inferred.\n Unused pins are tied to zero.\n Direction Name Description Cell type Input clear Asynchronous reset Flip-flop or latch preset Asynchronous preset Flip-flop or latch next_state Synchronous data Flip-flop clocked_on Clock Flip-flop data_in Asynchronous data Latch enable Clock or asynchronous enable Latch synch_clear Synchronous reset Flip-flop synch_preset Synchronous preset Flip-flop synch_toggle Synchronous toggle Flip-flop synch_enable Synchronous enable Flip-flop Output Non-inverting output Flip-flop or latch 231 Controlling Mapping and Optimization Feedback Direction Name Description Cell type QN Inverting output Flip-flop or latch During technology mapping, the tool uses the SEQGEN as the starting point for mapping.\n The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register.\n Topics in this section Mapping Sequential Elements Exactly as Described in RTL Mapping of Scan Cells Mapping of Synchronous Reset or Preset Registers Specifying Synchronous Input Types for Library Cell Pins Controlling Sequential Output Inversion Preventing Connections to Register QN Pins Mapping of Synchronous Enable Logic to a MUX Identification of Shift Registers"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling the Adjustment of I/O Clock Latencies"}, {"role": "assistant", "content": "By default, the tool adjusts the latencies of the I/O clocks, which are the clocks that constrain the boundary ports, when it performs concurrent clock and data optimization during the clock_opt command.\n The tool also uses concurrent clock and data optimization techniques to adjust the I/O clock latencies when you subsequently run the compute_clock_latency command.\n The tool does not update the I/O clock latencies For the entire block when you disable this feature by setting the ccd.adjust_io_clock_latency to false or when you disable concurrent clock and data optimization for boundary paths by setting the ccd.optimize_boundary_timing application option to false For specific I/O paths when you exclude the corresponding path groups from concurrent clock and data optimization by using the ccd.skip_path_groups application option For specific I/O clocks when you disable latency adjustment those I/O clocks by using the set_latency_adjustment_options -exclude_clocks command 379 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Validating DEF Files"}, {"role": "assistant", "content": "To analyze the input DEF files before annotating the floorplan information on the block, enable check-only mode by using the -syntax_only option.\n The check-only mode provides diagnostic information about the correctness and integrity of the DEF file.\n The check-only mode does not annotate any floorplan information onto the block.\n fc_shell> read_def -syntax_only block.def fc_shell> check_duplicates -remove The check_duplicates -remove command ensures that no duplicate shapes and vias are present in the block due to the execution of the read_def command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Multivoltage Cells"}, {"role": "assistant", "content": "A multivoltage design requires special multivoltage cells, such as level shifters and isolation cells, at the interface between power domains.\n Level shifters are required between power domains that operate at different voltage levels, while isolation cells are required between power domains that are in different states (powered-down versus always-on or powered-up)."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Abstracts for Minimum Pulse Width Analysis"}, {"role": "assistant", "content": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations.\n The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation.\n You can use the following application options to: Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to true The data paths to these registers are not retained.\n By default, this application is set to false Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack.\n This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Improving the Banking Ratio"}, {"role": "assistant", "content": "During the initial_mapping stage, the tool can prioritize the use of sequential library cells that have functionally equivalent multibit library cells.\n After you run the compile_fusion command, if the report_multibit -ignored_cells command indicates that many cells were not banked due to a lack of multibit cells in the library, you can enable this feature by setting the compile.seqmap.prefer_registers_with_multibit_equivalent application option to true and rerunning the compile_fusion command.\n However, enabling this feature might degrade the design QoR."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Deriving the Clock Trees"}, {"role": "assistant", "content": "The Fusion Compiler tool derives the clock trees by tracing through the transitive fanout from the clock roots to the clock endpoints.\n In general, the tracing terminates when it finds a clock pin of a sequential cell or macro; however, the tool traces through sequential cells if they are integrated clock-gating (ICG) cells or their fanout drives a generated clock.\n If the clock-gating logic uses a non-unate cell, such as an XOR or XNOR gate, the tool uses both the positive-unate timing arc and the negative-unate timing arc when tracing the clock path.\n If this does not correspond to the functional mode of the block, use the set_case_analysis command to hold all nonclock inputs of the cell at a constant value, which forces the cell into the required functional mode for clock tree synthesis.\n For example, suppose a block has the gating logic shown in Figure 71 Figure 71 Non-Unate Gated Clock To force the XOR gate (U0) into functional mode for timing analysis, use the following command: fc_shell> set_case_analysis 0 U0/B"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Incomplete UPF Information"}, {"role": "assistant", "content": "The Early Data Check Manager allows you to check designs for power and multivoltage issues early in the design cycle.\n You can configure different error conditions in different ways.\n The tool provides comprehensive reports about the data checks.\n The general flow is as follows: 1.\n Use the set_early_data_check_policy command to define the global violation handling policy for data checks.\n 2.\n Proceed with your tool flow.\n The tool detects and responds to violations throughout the flow.\n 3.\n Use the report_early_data_checks command to obtain a report about all violations or specific data checks.\n 4.\n Use the get_early_data_check_records command to get a Tcl collection of violations that can be used in other commands.\n 5.\n Use the write_early_data_check_config command to save the settings in a file for future use.\n 6.\n Use the remove_early_data_check_records command to clear the data in preparation for another iteration.\n For more information about the Early Data Check Manager, see the Fusion Compiler Data Model User Guide For a list of power and multivoltage data checks, see the Fusion Compiler Multivoltage User Guide 115 Setting Up Multivoltage Designs Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Command"}, {"role": "assistant", "content": "The following topics describe how you can control the multibit optimization performed during the clock_opt command: Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Enabling Post-Clock-Tree-Synthesis Multibit Debanking Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Some logic libraries have mixed-drive-strength multibit cells where some bits have a higher drive strength than others.\n For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit.\n To enable this feature for the clock_opt command, set the clock_opt.flow.enable_multibit_rewiring application option to true Enabling Post-Clock-Tree-Synthesis Multibit Debanking To improve the timing QoR, the clock_opt command can debank multibit registers during the final_opt stage, if doing so does not introduce hold timing violations.\n To enable this feature, set the clock_opt.flow.enable_multibit_debanking application option to true before you run the final_opt stage of the clock_opt command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Implementing MSCTS Multiple H-Tree"}, {"role": "assistant", "content": "To improve clock QoR, latency, and skew, you can build multiple global trees in different sections of the floorplan by using the -htree_sections option with the set_regular_multisource_clock_tree_options command.\n The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n 403 Implementing Multisource Clock Trees Feedback Figure 86 MSCTS Multiple H-Tree You can define the different sections in the floorplan by using a symmetric configuration of tap drivers or only tap locations by coordinates, as shown in the following example: set_regular_multisource_clock_tree_options - htree_sections [ list \\ [list -section_name \"sectionA_name\" -tap_boundary {{315.8800 1275.8000} {1750.0400 2187.1000}} -prefix \"sectionA\" -tap_boxes {4 4}] \\ [list -section_name \"sectionB_name\" -tap_locations {{700472} {1350 472}} -prefix \"section\"]] Figure 87 MSCTS Multiple H-Tree"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Handling Multiple Levels of Physical Hierarchy"}, {"role": "assistant", "content": "For designs with multiple levels of physical hierarchy, before you create an abstract for a block with an abstract instantiated in it, Bind the lower-level blocks that you want represented by abstracts to the specific abstracts For example, assume you have a design with multiple levels of physical hierarchy as shown in the following figure.\n Figure 192 A Design With Multiple Levels of Physical Hierarchy BOT MID TOP 835 Reporting Abstract Inclusion Reasons Feedback To create an abstract for the block named BOT, use the following commands: fc_shell> open_block BOT fc_shell> create_abstract To create an abstract for the block named MID, use the following commands: fc_shell> open_block MID fc_shell> change_abstract -view abstract -references BOT fc_shell> create_abstract By default, the create_abstract command preserves all levels of the physical hierarchy.\n To flatten the physical hierarchy and retain only the relevant logic of the lower-level blocks, use the -preserve_block_instances false option, as shown in the following example: fc_shell> open_block MID fc_shell> create_abstract -preserve_block_instances false Use flattened abstracts in top-level implementation flows where the lower-level blocks are treated as read-only.\n Using flattened abstracts reduces the netlist size at the top level.\n It also simplifies data management because you do not need to include the lower-level blocks in the reference library list of the top level."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I ECO-Aware Removal of Track Based Metal Fill Shapes"}, {"role": "assistant", "content": "To automatically remove track based metal fill shapes that are causing DRC violations after ECO, use the -remove_by_rule drc_auto option with the signoff_create_metal_fill command.\n This action removes DRC violating track based metal fill shapes or vias from design, including any floating connections created due to removal of DRC violating shape.\n For example, fc_shell> signoff_create_metal_fill -remove_by_rule drc_auto"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing Application Options"}, {"role": "assistant", "content": "The Fusion Compiler tool provides application options that affect the individual routing engines (global routing, track assignment, and detail routing), as well as application options that affect all three routing engines.\n For information about the application options that affect all three routing engines, see the route.common_options man page.\n For information about the application options that affect global routing, see the route.global_options man page.\n For information about the application options that affect track assignment, see the route.track_options man page.\n For information about the application options that affect detail routing, see the route.detail_options man page.\n Zroute uses these option settings whenever you perform routing functions.\n When you run a routing command, Zroute writes the settings for any routing options that you have set (or that the tool has set for you) in the routing log.\n To display the settings for all routing options, not only those that have been set, set the route.common.verbose_level application option to 1.\n fc_shell> set_app_options \\ -name route.common.verbose_level -value 1 519 Routing Clock Nets Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up the IC Validator Environment"}, {"role": "assistant", "content": "To run an IC Validator In-Design command, you must specify the location of the IC Validator executable by setting the ICV_HOME_DIR environment variable.\n You can set this variable in your.cshrc file.\n To specify the location of the IC Validator executable, use commands similar to those shown in the following example: setenv ICV_HOME_DIR /root_dir/icv set path = ($path $ICV_HOME_DIR/bin/LINUX.64) You must ensure that the version of the IC Validator executable that you specify is compatible with the Fusion Compiler version that you are using.\n To report the version compatibility, use the report_versions command.\n For more information about the IC Validator tool, see the IC Validator documentation, which is available on SolvNet."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Gating in the Compile Log File"}, {"role": "assistant", "content": "The compile log file contains information about clock gating, which can help you debug simple setup issues.\n By default, the clock-gating information is displayed after Clock-gate insertion n the initial_map stage Clock-gate restructuring in the logic_opto stage Clock-gate restructuring in the initial_opto stage Self-gating insertion in the initial_opto stage, if enabled The reported information includes the following: The number of preexisting clock gates that have a dont_touch attribute, which prevents optimization and might lead to unsatistactory results The number of clock-gating library cells that have a CTS purpose, which is required for insertion Clock-gating metrics such as the number of elements and the number of gated registers A summary of reasons for registers that could not be gated If the self-gating or fanin-based sequential clock gating features are enabled, their metrics are displayed separately.\n An example of the compile log for a run that includes self-gating is as follows: Number of Pre-Exsting Clock Gates with dont_touch Attribute: 0 Number of ICG library cells with CTS purpose: 12 Tool Gated Register Summary Clock Gating Type | Number of Clock Gates | Register Count | Bitwidth | | | Equivalent Regular Clock Gating | 1 | 2 | 2 Self Gating | 0 | 0 | 0 Regular Clock Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Enable is Constant One | 2 | 2 289 Introduction to Clock Gating Feedback Self Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Register is clock gated, and ineraction | | is set to none | 2 | 2 The tool as not able to find enough registers | | that are compatible to this register | | in order to be gated.\n | 2 | 2"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Saving UPF Information"}, {"role": "assistant", "content": "During physical implementation, the tool updates the power intent of the design.\n To generate an updated UPF file, use the save_upf command.\n You can use this UPF file in the subsequent steps of the design flow.\n The save_upf command separates the UPF commands based on the input UPF file, and adds a comment indicating the input UPF file and the time it was loaded.\n Assume you load, commit, and save UPF information as shown in the following example script: load_upf top_1.upf load_upf top_2.upf load_upf top_3.upf commit_upf save_upf top.upf 116 Setting Up Multivoltage Designs Feedback The resulting top.upf file contains the following information: ## Start - load_upf top_1.upf on Wed Oct 26 17:03:18 2016 ## End - load_upf ## Start - load_upf top_2.upf on Wed Oct 26 17:03:49 2016 ## End - load_upf ## Start - load_upf top_3.upf on Wed Oct 26 17:04:22 2016 ## End - load_upf"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Spreading Repeater Cells During Placement"}, {"role": "assistant", "content": "If a block has many chains of repeater cells (buffers, inverters, or pipelined registers) along the edges or corners of macro cells or blockages, the tool might clump the cells along the edges or corners, increasing congestion.\n You can reduce this congestion by setting the place.coarse.spread_repeater_paths application option to true before you run the create_placement compile_fusion, or clock_opt command.\n Then, the tool reduces congestion along the edges and corners by spreading the repeater cells in an orthogonal direction."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Minimizing Large Displacements During Legalization"}, {"role": "assistant", "content": "To minimize large displacements of cells during legalization, enable Orientation optimization by setting the place.legalize.optimize_orientations application option to true When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization.\n Stream placement by setting the place.legalize.stream_place application option to true When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization.\n You can further control stream placement by using the place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Viewing Error Data"}, {"role": "assistant", "content": "RedHawk or RedHawk-SC Fusion saves the checking error data file, named missing_via.\n supplyNetName.err, in the working directory.\n The tool generates one error data file for each supply net.\n Before you quit the current session, be sure to save the block to keep the generated error data in the block.\n To open an error data file in the error browser, choose File > Open...\n from the Error Browser dialog box, and then select the error data file to open in the Open Error Data dialog box (see Figure 202 ).\n For more information about the error browser, see \"Using the Error Browser\" in the Fusion Compiler Graphical User Interface User Guide 894 Missing Via and Unconnected Pin Checking Feedback Figure 202 Opening Error Data from the Error Browser See Also Specifying RedHawk and RedHawk-SC Working Directories"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Boundary Cells"}, {"role": "assistant", "content": "The Fusion Compiler tool provides several methods for inserting boundary cells, depending on where you want to insert the boundary cells.\n To insert boundary cells around the core area, hard macros, and placement blockages, use the compile_boundary_cells command.\n To insert boundary cells only around one or more voltage areas, use the compile_boundary_cells command with the -voltage_area option.\n To insert boundary cells only around specific objects, use the compile_targeted_boundary_cells command with the -target_objects option.\n You can use this command to insert boundary cells around specific macros, voltage areas, voltage area shapes, placement blockages, routing blockages, and the core area.\n The set_boundary_cell_rules command configures boundary cell insertion for both the compile_boundary_cells and compile_targeted_boundary_cells commands.\n However, some rules are honored only by the compile_boundary_cells command.\n For details, see Specifying the Boundary Cell Insertion Requirements"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Distributed RedHawk Fusion Rail Analysis"}, {"role": "assistant", "content": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow.\n By default, the analyze_rail command uses a single process to perform RedHawk rail analysis.\n To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run.\n You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session.\n This allows you to run multiple RedHawk analyses with only one Fusion Compiler license.\n Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key.\n To examine the generated analysis result, first run the open_rail_result command to load the result that is saved in the directory you specify.\n You can then investigate the problematic areas in the map and check for violations in a text file or in an error view.\n You can open one result context at a time.\n To load the rail context generated in another analysis run, first close the current rail result using the close_rail_result command, and then open the desired rail result (see Displaying Maps in the GUI ).\n License Requirement By default, the number of required licenses is the number of script files or configurations specified with the -multiple_script_files option during distributed processing mode.\n If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message.\n To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the analyze_rail run, set the rail.license_checkout_mode application option to wait.\n If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately.\n By default, the rail.license_checkout_mode application option is set to nowait When the analysis is finished, run the remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses.\n fc_shell> remove_licenses SNPS_INDESIGN_RH_RAIL 915 Performing Distributed RedHawk Fusion Rail Analysis Feedback In Figure 210, the rail.license_checkout_mode application option is set to wait.\n There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses.\n In this case, the tool first checks out two licenses and waits for other licenses to become available.\n When a script finishes the job, the tool reuses its license immediately to submit other scripts.\n Figure 210 Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6 Set rail.license_checkout_mode to wait The tool first submits two scripts to the farm machines, because there are only two licenses available.\n...\n The tool checks for available licenses during the analyze_rail run.\n When a license becomes available, the tool reuses it.\n Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1.\n Define the distributed processing configuration by using the set_host_options command.\n You can specify one or more of the following options: Option Description -submit_protocol Specifies the protocol to submit jobs, such as LSF, GRD, or SGE.Note: Before job submission, run the rsh command to check if the target farm machine supports the rsh protocol to accept distributed processing from on a remote machine.\n -target Specifies to submit jobs for RedHawk only.\n -timeout Specifies the job submission timeout value.\n 916 Performing Distributed RedHawk Fusion Rail Analysis Feedback Option Description -submit_command Specifies the full path name of the LSF, GRD, SGE, or custom job submission program along with other options as needed, such as qsub or bsub.\n -max_cores Controls the number of cores each distributed worker job can use.\n The default is 1.\n 2.\n Run the analyze_rail command with the following options: Option Description -submit_to_other_machines Enables RedHawk job submission to the target farm machines.\n -multiple_script_files\\ directory_name script_name Specifies the RedHawk scripts and the directories for saving analysis results.\n Example 51 %> rsh myMachine ls test1 CSHRC DESKTOP > set_host_options \"myMachine\" -target RedHawk \\ -max_cores 2 -timeout 100 > analyze_rail -submit_to_other_machines \\ -voltage_drop static -nets {VDD VDDG VDDX VDDY VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only.\n Timeout value is 100 and the number of cores to use is 2.\n Example 52 > set_host_options -submit_protocol sge \\ -submit_command { qsub -P normal } > analyze_rail -submit_to_other_machines -voltage_drop \\ static -nets {VDD VSS} The above example enables job submission to a machine on the SGE farm machine.\n Example 53 > set_host_options -submit_protocol lsf \\ -submit_command {bsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{result1 RH1.tcl} {result2 RH2.tcl}} > open_rail_result result1 917 Voltage Driven Power Switch Cell Sizing Feedback > close_rail_result > open_rail_result result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2.\n Example 54 > set_app_options -name rail.license_checkout_mode \\ -value wait > set_host_options -submit_protocol sge \\ -submit_command {qsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{ result1 RH1.tcl} {result2 RH2.tcl} \\ {result3 RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the analyze_rail run."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Restricting the Target Libraries Used"}, {"role": "assistant", "content": "By default, the tool can select any library cell from the target library during optimization.\n In some cases, you might want to restrict the library cells used for clock tree synthesis and optimization.\n For example, you might want to exclude specific double-height cells from the target library for some design blocks during optimization.\n To restrict the library cells used for clock tree synthesis and optimization, 1.\n Specify the library subset by using the set_target_library_subset command.\n By default, the library subset restriction applies to 78 Setting Up Libraries Feedback The top block and all its subblocks To set it for a specific subblock, use the -objects option.\n Both clock and data paths.\n To set it for only the clock or data paths, use the -clock or -data option.\n You can further restrict the target library subset setting as follows: Specify a list of cells from the libraries that should not be used by using the -dont_use option.\n Specify that these libraries cannot be used for any other objects, other than the specified objects, by using the -only_here option.\n 2.\n Enable the use of the target library subset by setting the opt.common.enable_target_library_subset_opt application option to 1.\n When you set target library subsets, remember the following points: The subset restriction applies to hierarchical cells but not to leaf cells.\n The command enforces the subset restriction on the specified blocks and their subdesigns in the hierarchy, except those subdesigns where a different subset restriction is set.\n A subset specified at a lower level supersedes any subset specified at a higher level.\n Figure 7 Logic Hierarchy of Design 79 Setting Up Libraries Feedback For example, assume your design has a logic hierarchy as shown in Figure 7 and you want to implement the following library restrictions during optimization and clock tree synthesis: Use only the cells from the library named LVT_lib for the Sub1 block and its subblocks, SubA and SubB.\n Do not use the cells from this library anywhere else in the design.\n To do so, use the following settings: fc_shell> set_target_library_subset -objects {top/Sub1} \\ -only_here [get_lib_cells LVT_lib/*] [get_libs LVT_lib] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 In addition to these settings, assume you specify the following setting: fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} Then, when adding buffers on the clock network during clock tree synthesis, the tool uses The buf1 and buf2 cells from the LVT_lib library for the block named Sub1 and its subblocks The buf1 and buf2 cells from the HVT_lib library for the rest of the design Reporting Target Library Subsets To find out which target library subsets have been defined for a top block or hierarchical cell, use the report_target_library_subset command.\n Reports that are generated by reporting commands, such as report_cells and report_timing, show the td attribute attached to the cells that are specified by the -dont_use or -only_here option.\n Removing Target Library Subsets To remove a target library subset restriction from a top block or hierarchical cell, use the remove_target_library_subset command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Handling Tap Columns and Relative Placement Group Overlaps"}, {"role": "assistant", "content": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option.\n The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns.\n This application option helps the relative placement engine know about the distance between the tap columns.\n 806 Changing the Structures of Relative Placement Groups Feedback This helps in better placement and structures of relative placement groups in the design.\n You must use this application option for n5 and older technical nodes.\n For n3 and beyond designs, the distance between tap columns is calculated automatically.\n place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting the Routing Results"}, {"role": "assistant", "content": "To report statistics about the routing results, use the report_design -routing command.\n This command reports the following information: Final wiring statistics, including the Number of signal net shapes for each metal layer Signal wire length for each metal layer Number of PG net shapes for each metal layer PG wire length for each metal layer Horizontal and vertical wire distribution for each metal layer Total number of signal net shapes for the block Total signal wire length for the block Final via statistics, including the Simple vias used in each via layer, including the number of instances of each via Double via conversion rate for each via layer Double via conversion rate for the block Custom vias used in the block, including the number of instances of each user- defined via By default, this command reports the information only for the top-level block.\n To report the information for the entire physical hierarchy, use the -hierarchical option.\n See Also Defining Vias"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Scan Registers"}, {"role": "assistant", "content": "When a design switches between the functional and scan modes, glitches might occur on asynchronous set and reset lines of scan registers, which can reset the state of these registers.\n The tool can prevent this by adding gating logic to the asynchronous set and reset lines.\n To enable this feature, you must specify a top-level port to control the gating logic by using the set_register_async_gating_pin -port command.\n This control port must be a predefined port in the RTL that is not connected to any other net.\n To get information about such gated scan registers, run the report_async_gated_registers command after physical synthesis.\n The added gating logic can be an AND or OR gate, depending on the polarity of the asynchronous pins on the scan registers.\n When gating logic is added, the Formality tool requires additional information to verify the design and the Fusion Compiler tool generates an appropriate.svf file that disables the gating logic in the functional mode.\n Note: This feature is supported only for the in-compile DFT flow.\n 260 Specifying Settings for Performance, Power, and Area Improvement Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Via Ladder Candidates for Library Pins"}, {"role": "assistant", "content": "To specify the valid via ladders that can be used for a given library pin during preroute optimization, use the set_via_ladder_candidate command.\n You can specify only one via ladder each time you use the set_via_ladder_candidate command.\n To specify multiple via ladder candidates for a library pin, use the command multiple times, as shown in the following example: fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP4\" 181 Specifying Settings for Preroute Optimization Feedback fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP2\" The order in which you specify multiple via ladders for the same library pin indicates the priority to use when selecting a via ladder to insert for that pin.\n Specify the via ladder candidates starting with the highest priority.\n In the previous example, the tool gives the VP4 via ladder priority over the VP2 via ladder.\n Note: If both the pattern_must_join attribute and a via ladder candidate apply to a pin, the via ladder has a higher priority than the pattern-based must-join connection when both methods have the same estimated delay.\n To specify that a library pin requires an electromigration via ladder, set the is_em_via_ladder_required pin attribute to true, as shown in the following example: fc_shell> set_attribute [get_lib_pins lib1/INV4/A] \\ is_em_via_ladder_required true If you set the is_em_via_ladder_required pin attribute to true for a specific library pin, you must specify an electromigration via ladder as a candidate with the set_via_ladder_candidate command.\n A via ladder can be identified as an electromigration via ladder by using one of the following methods: By using the forElectromigration=1 construct when defining the via rule in the technology file, as shown in the following example: ViaRule \"EMVP1\" {...\n...\n...\n forElectromigration=1 By setting the for_electro_migration attribute to true, as shown in the following example: fc_shell> set_attribute [get_via_rules EMVP1] \\ for_electro_migration true See Also Defining Via Ladder Rules 182 Specifying Settings for Preroute Optimization Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing On Route Placement of Repeaters"}, {"role": "assistant", "content": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command.\n place_group_repeaters \\ -cells cell_list | -repeater_groups group_id_list [-lib_cell_input pin_name ] \\ [-lib_cell_output pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Timing-Driven Global Routing"}, {"role": "assistant", "content": "By default, the route_global command is not timing-driven.\n To enable timing-driven global routing, set the route.global.timing_driven application option before you run the route_global command.\n During timing-driven global routing, the global router considers the impact of layer resistance by minimizing the usage of pin access layers, even if this increases wire length.\n By default, when you enable timing-driven global routing, the tool 1.\n Calculates the net delays of the block If the design library contains global route information, the tool uses the global route information to calculate the net delays; otherwise, it uses virtual routing to calculate the net delays.\n The global routing results can vary depending on whether the initial net delays were calculated by using global route information or virtual routing.\n To remove existing global route information from the signal nets in the block, use the -global_route and -net_types signal options with the remove_routes command, as shown in the following example: fc_shell> remove_routes -global_route -net_types signal 2.\n Performs an initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell 529 Routing Signal Nets Feedback 3.\n Performs two rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows 4.\n Updates the design timing based on the first three global routing phases 5.\n Identifies newly critical nets based on the timing update 6.\n Performs three rerouting phases, in which the tool rips up and reroutes the newly critical nets To increase the number of rerouting phases after the timing update, set the global routing effort level to high or ultra by using the -effort_level option with the route_global command.\n To reduce runtime, at a possible cost to the timing QoR, set the route.global.advance_node_timing_driven_effort application option.\n When you set this application option to medium, the tool rips up and reroutes the newly critical nets only if doing so does not increase congestion.\n In addition, the number of rerouting phases is reduced for medium-, high-, and ultra-effort global routing.\n When you set this application option to low, the tool does not perform the timing update and the number of rerouting phases is reduced for medium, high-, and ultra- effort global routing.\n The following table summarizes the timing-driven global routing behavior based on the effort level settings.\n The shaded cell shows the default behavior.\n Table 32 Number of Rerouting Phases Based on the Effort Level Settings route.global.advance_node_timing_driven_effort setting route_global -effort_level setting low medium high (default) low medium (default) 3,4 3,5 high 3,4 3,4 ultra 3,4 3,4 To control the tradeoff between timing QoR and DRC convergence, set the route.global.timing_driven_effort_level application option.\n By default, this option has a setting of high, which favors timing QoR over DRC convergence.\n 3.\n Timing update performed after the second rerouting phase.\n 4.\n Newly critical nets are ripped up and rerouted only if it does not increase congestion.\n 5.\n Newly critical nets are always ripped up and rerouted.\n 530 Routing Signal Nets Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Cut Space and Cut Distance for Repeater Groups"}, {"role": "assistant", "content": "Use one of the following mutually exclusive options to control cutting for repeater groups: -layer_cutting_spacing specifies the cut space of the routes to the driver pin.\n The cut starts from the driver side.\n -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Local Skew Optimization"}, {"role": "assistant", "content": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths.\n If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design.\n However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design.\n During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths.\n To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the synthesize_clock_trees and clock_opt commands, set the cts.compile.enable_local_skew and cts.optimize.enable_local_skew application options to true fc_shell> set_app_options -list {cts.compile.enable_local_skew true} fc_shell> set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you 360 Specifying the Clock Tree Synthesis Settings Feedback specify with the set_clock_tree_options -target_skew command.\n To prevent the tool from deriving skew targets, use the following application option setting: fc_shell> set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Via Ladder Rule Files"}, {"role": "assistant", "content": "The command generates two via ladder rule files: An XML file that provides information about the via ladder rules The XML file has the following syntax: <EmRule> <!\n template definition > <Template name=\" rule_name \" for_electro_migration=\"true\" for_high_performance=\"true\"> <Layer name=\" layer_name \" row_number=\" cuts_per_row...\n more layers </Template> \u2026 more templates </EmRule> Each Template section specifies the template for a via ladder rule.\n Within a template section, the via ladder structure is specified by specifying the number of cuts per row for each metal layer involved in the via ladder.\n By default, the generated XML file is named auto_perf_via_ladder_rule.xml.\n To specify a different name, use the -xml_file option.\n A script file that defines the via ladder rules The script file contains a create_via_rule command for each template defined in the XML file, as well as set_attribute commands to set the appropriate via rule attributes.\n By default, the generated script file is named auto_perf_via_ladder_rule.tcl.\n To specify a different file name, use the -rule_file option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Finding Substitute Locations for Invalid Taps"}, {"role": "assistant", "content": "If the specified location for a tap is invalid, use the -snap_distance option of the create_taps command to find a substitute location for the tap.\n The command searches the nearby layout shapes within the specified snap distance both horizontally and vertically on the same layer as defined by the -layer option.\n The tap is reinserted at the corner of a valid shape which is within the minimum distance to the specified location.\n Note: You can search for a substitute location only for the invalid taps that are specified by the -point and -layer options.\n For example, fc_shell> create_taps -point {50,50} -layer {M1} \\ -snap_distance 100 Snap tap point from original location (50.000, 50.000) to new location (90.000, 65.910) As shown in Figure 201, the specified tap location does not touch any layout shape.\n The red rectangle is the shape closest to the specified location and its lower-right corner has 889 Missing Via and Unconnected Pin Checking Feedback the minimum distance among all the other rectangles.\n The tool reinserts the tap at the lower-right corner of the red rectangle.\n Figure 201 Finding a Substitute Location for an Invalid Tap Original {x,y} 100 100 100 100 Snapped tap"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Checking for Filler Cell DRC Violations"}, {"role": "assistant", "content": "By default, the remove_stdcell_fillers_with_violation command checks for DRC violations between all cell instances with xofiller in their name and top-level signal routing objects and removes the violating filler cells.\n You can control the following aspects of the filler cell checking: The string used to identify the filler cells To specify a different string to identify the filler cells, use the -name option.\n The region in which to check for violations To restrict filler cell check to specific regions, use the -boundary option.\n 642 Inserting Filler Cells Feedback The checked objects To check for violations between filler cells and all neighboring objects, such as signal net shapes, other filler cells, standard cells, PG rails, and terminals, use the -check_between_fixed_objects true option.\n Restrict DRC to shorts-checking only By default, the command removes all filler cells that cause a routing DRC violation.\n To remove only those filler cells that cause a short by overlapping a routing shape, use the -shorts_only true option.\n Whether double-patterning rules are checked The command checks for double-patterning violations only when the following criteria are met: The route.common.color_based_dpt_flow application option is true The technology file defines double-patterning rules To check for DRC violations on filler cells before removing them, use the -check_only true option.\n When you use this option, this command writes a report to a file named block _fillers_with_violation.rpt in the current working directory.\n The report lists the filler cells with violations and reports the first violation for each filler cell."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Orientation of Relative Placement Groups"}, {"role": "assistant", "content": "The Fusion Compiler tool supports the following orientations for relative placement groups: R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top.\n R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom.\n MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation.\n MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation.\n Figure 182 shows how the column and row positions in a relative placement group are placed for the four orientations.\n 802 Specifying Options for Relative Placement Groups Feedback Figure 182 Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length.\n You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command.\n For example, the following command sets the relative placement group orientation to MY.\n fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy.\n 803 Specifying Options for Relative Placement Groups Feedback Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Ensuring Clock Tree Exceptions are Valid"}, {"role": "assistant", "content": "To identify pins on the clock network, the tool checks if the is_clock_is_used_as_clock pin attribute is true during clock tree synthesis.\n If you use the set_clock_balance_points command to specify a clock tree exception on a pin for which the is_clock_is_used_as_clock attribute is false, the tool accepts the exception, but ignores it during clock tree synthesis.\n 347 Defining the Clock Trees Feedback Consider the clock network in the following figure.\n Figure 75 Specifying Exceptions on Pins Beyond the Clock Network CLK U2 FF3 n5 By default, the tool sets The is_clock_is_used_as_clock attribute of the U2/A, U2/Y, and FF3/D pins to false and considers the network beyond the U2/A pin as part of the data network The U2/A pin as an ignore pin and excludes the network beyond this from clock tree synthesis During clock tree synthesis, the tool adds a guide buffer and isolates the U2/A pin from the rest of the clock network.\n During subsequent data path optimization, the tool can fix any existing DRC violations beyond the guide buffer.\n Assume you want clock tree synthesis to fix DRC violations up to the FF3/D pin using clock tree constraints.\n To do so, you must 1.\n Specify the FF3/D pin as an explicit ignore pin as follows: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins FF3/D] 348 Defining the Clock Trees Feedback 2.\n Force clock tree synthesis to consider the FF3/D pin as a pin on the clock network by using the set_sense -clock_leaf command as follows: fc_shell> set_sense -clock_leaf [get_pins FF3/D] The set_sense -clock_leaf command sets The is_clock_used_as_clock attribute to true for all the pins of the clock branches that fanin to the pin specified as the clock leaf The is_clock_used_as_clock attribute to false for all the pins in the fanout from the pin specified as the clock leaf, and the tool does not propagate the clock beyond this pin To check the value of the is_clock_used_as_clock pin attribute, use the get_attribute command, as shown in the following example: fc_shell> get_attribute [get_pins FF3/D] is_clock_used_as_clock"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Routing Blockages"}, {"role": "assistant", "content": "To remove routing blockages from the current block, use the remove_routing_blockages command.\n To remove specific routing blockages, specify the routing blockages, either as a list or collection, such as that returned by the get_routing_blockages command.\n To remove all routing corridors, specify the -all option.\n 473 Routing Constraints Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Net Names, Buffers Types, and Their Locations"}, {"role": "assistant", "content": "When you use the add_buffer_on_route command, you must specify the following: The net on which to add buffers The type of buffers to add and where to add them on the net by using one of the following methods: Adding Buffers in a Specified Configuration Adding Buffers at Specified Locations Adding Buffers at a Specified Interval Adding Buffers at an Interval That is a Ratio of the Net Length Adding Buffers on a Bus in a Specified Pattern 964 Adding Buffers on Routed Nets Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Replacing Clock Gates"}, {"role": "assistant", "content": "If you want to replace all the technology-independent clock gates in your RTL with integrated clock-gating cells from the libraries, use the replace_clock_gates command before executing the compile_fusion command.\n The replace_clock_gates command identifies combinational elements in the clock network acting as clock gates and replaces them.\n When you use the replace_clock_gates command, the tool honors the constraints specified by the set_clock_gate_style set_lib_cell_purpose, and set_target_ligrary_subset commands when it selects a library cell.\n When the tool identifies combinational elements, these elements must have only two input pins (the clock pin and the enable signal pin) and only one output pin.\n If the cell does not meet these criteria, the cell is not a candidate for replacement.\n The following table lists the WVGTECH instances and their replacement cells.\n Combinational Cell in RTL Integrated Clock Gate Replacement AND gate Rising-edge triggered latch-based clock gate OR gate Falling-edge triggered latch-based clock gate NAND gate Falling-edge triggered latch-based clock gate.\n Clock input pin is inverted.\n NOR gate Falling-edge triggered latch-based clock gate.\n Both input pins are inverted.\n The new clock-gating cell is inferred with the following name: rep_clock_gate_+<instance_name_of_combinational_cell> The tool reports replaced clock gates as tool-inserted clock gates."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling the Optimization of Relative Placement Cells"}, {"role": "assistant", "content": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed.\n When a relative placement cell is removed during optimization, the relative 805 Specifying Options for Relative Placement Groups Feedback placement information of the instance is also removed, disrupting the relative placement structure.\n To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting Allow unrestricted optimization of the relative placement cells all_opt Allow only sizing of the relative placement cells size_only Allow only in-place sizing of the relative placement cells size_in_place Prevent any optimization of the relative placement cells no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Importing the Floorplan Information"}, {"role": "assistant", "content": "A floorplan contains physical constraints such as the core area and shape, port locations, macro locations and orientations, and so on, which are required for performing physical synthesis and optimization.\n 103 Importing the Floorplan Information Feedback If you have a floorplan for your block, read in the floorplan as a DEF file, as described in Reading DEF Files If you do not have a floorplan for your block, you can perform design planning and generate a floorplan as described in the Fusion Compiler Design Planning User Guide During the early stages of design process, you can use automatically-generated floorplan information to run physical synthesis, as described in Using Automatic Floorplanning"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Prerequisites for Routing"}, {"role": "assistant", "content": "Before you can run Zroute, you must ensure that the block and physical library meet the following requirements: Library requirements Zroute gets all of the design rule information from the technology file; therefore, you must ensure that all design rules are defined in the technology file before you start routing.\n For more information about the technology file and defining routing design rules, see the Synopsys Technology File and Routing Rules Reference Manual Block requirements Before you perform routing, your block must meet the following conditions: Power and ground nets have been routed after design planning and before placement.\n For more information, see the Fusion Compiler Design Planning User Guide Clock tree synthesis and optimization have been performed.\n For more information, see Clock Tree Synthesis Estimated congestion is acceptable.\n Estimated timing is acceptable (about 0 ns of slack).\n Estimated maximum capacitance and transition have no violations.\n To verify that your block meets the last three prerequisites, you can check the routability of its placement as explained in Checking Routability 442 Defining Vias Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Applying Required Settings for High Performance Cores"}, {"role": "assistant", "content": "You can apply tool settings required for achieving the best QoR for high performance cores by using the set_hpc_options command.\n The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis.\n To List the supported high performance core types and implementation stages, use the -list option Specify the type of high performance core, use the -core option Specify the stage of the implementation flow, use the -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the set_technology command before you run the set_hpc_options command, as shown in the following example script: set_technology -node 7 set_hpc_options -core A72 -stage clock_opt_cts...\n clock_opt -from build_clock -to route_clock...\n 209 Applying Mega-Switch Command Settings Feedback set_hpc_options -core A72 -stage clock_opt_opto...\n clock_opt -from final_opto...\n set_hpc_options -core A72 -stage route_auto...\n route_auto...\n set_hpc_options -core A72 -stage route_opt...\n route_opt..."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Merging Clock Gates"}, {"role": "assistant", "content": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage.\n The tool looks for clock-gating cells that share a common clock and enable signal.\n This feature is on by default.\n The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching.\n Note that the the tool also checks clock-gating style and multivoltage constraints.\n Clock-gating cells with the dont_touch or size_only constraints are not optimized.\n To disable this feature, use the set_clock_gate_transformations command.\n 313 Setting Clock Gating Transformations Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling IR-Drop-Aware Placement"}, {"role": "assistant", "content": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells.\n Figure 22 Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in Figure 22 The upper category consists of the top one percent of the total number of cells with the highest voltage drop values.\n During placement, the tool spreads these cells the most.\n The middle category consists of the next five percent of the cells.\n During placement, the tool spreads these cells less than those in the upper category.\n The lower category consists of the rest of the cells.\n The tool does not spread these cells.\n 160 Specifying Placement Settings Feedback You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options.\n The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false.\n They are true by default.\n The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa.\n The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ 161 Specifying Legalization Settings Feedback -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command.\n The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Constraints for Auto Floorplanning"}, {"role": "assistant", "content": "Use the commands and application options described in this topic to create constraints for auto floorplanning.\n Commands Use the following two commands to set and report auto floorplanning constraints.\n These two commands do not affect explicit floorplanning.\n set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile.\n For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8 report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command.\n To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands: Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin Pin placement constraints set_block_pin_constraints set_individual_pin_constraints Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning.\n compile.auto_floorplan.initialize (default: auto auto : Creates missing floorplan information.\n The tool exits with an error when inconsistent information is provided.\n true : Always creates the core and boundary.\n false : Never creates the core and boundary; uses only existing information.\n The tool exits with an error when encountering missing or inconsistent information.\n 111 Importing the Floorplan Information Feedback By default, the following objects are preserved: Existing placement of fixed macros Existing placement of pins and pads Existing shaping of voltage areas compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped all : Always places and shapes objects even if they are fixed.\n Unplaced and unshaped objects will always be placed and shaped.\n unfixed : Places and shapes objects that are not fixed.\n Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify.\n Unplaced and unshaped objects will always be placed and shaped.\n unplaced, unshaped : Never places or shapes objects when they are already placed.\n Unplaced and unshaped objects will always be placed and shaped.\n none : Never places or shapes objects even if they are not already placed.\n This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning.\n Application option setting Fixed objects Placed objects Unplaced objects all Placed and shaped Placed and shaped Placed and shaped unfixed Kept Placed and shaped Placed and shaped unplaced, unshaped Kept Kept Placed and shaped none Kept Kept Kept compile.auto_floorplan.keep_bounds (default: auto 112 Setting Up Multivoltage Designs Feedback auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing bounds.\n false : Removes existing bounds.\n compile.auto_floorplan.keep_placement_blockages (default: auto auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing placement blockages.\n false : Removes existing placement blockages.\n Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Clock Tree Design Rule Constraints"}, {"role": "assistant", "content": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis: clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the set_max_capacitance command.\n If you do not specify this constraint, the clock tree synthesis default is 0.6 pF.\n clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the set_max_transition command.\n If you do not specify this constraint, the clock tree synthesis default is 0.5 ns.\n By default, these constraints apply to all corners associated with the current mode.\n To set the constraint for a specific mode, use the -mode option with the get_clocks command to identify the clocks.\n To set the constraint for specific corners associated with the specified mode, use the -corners option with the constraint command.\n Be careful to apply the correct constraints across all the modes and their associated corners.\n For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell> set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the -mode option with the get_clocks command to specify the mode and use the -corners option to specify the corner.\n For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell> set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell> set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell> set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]] 356 Specifying the Clock Tree Synthesis Settings Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Sorting and Filtering the Data"}, {"role": "assistant", "content": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further.\n To sort and filter the data, see the following topics: Sorting the Data Filtering Metrics Filtering Runs Example Analysis See Also Exploring the Detailed Comparison Data 274 Performing Design Analysis Feedback Sorting the Data Click any column header to sort the data using that metric.\n The first click performs an ascending sort, while the second click performs a descending sort.\n For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom: 275 Performing Design Analysis Feedback Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly.\n For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in Figure 39 Figure 39 Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column.\n For example, to display only the first four runs in a table, select the runs as shown in Figure 40 Figure 40 Choose Baseline and Visible Runs Dialog Box 276 Performing Design Analysis Feedback Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further.\n Suppose you open the comparison report shown in Figure 41 and set the util60_aspect1%1_layerM9 run as the base run.\n Figure 41 Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer.\n This suggests that restricting the metal layers significantly impacts timing.\n 277 Performing Design Analysis Feedback You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs.\n You could restrict your analysis to your lower-utilization runs by turning off the 278 Performing Design Analysis Feedback visibility of your higher-utilization runs as shown in Figure 42, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals.\n Figure 42 Displaying Lower-Utilization Runs"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges"}, {"role": "assistant", "content": "To insert maximum pattern routing guides along the nonpreferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects mprg_nonpreferred option.\n When you specify this object type, the command creates maximum pattern routing guides parallel to each nonpreferred-direction boundary edge.\n The maximum edge threshold for these routing guides is zero.\n 486 Routing Constraints Feedback By default, The routing guides are inserted only in the top-level block To insert routing guides in all soft macros in a hierarchical block, use the -hierarchical option.\n The routing guides are inserted on all routing layers To insert the routing guides only on specific routing layers, use the -layers option.\n The routing guides have the default metal width specified for the routing layer in the technology file To specify a different width in microns, use the -width_nonpreferred option.\n For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual The routing guides abut the preferred-direction edges The routing guides are offset from the nonpreferred-direction edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns, use the -spacing_nonpreferred option.\n For information about specifying the minimum spacing for a layer, see the \"Minimum Spacing Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual Figure 104 shows the routing guides inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n S is the spacing specified by the -spacing_nonpreferred option.\n W is the width specified by the -width_nonpreferred option.\n 487 Routing Constraints Feedback Figure 104 Routing Guide Perimeter Constraint Objects See Also Using Routing Guides to Limit Edges in the Nonpreferred Direction"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Querying Placement Blockages"}, {"role": "assistant", "content": "To return a collection of placement blockages in the current block that match certain criteria, use the get_placement_blockages comandcomandsget_placement_blockages get_placement_blockages command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Trunk Splitting"}, {"role": "assistant", "content": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split.\n custom.route.bus_split_ignore_width custom.route.bus_split_even_bits The custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section.\n The custom.route.bus_split_even_bits application option requires that you set the custom.route.bus_split_ignore_width application option.\n If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes).\n In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set.\n The spacing between the power and ground rails can accommodate three bits only.\n Figure 163 a shows the two possible results when the custom.route.bus_split_even_bits application option is turned off.\n Figure 163 b shows the result when the custom.route.bus_split_even_bits application option is turned on.\n Figure 163 Splitting Bus Trunk to Route Through Power and Ground Rails 768 Using Custom Routing Application Options Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Registers"}, {"role": "assistant", "content": "Before you run the compile_fusion command on an RTL design, you can create a multibit bus consisting of specific unmapped single-bit registers by using the create_multibit command.\n Then, when you run the compile_fusion command, 247 Performing Multibit Optimization Feedback during the initial_map stage, the tool maps the single-bit cells of the bus created by the create_multibit command into a multibit register bank.\n The single-bit registers you specify with the create_multibit -sort command must Be unmapped Be of the same type Be in the same logical hierarchy Not be part of an existing bus In the following example, the single-bit cells are combined in alphanumeric descending order, which is reg4, reg3, reg2, and reg1: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort descending fc_shell> compile_fusion In the following example the single-bit cells are combined in alphanumeric ascending order, which is reg1, reg2, reg3, and reg4: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort ascending fc_shell> compile_fusion In the following example, the single-bit cells are combined in the specified order, which is reg2, reg4, reg1, and reg3: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort none fc_shell> compile_fusion Note: You must set the compile.flow.enable_multibit application option to true before you run the create_multibit command on unmapped single bit registers.\n If not, the tool issues the following error message: Error: create_multibit command failed: multibit flow is disabled.\n (MBIT-068)"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Aligning by the Right Edges"}, {"role": "assistant", "content": "To align a group by aligning the right edges, use the -alignment right option of the set_rp_group_options command.\n Note: For hierarchical relative placement groups, the bottom-right alignment does not propagate through the hierarchy.\n Figure 175 shows cells that are right aligned.\n 796 Specifying Options for Relative Placement Groups Feedback Figure 176 Bottom-Right-Aligned Relative Placement Group U4 U3 U2 U1 row 3 row 2 row 1 row 0 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Exploring the Detailed Comparison Data"}, {"role": "assistant", "content": "When you launch the QORsum report, the application opens the QOR Summary table, which summarizes high-level timing, power, and congestion metrics for each of your runs.\n This and other summary views help you sort and filter the data to pinpoint the runs you want to explore further.\n Detailed table panels provide deeper insight into your data than can be found on the summary tables.\n For example, a summary table might give a high-level overview of design timing (WNS, TNS, NVE) at each major stage in the flow.\n A detailed table might show more in-depth path-group based timing information, showing the timing numbers for each separate scenario and path group in the design.\n This is only one example.\n There are many detailed table panels in the QORsum report, that shows information like statistics about each library cell instantiated in the design (number of instances, type of cell, total, area), or information about how much wirelength is on each routed metal layer.\n A detailed table lets you view this information for up to six different datasets at once.\n A dataset is a set of data captured for a specific run and stage/label in the flow.\n For example, you might view the route_opt command results for three different runs at once.\n Or you might view one run, but looking at the progression of results across different stages in the design flow (place_opt, clock_opt, route_opt), as shown in the following figure.\n 279 Performing Design Analysis Feedback Figure 43 Path Group Details The flows are shown side by side as columns under each metric.\n For example, the WNS column group (and the column group of each metric) shows the same six columns labeled 1, 2, 5, 6, 9, 10.\n These columns represent the results of each flow, and are given a flow ID number, rather than showing the full flow name, to prevent the columns from being too wide.\n The first column under each metric is the baseline, and the other five are the test flows being compared to that baseline.\n A legend is shown above the table with the flow ID number in a gold box (for the baseline) or a blue box (for the test flows), followed by the flow name.\n You can expand or collapse the legend by clicking the Legend button.\n You can also see the flow ID numbers in the \"Choose Baseline and Visible Runs\" dialog box, which is opened by clicking the Runs button.\n The detailed table views can display up to six runs at one time (your baseline run, plus the first five other runs selected in the Choose Baseline and Visible Runs dialog box).\n To change the runs that are displayed, 1.\n Click the Runs button to open the Choose Baseline and Visible Runs dialog box.\n 2.\n From the Visible Runs (Summary) column, select or deselect the runs accordingly.\n This selects and deselects those runs from the Visible flows (Detailed) column.\n Because a detailed table may show hundreds or even thousands of lines of data, it is not possible to view more than six datasets at a time.\n But if you want to see more details about these metrics across all runs and all flow stages/labels loaded into the QORsum report, there is an alternate view that shows this.\n This is called the Focused View.\n It can be accessed either by clicking the Focused View toggle button at the top of the report (see Figure 1), or by clicking on the frozen columns on the left side of the detailed table.\n In the focused view, you can see the results for all runs and all flow stages for a specific row of data from a detailed table.\n For example, in a path-group based timing detailed table, you might want to focus on the information only for path_group1 in scenarioA.\n To see this, click on the row in the detailed table for that path group and scenario.\n The Focused View for it opens.\n 280 Performing Design Analysis Feedback Using the same path-group timing example, the focused view shows one path group at a time.\n You can change the focus to a different path group by selecting a different scenario or path group name in the drop-down menus at the top of the report.\n See Figure 44 Figure 44 Focused View Drop-down Menu Filtering the Detailed Data Detailed views offer filters to focus on specific data.\n Some views have default filters that are shown automatically.\n For example, the following detailed views have default scenario and path group filters: Path Type Details, Path Group Details, and Logic Level Details.\n You can modify the default filters by Removing the filter by clicking the X symbol before the filter name Changing the filter value Enable and disable the filter by clicking anywhere on the filter but the X symbol or value field You can also apply custom filters to the detailed data.\n To create a custom filter, 1.\n Click the Filter button to display the Add Filter fields, which are shown in the following figure: 2.\n Define the filter by defining the filter criteria and selecting the datasets to include in the results.\n 281 Performing Design Analysis Feedback To define the filter, select the column and comparison type, and then specify the comparison value.\n To perform a numeric comparison, select one of the following comparison types:!= <=, or >= and specify a numeric value in the Value field.\n To perform a string comparison, select the contains comparison type and specify a string value in the Value field.\n To perform a regular expression comparison, select the regexp comparison type and specify a regular expression in the Value field.\n To filter based on the available values of the selected column, select the enum comparison type, which populates the Value field with a drop-down menu that contains the available values, and then enable one or more of the displayed values.\n When a value is enabled, a check mark is displayed before the value.\n To enable or disable a value, highlight the value by clicking it or navigating to it by using the Up and Down arrows, and then press Enter, which toggles the value status.\n You can also type a string in the Value field to filter the available values in the drop-down menu.\n To dismiss selected values, click the X symbol.\n 3.\n Apply the filter by clicking the green check mark.\n For example, to filter the Path Group Details view by displaying the path groups in the func@cworst scenario, define the filter as shown in the following figure:"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Clock-Gate Enable Signals"}, {"role": "assistant", "content": "A clock gate often has an enable signal that is a Boolean expression comprising of one or more of the following reference (or invariant) points: Hierarchical ports Sequential output pins Black box output pins To report the clock gate enable signal as a Boolean function, use the report_clock_gating_enable_condition command.\n You must specify a collection of clock gates to be reported."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating Via Ladder Rules for Electromigration Via Ladders"}, {"role": "assistant", "content": "Instead of explicitly defining via ladder rules for electromigration via ladders, you can use the generate_via_ladder_template command to generate via ladder rules and constraints based on a configuration file.\n The configuration file is an XML file that provides information about the via ladder rules, as well as the association between the via ladder rules and specific pins.\n You must specify the name of the configuration file by using the -config_file option.\n The command generates two script files: A script file that defines the via ladder rules, which is called the template script file This script file contains a create_via_rule command for each template defined in the configuration file, as well as set_attribute commands to set the appropriate via rule attributes.\n By default, the file is named auto_gen_via_ladder_template.tcl.\n To specify a different file name, use the -template_file option.\n A script file that defines the via ladder constraints, which is called the association script file This script file contains set_via_ladder_candidate commands for the pins specified in the configuration file, as well as set_attribute commands to set the is_em_via_ladder_required attribute for the pins to true By default, the file is named auto_gen_via_ladder_association.tcl.\n To specify a different file name, use the -association_file option.\n 449 Inserting Via Ladders Feedback The configuration file has the following syntax: <EmRule> <!\n template definition > <Template name=\" rule_name \"> <Layer name=\" layer_name \" row_number=\" cuts_per_row [max_stagger_tracks=\" count \"] [upper_cut_x_min_spacing=\" x_spacing \"] [upper_cut_y_min_spacing=\" y_spacing \"] />...\n more layers </Template> \u2026 more templates <!\n Pin to template association > <Pin name=\" pin_name \"> <Template name=\" rule_name \"/> </Pin>...\n more associations </EmRule> Each Template section specifies the template for a via ladder rule.\n You can specify one or more Template sections.\n Within a template section, you specify the via ladder structure by specifying the number of cuts per row for each metal layer involved in the via ladder.\n The command uses the information in the configuration file and associated information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file The cut layers that connect the specified metal layers The cut names The minimum required length for each metal layer Note: You must open the block before running the generate_via_ladder_template command to ensure that the command has access to the technology data for the block.\n Each Pin section specifies the template associated with a pin, where the pin name can include the asterisk wildcard character (*).\n You can specify one or more Pin sections.\n The template specified in the Pin section's Template attribute must be one of the templates specified in the Template sections.\n For example, assume you have a configuration file named vl_config that has the following contents: <EmRule> <Template name=\"template_1_3231\"> <Layer name=\"M1\" row_number=\"3\"/> <Layer name=\"M2\" row_number=\"2\"/> <Layer name=\"M3\" row_number=\"3\"/> 450 Inserting Via Ladders Feedback <Layer name=\"M4\" row_number=\"1\"/> </Template> <Pin name=\"*/BCELLD5A11*/Z\"> <Template name=\"template_1_3231\"/> </Pin> </EmRule> To generate the script files to define the via ladder rules and constraints, use the following command: fc_shell> generate_via_ladder_template -config_file vl_config Example 17 shows the template script file generated by this command.\n Example 18 shows the association script file generated by this command.\n Example 17 Template Script File create_via_rule -name template_1_3231 \\ -cut_layer_names {VIA1 VIA2 VIA3} -cut_names {V1S V2S V3S} \\ -cut_rows {2 3 1} -cuts_per_row {3 2 3} set viaRule [get_via_rules template_1_3231] set_attribute $viaRule upper_metal_min_length_table {0.3 0.2 0.4} set_attribute $viaRule for_electro_migration true Example 18 Association Script File foreach_in_collection pin [get_lib_pins -quiet */BCELLD5A11*/Z] { set_attribute -quiet $pin is_em_via_ladder_required true set_via_ladder_candidate $pin -ladder_name \"template_1_3231\" See Also Defining Via Ladder Rules Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing the Threshold-Voltage Filler Cell Information"}, {"role": "assistant", "content": "To remove the filler cell insertion rules and the threshold-voltage type annotations, use the -clear_vt_information option with the create_vtcell_fillers command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Displaying Maps in the GUI"}, {"role": "assistant", "content": "When analysis is complete, the tool saves the design data and analysis results (*.result) in the in-design.redhawk/ design_name.result directory under the RedHawk working directory.\n You must run the open_rail_result command to load the analysis results before displaying a map in the Fusion Compiler GUI.\n Table 70 lists the map types that are supported in the RedHawk Fusion analysis flow.\n Table 70 Analysis Maps Supported in RedHawk Fusion Flow Map Type Description Rail voltage drop map Displays the voltage drop map, which is a color-coded display of voltage drop values overlaid on the physical supply nets.\n For static analysis, the map displays average voltage drop values.\n For dynamic analysis, the map displays peak voltage drop values, average voltage drop values, or peak voltage rise values.\n Note: The tool shows all the layers in the LEF or DEF file on the voltage drop map even if the layers are absent in the Fusion Compiler library file.\n Rail parasitics map Shows parasitic resistance of a given supply net in the block when voltage drop analysis is complete.\n It shows the resistance for any given shape of the net.\n Rail power map Displays instance-based power map or power density map for the block when voltage drop analysis is complete, based on the RedHawk power calculation results.\n Instance-based power map: Shows power values of the cell instances in the block Power density map: Shows power density values for area in the block Rail current map Displays current distribution for the block when voltage drop analysis is complete.\n Rail minimal path resistance map Shows minimum path resistance values for a selected net when minimal path resistance analysis is complete.\n Rail electromigration map Shows current violations for the block when static or dynamic electromigration analysis is complete.\n 932 Displaying Maps in the GUI Feedback Table 70 Analysis Maps Supported in RedHawk Fusion Flow (Continued) Map Type Description Rail instance peak current map Shows peak current values for different instances or areas in the block.\n Rail instance effective voltage drop map Shows effective voltage values of a given instance in the block when voltage drop analysis is complete.\n Rail instance effective resistance map Shows effective resistance values of a given instance in the block when effective resistance analysis is complete.\n Rail instance switch cell Displays current, effective voltage, and voltage difference maps for switch cells in the block when dynamic analysis is complete and switch cell model input files are available.\n If no switch model input file is available, the tool treats these switch cells as black boxes and no rail map is displayed.\n Instance-based current map: This map shows how current flows through the selected switch cell.Instance-based effective voltage map: This map shows the effective voltage at the selected switch cell.Instance-based voltage difference map: This map shows the voltage difference across the selected switch cell.\n To display maps in the Fusion Compiler GUI, 1.\n To load the rail analysis result using the GUI, choose Task > Rail Analysis > 2D Rail Analysis.\n The Block Level 2D Rail Analysis window appears.\n In the window, click the open_rail_result link.\n Alternatively, run the open_rail_result command to load the design data and analysis results (*.result) saved in the design_name directory under the RedHawk working directory when analysis is complete.\n 2.\n In the GUI layout window, choose View > Map and select the map to display.\n In the map, problem areas are highlighted in different colors.\n Move the pointer over an instance to view more information in the InfoTip.\n By default, the tool displays information for all instances in the block.\n To examine information of one specific instance, deselect all the instances and then select the instance to display from the list.\n Use the options in the map panel to change map display: Value: Sets the type of map to display Bins: Changes the number of unique bins used to display the map From: and To: Sets the range of density values displayed in the power density map Text: Displays the calculated values in the layout; if the values are not visible, zoom in to view them 933 Displaying Maps in the GUI Feedback Examples The following examples show how to display various types of maps in the GUI: Figure 212 shows how to display a rail instance effective voltage drop map and check for hotspots in the instance effective voltage drop map.\n Figure 213 shows how to display a rail map for the switch cells in the block and examine the voltage information of the selected switch cell.\n Figure 214 shows how to display a power density map for the block.\n 934 Displaying Maps in the GUI Feedback Figure 212 Displaying a Rail Instance Effective Voltage Drop Map Hover over the red spot to see the voltage drop number on the instance Select the instance to display Choose Rail Instance Effective Voltage Drop Click \"Zoom to Critical\" to examine the critical area Histogram for the range of map values (in volts) Options for map display control 935 Displaying Maps in the GUI Feedback Figure 213 Displaying Maps for Switch Cells Choose Rail Instance Switch Cell.\n Select the instance to Choose the type of map to display The tool shows the switch cells display on the selected power domain in the map.\n In the map, hover over a switch cell to examine its voltage information 936 Displaying Maps in the GUI Feedback Figure 214 Displaying a Power Density Map Choose Rail Power Choose Density to display power density values See Also Specifying RedHawk and RedHawk-SC Working Directories 937 Displaying ECO Shapes in the GUI Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Voltage Areas"}, {"role": "assistant", "content": "A voltage area is a physical placement area for the cells associated with a power domain.\n For multivoltage designs, the power domains are defined in the UPF specification.\n For single-voltage designs, the tool creates a default power domain when you read the Verilog netlist and associates it with a default voltage area, which comprises the core area of the block.\n The placer treats a voltage area the same as an exclusive move bound; it must place the cells in a voltage area within a specified region and it must place all other cells outside of the voltage area.\n Voltage areas can be rectangular or rectilinear.\n In addition, they can be disjoint, nested, or overlapping.\n For overlapping voltage areas, the effective shape of each voltage area is determined by the stacking order of the voltage area shapes.\n To define a voltage area, use the create_voltage_area command.\n When you define a voltage area, at a minimum, you must specify the power domains associated with the voltage area.\n To specify the power domains, use the -power_domains option.\n You can specify one or more power domains; however, all specified power domains must have the same primary supply net.\n If you specify a single power domain, the name of the voltage area is derived from the name of the power domain.\n If you specify multiple power domains, you must specify a name for the voltage area by using the -name option.\n A voltage area consists of one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping.\n To define the boundaries of these shapes, use the -region option with the create_voltage_area command (if you are creating a new voltage area) or the create_voltage_area_shape command (if you are adding shapes to an existing voltage area).\n Note that you can specify one or more shapes when using the create_voltage_area command, but only a single shape in each create_voltage_area_shape command.\n To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly } { urx ury }} To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 } { x2 y2 } { x3 y3 } { x4 y4 }...} If a voltage area consists of multiple abutting or overlapping shapes, you can merge the shapes into a minimum set of disjoint shapes based on the stacking order of the shapes.\n For information about how to merge the voltage area shapes, see Merging Voltage Area Shapes The tool also uses the stacking order to resolve overlapping shapes from different voltage areas.\n For information about resolving overlapping voltage areas, see Resolving Overlapping Voltage Areas 120 Setting Up Multivoltage Designs Feedback To ensure that no shorts occur at the boundaries of the voltage areas, you can define guard bands for the voltage areas, which act as hard keepout margins surrounding the voltage areas.\n If you define guard bands for a voltage area shape, the guard bands are included in the effective boundary of the shape; however, they are not included in the effective placement area of the voltage area.\n For information about defining guard bands, see Defining Guard Bands To modify an existing voltage area, use the set_voltage_area command, as described in Modifying Voltage Areas Multivoltage designs typically have power domains that are shut down and powered up during the operation of the chip while other power domains remain powered up.\n When dealing with shutdown domains, there can be some situations in which certain cells in the shutdown portion need to continuously stay active, such as for implementing retention registers, isolation cells, retention control paths, and isolation enable paths.\n These cells are referred to as always-on cells.\n To define a special placement area for always-on cells (an always-on well) within a voltage area, define an exclusive move bound within the boundary of the voltage area.\n For information about defining exclusive move bounds, see Defining Move Bounds After creating the voltage areas, run the check_mv_design command to verify that the design does not have any multivoltage violations."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock-Gating Enable Source Selection"}, {"role": "assistant", "content": "By default, the tool extracts the clock-gating enable condition from one of these sources: Signals connected directly to the synchronous enable pin of the sequential element, as shown in Figure 48 Figure 48 Directly Connected Enable Signal The enable condition on the feedback loops of the input and output data pins of the sequential element, as shown in Figure 49 Figure 49 Enable Signal in a Feedback Loop When using clock gating, you can specify the signal source of the enable logic.\n The set_clock_gating_objects -enable_source option applies to all objects specified with the -force or -include options in the same command.\n If you use the -enable_source option, you cannot use the -clear -reset, or -exclude options.\n 296 Setting Up Clock Gating Feedback The -enable_source option can be one of the following: none enable_pin_only feedback_loop_only both (default) prefer_enable_pin prefer_feedback_loop For example, the following command inserts an always-enabled clock-gating cell: set_clock_gating_objects -force [get_cells u_dfx/input_b_reg*] \\ -enable_source none The following command uses the enable signal from the synchronous enable pin, if there is one.\n Otherwise, the tool uses the enable on the feedback loop of the register.\n set_clock_gating_objects -include [get_cells u_dfx/input_c_reg*] \\ -enable_source prefer_enable_pin"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Identifying the Clock Endpoints"}, {"role": "assistant", "content": "When deriving the clock trees, the tool identifies two types of clock endpoints: Sink pins clock tre synthesistop pindefinedexceptions for clock tre synthesistop pinsclock tre exceptionstop pinclock tre sinksdefining Sink pins are the clock endpoints that are used for delay balancing.\n The tool assigns an insertion delay of zero to all sink pins and uses this delay during delay balancing.\n During clock tree synthesis, the tool uses sink pins in calculations and optimizations for both design rule constraints and clock tree timing (skew and insertion delay).\n Sink pins are also referred to as balancing pins.\n Ignore pins clock tre synthesisexclude pindefinedexceptions for clock tre synthesisexclude pinsclock tre exceptionsexclude pin Ignore pins are clock endpoints that are excluded from clock tree timing calculations and optimizations.\n The tool uses ignore pins only in calculations and optimizations for design rule constraints.\n During clock tree synthesis, the tool isolates ignore pins from the clock tree by inserting a guide buffer before the pin.\n Beyond the ignore pin, the tool never performs skew or insertion delay optimization, but does perform design rule fixing.\n The tool identifies the following clock endpoints as sink pins: A clock pin on a sequential cell (a latch or flip-flip), unless that cell drives a generated clock A clock pin on a macro cell 342 Defining the Clock Trees Feedback The tool identifies the following clock endpoints as clock tre synthesisimplicitexclude pin ignore pins: Source pins of clock trees in the fanout of another clock For example, in Figure 73, the source pin of the driven clock (clk2) is an ignore pin of the driving clock (clk1).\n Sinks of the driven clock are not considered sinks of the driving clock.\n Figure 73 Cascaded Clock With Two Source Clocks CLK clk1 clk2 Nonclock input pins of sequential cells Three-state enable pins Output ports Incorrectly defined clock pins (for example, the clock pin does not have trigger edge information or does not have a timing arc to the output pin) Buffer or inverter input pins that are held constant by using the set_case_analysis command Note: The tool does not synthesize a clock tree if its source is held constant by using the set_case_analysis command.\n Input pins of combinational cells or integrated clock-gating cells that do not have any fanout or that do not have any enabled timing arcs To verify that the tool has correctly identified the sink pins and ignore pins, examine the clock trees in the GUI, as described in Analyzing Clock Trees in the GUI If the default sink and ignore pins are correct, you are done with the clock tree definition.\n Otherwise, first identify any timing settings, such as disabled timing arcs and case analysis settings, that affect the clock tree traversal.\n To identify disabled timing arcs in the block, use the report_disable_timing command.\n To identify case analysis settings in the block, use the report_case_analysis command.\n Remove any timing settings that cause an incorrect clock tree definition.\n 343 Defining the Clock Trees Feedback If necessary, you can override the default balancing and ignore pin settings by using the set_clock_balance_points command, as described in Defining Clock Tree Exceptions The implicit ignore on an intermediate pin can be inferred by any of the following reasons: All the register pins in the fanout are EXPLICIT IGNORE Disabled path on a MUX input is caused by the set_case_analysis command Disabled timing arc on a downstream pin is set by the set_disable_timing set_false_path commands, disable timing due to conditional arcs.\n set_sense -stop_propogation constraint on a downstream pin Dangling pin in the downstream path Downstream path goes to a data pin of a register or a subblock Downstream path has an unconstrained output port without any set_clock_balance_point -consider_for_balancing true setting Downstream path has a constrained set_output_delay output port Pins on the path to cascaded create_clock definition Note: This implicit or explicit ignore does not essentially mean that the clock endpoints are excluded from clock tree calculations.\n Explicit ignore means, the endpoints are not considered for skew balancing with other endpoints of the clock, but the portion is considered for DRC fixing in clock tree."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Advanced Logic Restructuring"}, {"role": "assistant", "content": "To improve the area, timing, and power QoR, you can enable advanced logic restructuring.\n To enable this feature for the final_opto stage of the compile_fusion and clock_opt commands, use the opt.common.advanced_logic_restructuring_mode application option, as shown in the following table.\n Table 15 Settings for the opt.common.advanced_logic_restructuring_mode Application Option To do this Use this setting Perform no restructuring none (default) Perform restructuring to improve the area QoR area Perform restructuring to improve the timing QoR timing Perform restructuring to improve the power QoR power Perform restructuring to improve the area and timing QoR area_timing Perform restructuring to improve the timing and power QoR timing_power Perform restructuring to improve the area and power QoR area_power Perform restructuring to improve the area, timing, and power QoR area_timing_power 184 Setting Up for Power-Related Features Feedback When restructuring, the tool does not Restructure across logical hierarchy Consider cells with dont_touch size_only, or fixed attributes Accept the results if it increases the wire length However, if your design does not have congestion or routing issues, you can specify that the tool accepts the restructuring results even if it increases the wire length by setting the opt.common.advanced_logic_restructuring_wirelength_costing application option to medium or none.\n The default is high"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Cross-Probing Information for Optimized Registers"}, {"role": "assistant", "content": "The compile_fusion command mergers registers and removes constant and unloaded registers during register optimization.\n To print the RTL file name and line number of these optimized register in the compile_fusion command log file and in the report_transformed_registers command output, set the compile.seqmap.print_cross_probing_info_for_removed_registers application option to true The following table shows the messages printed out during the different types of register optimization.\n Table 21 Cross-Probing Information Messages Printed During Register Optimization Register Optimization Information Message Constant register removal Information: The register 'a/b_reg { {/user/test/design.v:49} }' is removed as constant 0 (SQM-4100) Unloaded register removal Information: The register 'a/c_reg{ {/user/test/design.v:193} }' is removed because it is unloaded.\n (SQM-4101) Register merging Information: The register 'a_reg[1] { {/user/testcases/top.v:113} }' is removed because it is merged to 'a_reg[0]'.\n (SQM-4102) 242 Performing Multibit Optimization Feedback The following example output shows the cross probing information that is reported by the report_transformed_registers command: Legend: c0r - Constant 0 Register Removed c1r - Constant 1 Register Removed ul - Unloaded Removed inv - Inverted rep - Replicated mrg - Merged register mb - Mutibit mbd - Mutibit debanked Register Transformation Filename: Line number mega_shift_reg c0r {{a/b/test1.v:112}} Carry_Flag_reg ul {{a/b/test2.v:117}} mega_shift_reg[10] mrg (mega_shift_reg[31]) {{a/b/test3.v:121 }}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Clock Trees"}, {"role": "assistant", "content": "To remove the buffers and inverters on a clock tree, use the remove_clock_tre comandcomandsremove_clock_tre remove_clock_trees command.\n The remove_clock_trees commands traverses the clock tree from its root to its sinks and removes all buffers and inverters, except those with dont_touch or size_only attributes.\n Cells beyond clock tree exceptions are considered part of the clock tree, but cells beyond a clock-to-data pin are considered part of the data path and are 394 Implementing Clock Trees and Performing Post-CTS Optimization Feedback not removed.\n In addition to removing the buffers and inverters, the remove_clock_trees command resets the attributes related to clock tree synthesis.\n Note: The remove_clock_trees command does not support clock mesh nets.\n By default, this command removes the buffers and inverters from all clock trees in all modes.\n To remove the buffers and inverters from specific clock trees, use the -clocks option to specify the clock trees.\n By default, when you use the -clocks option, the clocks are selected from the current mode.\n To select clocks from a specific mode, use the get_clocks -mode command to select the clocks.\n For example, to remove only the clock tree in the current mode named my_clk, use the following command: fc_shell> remove_clock_trees -clocks [get_clocks my_clk] Table 28 shows how clock tree removal is affected by the structure of the clock tree.\n Table 28 Clock Tree Removal Behavior Object Impact on clock tree removal Boundary cell Removed.\n Cells on don't touch net Preserved.\n Don't touch cell Preserved.\n Fixed cell Preserved.\n Generated clock Preserved, if generated clock is defined on buffer/inverter pin.\n Traversal and clock tree removal continue past the generated clock.\n Guide buffer Removed.\n Integrated clock-gating (ICG) cell Preserved.\n Traversal (and clock tree removal) continues past the integrated clock-gating cell.\n Block abstraction model Preserved.\n Traversal (and clock tree removal) continues past the block abstraction model.\n Inverter Removed in pairs only.\n If a clock tree contains a single inverter, it is not removed.\n Isolation cell Preserved.\n Level shifter Preserved.\n 395 Implementing Multisource Clock Trees Feedback Table 28 Clock Tree Removal Behavior (Continued) Object Impact on clock tree removal Three-state buffer Preserved.\n Traversal (and clock tree removal) stops at the three-state buffer.\n Buffer or inverter added beyond exception Removed.\n By default, the remove_clock_trees command removes the detail route shapes of the clock nets it removes.\n However, you can preserve the route shapes of the clock nets by setting the shape_use attribute of the clock nets to user_route"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Viewing Minimum Path Resistance Analysis Results"}, {"role": "assistant", "content": "When the analysis is complete, run the report_rail_result -type minimum_path_resistance command to display a minimum path resistance map, write the results to an output file, or query the attributes on the cell instances or pins.\n The following example writes the calculated minimum path resistances for the VDD net to an output file called minres.rpt.\n fc_shell> open_rail_result fc_shell> report_rail_result -type minimum_path_resistance \\ -supply_nets { vdd } minres.rpt fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669 The output minres.rpt report includes the entire resistance information.\n fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669 909 Performing Minimum Path Resistance Analysis Feedback To write out a detailed minimum resistance path report for a cell instance, run the report_rail_minimum_path command and specify the net and the cell to report.\n To see the segment-by-segment resistance of that minimum resistance path shown in the GUI, use the -error_cell option of the report_rail_minimum_path command to save the geometries on the path of the minimum path resistance to an error cell.\n You can then open the error cell in an error browser and check the minimum resistance path from the pin of the cell to the nearest tap and trace each go-through geometries.\n In the following example, all geometries on the minimum resistance path are traced and written to the error cell named test.err.\n fc_shell> open_rail_result fc_shell> report_rail_minimum_path -cell U19 -net VDD -error_cell Shown in Figure 206, each geometry is classified by layer in the error browser.\n Click a geometry to check for detailed information, such as IR drop, resistance, bounding box, and so on.\n In the GUI, the traced path is highlighted in yellow in the design layout (see Figure 207 ).\n Figure 206 Displaying Error Cells in the Error Browser 910 Performing Minimum Path Resistance Analysis Feedback Figure 207 Traced Segment is Highlighted in the Design Layout See Also Displaying Maps in the GUI Writing Analysis and Checking Reports Querying Attributes"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using the Global Router During Initial Clock Tree Synthesis"}, {"role": "assistant", "content": "By default, initial clock tree synthesis uses the virtual router to build the clock trees.\n For designs with complex floorplans, this can introduce congestion hotspots and degrade clock QoR after clock routing.\n The tool can use the global router during the initial clock tree synthesis stage of the synthesize_clock_trees and clock_opt commands.\n To enable this feature, set the cts.compile.global_route_aware_buffering application option to true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running the signoff_check_drc Command"}, {"role": "assistant", "content": "To perform signoff design rule checking by running the signoff_check_drc command, 1.\n Set up the IC Validator environment as described in Setting Up the IC Validator Environment 2.\n (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 665 Performing Signoff Design Rule Checking Feedback 3.\n Set the application options for signoff design rule checking.\n At a minimum, you must specify the foundry runset to use for design rule checking by setting the signoff.check_drc.runset application option.\n For information about the options for command-based signoff design rule checking, see Setting Options for Signoff Design Rule Checking 4.\n Save the block to disk.\n When you run signoff design rule checking, the IC Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the save_block command to save the current state of the block before running signoff design rule checking.\n 5.\n Run signoff design rule checking by using the signoff_check_drc command.\n By default, the signoff_check_drc command performs the following tasks: 1.\n Loads the block into the IC Validator tool, as described in Reading Blocks for Signoff Design Rule Checking 2.\n Performs signoff design rule checking, as described in Signoff Design Rule Checking 3.\n Generates an error data file and IC Validator results files, as described in Signoff DRC Results Files You can use the results files to view the violations in the error browser, as described in Using the Error Browser, or to perform automatic design rule fixing, as described in Automatically Fixing Signoff DRC Violations You can use the following methods to analyze the DRC violations reported by the signoff_check_drc command: View the violations in the error browser, as described in Using the Error Browser.\n View the density of violations in a heat map, as described in Viewing the Violations in an ICV Heat Map See Also Checking Signoff Design Rules Interactively in the GUI 666 Performing Signoff Design Rule Checking Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Hierarchical Implementation"}, {"role": "assistant", "content": "The following topics describe how to perform synthesis, placement, optimization, clock tree synthesis, routing, and postroute optimization on hierarchical designs.\n Performing Hierarchical Synthesis Using Abstracts Performing Hierarchical Synthesis Using ETMs Performing Prechecks for Hierarchical Synthesis Flows Providing Block-Level Test Models Specifying Block-Level Power Intent Overview of Abstract Views Creating Abstract Views Reporting Abstract Inclusion Reasons Making Changes to a Block After Creating an Abstract Creating a Frame View Linking to Abstract Views at the Top-Level Changing the Block From Abstract to Design View Linking to Subblocks With Multiple Labels Specifying the Editability of Blocks From the Top-Level Preparing for Top-Level Closure With Abstracts Checking Designs With Abstracts for Top-Level-Closure Issues Performing Top-Level Closure With Abstract Views Creating ETMs and ETM Cell Libraries Linking to ETMs at the Top Level Performing Top-Level Closure With ETMs Transparent Hierarchy Optimization 817 Performing Hierarchical Synthesis Using Abstracts Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Redundant Vias"}, {"role": "assistant", "content": "Redundant via insertion is an important design-for-manufacturing (DFM) feature that is supported by Zroute throughout the routing flow.\n In each routing stage, Zroute concurrently optimizes via count as well as wire length.\n The redundant via result is measured by the redundant via conversion rate, which is defined as the percentage of single vias converted into redundant vias.\n You should also pay attention to the number of unoptimized single vias.\n If a block has fewer unoptimized single vias, it is usually better for DFM.\n The following topics describe how to insert redundant vias: Inserting Redundant Vias on Clock Nets Inserting Redundant Vias on Signal Nets 621 Inserting Redundant Vias Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying a Design Scenario for Rail Analysis"}, {"role": "assistant", "content": "By default, RedHawk or RedHawk-SC Fusion analyzes only the current design scenario for a multicorner-multimode design.\n To specify a different design scenario for rail analysis, use the rail.scenario_name application option.\n The tool honors the specified design scenario for the IR-driven features in power integrity flow, such as IR-driven placement, IR- driven concurrent clock and data optimization, and IR-driven optimization.\u200b Here is a script example: open_lib open_block set_app_option -name rail.technology -value 7 set_app_options -name rail.tech_file -value./Apache.tech set_app_options -name rail.lib_files -value {\\ A.lib \\ B.lib } set_app_options -name rail.switch_model_files -value {./switch_cells.txt } source./test_taps.tcl current_scenario func_max set_app_options -name rail.scenario_name -value func_typ analyze_rail -voltage_drop"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Threshold-Voltage-Based Filler Cell Insertion"}, {"role": "assistant", "content": "By default, the create_vtcell_fillers command fills all empty space in the horizontal standard-cell rows of the entire block.\n You can control the following aspects of the filler cell insertion: The region in which to insert the filler cells Use the -region option to restrict filler cell insertion to the specified regions.\n Use the -voltage_area option to restrict filler cell insertion to the specified voltage areas.\n The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name number To identify the filler cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix filler_library_cell_name number To change the separator character from the default exclamation mark (!), use the -separator option.\n 658 Inserting Metal Fill Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Optimizing Datapaths"}, {"role": "assistant", "content": "Th following script disables the ungrouping of the DP_OP cell with datapath gating element add_3: # Disable ungrouping of DP_OP with datapath gating set_datapath_gating_options -ungroup false [get_cells add_3] Analyzing Datapath Extraction To get the best QoR results from datapath optimization, ensure that the biggest possible datapath blocks are extracted from the RTL code during compile.\n To examine how the datapath blocks will be extracted from your RTL before compile, use the analyze_datapath_extraction command.\n The command analyzes the arithmetic contents of the design and provides feedback, so you can improve the RTL code as needed.\n The following example shows a datapath report: Cell : DP_OP_123_2304_10297_J1 Current Implementation : str(area,speed) Contained Operations : add_30(test.v:30) add_30_2(test.v:30) mult_36(test.v:36) Multiplier Arch : benc_radix4 Data Var Type Class Width Expression PI_0 PI Unsigned 6 PI_1 PI Unsigned 1 PI_2 PI Unsigned 24 T16 IFO Unsigned 7 PI_0 + PI_1 (test.v:30) PO_0 PO Unsigned 30 PI_2 * T16 (test.v:36) 225 Controlling Mapping and Optimization Feedback To report the resources and datapath blocks used in the design, use the report_resources command.\n To report the implementation overview, specify the -summary with the report_resources command.\n For example, fc_shell> report_resources -hierarchy Controlling Datapath Gating The following figure shows signal transitions of the inputs of a DP_OP cell that is generated during datapath gating optimization.\n To control datapath gating, use the set_datapath_gating_options command.\n The following script disables datapath gating on the datapath element add_3: # Disable datapath gating on particular operator set_datapath_gating_options -enable false [get_cells add_3]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Placement-Aware Clock Gating"}, {"role": "assistant", "content": "When you enable placement-aware clock gating, the tool performs the following optimizations: Replication of clock gates with timing-critical enables Adjustment of clock gates so they are placed closer to their gated registers Automatic clock network latency annotation for clock-gate cells To enable this feature, set the compile.clockgate.physically_aware application option to true.\n (The default is false.) The example in Figure 61 shows the difference between using and not using physically- aware clock gating.\n In this layout view, you can see that the integrated clock gates (shown in red) are physically closer to their gated registers.\n 316 Fanin-Based Sequential Clock Gating Feedback Figure 61 Placement-Aware Clock Gating Clock gate cells are shown in red Gated clock nets are shown in blue Placement-Aware Clock Gating Disabled Placement-Aware Clock Gating Enabled"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Datapath Implementation"}, {"role": "assistant", "content": "All the extracted datapath elements and the synthetic operators are implemented by the DesignWare datapath generator in Fusion Compiler.\n The DesignWare datapath generator uses the smart generation technology to perform the following tasks: Implement datapath blocks using context-driven optimizations Revisit high-level optimization decisions for a given timing context Consider logic library characteristics Use these commands and application option for datapath implementation: set_datapath_architecture_options This command controls the strategies used to generate the datapath cells for arithmetic and shift operators.\n The following example specifies to use Booth-encoded architectures to generate multiplexers: fc_shell> set_datapath_architecture_options -booth_encoding true set_implementation This command specifies the implementation to use for dividers and synthetic library cell instances with a specified name.\n The following example specifies to use the cla3 implementation for the instantiated DesignWare cell U1.\n fc_shell> set_implementation cla3 U1 set_synlib_dont_use 224 Controlling Mapping and Optimization Feedback This command prevents using specific implementation.\n The following example specifies not to use the rpl implementation.\n fc_shell> set_synlib_dont_use \\ {dw_foundation/DW_div/cla standard/DW_div/rpl} compile.datapath.ungroup By default, all DesignWare cells and datapath blocks are ungrouped during timing optimization.\n To disable the ungrouping, set the compile.datapath.ungroup application option to false, changing from its default of true.\n For example, fc_shell> set_app_options \\ -name compile.datapath.ungroup -value false"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Balance Mode Option"}, {"role": "assistant", "content": "You use the custom.route.balance_mode application option in interposer designs to reduce the skews caused by wire length and via cut count differences.\n This topic describes how to set the custom.route.balance_mode application option and provides examples to demonstrate its use.\n To route using the balance mode: Set the custom.route.balance_mode application option to true.\n set_app_options -name custom.route.balance_mode -value true When custom.route.balance_mode is true: The Custom Router creates feedthrough routes between two \u03bcbumps and a C4 bump on the same net.\n The wire lengths between the \u03bcbumps and the C4 bump are equal.\n The number of via cuts is the same in all related \u03bcbump-C4 bump connections.\n Example 1 shows how the custom.route.balance_mode option is used when routing \u03bcbumps to a C4 bump.\n The designated routing layers are M1 through M5.\n The M2 and M4 772 Routing With the Custom Router Feedback layers are used for horizontal connections; and the M1, M3, and M5 layers are used for vertical connections.\n The number of via cuts and the array dimensions are also defined.\n Example 42 Routing with custom.route.balance_mode turned on create_routing_rule skew -widths {M1 6 M2 6 M3 6 M4 6 M5 25} -vias {{VIA12_1cut 3x3 R} {VIA23_1cut 3x3 R} {VIA34_1cut 3x3 R} {VIA45_1cut 2x5 R}} set_routing_rule $nets_to_route -rule skew -max_routing_layer M5 -min_routing_layer M1 set_attribute [get_layers \"M2 M4\"] routing_direction horizontal set_attribute [get_layers \"M1 M3 M5\"] routing_direction vertical set_ignored_layers -min_routing_layer M1 -max_routing_layer M5 set_app_options -list {custom.route.balance_mode true} route_custom -nets $nets_to_route The results from the example show that the wire lengths and the number of vias are the same in each of the four \u03bcbump-to-C4 bump connections."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock-Gate Multilevel Expansion"}, {"role": "assistant", "content": "It is difficult to determine the optimum number of clock-gate levels manually.\n The Fusion Compiler tool can analyze all clock gates and insert additional clock gates to take advantage of shared enable signals.\n Inserting additional clock gates might improve power, area, or other metrics, depending on the design.\n If six or more clock gates share an enable signal, the tool inserts an additional level of clock gates.\n The new clock gates are then considered for further level expansion.\n As a result, the tool might insert multiple levels of clock gates during this operation.\n To allow the tool to expand the number of clock-gate levels, set the compile.clockgate.enable_level_expansion application option to true (the default is false ) and set the compile.clockgate.max_number_of_levels application option to a nonzero value (the default is 0).\n In this case, the tool adds clock gates until either of the following conditions is met: All common enable signals are identified and used for multilevel clock-gate expansion.\n The user-specified maximum number of clock-gate levels is reached.\n The tool names a newly-inserted clock gate as follows, based on the status of the set of clock gates whose enable functions are modified by the new clock gate: If at least one of the clock gates is a tool-inserted clock gate, the base name is clock_gate_ml.\n The name is appended with the register base name, similar to the naming convention for other tool-inserted clock gates.\n If all of the clock gates are preexisting clock gates, the tool uses the name of the preexisting clock gate with the largest fanout and appends _ml_pe The compile.clockgate.max_number_of_levels application option specifies the maximum number of allowed clock-gate levels.\n The default is 0, which allows an infinite number of levels.\n However, to use the clock-gate level expansion capability, you must set this application option to a nonzero value (in addition to setting the compile.clockgate.enable_level_expansion application option to true ).\n If you specify clock-gate level expansion, but the maximum number of allowed levels is low, the expansion operation cannot take full advantage of the tool's ability to analyze common enable signals.\n To enable or disable clock-gate level expansion for specific clock gates, use the set_clock_gate_transformations -expand_levels command.\n 310 Controlling the Number of Clock-Gate Levels Feedback The following usage notes apply: New clock gates inherit the constraints set by the set_clock_gate_transformations set_clock_gate_style set_dont_touch set_size_only set_lib_cell_purpose and set_boundary_optimization commands.\n Clock-gate latency estimations are updated after the insertion operation.\n When the insertion operation modifies the enable signal of a clock gate, the gate retains its original designation of being either preexisting or tool-inserted.\n Self-gating is restricted from adding another clock-gate level if the maximum number of levels is already reached.\n Integrated clock gates inside multibit cells are counted as part of the clock-gate level count.\n However, they are not candidates for clock-gate level expansion.\n New clock gates do not inherit timing exceptions."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Voltage Drop Analysis"}, {"role": "assistant", "content": "Note: Before running the analyze_rail command to calculate voltage drops and current violations, ensure you have provided the input files required by each analysis mode.\n For more information about preparing input files, see Preparing Design and Input Data for Rail Analysis Voltage drop analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n To invoke the RedHawk/RedHawk-SC tool for calculating voltage drops of the specified power and ground networks, use the analyze_rail command with the following options: Use the -voltage_drop option to specify the analysis mode.\n static : Performs static voltage drop analysis.\n dynamic : Performs dynamic voltage drop analysis.\n dynamic_vectorless : Performs dynamic voltage drop analysis without Verilog Change Dump (VCD) inputs.\n dynamic_vcd : Performs dynamic voltage drop analysis with VCD inputs.\n When enabled, use the -switching_activity option to specify a switching activity file.\n Use the -nets option to specify the power and ground supply nets to analyze.\n The tool considers all the switched or internal power nets of the specified power nets in the analysis.\n You do not need to explicitly specify the internal power nets.\n (Optional) Use the -switching_activity option to specify a switching activity file.\n The supported file formats are: VCD SAIF, and ICC_ACTIVITY.\n When not specified, by default the tool uses the toggle rate for rail analysis.\n 900 Performing Voltage Drop Analysis Feedback Note: If you are using the dynamic vector-free mode, you do not need to provide switching activity information.\n To specify a switching activity file, use the -switching_activity option by using the following syntax: -switching_activity { type file_name strip_path ] [ start_time end_time ]} VCD : Specifies a VCD file that is generated from a gate-level simulation.\n By default, rail analysis reads and uses all time values in the VCD file.\n To specify the time window to read from the VCD file, use the optional start_time and end_time arguments with the -switching_activity option.\n When specified, the tool reads all time values from the VCD file, but uses only the specified time window for rail analysis.\n SAIF : Specifies one or more SAIF files generated from a gate-level simulation.\n icc_activity : Runs the Fusion Compiler write_saif command to generate a SAIF file that contains the user-annotated and simulated switching activity (including state-dependent and path-dependent information) for the complete design without running the propagation engine.\n The strip_path argument removes the specified string from the beginning of the object names.\n Using this option modifies the object names in the VCD or SAIF file to make them compatible with the object names in the block.\n The strip_path argument is case- sensitive.\n (Optional) By default, the tool uses the RedHawk/RedHawk-SC power analysis feature to calculate the power consumption of the specified power and ground network.\n If you prefer having the Fusion Compiler tool generate the necessary power data for rail analysis, set the -power_analysis option to icc2 For a detailed description about how to run power analysis using the Fusion Compiler report_power command.\n (Optional) By default, the analyze_rail command automatically generates a GSR file for running RedHawk rail analysis.\n To specify an external GSR file to append to the GSR file generated in the current run, use the -extra_gsr_option_file option.\n (Optional) Use the -redhawk_script_file option to specify an existing RedHawk script file generated in an earlier analyze_rail run.\n When using an existing script file for rail analysis, the tool honors the settings in this file and ignores all other currently enabled options.\n For example, if you run the 901 Performing Voltage Drop Analysis Feedback analyze_rail -voltage_drop static -redhawk_script_file myscript.tcl command, the tool ignores the -voltage_drop option setting.\n When the -redhawk_script_file option is not specified, you must specify the nets to analyze by using the -nets option.\n The following example performs static voltage drop analysis on the VDD and VSS nets with the optional settings defined in a GSR configuration file.\n fc_shell> analyze_rail -voltage_drop static -nets {VDD VSS} \\ -extra_gsr_option_file add_opt.gsr"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Diodes After Detail Routing"}, {"role": "assistant", "content": "You can fix antenna violations after detail routing by explicitly specifying which violations to fix and providing constraints for fixing them.\n Based on the specified constraints and the setting of the route.detail.diode_insertion_mode application option, Zroute either inserts new diodes or reuses existing spare diodes to fix the specified violations.\n To insert diodes after detail routing, use the create_diodes command.\n When you use this command, you must use the -options option to specify the location of each antenna violation to fix by specifying the port and cell instance, the reference cell for the diode, the number of diodes to insert, the highest allowed routing layer used for connecting the diode, and the maximum distance from the specified pin that the diode can be inserted.\n If a diode cannot be inserted or reused within the specified distance, the tool does not insert a diode for that violation.\n Use the following format to specify these values: port_name instance_name diode_reference number_of_diodes max_routing_layer max_routing_distance Note: You can use this command to insert diodes for top-level ports by specifying the name of the top-level block for the cell instance.\n 620 Inserting Redundant Vias Feedback The create_diodes command uses the following application options to control diode insertion: To control whether Zroute inserts new diodes or reuses spare diodes, set the route.detail.diode_insertion_mode application option.\n To control whether Zroute can reuse filler cell locations, set the route.detail.reuse_filler_locations_for_diodes application option.\n To specify the logic hierarchy in which to insert the diodes for top-level ports, set the route.detail.use_lower_hierarchy_for_port_diodes application option.\n For example, to insert 2 Adiode diode cells to fix an antenna violation on the A port of the CI cell instance, where the diodes must be inserted using no higher layer than M5 and within 2.5 microns of the port, enter the following command: fc_shell> create_diodes {{A CI Adiode 2 M5 2.5}}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Dense Tap Arrays"}, {"role": "assistant", "content": "dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the create_tap_cells command.\n To insert a dense tap array, use the create_dense_tap_cells command.\n You must specify the following information: The tap cell used in the tap wall (the -lib_cell option) You must specify the same tap cell as when you ran the create_tap_cells command.\n By default, the tool uses the following naming convention for inserted tap cells: tapfiller!\n library_cell_name number Use the -separator option to change the separator character from its default of \"!.\" To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: tapfiller!\n prefix library_cell_name number The tap distance (the -distance option) The specified distance must be smaller than the tap distance used by the create_tap_cells command.\n The tap insertion region (the -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} The create_dense_tap_cells command first removes the existing tap cells that are completely within the tap insertion region, and then reinserts the tap cells with the specified tap distance to create a denser array in the specified region.\n To avoid tap rule violations, specify the same tap cell insertion pattern as was used by the create_tap_cells command.\n The create_dense_tap_cells command supports the following options to control the tap cell insertion: -offset -pattern -skip_fixed_cells, and -at_distance_only.\n For details about these options, see the man page.\n After insertion, the command fixes the placement of the inserted tap cells.\n 592 Performing Boundary Cell Insertion Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Repeater Groups"}, {"role": "assistant", "content": "To remove a group of repeaters, use the remove_eco_repeater command.\n The nets are restored to their original names and routes shapes."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Physical Constraints for Placement and Legalization"}, {"role": "assistant", "content": "During placement and legalization, the floorplan information dictates where cells are placed.\n The following topics describe how to specify additional physical constraints that affect placement and legalization: Defining Keepout Margins Defining Area-Based Placement Blockages Defining Placement Bounds Defining Placement Attractions Specifying Locations for Unmapped Cells Defining Cell Spacing Constraints for Legalization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Abstract Inclusion Reasons"}, {"role": "assistant", "content": "In the Fusion Compiler tool, the create_abstract command includes netlist objects such as the cells, nets, and pins in the abstract view at both the top-level and block-level.\n This command reports the reasons for the inclusion of netlist objects.\n 836 Making Changes to a Block After Creating an Abstract Feedback To report the reasons for including specific netlist objects in the abstract view, you can use the report_abstract_inclusion_reason command for objects across all hierarchies in the abstract.\n For each reason reported, a reason code is displayed.\n These reason codes correspond to the valid reasons for inclusion in the abstract.\n There can be multiple reasons for the same netlist object.\n Note: The report_abstract_inclusion_reason command does not report reasons for the hierarchical cells or pins on hierarchical cells.\n You can perform reason reporting from the top-level design, where the abstract is instantiated, without having the abstract as the current block.\n The following example reports the reasons for abstract inclusion for the pins in abstract view: fc_shell> report_abstract_inclusion_reason [get_pins -of_object [get_cells -filter \"is_hierarchical==false\" -hierarchical *]] Legend mv - MV Logic comp - Compact interface logic cell - Cell inclusion Pin name Reason(s) for inclusion AINV_P_260/I comp, cell AINV_P_260/VDD cell AINV_P_260/VSS cell AINV_P_260/ZN comp, cell AINV_P_262/I comp, cell AINV_P_262/VDD cell AINV_P_262/VSS cell AINV_P_262/ZN comp, cell AINV_P_263/I mv, comp, cell A legend is displayed at the beginning of the report for the queried objects, specifying the detailed reason for each reason code."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Cell Spacing Constraints"}, {"role": "assistant", "content": "To report the cell spacing rules, use the report_spacing_rules comandcomandsreport_spacing_rules report_placement_spacing_rules command.\n This command reports the cell spacing labels defined in the current session, the library cells (and their sides) to which they apply, and the rules defined for them."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Restricting the Target Libraries Used"}, {"role": "assistant", "content": "You can restrict the libraries used during clock tree synthesis for the top level or a lower level of the logical hierarchy of a design by using the set_target_library_subset -clock command.\n To enable the use of the target library subset, you must set the opt.common.enable_target_library_subset_opt application option to The following example specifies the buf1 and buf2 cells from the HVT_lib and LVT_lib libraries as clock tree references.\n However, it restricts the lower-level block named TSK_BLK to use only the cells from the LVT_lib library for its clock nets.\n Therefore, only buf1 and buf2 cells from the LVT_lib library are used as clock references for that block.\n fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} fc_shell> set_target_library_subset -clock {LVT_lib} \\ -objects [TOP/TSK_BLK] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 359 Specifying the Clock Tree Synthesis Settings Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Automatically Fixing Double-Patterning Odd-Cycle Violations"}, {"role": "assistant", "content": "If your block uses double-patterning technology, you must perform separate signoff DRC fixing runs for the non-double-patterning routing rules and the double-patterning routing rules.\n To perform automatic fixing of the signoff DRC violations for a block that uses double- patterning technology, 1.\n Perform automatic fixing for the non-double-patterning signoff DRC violations by using the process described in Automatically Fixing Signoff DRC Violations When you run the signoff_check_drc and signoff_fix_drc commands, use the -unselect_rules option to ignore the double-patterning rules during signoff design rule checking.\n fc_shell> signoff_check_drc -unselect_rules { list_of_dpt_rules Note: To determine the double-patterning rules for your technology, see the design rule manual (DRM) provided by your vendor.\n 2.\n Perform automatic fixing for the double-patterning odd-cycle violations by using the process described in Automatically Fixing Signoff DRC Violations Before you run the signoff_fix_drc command, set the signoff.fix_drc.custom_guidance application option to dpt fc_shell> set_app_options \\ -name signoff.fix_drc.custom_guidance -value dpt When you run the signoff_check_drc and signoff_fix_drc commands, use the -select_rules option to consider only the double-patterning rules during signoff design rule checking.\n fc_shell> signoff_check_drc -select_rules { list_of_dpt_rules 3.\n Perform signoff design rule checking to verify the results by using the process described in Performing Signoff Design Rule Checking"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating a Congestion Map"}, {"role": "assistant", "content": "To display the global route congestion map, choose View > Map > Global Route Congestion in the GUI.\n If the design library contains global route congestion information for the block, the tool generates the congestion map based on this information; otherwise, you must click Reload to generate the congestion map.\n When you click Reload, the tool opens a dialog box that contains the following command: route_global -congestion_map_only true Note: By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing.\n When you click OK in this dialog box, the tool generates a new congestion map.\n If you want to use different options for the route_global command, you can modify this command before clicking OK.\n 566 Analyzing the Routing Results Feedback Figure 118 shows an example of a congestion map.\n Figure 118 Global Route Congestion Map By default, the congestion map displays only the hard congestion data.\n To display soft congestion data, select the desired rule level in the Rule level drop-down list.\n The rule level refers to the spacing weight level of the soft nondefault spacing rules.\n The congestion map displays the sum of the hard and soft congestion with a weight level of at least the selected rule level.\n The congestion map shows the borders between global routing cells highlighted with different colors that represent the congestion values.\n The congestion map supports two methods for calculating the congestion value: Sum of overflow for each layer (the default) In this mode, the tool calculates the congestion value as the sum of the overflow for all selected layers.\n Underflow is not considered; if a layer has underflow, it contributes zero overflow to the total overflow calculation.\n Total demand minus total supply In this mode, the tool calculates the congestion value by subtracting the supply for all selected layers from the demand for all selected layers.\n Note that because this calculation considers the underflow, it produces a more optimistic congestion result in regions that contain both overflow and underflow.\n For example, assume that the METAL2 layer is heavily congested with a demand of 13 routing tracks and a supply of only 7 tracks for an overflow of 6.\n The METAL4 is 567 Analyzing the Routing Results Feedback moderately congested with an overflow of 4, and the METAL6 layer is not congested and contains an underflow of 3.\n Other layers are not used in the congestion calculation in this example.\n The sum of overflow calculation results in a congestion value of 6+4=10.\n The underflow of 3 for the METAL4 layer is not used in the calculation.\n The total demand calculation results in a congestion value of 6+4-3=7.\n In this case, the underflow of 3 for the METAL4 layer is used in the calculation.\n To select the mode, select either \"Sum of overflow for each layer\" or \"Total demand minus total supply\" in the \"Congestion calculation\" section of the Map Mode panel.\n By default, all metal layers are selected in the congestion map, except those specified as ignored layers with the set_ignored_layers command.\n To display the congestion map for a subset of layers, select (or deselect) the layers on the Map Mode panel.\n For example, if the global routing report shows that the maximum overflow occurs on the METAL2 layer, you can deselect all layers, except for METAL2, to display only the METAL2 congestion.\n The Map Mode panel also displays a histogram showing the number of global routing cells in different ranges (bins) of congestion values for the selected layers.\n If your block contains global routing cells that have no available routing resources, an additional bin named Blocked is displayed that shows the number of global routing cells with no routing resources.\n You can select which bins to display in the congestion map by selecting or deselecting them on the Map Mode panel.\n If the block shows congested areas, zoom into the congested area to see the congestion value on the global routing cell.\n For example, in Figure 119, the red highlight on the edge of the global routing cell shows 18/9.\n This means there are 9 wire tracks available, but 18 tracks are needed.\n 568 Analyzing the Routing Results Feedback Figure 119 Global Route Overflow on Global Routing Cell"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Commands and Examples"}, {"role": "assistant", "content": "This table shows some reporting commands to report QoR, timing, area, and so on.\n Use this command To do this report_area Report area information of the current design.\n - Area is based on physical libraries.\n - Numbers of ports and nets are not reported.\n report_qor Report QoR information and statistics for the current design.\n - Information is based on physical libraries.\n report_timing Report the timing information of the current design.\n 262 Performing Design Analysis Feedback Use this command To do this report_power Calculate and report dynamic and static power of the design or instance.\n report_clock_gating Report total clock-gating statistics of the design.\n report_logic_levels Report logic levels of the design.\n report_area Example fc_shell> report_area -designware -hierarchy -physical **************************************** Report : area Design : test...\n **************************************** Information: Base Cell (com): cell XNOR2ELL, w=3300, h=6270 (npin=3) Information: Base Cell (seq): cell LPSDFE2, w=10560, h=6270 (npin=5) Number of cells: 8 Number of combinational cells: 4 Number of sequential cells: 4 Number of macros/black boxes: 0 Number of buf/inv 0 Number of references 2 Combinational area: 49.66 Buf/Inv area: 0.00 Noncombinational area: 231.74 Macro/Black box area: 0.00 Total cell area: 281.40 ____________________________________________________________________ Hierarchical area distribution Global cell area Local cell area Hierarchical cell Absolute Percent Combi- Noncombi- Black- Total Total national national boxes Design test 281.40 100.0 37.24 231.74 0.00 test mult_10 12.41 4.4 12.41 0.00 0.00 DW_mult_uns_J1_H3_D1 Total 49.66 231.74 0.00 Area of detected synthetic parts Perc.of Module Implem.\n Count Area cell area 263 Performing Design Analysis Feedback DW_mult_uns pparch 1 12.41 4.4% Total: 1 12.41 4.4% Estimated area of ungrouped synthetic parts Estimated Perc.\n of Module Implem.\n Count area cell area DW_mult_uns pparch 3 48.28 17.2% Total: 3 48.28 17.2% Total synthetic cell area: 60.69 21.6% (estimated) ____________________________________________________________ Core Area: 1767 Aspect Ratio: 1.0902 Utilization Ratio: 0.1593 The above information was from the logic library.\n The following information was from the physical library: Total moveable cell area: 281.4 Total fixed cell area: 0.0 Total physical cell area: 281.4 Core area: 0.000, 0.000, 40.260, 43.890 report_qor Example fc_shell> report_qor *********************************************** Report : qor Design : top...\n *********************************************** Scenario 'SC1' Timing Path Group 'clk' Levels of Logic: 6 Critical Path Length: 0.28 Critical Path Slack: -0.19 Critical Path Clk Period: 0.30 Total Negative Slack: -0.80 No.\n of Violating Paths: 11 Worst Hold Violation: -0.07 Total Hold Violation: -0.13 No.\n of Hold Violations: 32.00 Cell Count 264 Performing Design Analysis Feedback Hierarchical Cell Count: 2 Hierarchical Port Count: 24 Leaf Cell Count: 287 Buf/Inv Cell Count: 45 Buf Cell Count: 4 Inv Cell Count: 41 CT Buf/Inv Cell Count: 0 Combinational Cell Count: 208 Sequential Cell Count: 79 Macro Count: 1 Area Combinational Area: 419.34 Noncombinational Area: 736.26 Buf/Inv Area: 67.60 Total Buffer Area: 9.66 Total Inverter Area: 57.94 Macro/Black Box Area: 2337.90 Net Area: 0 Net XLength: 0 Net YLength: 0 Cell Area (netlist): 3493.49 Cell Area (netlist and physical only): 3493.49 Net Length: 0 Design Rules Total Number of Nets: 363 Nets With Violations: 0 Max Trans Violations: 0 Max Cap Violations: 0 report_transformed_registers Example The report_transformed_registers command reports the following information about registers that are modified or removed during compile: Sequential output ports inversion Constant registers that are removed and the constant values Constant registers that are preserved by users Unloaded registers that are removed Unloaded registers that are preserved by users Register merging 265 Performing Design Analysis Feedback Register replication Shift registers Multibit registers Summary of register optimizations Use the report_transformed_registers command only on a mapped design generated by compile or incremental compile.\n If you run the command on an unmapped design, the report_transformed_registers command reports no information.\n The information of transformed or optimized registers is stored in the design library, so you can query the same information by using the report_transformed_registers command in different sessions.\n For example, fc_shell> report_transformed_registers **************************************** Report: report_transformed_registers Version:...\n Date:...\n **************************************** Legend: C0p - constant 0 register preserved C1p - constant 1 register preserved C0r - constant 0 register removed C1r - constant 1 register removed ulp - preserved unloaded register ulr - removed unloaded register mrg - merged register srh - shift register head srf - shift register flop mb - multibit rep - replicated inv - inverted Register Optimization I_RISC_CORE/I_DATA_PATH/PSWL_Carry_reg C0r I_RISC_CORE/I_STACK_TOP/I3_STACK_MEM/Stack_Mem_reg[0][0] C0r I_RISC_CORE/I_STACK_TOP/I3_STACK_MEM/Stack_Mem_reg[1][0] C0r To report the count of each type of register transformation, specify the -summary option as shown in the following example: fc_shell> report_transformed_registers -summary **************************************** Report: report_transformed_registers Version:...\n Date:...\n 266 Performing Design Analysis Feedback **************************************** Legend: C0p - constant 0 register preserved C1p - constant 1 register preserved C0r - constant 0 register removed C1r - constant 1 register removed ulp - preserved unloaded register ulr - removed unloaded register mrg - merged register srh - shift register head srf - shift register flop mb - multibit rep - replicated inv - inverted Register Count Constant Registers Deleted 12 Constant Registers Preserved 1 Unloaded Registers Deleted 101 Unloaded Registers Preserved 38 Shift Registers 170 Merged 12 Multibit 10 Inverted 15 Replicated 4"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Primary Corner for Clock Tree Synthesis"}, {"role": "assistant", "content": "During initial clock tree synthesis, by default, the tool identifies the corner with the worst clock delays and inserts buffers to balance the clock delays in all modes of this corner.\n To identify a specific corner as the primary corner for initial clock tree synthesis, use the cts.compile.primary_corner application option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Resolving Overlapping Voltage Areas"}, {"role": "assistant", "content": "If voltage area shapes from two or more voltage areas overlap, either completely or partially, the tool uses the stacking order of the shapes to determine the effective shapes of the voltage areas.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The tool assigns the overlapped region to the voltage area associated with the top shape.\n Unlike merging shapes within a voltage area, when the tool resolves overlapping shapes from different voltage areas, it does not remove any shapes; only the interpretation of the shapes changes.\n 122 Setting Up Multivoltage Designs Feedback For example, assume you want to create nested voltage areas, as shown in Figure 15 Figure 15 Nested Voltage Areas To generate these effective voltage areas, you must specify the outer voltage area first, followed by the inner voltage area, so that the voltage area shape for the inner voltage area is on top: fc_shell> create_voltage_area -power_domains PD1 \\ -region { {0 0} {30 30} } {PD1} fc_shell> create_voltage_area -power_domains PD2 \\ -region { {10 10} {20 20} } {PD2} fc_shell> get_attribute -objects [get_voltage_areas PD2] \\ -name effective_shapes {{10.0000 10.0000} {20.0000 20.0000}} fc_shell> get_attribute -objects [get_voltage_areas PD1] \\ -name effective_shapes {{0.0000 0.0000} {10.0000 0.0000} {10.0000 20.0000} {20.0000 20.0000} {20.0000 10.0000} {10.0000 10.0000} {10.0000 0.0000} {30.0000 0.0000} {30.0000 30.0000} {0.0000 30.0000}} If you specify the inner voltage area first, the shape for the outer voltage area is on top and it masks the inner voltage area, so it is ignored by the tool, as shown in the following example: fc_shell> create_voltage_area -power_domains PD2 \\ -region { {10 10} {20 20} } {PD2} fc_shell> create_voltage_area -power_domains PD1 \\ -region { {0 0} {30 30} } {PD1} fc_shell> get_attribute -objects [get_voltage_areas PD2] \\ -name effective_shapes fc_shell> get_attribute -objects [get_voltage_areas PD1] \\ 123 Setting Up Multivoltage Designs Feedback -name effective_shapes {{0.0000 0.0000} {30.0000 30.0000}} To report the stacking order of the voltage area shapes, use the report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in Modifying the Stacking Order"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Clock-Tree Layer Constraints"}, {"role": "assistant", "content": "To specify clock-tree layer constraints, use the set_clock_routing_rules command.\n To specify the minimum and maximum routing layers, use the -min_routing_layer and 202 Specifying the Routing Resources Feedback -max_routing_layer options.\n Specify the routing layers by using the layer names from the technology file.\n By default, the set_clock_routing_rules command assigns the specified layer constraints to all clock trees.\n Table 17 shows the options used to restrict the layer constraints.\n Table 17 Restricting Clock-Tree Layer Constraints To assign a layer constraint to Use this option Specific clock trees -clocks clocks Nets connected to the clock root -net_type root Nets connected to one or more clock sinks -net_type sink Internal nets in the clock tree (all nets except the root and sink nets) -net_type internal Specific clock nets -nets nets Figure 27 shows the root, internal, and sink nets of a clock tree after clock tree synthesis.\n By default, the root-net layer constraints are applied to all the single-fanout clock nets starting from the clock root up to the point where the clock tree branches out to a fanout of more than one.\n Internal-net layer constraints are applied to the nets from this point until the sink nets.\n Figure 27 Root, Internal, and Sink Clock Net Types 1.\n You can use this option with the -clocks option to further restrict the assignment.\n This option is not valid with the -nets option.\n 203 Specifying the Routing Resources Feedback For example, to use layers M4 through M7 when routing the root nets of the CLK1 clock, use the following command: fc_shell> set_clock_routing_rules -clocks CLK1 -net_type root \\ -min_routing_layer M4 -max_routing_layer M7 To specify a transitive fanout limit to use when identifying root nets, use the set_clock_tree_options -root_ndr_fanout_limit command.\n For example, to specify that any clock net with a transitive fanout of more than 300 sinks be considered as a root net, use the following command: fc_shell> set_clock_tree_options -root_ndr_fanout_limit 300 Figure 28 shows the root, internal, and sink nets of the same clock tree when a transitive fanout limit of 300 is specified for identifying the clock root nets.\n Figure 28 Using a Fanout Limit for Selecting Root Nets When calculating the transitive fanout of clock nets for the purpose of identifying root nets, the tool includes only the valid clock sinks; It does not include the ignore pins.\n If a net identified as a root net is less than 10 microns, the tool uses internal-net layer constraints for that net.\n Note: Specifying a smaller value with the set_clock_tree_options -root_ndr_fanout_limit command increases the number of clock nets that are assigned the root-net layer constraints, which can increase routing congestion.\n To remove the transitive fanout limit specified with the set_clock_tree_options -root_ndr_fanout_limit command, use the remove_clock_tree_options -root_ndr_fanout_limit command.\n 204 Specifying the Routing Resources Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Datapath Optimization"}, {"role": "assistant", "content": "Datapath design is commonly used in applications that contain extensive data manipulation, such as 3-D, multimedia, and digital signal processing (DSP).\n By default, when you run the compile_fusion command, datapath optimization is enabled and both standard and DesignWare Foundation libraries are automatically linked.\n During datapath optimization, the tool performs the following tasks: Shares (or reverses the sharing) of datapath operators Uses the carry-save arithmetic technique Extracts the data path Performs high-level arithmetic optimization on the extracted data path Explores better solutions that might involve a different resource-sharing configuration Makes tradeoffs between resource sharing and datapath optimization Topics in this section Datapath Extraction Transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks.\n Datapath Implementation Uses a datapath generator to generate the best implementations for the extracted components.\n Optimizing Datapaths"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Command"}, {"role": "assistant", "content": "By default, the tool performs leakage power optimization during compile.\n To produce optimal leakage power optimization, use libraries with multithreshold voltage group cells.\n To set up leakage optimization, 1.\n Enable at least one scenario for leakage power by using the set_scenario_status -leakage_power true command.\n For example, fc_shell> set_scenario_status -leakage_power true SC1 If the block has multiple scenarios enabled for leakage power, the tool uses the worst- case leakage value of all the specified scenarios.\n 2.\n Set the threshold_voltage_group attribute on the reference library cells.\n For example, fc_shell> set_attribute [get_lib_cells -quiet lib1_name/*] \\ threshold_voltage_group HVT 3.\n Set the threshold_voltage_group attribute to one of the three built-in threshold voltage group types: high, normal, or low threshold voltage.\n 189 Setting Up for Power-Related Features Feedback If there are more than three threshold-voltage groups, you should group them into the three voltage group types as follows: fc_shell> set_threshold_voltage_group_type \\ -type high_vt {HVT HVTX} fc_shell> set_threshold_voltage_group_type \\ -type low_vt {LVT LVTX} fc_shell> set_threshold_voltage_group_type \\ -type normal_vt {RVT RVTX}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Tree Synthesis"}, {"role": "assistant", "content": "To learn how to perform clock tree synthesis in the Fusion Compiler tool, see the following topics: Prerequisites for Clock Tree Synthesis Defining the Clock Trees Verifying the Clock Trees Setting Clock Tree Design Rule Constraints Specifying the Clock Tree Synthesis Settings Implementing Clock Trees and Performing Post-CTS Optimization Implementing Multisource Clock Trees Analyzing the Clock Tree Results"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Map"}, {"role": "assistant", "content": "To highlight violations from the Error Browser: 1.\n In the GUI, choose View > Error Browser.\n 2.\n Select the error data generated from the DRC run.\n 3.\n Select violations from the Error Browser to automatically highlight them on the heat map.\n 682 Performing Signoff Design Rule Checking Feedback 683 Performing Signoff Design Rule Checking Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Soft Shielding Rules During Signal Routing"}, {"role": "assistant", "content": "Zroute considers shielding rules as soft rules during signal routing.\n If a net has a shielding rule and is not shielded before signal routing, by default, Zroute reserves shielding space during the whole routing process: global routing, track assignment, and detail routing.\n At the end of detail routing, it reports the shielding space violations and the locations where shielding wires cannot be established.\n The following log file example shows shielding soft spacing violations, which are highlighted in text: DRC-SUMMARY: @@@@@@@ TOTAL VIOLATIONS = 13 Diff net var rule spacing : 2 Same net spacing : 2 Less than minimum area : 4 Short : 1 Soft spacing (shielding) : 2 Signal routing only reserves space for the shielding; it does not actually insert it.\n You must run create_shields after signal routing to physically place the shielding wires.\n The reported soft rule violations help you to understand the shielding rate.\n Note that the router reserves space only for same-layer shielding and not for coaxial shielding; therefore, postroute coaxial shielding can produce a very low shielding rate.\n 544 Shielding Nets Feedback If you want to use power and ground nets for shielding, and do not want Zroute to reserve space for the shielding when power and grounds nets are available, set the route.common.allow_pg_as_shield application option to true before running signal routing."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing the Secondary Power and Ground Pins"}, {"role": "assistant", "content": "If the secondary power and ground pins have the appropriate attributes in the frame view, you can use Zroute to route the secondary power and ground pins.\n By default, Zroute performs four topology ECO iterations to fix secondary PG cluster fanout violations.The topology ECO iterations can be time consuming, so you can control the effort level, and therefore the runtime, by setting the route.detail.topology_eco_effort_level application option to one of the following values: off, which disables topology ECO; this is the default low, which peforms one topology ECO iteration medium, which peforms four topology ECO iterations high, which peforms eight topology ECO iterations For example, to connect the secondary power pins to the VDD1 net, run the following command: fc_shell> route_group -nets VDD1 The following example add new cells, which have secondary power and ground pins, to a block; logically connects the power and ground pins; and then connects the secondary power pins to the VDD2 net.\n fc_shell> add_buffer {TOP/U1001/Z} {libA/BUFHVT} \\ -new_cell_names mynewHVT fc_shell> add_buffer {TOP/U1002/Z} {libA/BUFHVT} \\ -new_cell_names mynewHVT fc_shell> legalize_placement 524 Routing Signal Nets Feedback fc_shell> connect_pg_net -automatic fc_shell> route_group -nets {VDD2}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Automatic Floorplanning"}, {"role": "assistant", "content": "During early design stages, a design often undergoes many iterations due to changes such as adding features and macros; as a result, the floorplan contains limited or no physical information.\n Automatic floorplanning can generate high-quality floorplans and create missing physical information early in the design cycle, which allows you to Achieve better correlation between the results of RTL synthesis and design implementation Identify and fix design issues early in the design cycle Generate a better starting point for place and route, eliminating costly iterations During automatic floorplanning, the compile_fusion command performs the following tasks: Creates the die, rows, and tracks Shapes and places voltage areas Places macros Places pins and I/Os By default, the top-level floorplan is created with a core utilization of 0.7.\n For information about setting constraints for automatic floorplanning, see Creating Constraints for Auto Floorplanning 110 Importing the Floorplan Information Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Skewing Latch and Discrete Clock Gates"}, {"role": "assistant", "content": "To skew latches and discrete clock gates together, set the ccd.skew_opt_merge_dcg_cells_by_driver application option to true before compile_fusion or place_opt final_opto.\n By default, the application option is set to false.\n Setting the ccd.skew_opt_merge_dcg_cells_by_driver application option to true enhances the concurrent clock and data optimization to skew latches and gating element by the same offset.\n This ensures the latch and gate are at the same level and improves hold timing of discrete clock gates.\n fc_shell> set_attribute -name ccd.skew_opt_merge_dcg_cells_by_driver -value true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing Using Custom Router"}, {"role": "assistant", "content": "Custom Router is a shape-based router that supports gridded or gridless routing for custom digital, mixed signal, and analog routing needs.\n In the Fusion Compiler environment, you can use Custom Router to create interconnects (or routes) for critical signals between blocks and continue with the Fusion Compiler tool to complete the physical implementation.\n You can also preroute critical signals or clock nets by using a set of custom routing constraints.\n In the Fusion Compiler environment, Custom Router provides the following features: Prerouting in the batch mode Tcl-based routing constraint management Automatic routing with custom routing constraints Hybrid flow for prerouting Double Data Rate (DDR) net routing flow Custom Router is fully integrated with the Fusion Compiler tool, and supports advanced design rules for 20 nm and below technologies.\n To learn about using Custom Router in the Fusion Compiler environment, see the following topics: Using Custom Router in the Fusion Compiler Tool Before Using Custom Router Defining Routing Constraints Managing Constraint Groups Using Custom Routing Application Options Routing With the Custom Router Shielding the Nets Checking the Routing Results 746 Using Custom Router in the Fusion Compiler Tool Feedback Using a Hybrid Routing Flow Using a DDR Routing Flow These topics describe how to use Custom Router to create custom routes in the Fusion Compiler environment.\n For detailed information about Custom Router, see the Custom Compiler Custom Router User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Adding Hard Macro Cells"}, {"role": "assistant", "content": "The add_to_rp_group command supports hard macro cells.\n When you add macro cells to a relative placement group, you cannot specify A pin name with which to align the macro cell by using the -pin option An orientation for the macro cells by using the -orientation option When you add hard macro cells, use the following steps: 1.\n Create the relative placement groups, add the cells, including the hard macro cells, and specify the relative placement options and settings.\n 2.\n Place the design by using the create_placement -floorplan command.\n 3.\n Fix the placement of the hard macro cells in the relative placement groups by using the set_placement_status fixed command.\n Before you can perform further placement and optimization, The hard macro cells in the relative placement groups must be placed and fixed The other cells in the relative placement groups that contain hard macro cells must be placed 4.\n Perform further placement and optimization."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Copying Clock Tree Exceptions Across Modes"}, {"role": "assistant", "content": "You can specify that the tool copies clock tree exceptions from one mode to one or more equivalent modes by using the set_clock_tree_options command with the -copy_exceptions_across_modes -from_mode, and -to_mode options.\n The following example specifies that during clock tree synthesis the clock tree exceptions in the mode name M1 should be copied to the modes name M2 and M3: fc_shell> set_clock_tree_options -copy_exceptions_across_modes \\ -from_mode M1 -to_mode {M2 M3} 350 Defining the Clock Trees Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Voltage Hotspot Analysis"}, {"role": "assistant", "content": "When rail analysis is complete, there might be hundreds to thousands of voltage drop violations reported in the analysis report, which might make it difficult to identify the root causes for the violations.\n Use the voltage hotspot analysis capability to generate hotspots for a power or ground net by dividing the whole chip into small grid boxes, and report rail-related information for the generated grid boxes.\n In addition, you can query cell- or geometry-based rail results only for the specific analysis type by using the get_instance_result and get_geometry_result commands.\n 939 Voltage Hotspot Analysis Feedback Hotspot analysis provides the following features: Identify the root cause of aggressors with high voltage drop, such as large current from the aggressor itself or from the neighboring cells due to simultaneous switching by the overlapping timing windows.\n Determine which design technique to use for fixing voltage violations based on the report, such as choosing a candidate reference cell for cell sizing replacement, moving or relocating cells to reduce voltage drops, or applying PG augmentation to solve a voltage drop issue.\n This section contains the following topics: Generating Hotspots Reporting Hotspots Removing Hotspots Voltage Hotspot Analysis Examples To write rail results only for the cell instances or geometries that reside in the hotspot area, use the get_instance_result and get_geometry_result commands.\n For more information, see Generating Instance-Based Analysis Reports and Generating Geometry- Based Analysis Reports"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Excluding Specific Sinks"}, {"role": "assistant", "content": "To exclude a specific sink from concurrent clock and data optimization, 1.\n Apply a cts_fixed_balance_pin attribute on the sink pin by using the set_attribute command as shown in the following example: fc_shell> set_attribute -objects reg21/CK \\ -name cts_fixed_balance_pin -value true 2.\n Set the ccd.respect_cts_fixed_balance_pins application option to true These setting prevents the tool from adjusting the latencies of the sinks that have a cts_fixed_balance_pin attribute set to true.\n However, changes in the clock tree due to concurrent clock and data optimization performed on other sinks can change the latencies of the sinks that have a cts_fixed_balance_pin attribute set to true To prevent the tool from making any changes to the clock paths between the sinks that have a cts_fixed_balance_pin attribute set to true and the clock root, set the 378 Implementing Clock Trees and Performing Post-CTS Optimization Feedback ccd.respect_cts_fixed_balance_pins application option to upstream instead of true This application option setting affects concurrent clock and data optimization performed during the place_opt clock_opt, and route_opt commands."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining the Clock Trees"}, {"role": "assistant", "content": "This section details the information required to analyze and define each clock tree before running clock tree synthesis.\n Before you run clock tree synthesis, analyze each clock tree in the block and determine What the clock root is What the required clock sinks and clock tree exceptions are Whether the clock tree contains preexisting cells, such as clock-gating cells Whether the clock tree converges, either with itself (a convergent clock path, definedclockconvergent convergent clock path) or with another clock tree (an overlaping clock path, definedclockoverlaping overlapping clock path) Whether the clock tree has timing relationships with other clock trees in the block, such as interclock skew requirements Use this information to define the clock trees and validate that the tool has the correct clock tree definitions.\n The Fusion Compiler tool derives the clock trees based on the clocks defined in the block.\n If the derived clock trees do not meet your requirements, you can define clock trees as described in the following topics: Deriving the Clock Trees Defining Clock Tree Exceptions Restricting Optimization on the Clock Network Copying Clock Tree Exceptions Across Modes 339 Defining the Clock Trees Feedback Deriving Clock Tree Exceptions From Ideal Clock Latencies Handling Endpoints With Balancing Conflicts"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Library Cell Families"}, {"role": "assistant", "content": "To identify redundancies, outliers, equivalences, and gaps in cell families, perform the following steps: 1.\n Create a collection of the libraries you want to analyze, which is known as a libset, by using the create_libset command, as shown in the following example: fc_shell> create_libset -name myLibset -libs {abcd1 abcd2} When you perform library analysis, you can specify the libset name, instead of specifying a list of libraries.\n In addition, the tool uses the libset name, instead of using a list of the library names, when it generates reports, plots, and so on during analysis.\n You can include a cell library in more then one libset.\n 2.\n Set up the library analysis environment by using the create_environment command.\n 89 Analyzing Libraries Feedback The create_environment command associates a predefined libset with a process label, process number, voltage, and temperature, which is then used for analyzing the libraries.\n You can specify the process label, process number, voltage, and temperature of the analysis environment by using one of the following methods: Specify the process label, process number, voltage, and temperature values by using the -ppvt option, as shown in the following example: fc_shell> create_environment -name env1 -libset myLibset \\ -ppvt {{SS1p, 1.0, 0.6, 125}} Specify a predefined operating condition from the reference library by using the -op_conds option, as shown in the following example: fc_shell> create_environment -name env2 -libset myLibset \\ -op_conds SS1p6125 Specify corners from which to infer the process label, process number, voltage, and temperature values by using the -corners option, as shown in the following example: fc_shell> create_environment -name env3 -libset myLibset \\ -corners nworst Specify that the tool infers the process label, process number, voltage, and temperature values from the scenario and UPF associated with the current design by using the -auto_infer_design option, as shown in the following example: fc_shell> create_environment -name env4 -libset myLibset \\ -auto_infer_design 3.\n (Optional) Specify a naming convention for library cells and perform lexical classification by using lexical attributes.\n A library cell naming convention can help the tool identify cell families in the subsequent steps of the flow.\n For example, assume a cell in your library is named AND2D4WSULVT.\n This name is the concatenation of the AND2, D4, WS, and ULVT string, which represent cell characteristics that are associated to a lexical attribute, as shown in the following table: Table 2 Lexical Attributes for the Naming Convention of an Example Library Column Lexical Attribute Allowed Pattern Values for Example Cell lexical_cell_prefix_name [a-zA-Z0-9]* AND2 90 Analyzing Libraries Feedback Column Lexical Attribute Allowed Pattern Values for Example Cell lexical_drive1_name D[0-9]* D4 lexical_well_substrate_bias_arch itecure WS WS lexical_device_threshold_voltage ULVT | SVT | LVT | MVT ULVT You can specify the naming convention for this library by using the set_lib_cell_naming_convention command, as shown in the following example: fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 1 -pattern {[a-zA-Z0-9]*} -attribute \"lexical_cell_prefix_name\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 2 -pattern {D[0-9]*} -attribute \"lexical_drive1_name\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 3 -pattern {WS} -attribute \"lexical_well_substrate_bias_architecure\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 4 -pattern {ULVT|SVT|LVT|MVT} -attribute \"lexical_device_threshold_voltage\" Note: For a list of all the predefined lexical attributes, see the man page for the set_lib_cell_naming_convention command.\n After you specify the naming convention, perform lexical classification by using the classify_lib_cell_attributes command, as shown in the following example: fc_shell> classify_lib_cell_attributes -libset myLibset To report the lexical classification results, use the report_lib_cell_classification_attributes command.\n To report the library cells which are not lexical classified under the given naming convention, use the report_lexical_unclassified_lib_cells command.\n If there are lexically unclassified cells, specify additional naming conventions and rerun lexical classification.\n 4.\n (Optional) Exclude specific cells from library analysis by using the set_use_for_library_analysis command.\n 91 Analyzing Libraries Feedback By default, the tool excludes physical-only cells during library analysis.\n However, you can exclude additional cells, such as library cells with a dont_use setting, as shown in the following example: fc_shell> set exclude_cells [filter_collection [get_lib_cells $libs/*] \"dont_use == true\"] fc_shell> set_use_for_library_analysis $exclude_cells false To report the cells that are excluded, use the report_lexical_ignored_lib_cells command.\n 5.\n Identify all library cell families by using the identify_lib_cell_families command.\n To report the tool-identified library cell families, use the report_lib_cell_families -all_initial command.\n To manually define library cell families, use the define_lib_cell_family command.\n To report these user-defined cell families, use the report_lib_cell_families -all_userdef command.\n 6.\n Analyze the libraries by using the run_library_analysis command, as shown in the following example: fc_shell> run_library_analysis -name myLibset_run1 -environment env1 The name of the environment you specify with the -environment option must correspond to an environment you previously created by using the create_environment command.\n 7.\n Identify redundancies in library cell families by using the find_library_redundancies command, as shown in the following example: fc_shell> find_library_redundancies -analysis myLibset_run1 The name of the analysis you specify with the -analysis option must correspond to the name of an analysis you previously performed by using the run_library_analysis command.\n In addition to redundant cells, the find_library_redundancies command also identifies outlier and equivalent cells in library families.\n 8.\n Identify gaps in library cell families by using the find_library_gaps command, as shown in the following example: fc_shell> find_library_gaps -analysis myLibset_run1 The name of the analysis you specify with the -analysis option must correspond to the name of an analysis you previously performed by using the run_library_analysis command.\n 92 Analyzing Libraries Feedback 9.\n Report the library cell gaps, redundancies, outliers, and equivalence identified during library analysis by using the report_library_analysis command, as shown in the following example: fc_shell> report_library_analysis -analysis myLibset_run1 \\ -analysis_type redundancy -detail fc_shell> report_library_analysis -analysis myLibset_run1 \\ -analysis_type outlier -detail fc_shell> report_library_analysis -analysis myLibset_run1 \\ -analysis_type equivalent -detail fc_shell> report_library_analysis -analysis myLibset_run1 \\ -analysis_type gap -detail 10.\n Generate plots by using the gui_plot_lib_cells_attributes command, as shown in the following example: fc_shell> gui_plot_lib_cells_attributes -libset myLibset \\ -lib_cell_type all -x_attrib_name leakage -y_attrib_name avgsl_fall_delay \\ -chart_type scatter"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Differential Groups"}, {"role": "assistant", "content": "To create a differential group or a differential pair for the nets, bundles, or topology edges, use the create_differential_group command.\n Custom Router pairs the closest pins, one from each net, and routes from a common gather point between the pins.\n The tool routes the net pair the closest to each other with the most similar routing patterns.\n You need to specify the following information: The name of the constraint group If you do not specify a name, the command names the constraint group differential_pair_ or differential_group_, where is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the -force option.\n The nets in the differential group To specify the nets included in the created group, use the -for option.\n If you specify two nets, the nets form a differential pair.\n If you specify three nets, the nets form a differential group.\n The constraints for the differential group To define the constraints that are applied per layer to the trunks and override any settings on the individual bits, use the options listed in Table 54 Table 54 Differential Group Constraints Option Constraint -twist_style Specifies the twist style.\n Valid values are diagonal : Applies 45-degree twists to the wires.\n none (default): Does not twist the wires.\n orthogonal : Applies 90-degree twists to the wires.\n -twist_interval Specifies the distance between each twist.\n -twist_offset Specifies the distance between the first twist and the connected pins.\n The default is 0.\n -valid_layers Specifies the layers on which to route the differential group.\n -layer_spacings Specifies the minimum spacing for each routing layer.\n -layer_widths Specifies the minimum width for each routing layer.\n 752 Defining Routing Constraints Feedback Option Constraint -shield_placement Specifies how to shield the main bus trunk if one or more nets of the constraint group are shielded.\n Valid values are double_interleave : Shields each wire individually.\n half_interleave : Inserts shared shielding every two wires.\n interleave : Inserts shared shielding between adjacent wires.\n outside (default): Places shields on the outside of the trunk or group.\n See also Intra-shield Placement -gap Specifies the spacing in microns between the outermost bus bits and other shapes in the block.\n The default is 0.\n The following example creates a differential pair for the prn and prp nets.\n The command names the differential pair differential_pair_0, because there is no name assigned to the different pair.\n No twist style is specified and the shield placement is set to default fc_shell> create_differential_group \\ -for [get_nets -physical_context {prn prp}] \\ -shield_placement default {differential_pair_0}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Routing Constraints"}, {"role": "assistant", "content": "The Fusion Compiler tool provides a set of application options to control custom routing results.\n The application options are applied globally.\n See Using Custom Routing Application Options You can also define net-specific routing constraints that override the routing application options.\n Routing constraints provide guidance during routing.\n In the Fusion Compiler environment, Custom Router honors both the Custom Router constraints and the Fusion Compiler nondefault routing rules.\n Note: You must apply net-specific routing constraints to physical nets.\n When specifying nets that will be constrained, use the get_nets -physical_context command to ensure the physical net is returned.\n For example: fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*]\\ -disabled_layers {M5 M6} -sharing true \\ -layer_gaps {M2 3 M3 5} {shielding_4} Table 52 lists the commands to define the Custom Router constraints by creating constraint groups.\n For information about the supported Fusion Compiler nondefault routing rules, see Using Nondefault Routing Rules To check or remove the created constraint groups, use the report_constraint_groups or remove_constraint_groups command.\n For more information about checking or removing constraint groups, see Managing Constraint Groups Table 52 Commands to Define Custom Router Routing Constraints Command Description create_bus_routing_style Specifies the routing style for group of nets that are routed as a single bus structure (or trunk).\n For more information, see Defining the Bus Routing Style create_differential_group Defines a differential group for routing.\n For more information, see Creating Differential Groups 749 Defining Routing Constraints Feedback Table 52 Commands to Define Custom Router Routing Constraints (Continued) Command Description create_wire_matching Defines matched wire length for a group of nets or pin-to-pin connections.\n For more information, see Defining Matching Wire Lengths create_length_limit Defines the minimum wire length for a group of nets or pin-to-pin connections.\n For more information, see Defining Minimum Wire Lengths create_net_shielding Defines the shielding style for a group of nets or bundles.\n For more information, see Inserting Shields on the Nets create_net_priority Determines the order in which the nets are routed.\n Nets with a higher priority are routed first.\n For more information, see Defining the Net Priority"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Missing Via and Unconnected Pin Checking"}, {"role": "assistant", "content": "Note: Missing via and unconnected pin checking is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n Before you check for missing vias and unconnected pins, make sure you have the required input files as described in Preparing Design and Input Data for Rail Analysis Check for missing vias or unconnected pins in the block during voltage drop analysis or in a separate run.\n For example, you can perform the checking after completing the power 890 Missing Via and Unconnected Pin Checking Feedback structure and before running the place_opt command.\n This allows you to find power network errors in the design before rail analysis.\n By default, RedHawk/RedHawk-SC Fusion detects the following types of power network errors: Unconnected pin shapes: Pin shapes that are not contiguously and physically connected to an ideal voltage source.\n Missing vias: If two overlapping metal shapes do not contain a via within their overlapping area, it is considered a potential missing via error.\n To check for and fix missing vias or unconnected pins, 1.\n Define configuration options by using the set_missing_via_check_options command, as described in Setting Checking Options 2.\n Save the block by using the save_block command.\n 3.\n Perform the checking by using the analyze_rail -check_missing_via command, as described in Checking Missing Vias and Unconnected Pins.\n In the RedHawk-SC Fusion flow, you must specify the -check_missing_via option together with the -voltage_drop option.\n 4.\n Examine the checking results by opening the generated error files in the error browser or writing the checking results to an output file, as described in Viewing Error Data and Writing Analysis and Checking Reports 5.\n Insert PG vias to fix the reported missing vias, as described in Fixing Missing Vias"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Clock Gates in an RTL Design"}, {"role": "assistant", "content": "To insert clock gating logic in an RTL design and to synthesize the design with the clock- gating logic, follow these steps: 1.\n Read the RTL design.\n 2.\n (Optional) Use the insert_dft command to insert test cells into the design.\n 3.\n Use the compile_fusion command to compile the design.\n During the compile process, the tool inserts clock gates on the registers qualified for clock-gating.\n By default, during clock-gate insertion, the compile_fusion command uses the clock gating default settings and also honors the setup, hold, and other constraints specified in the logic libraries.\n To override the setup and hold values specified in the library, use the set_clock_gating_check command before compiling the design.\n The default settings are suitable for most designs.\n The compile_fusion command automatically connects the scan enable and test ports or pins of the integrated clock-gating cells, as needed.\n 4.\n Use the report_clock_gating command to report the registers and the clock-gating cells in the design.\n Use the report_power command to get information about the dynamic power used by the design after clock-gate insertion.\n The following example illustrates a typical command sequence for clock using default settings: fc_shell> read_verilog design.v fc_shell> create_clock -period 10 -name CLK fc_shell> compile_fusion fc_shell> insert_dft 302 Replacing Clock Gates Feedback fc_shell> report_clock_gating fc_shell> report_power"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running and Placing Group Repeaters"}, {"role": "assistant", "content": "Use the add_group_repeaters and place_group_repeaters commands to display the summary report for variant cell swapping in command cell collections."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Gate Efficiency Reporting"}, {"role": "assistant", "content": "The clock gate efficiency reporting feature calculates the efficiency of clock-gates by considering toggle rate.\n This computation based on toggle rate has a direct dependency on power saving which can be used to improve gating efficiency.\n The report_clock_gating_efficiency command reports the overall clock gating efficiency of the user specified clock gates for each clock tree.\n The syntax of the command is as follows: - report_clock_gating_efficiency [-by_register] [-by_clock_gate] [-bin_size] [-type clock_gate | self_gate | fanin_seqcg] [-origin tool_inserted | pre_existing] [-sortby name | stage | gating_efficiency] 323 Clock Gate Efficiency Reporting Feedback The following figure shows the report_clock_gating_efficiency command report: The columns of this report include the following parameters: Toggle Savings Distribution : A histogram of registers efficiency with a bin size of 5 (the bin size can be modified) Number of Registers : The number of registers in each histogram bin Accumulated Percentage : The cumulative percentage of registers encountered so far Number of Bitwidth : The bitwise equivalent for the number of registers in each bin Accumulated Percentage (of the bitwidth): The cumulative bitwise register equivalent percentage encountered so far 324 Clock Gate Efficiency Reporting Feedback The reports can be refined to report efficiency with respect to the following: Bin size using the following command: report_clock_gating_efficiency -bin_size #numberofbin Registers using the following command: report_clock_gating_efficiency -by_register 325 Clock Gate Efficiency Reporting Feedback The columns of this report include the following parameters: Register : The name of the register under consideration Bitwidth : Bitwidth of the register Local Clock Toggle Rate : Toggle rate at the clock pin of the register after gating D Toggle Rate : Toggle rage at the D-pin of the register Q Toggle Rate : Toggle rage at the Q-pin of the register D/Clk Toggle Rate : D toggle rate per local clock toggle rate Q/Clk Toggle Rate : Q toggle rate per local clock toggle rate Current Gating Efficiency : Efficiency of the register computed as 1 (local clock toggle by root clock toggle) Clock gates using the following command: report_clock_gating_efficiency -by_clock_gate The columns of this report include the following parameters: Clock : The root clock of the clock gate Clock Gating Stage : Stage of the clock gate Gating Element Number of Fanout Registers : The number of registers the clock gate is directly driving Number of Fanout Bitwidth : The bitwidth equivalent for the number of registers the clock gate is directly driving 326 Clock Gate Efficiency Reporting Feedback Toggle Savings : Toggle saving of the clock-gate Clock Gating Efficiency : The efficiency of the clock gate Receiver Clock Gate : The name of clock-gate directly driven by the clock-gate under consideration The output can also be sorted based on name, efficiency, or stage of clock gates in ascending order using the following command: report_clock_gating_efficiency -sort_by [name | stage | gating_efficiency] name : Alphabetically stage : By clock gate stage gating_efficiency : By clock gate or register gating efficiency 327 Self-Gating Optimization Feedback The following figure shows an example report:"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Off-Grid Routing"}, {"role": "assistant", "content": "You can prevent off-grid routing of wires or vias by requiring them to be aligned to the wire track or discourage off-grid routing of vias by increasing the cost associated with off-grid routing."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running Tasks in Parallel"}, {"role": "assistant", "content": "To efficiently run the same task on several blocks in your design, you can use the run_block_script command to enable distributed processing and perform the tasks in parallel.\n The run_block_script command accepts a Tcl script and applies the commands in the script to the blocks you specify.\n For example, to compile the subblocks of a design in parallel in a hierarchical flow, 1.\n Write the script to run on the blocks in the design.\n The following example performs the steps necessary to compile each subblock in the design.\n You can add additional commands to the script as needed to perform other operations.\n open_lib $block_libfilename open_block $block_refname.design commit_upf set_editability -from_level 1 -value false compile_fusion -from initial_map -to initial_map create_abstract -read_only create_frame save_block $block_refname -as $block_refname/initial_map compile_fusion -from logic_opto -to logic_opto create_abstract -read_only create_frame save_block $block_refname -as $block_refname/logical_opt compile_fusion -from initial_place -to initial_place create_abstract -read_only create_frame save_block $block_refname -as $block_refname/initial_place save_block save_lib close_block -force -purge close_lib 2.\n Run the run_block_script command to process each block in parallel by using the script created in step 1.\n The following example specifies the settings for distributed processing with the set_host_options command and runs the block_synthesis.tcl synthesis script on the subblocks in parallel by using the Load Sharing Facility (LSF).\n The command writes data and log files to the my_work_dir directory.\n fc_shell> set block_list [get_attribute \\ [get_cells -hierarchical -filter \"is_soft_macro==true\" \\ ref_full_name] fc_shell> set block_list [lsort -unique $block_list] fc_shell> set_host_options -name myhost -submit_command \"sh\" fc_shell> run_block_script \\ -host_options myhost \\ 68 Enabling Multicore Processing Feedback -script block_synthesis.tcl \\ -blocks $block_list \\ -work_dir my_work_dir To control the order in which blocks are processed, use the -run_order option with the top_down or bottom-up argument.\n When you specify the -run_order top-down option, the tool delays processing for a child block until all parent blocks for the child block are processed.\n When you specify the -run_order bottom-up option, the tool begins by processing the child blocks, then processes the parent blocks.\n By default, blocks are processed in a bottom-up order."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Multicore Configurations"}, {"role": "assistant", "content": "To report the values set by the set_host_options command, use the report_host_options command.\n 66 Enabling Multicore Processing Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Single-Loop Matching"}, {"role": "assistant", "content": "To create single-loops to extend wires for length matching, use the Custom Router single- loop matching application options.\n Single-loop matching is typically used in DDR routing flows Figure 164 Adding Single Loops to Extend Wires Application Option Description custom.route.single_loop_match Adds single loops to extend wire lengths.\n 771 Using Custom Routing Application Options Feedback Application Option Description custom.route.single_loop_match_max_spacing Specifies the maximum spacing in the loop.\n custom.route.single_loop_match_min_spacing Specifies the minimum spacing in the loop.\n custom.route.single_loop_match_offset_layer Routes the segment at the top of the figure on a layer different from other segments in the loop."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Analyzing the Clock Tree Results"}, {"role": "assistant", "content": "After synthesizing the clock trees, analyze the results to verify that they meet your requirements.\n Typically the analysis process consists of the following tasks: Analyzing the clock tree QoR (as described in Generating Clock Tree QoR Reports Analyzing the clock tree timing (as described in Analyzing Clock Timing Verifying the placement of the clock instances, using the GUI (as described in Analyzing Clock Trees in the GUI"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing Signal Electromigration Violations"}, {"role": "assistant", "content": "Before fixing signal electromigration violations, make sure that the block is detail routed, the signal electromigration constraints are defined in the design library, the switching activity is defined for all boundary nets, crosstalk analysis is enabled, and there are no timing or DRC violations.\n You can optionally use the report_signal_em command first to report electromigration violations before attempting to fix them.\n 557 Performing ECO Routing Feedback To fix signal electromigration violations, use the fix_signal_em command, which performs the following tasks: Runs signal electromigration analysis for nets by calculating the current on every edge of a net and comparing it with the constraints set by the read_signal_em_constraints command.\n Fixes violations by applying nondefault routing rules to widen the metal shapes and then performing ECO routing.\n The fix_signal_em command runs a single fixing iteration; if violations remain after running this command, you must rerun it to address the remaining violations.\n By default, the command fixes signal electromigration violations on all nets.\n To fix the violations only on specific nets, use the -nets option.\n See Also Analyzing Signal Electromigration Performing ECO Routing"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Settings for Multivoltage Designs"}, {"role": "assistant", "content": "For multivoltage designs, to Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the add_buffer_on_route command.\n Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format.\n When you use this option, you must also use the -lib_cell option.\n Specify different single-rail and dual-rail library cells for different voltage areas, use the -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format.\n 970 Optimizing the Fanout of a Net Feedback When you use this option, you must also use the -lib_cell option.\n For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option.\n For the default voltage area, specify DEFAULT_VA as the voltage area name.\n Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the -allow_physical_feedthrough_buffer option.\n This option can only be used with the -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area.\n After you run the add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command.\n Add cells within gas stations of specified supply nets, use the -respect_gas_station option and specify the supply net.\n Gas stations are areas with a constant power supply.\n These areas used for buffering nets that go through power domains that are powered down.\n To specify the maximum allowed distance from the gas station to the added buffer, use the -max_distance_route_to_gas_station option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Blockages That Allow Buffers Only"}, {"role": "assistant", "content": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type allow_buffer_only -blocked_percentage 70 144 Specifying Physical Constraints for Placement and Legalization Feedback Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Merging Voltage Area Shapes"}, {"role": "assistant", "content": "To merge the voltage area shapes into a minimum set of disjoint shapes, use the -merge_regions option with the create_voltage_area create_voltage_area_shape or set_voltage_area command.\n When you use the create_voltage_area -merge_regions command, the merges the shapes specified with the -region option.\n When you use the create_voltage_area_shape -merge_regions command, the merges the shape specified with the -region option and the existing shapes of the specified voltage area.\n When you use the set_voltage_area -merge_regions command, the tool merges all existing shapes of the specified voltage area.\n The tool merges the voltage area shapes based on their stacking order.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The merged shape replaces the top shape of a set of abutting or overlapping shapes; the other shapes in the set are removed and are no longer associated with the voltage area.\n 121 Setting Up Multivoltage Designs Feedback For example, assume that you use the following command to create a voltage area comprising three rectangle shapes, as shown on the left side of Figure 14 fc_shell> create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } {PD1} fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_1 VOLTAGE_AREA_SHAPE_2 VOLTAGE_AREA_SHAPE_3} After you use the -merge_regions option to merge these shapes, the voltage area consists of a single rectilinear shape, as shown on the right side of Figure 14.\n The merged voltage area shape is named VOLTAGE_AREA_SHAPE_3, which was the last voltage area shape defined when the voltage area was created.\n fc_shell> set_voltage_area PD1 -merge_regions Information: Merging abutted and overlapping shapes in voltage_area 'PD1'.\n (NDMUI-154) fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_3} Figure 14 Merging Voltage Area Shapes To report the stacking order of the voltage area shapes, use the report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in Modifying the Stacking Order"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Timing Driven Sink Transition Target"}, {"role": "assistant", "content": "The tool supports the setup and hold timing on critical endpoints by achieving a sharper transition on the critical launch and capture clock pins.\n The tool populates the ideal timing information from the and uses it to identify the critical endpoints.\n A transition target tighter than the user specified max_transition is applied for the clock pins of timing critical endpoints and the clock tree is built considering the tightened transition which helps to improve the timing.\n To enable timing driven sink transition target, set the cts.compile.timing_driven_sink_transition application option to true before the compile_fusion stage."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Datapath Extraction"}, {"role": "assistant", "content": "Datapath extraction transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks to be implemented by a datapath generator.\n This transformation improves the quality of results (QoR) by using carry-save arithmetic.\n 222 Controlling Mapping and Optimization Feedback Carry-save arithmetic does not fully propagate carries but stores results in an intermediate form.\n The carry-save adders are faster than the conventional carry-propagate adders because the carry-save adder delay is independent of bit-width.\n These adders use significantly less area than carry-propagate adders because they do not use full adders for the carry.\n The following example shows the code for the a * b + c + d = z expression.\n As shown in Figure 30, the conventional implementation of the expression use three carry-propagate adders, whereas the carry-save arithmetic requires only one carry-propagate adder and two carry-save adders.\n The figure also shows the timing and area numbers for both implementations.\n module dp (a, b, c, d, e); input [15:0] a, b; input [31:0] c, d; output [31:0] Z; assign Z = (a * b) + c + d; endmodule Figure 30 Conventional Carry-Propagate Adder Versus Carry-Save Adder 223 Controlling Mapping and Optimization Feedback The tool supports extraction of the following components: Arithmetic operators that can be merged into one carry-save arithmetic tree Operators extracted as part of a datapath: *, +, -, >, <, <=, >=, ==,!=, and MUXes Variable shift operators (<<, >>, <<<, >>> for Verilog and sll, srl, sla, sra, rol, ror for VHDL) Operations with bit truncation The datapath flow can extract these components only if they are directly connected to each other, that is, no nonarithmetic logic between components.\n Keep the following points in mind: Extraction of mixed signed and unsigned operators is allowed only for adder trees Instantiated DesignWare components cannot be extracted"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Querying Voltage Areas"}, {"role": "assistant", "content": "You can query the following information about voltage areas: The voltage areas in the current block To create a collection of voltage areas in the current block, including the default voltage area, use the get_voltage_areas command.\n Detailed information about the voltage areas 126 Setting Up Multivoltage Designs Feedback To display detailed information about voltage areas, including the default voltage area, use the report_voltage_areas command.\n To include information about the voltage area shapes that comprise each voltage area, use the -verbose option with the report_voltage_areas command.\n Effective placement area of a voltage area To display the effective placement area of a voltage area, query the effective_shapes attribute of the voltage area.\n Effective guard bands of a voltage area To display the effective guard bands of a voltage area, query the effective_guard_band_boundaries attribute of the voltage area.\n Note that you can also query this attribute for individual voltage area shapes."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Verifying the Clock Trees"}, {"role": "assistant", "content": "Before you synthesize the clock trees, use the check_clock_tre comandcomandscheck_clock_tre check_clock_trees command to verify that the clock trees are properly defined.\n For example, to verify that the CLK clock tree is properly defined, use the following command: fc_shell> check_clock_trees -clocks [get_clocks CLK] If you do not specify the -clock option, the tool checks all clocks in the current block.\n The check_clock_trees command checks for the following issues: Clock (master or generated) with no sinks Loops in the clock network Multiple clocks reach the same register because of overlapping clocks, but multiple- clocks-per-register propagation is not enabled Ignored clock tree exceptions Stop pin or float pin defined on an output pin Buffers with multiple timing arcs used in clock tree references Situations that cause an empty buffer list 354 Verifying the Clock Trees Feedback Generated clock without a valid master clock source A generated clock does not have a valid master-clock source in the following situations: The master clock specified in create_generated_clock does not exist The master clock specified in create_generated_clock does not drive the source pin of the generated clock The source pin of the generated clock is driven by multiple clocks, and some of the master clocks are not specified with create_generated_clock For example, in Figure 78, the GEN_REG/Q pin is driven by both CLKA and CLKB.\n If only CLKA is specified as a master clock in a create_generated_clock command, GEN_CLK does not have a valid master clock source.\n Figure 78 Generated Clock With Invalid Master Clock Source REG1 REG2 GEN_REG CLKA CLKB GEN_CLK For multicorner-multimode designs, the check_clock_trees command checks all active scenarios for the following issues: Conflicting per-clock exception settings Conflicting balancing settings Before you implement the clock trees, you should manually fix the reported issues.\n Each message generated by the check_clock_trees command has a detailed man page that describes how to fix the identified issue.\n You can improve the clock tree and timing QoR by fixing all the issues identified by the check_clock_trees command.\n 355 Setting Clock Tree Design Rule Constraints Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Via Ladders"}, {"role": "assistant", "content": "via ladder, which is also referred to as a via pillar, is a stacked via that starts from the pin layer and extends into an upper layer where the router connects to it.\n Via 446 Inserting Via Ladders Feedback ladders reduce the via resistance, which can improve performance and electromigration robustness.\n To use via ladders, Via ladder rules must be defined in the technology data for the design For information about defining via ladder rules, see Defining Via Ladder Rules You must insert the via ladders before you perform global routing The Fusion Compiler tool provides the following methods for inserting via ladders: Automatic insertion during preroute optimization, as described in Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization Constraint-based insertion by using the insert_via_ladders command, as described in Constraint-Based Via Ladder Insertion Manual insertion by using the create_via_ladder command, as described in Manual Via Ladder Insertion See Also Querying Via Ladders Removing Via Ladders Controlling Via Ladder Connections"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Useful Skew"}, {"role": "assistant", "content": "This figure shows how concurrent clock and data optimization allows for clock skew to remove negative slack and potential area and leakage recovery.\n 255 Running Concurrent Clock and Data Optimization Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Postroute Logic Optimization"}, {"role": "assistant", "content": "Before performing postroute optimization, ensure that the block is fully routed and legalized and does not have excessive logical or routing DRC violations.\n To verify the legality of the design, use the check_legality command.\n To verify the routing, use the check_routes command.\n To perform postroute logic optimization, 1.\n Update the clock latency by using the compute_clock_latency command.\n 2.\n Run the route_opt command two times.\n The legalization and ECO routing performed by the first route_opt run might impact the block timing, which is then optimized by the second route_opt run.\n As the number of changes during postroute logic optimization decreases, the timing improvement from subsequent route_opt runs decreases.\n The route_opt command performs the following tasks: 1.\n Performs extraction and updates the timing By default, the route_opt command uses the PrimeTime delay calculation engine, which requires that you use cell libraries generated by O-2018.06 or later versions of the Library Manager tool.\n Before using PrimeTime delay calculation, use the check_consistency_settings command to verify that the Fusion Compiler and PrimeTime settings are consistent, as described in Checking for Consistency in Timing Analysis and Extraction Settings in the Fusion Compiler Timing Analysis User Guide The route_opt command supports both graph-based analysis (GBA), the default, and path-based analysis (PBA).\n To enable path-based optimization, use the time.pba_optimization_mode application option.\n To use path-based timing for the worst path of each endpoint, which is identified by using graph-based analysis, set this application option to path This is the recommended setting because it provides the best tradeoff between runtime and QoR.\n To use exhaustive path-based search algorithms for each endpoint, set this application option to exhaustive Using this setting increases the runtime.\n 549 Performing Postroute Optimization Feedback 2.\n Performs the enabled optimizations By default, the route_opt command optimizes for setup, hold, area, and logical DRC violations for the data paths in the block.\n To enable additional optimizations, set the application options shown in Table 33 before running the route_opt command: Table 33 Application Options to Enable route_opt Optimizations Optimization Application option settings Concurrent clock and data optimization and timing-driven clock logical DRC fixing route_opt.flow.enable_ccd true Clock logical DRC fixing route_opt.flow.enable_cto true Clock tree area recovery route_opt.flow.enable_clock_power_recovery area Clock tree power recovery route_opt.flow.enable_clock_power_recovery power Power optimization route_opt.flow.enable_power true Path-based optimization with machine learning route_opt.flow.enable_ml_opto true time.pba_optimization_mode path IR-driven optimization with machine learning For IRDOPT, set the following application options: set_app_options -name route_opt.flow.enable_irdrivenopt -value true set_app_options -name opt.common.ir_drop_threshold -value 10 For IRDCCD, set: set_app_options-name opt.common.power_integrity-value true To turn on the machine learning flow, set the following application option: set_app_options -name ccd.ccd_opt_voltage_drop_enable_ml_predictor -value true Note: The route_opt command honors only the route_opt application options; it does not honor the settings of the opt application options, except the opt.common.allow_physical_feedthrough application option.\n 3.\n Legalizes the block 4.\n Performs ECO routing 6.\n For information about setting application options to control concurrent clock and data optimization, see Controlling Concurrent Clock and Data Optimization 7.\n This optimization is supported only when concurrent clock and data optimization is not enabled.\n 8.\n The type of power optimization performed depends on scenario configuration.\n Total power optimization is performed if there is an active scenario with both leakage power and dynamic power enabled.\n Leakage power optimization is performed if there is an active scenario with only leakage power enabled.\n 550 Performing Postroute Optimization Feedback By default, the route_opt command performs five detail routing iterations during the ECO routing phase.\n To change the number of iterations, use the route.detail.eco_max_number_of_iterations application option.\n To perform track assignment instead, set the route_opt.eco_route.mode application option to track If the PrimeTime tool reports setup or hold violations during signoff timing analysis, you can use the following process to fix these violations: 1.\n Specify the target endpoints and their PrimeTime timing information by using the set_route_opt_target_endpoints command with the -setup_timing and -hold_timing options.\n 2.\n Optimize the endpoints by using the route_opt command.\n 3.\n Remove the adjusted timing information by using the set_route_opt_target_endpoints -reset command.\n You can also use this process to perform incremental optimization on specific endpoints.\n In this case, use the -setup_endpoints -hold_endpoints, and -ldrc_objects options to specify the endpoints.\n To close the final setup, hold, or logical DRC violations with minimal disturbance to the block, use size-only mode when you run the route_opt command.\n To enable size- only mode, set the route_opt.flow.size_only_mode application option to one of the following values: true_footprint, which allows resizing a cell only to a library cell that is an exact physical match, as determined by the tool after analysis This ensures that legalization or ECO routing is not required after resizing footprint, which allows resizing a cell only to a library cell that has the same footprint attribute in the library equal, which allows resizing a cell only to a library cell that is equal in size equal_or_smaller, which allows resizing a cell only to a library cell that is equal or smaller in size To disable size-only mode, set the route_opt.flow.size_only_mode application option to none or \"\", which is the default."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Making ECO Changes Using Netlist Editing Commands"}, {"role": "assistant", "content": "If the ECO changes are minimal, you can update the design by using netlist editing commands given.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true, before you run the netlist editing commands.\n For a list of netlist editing commands, see the Common Design Objects topic in the Fusion Compiler Data Model User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Tap Cells"}, {"role": "assistant", "content": "tap cell is a special nonlogic cell with a well tie, substrate tie, or both.\n These cells are typically used when most or all of the standard cells in the library contain no substrate or well taps.\n Generally, the design rules specify the maximum distance allowed between every transistor in a standard cell and a well or substrate tap.\n Before global placement (during the floorplanning stage), you can insert tap cells in the block to form a two-dimensional array structure to ensure that all standard cells placed subsequently comply with the maximum diffusion-to-tap distance limit.\n After you insert the tap cells, visually check to ensure that all standard-cell placeable areas are properly protected by tap cells.\n 581 Inserting Tap Cells Feedback The Fusion Compiler tool provides two methods to insert a tap cell array: Insert the tap cell array based on the site rows and the maximum distance between tap cells To use this method, use the create_tap_cells command, as described in Using the create_tap_cells Command Insert the tap cell array using a specified offset and pitch, and optionally insert additional tap cells near the boundary To use this method, use the create_cell_array command, as described in Using the create_cell_array Command Advanced nodes often require the insertion of additional tap cells to manage the substrate and well noise.\n You can use the following capabilities to insert additional tap cells after standard tap cell insertion: Insertion of tap walls tap wall is a row or column of tap cells placed linearly without any gaps between cells.\n You can insert a tap wall outside or inside of the boundary of a block, macro, or hard placement blockage.\n A tap wall that is outside a boundary is called an exterior tap wall.\n A tap wall that is inside a boundary is called an interior tap wall To insert an exterior tap wall, use the create_exterior_tap_walls command, as described in Inserting Exterior Tap Walls To insert an interior tap wall, use the create_interior_tap_walls command, as described in Inserting Interior Tap Walls Insertion of tap meshes tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window.\n To insert a tap mesh, use the create_tap_meshes command, as described in Inserting Tap Meshes Insertion of dense tap arrays dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the create_tap_cells command.\n To insert a dense tap array, use the create_dense_tap_cells command, as described in Inserting Dense Tap Arrays"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I UPF Flows"}, {"role": "assistant", "content": "The Fusion Compiler tool supports both the traditional UPF flow and the golden UPF flow.\n The golden UPF flow is an optional method of maintaining the UPF multivoltage power intent of the design.\n It uses the original \"golden\" UPF file throughout the synthesis, physical implementation, and verification steps, along with supplemental UPF files generated by the Fusion Compiler tool.\n 39 Fusion Compiler Concepts Feedback Figure 3 compares the traditional UPF flow with the golden UPF flow.\n Figure 3 UPF-Prime (Traditional) and Golden UPF Flows The golden UPF flow maintains and uses the same, original \"golden\" UPF file throughout the flow.\n The Fusion Compiler tool writes power intent changes into a separate \"supplemental\" UPF file.\n Downstream tools and verification tools use a combination of the golden UPF file and the supplemental UPF file, instead of a single UPF' or UPF'' file.\n The golden UPF flow offers the following advantages: The golden UPF file remains unchanged throughout the flow, which keeps the form, structure, comment lines, and wildcard naming used in the UPF file as originally written.\n You can use tool-specific conditional statements to perform different tasks in different tools.\n Such statements are lost in the traditional UPF-prime flow.\n Changes to the power intent are easily tracked in the supplemental UPF file.\n You can optionally use the Verilog netlist to store all PG connectivity information, making connect_supply_net commands unnecessary in the UPF files.\n This can significantly simplify and reduce the overall size of the UPF files.\n To enable the golden UPF flow, use the following application option setting before you load the UPF: fc_shell> set_app_options -as_user_default \\ -list {mv.upf.enable_golden_upf true} To load supplemental UPF files, use the -supplemental option with the load_upf command.\n For more information about using the golden UPF flow, see SolvNet article 1412864, \"Golden UPF Flow Application Note.\" 40 Fusion Compiler Concepts Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reading Designs Using the -autoread Option"}, {"role": "assistant", "content": "To enable the tool to automatically read a list of RTL files, specify the -autoread option with the analyze command, as shown in the following example.\n When this option is specified, the RTL language used to analyze the RTL files is automatically determined by the file name extension.\n To control the file name extensions, use the following application options: hdlin.autoread.verilog_extensions hdlin.autoread.sverilog_extensions hdlin.autoread.vhdl_extensions, and hdlin.autoread.exclude_extensions set DESIGN_NAME top analyze -autoread -top ${DESIGN_NAME} ${RTL_FILE_LIST} elaborate ${DESIGN_NAME} elaborate -hdl_library TOP_HDL_LIB top set_top_module ${DESIGN_NAME} 100 Reading the Design Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Design Rule Checking in an External Tool"}, {"role": "assistant", "content": "Calibre interface You can perform design rule checking with the Calibre tool, convert the Calibre DRC error file to an Fusion Compiler error data file, and then report or view the errors in the Fusion Compiler tool.\n To convert the Calibre DRC error file to an Fusion Compiler error data file, use the read_drc_eror_file comandcomandsread_drc_eror_file read_drc_error_file command.\n For example, fc_shell> read_drc_error_file -file Calibre_error_file By default, the command generates an error data file named cell_name.err, where cell_name is derived from the Calibre error report.\n You can specify a name for the error data file by using the -error_data option.\n Note: The read_drc_error_file command supports only flat Calibre DRC error files; it does not support Calibre hierarchy DRC error files.\n You can load the error data file created by the read_drc_error_file command into the error browser to report or display the DRC violations.\n For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Signoff Design Rule Checking"}, {"role": "assistant", "content": "IC Validator In-Design signoff design rule checking (DRC) runs the IC Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry signoff runset.\n You can perform signoff design rule checking by Running the signoff_check_drc command Using the Live DRC feature in the Fusion Compiler GUI After place and route, use the signoff_check_drc command to perform signoff design rule checking on the entire block.\n After engineering change orders (ECO), use either method to perform incremental signoff design rule checking on the modified portions of the block.\n See Also Automatically Fixing Signoff DRC Violations"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Clock Tree Synthesis Settings"}, {"role": "assistant", "content": "The clock tree synthesis options guide the implementation of the clock trees.\n The following topics describe how to set these options: Specifying the Clock Tree References Setting Skew and Latency Targets Enabling Local Skew Optimization Specifying the Primary Corner for Clock Tree Synthesis Preventing Specific Clocks From Being Synthesized Preserving Preexisting Clock Trees Enabling Clock Tree Power Reduction Techniques Enabling Wire Length Aware Power-Driven Relocation Reducing Electromigration Handling Inaccurate Constraints During Clock Tree Synthesis Defining Clock Cell Spacing Rules Creating Skew Groups Defining a Name Prefix for Clock Cells Using the Global Router During Initial Clock Tree Synthesis Specifying Constraints for Clock Nets Constructing Faster Clock Tree to Specific Endpoints Improving Latency-Driven Clock-Gate Splitting Improving the Repeater Levels in Clock Tree Reducing Signal Integrity Effects on Clock Nets Specifying Settings for Clock Latency Adjustments Timing Driven Sink Transition Target Reporting the Clock Tree Settings 357 Specifying the Clock Tree Synthesis Settings Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Hierarchical Relative Placement Groups"}, {"role": "assistant", "content": "To create a hierarchical relative placement group by adding a group to another group, use the -rp_group option with the add_to_rp_group command.\n Specify the column and row position within the relative placement group by using the -column and -row options.\n The group you specify with the -rp_group option must be in the same design as the hierarchical group in which you are including it.\n When you include a relative placement group in a hierarchical group, it is as if the included group is directly embedded within its parent group.\n An included group can be used only in a group of the same design and only one time.\n However, a group that contains an included group can be further included in another group in the same design or can be instantiated in a group of a different design.\n The script in Example 43 creates a hierarchical group (rp4) that contains three included groups (rp1, rp2, and rp3).\n Groups rp1, rp2, rp3, and rp4 are all in the design top.\n The contents of groups rp1, rp2, and rp3 are treated as leaf cells when they are included in group rp4.\n You can further include group rp4 in another group in the design top, or you can instantiate group rp4 in a group of a different design.\n The resulting hierarchical relative placement group is shown in Figure 168 Example 43 Including Groups in a Hierarchical Group create_rp_group -name rp1 -columns 2 -rows 1 add_to_rp_group rp1 -cells U1 -column 0 -row 0 add_to_rp_group rp1 -cells U4 -column 1 -row 0 create_rp_group -name rp2 -columns 2 -rows 1 add_to_rp_group rp2 -cells U2 -column 0 -row 0 add_to_rp_group rp2 -cells U5 -column 1 -row 0 787 Adding Objects to a Group Feedback create_rp_group -name rp3 -columns 2 -rows 1 add_to_rp_group rp3 -cells U3 -column 0 -row 0 add_to_rp_group rp3 -cells U6 -column 1 -row 0 create_rp_group -name rp4 -columns 1 -rows 3 add_to_rp_group rp4 -rp_group rp1 -column 0 -row 0 add_to_rp_group rp4 -rp_group rp2 -column 0 -row 1 add_to_rp_group rp4 -rp_group rp3 -column 0 -row 2 Figure 168 Including Groups in a Hierarchical Group rp3 rp2 rp1 U3 U2 U4 U5 U6 U1 rp4 rp1 U4 U1 U3 U6 rp2 U2 U5 rp3 col 0 col 1 col 0 col 1 col 0 col 1 row 0 row 0 row 0 row 2 row 0 row 1 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Keepout Margins"}, {"role": "assistant", "content": "A keepout margin is a region (the shaded portions in Figure 21 ) around the boundary of fixed cells in a block in which no other cells are placed.\n 137 Specifying Physical Constraints for Placement and Legalization Feedback Figure 21 Placement Keepout Margins left bottom right top Outer keepout margin Fixed cell left bottom right top Inner keepout margin Fixed cell An outer keepout margin is a region outside the cell boundary, while an inner keepout margin is a region inside the cell boundary.\n The width of the keepout margin on each side of the fixed cell can be the same or different, depending on how you define the keepout margin.\n In addition, keepout margins can be defined as hard or soft.\n Keeping the placement of cells out of such regions avoids congestion and net detouring and produces better QoR.\n kepout marginscel-specific, seting To define a keepout margin, use the set_kepout_margin comandcomandset_kepout_margin create_keepout_margin command.\n By default, the command creates a hard keepout margin.\n To create a soft keepout margin, use the -type soft option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating New Relative Placement Groups in a Placed Design"}, {"role": "assistant", "content": "You can create a new relative placement group of cells in a placed design and relative placementincremental relative placement place the relative placement groups incrementally by using the place_opt -from final_place command.\n If you select cells that are placed far apart in the initial placement for the same relative placement group, performing incremental relative placement might degrade the QoR.\n The following example shows how to add a new relative placement group to a design that is already placed and optimized, and performs incremental placement and optimization: fc_shell> create_rp_group -name new_rp -columns 1 -rows 2 fc_shell> add_to_rp_group new_rp -cells U1 -column 0 -row 0 fc_shell> add_to_rp_group new_rp -cells U2 -column 0 -row 1...\n fc_shell> place_opt -from final_place For a placed design, if you create a new relative placement group and specify an anchor location by using the -x_offset and -y_offset options with the set_rp_group_options command, you can use the legalize_rp_groups command to legalizes the newly created group anchored by the specified x- and y-coordinates.\n Using the 811 Analyzing Relative Placement Groups Feedback legalize_rp_groups command for incremental relative placement groups reduces the turnaround time."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Preparing for Top-Level Closure With Abstracts"}, {"role": "assistant", "content": "Before you can perform synthesis, placement, optimization, clock tree synthesis, and routing at the top level, you must perform the following tasks: Apply the top-level-timing constraints and settings.\n You can split the chip-level constraints in to separate top- and block-level constraints by using the split_constraints command.\n Review and specify the relationship between the top- and block-level modes, corners, and clocks by using the set_block_to_top_map command.\n If the pre-clock tree implemented blocks, which have undergone CCD optimization, are used for top-level placement and optimization, then the ideal clock latencies adjusted dynamically by different engines such as CCD and clock-gate estimation on the clock pins of registers or integrated clock gating (ICG) cells inside the blocks might not be seen at the top-level leading to timing inaccuracies at the top-level.\n Promote these clock latency constraints from block-level to the top-level by using the promote_clock_data -latency_offset -auto_clock connected command.\n Apply the top-level clock tree synthesis settings and exceptions.\n If the top-level exceptions do not include the balance points on the pins within lower-level blocks, promote the balance points from the lower levels by using the promote_clock_data -auto_clock connected -balance_points command.\n If concurrent clock and data (CCD) optimization is performed at the block level, the tool derives median clock latencies for the block-level clock ports, which accounts for the latency adjustments that were derived for the block-level registers during concurrent clock and data optimization.\n Promote these block-level clock latencies as clock balance point delays for the block-level clock pins by using the promote_clock_data -auto_clock connected -port_latency command.\n If the lower-level blocks contain clock-meshes, promote the mesh annotations (annotated transitions and delays) by using the promote_clock_data -mesh_annotations command.\n If you need to promote clock data for a specific top-level clock, use the promote_clock_data -clocks {top_clock} -port_latency command.\n The command also promotes clock-independent exceptions.\n If any of the given top-level clocks has no mapping to any block-level clock in any mode, the tool issues a warning.\n If there are any active modes, corners, or clocks at the top-level, which cannot be mapped to corresponding modes, corners, or clocks in the block-level, you can still promote the clock data for other mapped modes, corners, or clocks using the promote_clock_data -balance_points -force command.\n This command issues errors for the unmapped modes, or corners, or clocks.\n 842 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Apply the top-level UPF constraints, which you can create from the full-chip UPF constraints by using the split_constraints command.\n The tool promotes the required UPF constraints from the lower-level blocks to the top level."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reducing Critical Areas"}, {"role": "assistant", "content": "A critical area is a region of the block where, if the center of a random particle defect falls there, the defect causes circuit failure, thereby reducing yield.\n A conductive defect causes a short fault, and a nonconductive defect causes an open fault.\n 632 Reducing Critical Areas Feedback The following topics describe how to Reduce critical area short faults by performing wire spreading Reduce critical area open faults by performing wire widening"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Mapping Rules for Programmable Spare Cells"}, {"role": "assistant", "content": "You can define mapping rules for programmable spare cells to control the Overlapping of spare cells and PG nets Splitting of multiple-height and merging of single-height spare cells Compatibility of the different types of spare cells To do so, use the set_programmable_spare_cell_mapping_rule command before you run the place_freeze_silicon command.\n To report or remove the mapping rules you specify, use the report_programmable_spare_cell_mapping_rule command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Routing Blockages"}, {"role": "assistant", "content": "A routing blockage defines a region where routing is not allowed on specific layers.\n Zroute considers routing blockages to be hard constraints.\n To define a routing blockage, use the create_routing_blockage command.\n At a minimum, you must define the boundary of the routing blockage and the affected layers.\n To create a rectangular routing blockage, use the -boundary option to specify the lower-left and upper-right corners of the rectangle using the following syntax: { { llx lly } { urx ury } } To create a rectilinear routing blockage, use the -boundary option to specify the coordinates of the polygon using the following syntax: { { x1 y1 } { x2 y2 }...\n } You can also create a rectilinear routing blockage by specifying the polygon as the combined area of a heterogeneous collection of objects with physical geometry, such as poly_rects, geo_masks, shapes, layers, and other physical objects.\n If you specify a layer, the resulting area includes the area of every shape on the layer.\n For all other objects, the resulting area includes the area of each object.\n You can create multiple routing blockages by specifying the boundary polygon as a geo_mask or a collection of physical objects.\n If the resulting area resolves to multiple, noncontiguous polygons, the command creates multiple routing blockages, one corresponding to each polygon.\n To specify the affected layers, use the -layers option.\n Specify the routing layers by using the layer names from the technology file.\n The layers can be metal, via, or poly layers.\n By default, the tool creates a routing blockage named RB_ objId in the current block that prevents routing of all nets within the routing blockage boundary.\n The routing blockage is considered as real metal for RC extraction and DRC checking and the router must meet the minimum spacing requirements between the routing blockage boundary and the net shapes.\n Use the following options to change the default behavior: -name blockage_name Specifies a name for the routing blockage.\n -cell cell Creates the routing blockage in a different physical cell.\n When you use this option, the tool creates the routing blockage in the cell's reference block using the coordinate system of the cell's top-level block.\n -zero_spacing 471 Routing Constraints Feedback Disables the minimum spacing rule between the routing blockage boundary and the net shapes (zero minimum spacing).\n This option also prevents the routing blockage from being treated as real metal during extraction and DRC checking.\n When you use this option, the net shapes can touch, but not overlap, the routing blockage boundary.\n Note: When you create a routing blockage to prevent via insertion, you must use the -zero_spacing option; otherwise, frame view extraction does not use the route guide to trim the via region.\n -net_types list_of_types Applies the routing blockage only to the specified net types.\n Specify one or more of the following net types: analog_ground analog_power analog_signal clock deep_nwell deep_pwell ground nwell power pwell reset scan signal tie_high, and tie_low.\n To remove the net type settings and prevent routing of all nets in the routing blockage, use the -net_types unset setting.\n To prevent signal routing on the M1 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell> create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types signal -layers M1 To prevent vias on the V1 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell> create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types signal -layers V1 -zero_spacing To prevent PG routing on the M2 layer within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell> create_routing_blockage \\ -boundary { {0.0 0.0} {100.0 100.0} } \\ -net_types {power ground} -layers M2 472 Routing Constraints Feedback"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up the Executables"}, {"role": "assistant", "content": "To run RedHawk Fusion or RedHawk-SC Fusion features, enable the features and specify the location of the RedHawk or RedHawk-SC executable by setting the rail.product and rail.redhawk_path application options.\n For example, fc_shell> set_app_options -name rail.product -value redhawk|redhawk_sc fc_shell> set_app_options -name rail.redhawk_path \\ -value /tools/RedHawk_Linux64e5_V19.0.2p2/bin You must ensure that the specified executable is compatible with the Fusion Compiler version that you are using.\n See Also Specifying RedHawk and RedHawk-SC Working Directories"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Viewing Your Checkpoint History"}, {"role": "assistant", "content": "To view your checkpoint history, navigate to the checkpoint directory.\n This directory contains a checkpoint_history.rpt file that captures the history of the checkpoints the tool encounters during each run, along with the runtime and memory usage for each checkpoint.\n The checkpoint directory also contains any checkpoint reports you have written to it.\n In some cases, you might want to clear the full or partial contents of your checkpoint history.\n A typical example is when a checkpointed run fails and you want to clear some or all of the data associated with that run, depending on whether you plan to rerun a portion of the flow or the entire flow.\n To clear your full checkpoint history, use the reset_checkpoints command.\n fc_shell> reset_checkpoints The reset_checkpoints command clears the full contents of the checkpoint directory, including any reports you have written to it.\n However, before clearing the checkpoint directory, the reset_checkpoints command saves a timestamped copy of the directory in your run directory.\n 61 Using Setup Files Feedback To clear a portion of the data in your checkpoint_history.rpt file, use the -from option to specify the name of a checkpoint.\n This option removes all checkpoints including and following the specified checkpoint from your checkpoint_history.rpt file; it does not remove any checkpoint reports you have written to the checkpoint directory.\n For example, suppose your checkpoint_history.rpt file contains the following data after your run a full checkpointed flow: Checkpoints Memory StartTime...\n remove_buffers 32290.86 2020-03-23_14:34:17...\n place_opt_to_initial_drc 36389.15 2020-03-23_17:21:56...\n incr_placement 37002.09 2020-03-23_19:13:02...\n place_opt_to_initial_opto 45655.59 2020-03-23_23:44:36...\n place_opt_to_final_opto 46322.34 2020-03-23_30:12:55...\n Suppose you want to rerun your flow beginning with incremental placement.\n To clear the last three checkpoints from your checkpoint_history.rpt file before rerunning that portion of your flow, use the following command: fc_shell> reset_checkpoints -from incr_placement After clearing the checkpoints, your checkpoint_history.rpt file lists only the first two checkpoints in your flow: Checkpoints Memory StartTime...\n remove_buffers 32290.86 2020-03-23_14:34:17...\n place_opt_to_initial_drc 36389.15 2020-03-23_17:21:56...\n Similarly, the get_checkpoint_data -list_names command returns only the remove_buffers and place_opt_to_initial_drc checkpoints: fc_shell> get_checkpoint_data -list_names remove_buffers place_opt_to_initial_drc"}]}
