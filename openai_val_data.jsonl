{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Mapping ECO Cells to Logically Equivalent Spare Cells"}, {"role": "assistant", "content": "To map an ECO cell to a specific spare cell, use the map_freeze_silicon command.\n Specify the ECO cell name and the corresponding spare cell name by using the -eco_cell and -spare_cell options.\n The following example maps the ECO cell named ECO1 to the spare cell named spare_1: fc_shell> map_freeze_silicon -eco_cell ECO1 -spare_cell spare_1 You can specify the ECO cell to spare cell mapping by using a map file and specifying this map file name by using the -map_file option with the map_freeze_silicon command.\n The map file has the following format: ECO_cell_1 spare_cell_1 ECO_cell_2 spare_cell_2...\n..."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Updating Via Ladders"}, {"role": "assistant", "content": "To verify that the via ladders in the block match the via ladder constraints and are properly connected to pins, use the verify_via_ladders command.\n By default, this command checks all via ladders.\n To restrict the checking to specific nets, use the -nets option.\n Note: If you use the -shift_vias_on_transition_layers true option when you insert the via ladders, you must also use this option when you verify the via ladders; otherwise, the command reports false violations.\n A via ladder matches the via ladder constraints if the pattern of connected vias and wires for the via ladder structure satisfies any of the via ladder templates assigned to the connected pin.\n The command flags a violation in the following situations:  A via ladder is connected to a pin that does not have a via ladder constraint  A via ladder is connected to a pin with a via ladder constraint, but none of the templates correctly describe the current via ladder structure  A pin has a via ladder constraint, but does not have a via ladder connected to it       A via ladder is properly connected to a pin if all the via enclosures at the base of the via ladder touch the same pin and that pin is logically connected to the same net as the via ladder.\n The command flags a violation in the following situations:  An enclosure of the via ladder base touches a different pin, unless the pins are must- join pins that belong to the same must-join set  An enclosure of the via ladder base does not touch any pin  An enclosure of the via ladder touches a pin that is not of the same net as the via ladder By default, the verify_via_ladders command reports the via ladder insertion status for each target pin, which can result in a very large report.\n To limit the number of via ladders reported for each category to 40, use the -report_all_via_ladders false option with the verify_via_ladders command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Skew Groups"}, {"role": "assistant", "content": "To define clock cell spacing rules, use the set_clock_cell_spacing command.\n At a minimum, you must specify the minimum spacing in the x-direction or the y-direction; typically you would specify the minimum spacing in both directions.\n To specify the minimum spacing in microns in the  X-direction, set the -x_spacing option to a nonzero value This value is usually dependent on the library cell's drive strength and clock frequency.\n        Y-direction, set the -y_spacing option to a nonzero value This value is usually less than half a row height.\n Note: Using a large spacing value increases the skew because the cells are spaced further away from the intended clusters of sinks.\n By default, the specified cell spacing requirements apply to all clock cells.\n To restrict the clock cell spacing rules to specific  Library cells, use the -lib_cells option  Clocks, use the -clocks option If adjoining clock cells both have cell spacing rules for a given direction, the sum of the spacing values applies.\n For example, if two adjoining clock cells both have a minimum cell spacing of 5 microns in the x-direction, they are placed at least 10 microns apart in the x-direction.\n You can relax the adjoining cell spacing rule by setting the cts.placement.cell_spacing_rule_style application option to maximum, in which case the tool uses the larger of the spacing settings between two adjoining cells instead of the sum of the spacing settings.\n For example, the clock cells in the previous example are placed at least 5 microns apart in the x-direction, instead of 10 microns.\n The clock cell spacing rules defined by the set_clock_cell_spacing command are honored by the synthesize_clock_trees balance_clock_groups, and clock_opt commands.\n To report clock cell spacing rules, use the report_clock_cell_spacings command.\n To remove clock cell spacing rules, use the remove_clock_cell_spacings command.\n By default, this command removes all clock cell spacing rules.\n To remove specific clock cell spacing rules, use the -lib_cells option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Synthesizing the Top-Level"}, {"role": "assistant", "content": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1.\n Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2.\n Apply any block-specific constraints and settings required for synthesizing the block.\n       3.\n Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command.\n 4.\n Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5.\n Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up the Executables"}, {"role": "assistant", "content": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished.\n You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished.\n To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command.\n When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database.\n By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed.\n However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results.\n       Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not.\n When opening rail results, the tool does not detect if the result is generated with or without the -bg option.\n The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa.\n Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory.\n To check if the background analyze_rail process is active, use the report_background_jobs command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Incremental Signoff ECO Flow"}, {"role": "assistant", "content": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool.\n You can also perform power or area recovery in the PrimeTime tool.\n       If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in  Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations?\n PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1.\n Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands.\n 2.\n Update the placement by using the place_eco_cells command as shown in the following example: place_eco_cells -legalize_mode minimum_physical_impact \\ -eco_changed_cells -legalize_only -displacement_threshold 10 For more information about the place_eco_cells command, see Placing ECO Cells 3.\n Add filler cells to the empty spaces in the site array, as described in Inserting Filler Cells       To reduce runtime, use the -post_eco option when you  Insert metal filler cells with the create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells  Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4.\n Update the routing by using the route_eco command, as described in Performing ECO Routing, or by manually rerouting the affected nets."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing Signal Electromigration Violations"}, {"role": "assistant", "content": "The comandsreport_signal_emreport_signal_em comand report_signal_em command performs signal electromigration analysis for each net by calculating the current on every edge and comparing this data with the constraints set by the read_signal_em_constraints command.\n For example, fc_shell> report_signal_em -violated -verbose       The report_signal_em command performs a timing update, if needed, and analyzes all nets for electromigration.\n The -verbose option causes the report to show detailed electromigration analysis information, which usually produces a very large report when used by itself.\n To get a report with a reasonable size, use the -violated option as well, which limits the report to only the nets with electromigration violations.\n To limit the analysis to specific nets, use the -nets option.\n set_em_options comandcomandset_em_options You can specify settings for electromigration analysis by setting the application options shown in the following table.\n Table 34 Application Options for Signal Electromigration Analysis Application option Default Description em.net_delta_temperature    em.net_duration_condition_for_peak    em.net_global_rms_relaxation_factor    em.net_metal_line_number      em.net_min_duty_ratio    em.net_use_waveform_duration false false true   em.net_violation_rule_types   When you perform signal electromigration analysis, the tool computes three current values:  Average  Root mean square  Peak The default report generated by the report_signal_em command lists the number of nets with electromigration violations and the types of constraints violated (mean, absolute       average, RMS, or peak).\n If you use the -verbose option, the report displays detailed information about the violations, as shown in Example 25 Example 25 Verbose Electromigration Report fc_shell> report_signal_em -violated -verbose...\n Net Name: clks/trimch_macroout_cb_group_gpaf0lts1_gpu_c_0_s_0[3] Violations: RMS PEAK  Flag Segment Layer BBox Coordinates Width/Cut Required AVERAGE RMS PEAK  v PATH_36_392230 M6D (1450.000, 995.612 -> 1452.715, 995.652) 0.040 0.085 1.514e-02 (-) 9.650e-01 (5.231e-01) 1.365e+00 (1.349e+00) VIA_S_11051278 V5D (1449.969, 995.582 -> 1450.071, 995.682) 1 - 1.465e-02 (-) 7.380e-01 (-) 1.044e+00 (-) v PATH_35_765189 M5A (1450.001, 994.973 -> 1450.039, 995.651) 0.038 0.047 1.417e-02 (-) 6.088e-01 (4.981e-01) 8.609e-01 (1.274e+00) VIA_S_11051279 V5D (1449.969, 994.942 -> 1450.071, 995.042) 1 - 1.369e-02 (-) 5.249e-01 (-) 7.423e-01 (-) PATH_36_392231 M6D (1407.370, 994.972 -> 1450.040, 995.012) 0.040 - 1.311e-02 (-) 2.047e-01 (5.231e-01) 2.894e-01 (9.443e-01) VIA_S_11051280 V5D (1407.339, 994.942 -> 1407.441, 995.042) 1 - 1.252e-02 (-) 1.926e-01 (-) 2.723e-01 (-)...\n The report shows the segment name (Segment column), layer name (Layer column), location coordinates (Bbox Coordinates column), metal width or via cut number (Width/Cut column), the constraint value (Required column), the average, RMS, and peak current in mA for the wire segment or via at that location.\n The letter \"v\" in the Flag column indicates a violation at that location.\n A hyphen in the Required column means that there is no electromigration constraint for that metal or via layer.\n In the AVERAGE, RMS, and PEAK columns, the first value is the calculated value and the value in parenthesis is the limit imposed by the electromigration constraints, where a hyphen indicates that there is no electromigration constraint."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Naming Convention for Tool-Inserted Clock Gates"}, {"role": "assistant", "content": "Clock gating applies to synchronous load-enable registers, which are flip-flops that share the same clock and synchronous control signals.\n Synchronous control signals include synchronous load-enable, synchronous set, synchronous reset, and synchronous toggle.\n Synchronous load-enable registers are represented by a register with a feedback loop that maintains the same logic value through multiple cycles.\n Clock gating applied to synchronous load enable registers reduces the power needed when reloading the register banks.\n  shows a simple register bank implementation using a multiplexer and feedback loop.\n  Synchronous Load-Enable Register With Multiplexer Flip Flop Mux Control Logic Register Bank EN CLK DATA IN   DATA OUT When the synchronous load enable signal (EN) is at logic state 0, the register bank is disabled.\n In this state, the circuit uses the multiplexer to feed the Q output of each storage element in the register bank back to the D input.\n When the EN signal is at logic state 1, the register is enabled, allowing new values to load at the D input.\n       These feedback loops can unnecessarily use power.\n For example, if the same value is reloaded in the register throughout multiple clock cycles (EN equals 0), the register bank and its clock net consume power while values in the register bank do not change.\n The multiplexer also consumes power.\n Clock gating eliminates the feedback net and multiplexer shown in by inserting a gate in the clock net of the register.\n Note: While applying the clock-gating techniques, the tool considers generated clocks similar to defined clocks.\n The clock-gating cell selectively prevents clock edges, thus preventing the gated-clock signal from clocking the gated register.\n  shows a latch-based clock-gating cell and the waveforms of the signals are shown with respect to the clock signal, CLK.\n  Latch-Based Clock Gating Flip Flop Control Logic Register Bank    Latch CLK ENCLK ENL EN CLK DATA IN DATA OUT CLK CLK EN ENL ENCLK The clock input to the register bank, ENCLK, is gated on or off by the AND gate.\n ENL is the enabling signal that controls the gating; it derives from the EN signal on the multiplexer shown in.\n The register bank is triggered by the rising edge of the ENCLK signal.\n The latch prevents glitches on the EN signal from propagating to the register's clock pin.\n When the CLK input of the 2-input AND gate is at logic state 1, any glitching of the EN signal could, without the latch, propagate and corrupt the register clock signal.\n The latch eliminates this possibility because it blocks signal changes when the clock is at logic 1.\n       In latch-based clock gating, the AND gate blocks unnecessary clock pulses by maintaining the clock signal's value after the trailing edge.\n For example, for flip-flops inferred by HDL constructs of rising-edge clocks, the clock gate forces the gated clock to 0 after the falling edge of the clock.\n By controlling the clock signal for the register bank, you can eliminate the need for reloading the same value in the register through multiple clock cycles.\n Clock gating inserts clock-gating circuitry into the register bank's clock network, creating the control to eliminate unnecessary register activity.\n Clock gating does the following:  Reduces clock network power dissipation  Relaxes datapath timing  Reduces congestion by eliminating feedback multiplexer loops For designs that have large register banks, clock gating can save power and area by reducing the number of gates in the design.\n However, for smaller register banks, the overhead of adding logic to the clock tree might not compare favorably to the power saved by eliminating a few feedback nets and multiplexers."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing Multivoltage Violations"}, {"role": "assistant", "content": "Table 73 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters.\n Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error: The repeater group (%d) is invalid.\n    report_repeater_g roups        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning: Failed to connect to route for %d object: {%s }.\n       place_group_repeat ers ECO-224 Error: The option -repeater_groups cannot be used when the app option eco.placement.eco_enable_ pipeline_register_placer is false.\n       place_group_repeat ers ECO-227 Warning: Failed to place %d repeaters for %d drivers in collection (%s), and failed cells are in collection (%s).\n   query_objects get_ports get_pins  get_cells     place_group_repeat ers ECO-228 Warning: Some repeaters from path driver (%s) have same repeater group id.\n The cells belonging to the path are {%s}.\n          place_group_repeat ers ECO-229 Warning: Failed to find intersection of cutline %s and route for cell {%s}.\n place_group_repeat ers ECO-231 Error: The repeater group (%d) has no cutline or invalid cutline.\n     set_repeater_gr oup        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error: Cutline {{%s} {%s}} is invalid.\n      place_group_repeat ers unplace_group_repeat ers ECO-233 Error: The cells in collection (%s) are invalid since they have no target input pin name (%s) and output pin name (%s).\n       -lib_cell_input  -lib_cell_output     -lib_cell_input   -lib_cell_output  place_group_repeat ers ECO-234 Warning: There is no repeater to be placed for the path driver (%s).\n place_group_repeat ers ECO-235 Warning: There is no route on driver net (%s).\n place_group_repeat ers ECO-236 Warning: There is no target load for path driver (%s).\n place_group_repeat ers ECO-237 Warning: Some cell to be placed has no load for path driver (%s).\n place_group_repeat ers ECO-239 Info:%s.\n                Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error: The option -cells cannot be used when the app option eco.placement.eco_enable_ virtual_connection is true.\n    -repeater_groups    place_group_repeat ers ECO-241 Warning: The distance based placement does not support multi-fanout path driver(%s).\n     place_group_repeat ers unplace_group_repeat ers ECO-242 Warning: The cell (%s) has no driver or load (number of driver: %d, number of load: %d).\n place_group_repeat ers ECO-243 Error: The cells in collection (%s) are invalid since they have no driver or load.\n       place_group_repeat ers ECO-244 Warning: The %s %s has no shape.\n    place_group_repeat ers ECO-246 Warning: Skip the path driver (%s) since the driver or load for the path has no shape.\n place_group_repeat ers ECO-251 Info: Place group repeaters successfully.\n    place_group_repeat ers ECO-252 Warning: Failed to place repeaters for repeater path which driver is %s.\n place_group_repeat ers ECO-253 Warning: The cutline information %s for cell %s is not on valid route.\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning: Failed to cut route for cell %s.\n    place_group_repeat ers ECO-255 Warning: Gap %s between driver and nearest route is larger than placing distance %s      place_group_repeat ers ECO-256 Warning: The first distance (%s) specified by command option is shorter than the gap (%s) between pin and route for driver (%s).\n (warning) The last distance (%s) specified by command option is shorter than the gap (%s) between pin and route for load (%s).\n  -first_distance -last_distance      place_group_repeat ers ECO-257 Warning: Cannot find cutline information for cell %s.\n place_group_repeat ers ECO-258 Info: The app option about virtual connection is turned on.\n Please make sure the cells in repeater group keep in order.\n  eco.placement.eco _enable_virtual_c onnection   place_group_repea ters -repeater_groups  place_group_repeat ers unplace_group_repeat ers ECO-259 Warning: The number of cells from repeater group (%d) is not consistent with the number of drivers from driver group (%s).\n place_group_repeat ers unplace_group_repeat ers ECO-260 Warning: The number of cells from repeater group (%d) is not consistent with the number of loads from load group (%s).\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning: The number of path loads is less than the number of cells in group (%d), so skip these path loads.\n place_group_repeat ers unplace_group_repeat ers ECO-262 Warning: The number of path loads is not an integral multiple of the number of cells in group (%d), so use path loads in order.\n place_group_repeat ers ECO-265 Warning: The pin shape {%s} of %s (%s) is projected to route %s {%s}.\n       unplace_group_repeat ers ECO-266 Warning: The cells in collection %s which are not placed before cannot be unplaced by unplace_group_repeaters.\n       add_group_repeat ers   placed_group_repe aters  unplace_group_rep eaters  unplace_group_repeat ers ECO-267 Error: Input and output routes are not merged after unplacing repeater %s since the routes are not aligned or not at the same layer.\n               Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-268 Error: The cells in collection (%s) are invalid since they are placed before.\n Apply the command unplace_group_repeaters to unplace them.\n    add_group_repeat ers   place_group_repea ters  add_group_repeaters place_group_repeat ers ECO-269 Error: Unable to check the current reference of cell '%s': %s.\n           add_group_repeaters place_group_repeat ers ECO-270 Error: Unable to find swappable variant reference for cell '%s': %s.\n     add_group_repeaters place_group_repeat ers ECO-271 Error: Candidate reference '%s' and reference (%s) of cell (%s) are not in the same variant cell group.\n          unplace_group_repeat ers ECO-272 Error: The mixed input cells are not supported, which includes the cells added by add_group_repeaters and the cells placed by place_group_repeaters.\n unplace_group_repeat ers ECO-273 Error: There are no placed cells to be unplaced.\n Please double check the cell status.\n          Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips ECO-274 Warning: You are deleting cell %s with eco_repeater_group_id %d.\n     place_group_repeat ers ECO-275 Error: Failed to traverse cutlines.\n The nets may have too many blockages.\n      -repeater_group"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting and Removing Cut Metal Shapes"}, {"role": "assistant", "content": "At advanced technology nodes, mask colors must be assigned to wires and vias to ensure correct processing of the net shapes during mask synthesis.\n The route_detail command and other routing commands in the tool usually add the necessary mask colors during routing.\n For net shapes that do not have a color assignment, use the derive_mask_constraint command to derive the color mask for the specified wires and vias from the nearest underlying tracks.\n In case of wide wires that occupy multiple tracks, the command takes the mask color opposite to the next unoccupied track.\n The following example derives the mask color for the net shapes of the net1 net.\n fc_shell> derive_mask_constraint \\ [get_shapes -of_objects [get_nets net1]]       Use options to the derive_mask_constraint command to control how the mask colors are derived.\n  Derive cut mask constraints for the specified nets or vias.\n fc_shell> derive_mask_constraint -derive_cut_mask \\ [get_vias -within {{600 600} {700 700}}]  Derive mask constraints from overlapping or touching pins or ports.\n fc_shell> derive_mask_constraint -follow_pin_mask \\ [get_shapes -of_objects [get_nets net1]]  Derive the mask constraint from the wider overlapping or touching object rather than the wire track.\n fc_shell> derive_mask_constraint -follow_wider_object_mask \\ [get_shapes -of_objects [get_nets net1]] See Also  Multiple-Patterning Concepts"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using the DRC Query Commands"}, {"role": "assistant", "content": "To report the total wire length at any stage of the routing flow, use the consolidated report_wirelength command.\n This command supports all net types, except power ground nets, by default such as signal nets, clock nets.\n It also supports non-stripe power ground nets by option control.\n This command generates a report, which includes the following information in the form of two tables, as shown in the figure:  Total wire length per layer with separate global and detailed routing lengths  Total wire length by both horizontal and vertical direction       In the generated report,  Virtual value means the estimated routing wire length for each net.\n For each net, the engine provides a virtual routing length before real routing.\n It remains even after route_auto  BestAvailable means the sum of wire length of all nets irrespective of the stage they are in the current design.\n This command also supports slanting wires and counts the real length of an angle wire in total and counts the projection length of the x-axis and y-axis."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing Diodes"}, {"role": "assistant", "content": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design.\n The command can perform the following changes:  Minimize the number of dual-rail buffers or inverters  Fix isolation violations in buffer trees  Fix buffers and inverters that have illegal settings, as follows:  Process, voltage, and temperature settings  Library cell purpose or subset settings  Target library subset settings  Bias voltages  Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows:  Swap buffer library cells to fix illegal settings  Swap single-rail buffers for dual-rail buffers  Swap dual-rail buffers for single-rail buffers  Change the backup supplies of dual-rail buffers and inverters  Change the input or output supplies of level shifters  Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough  Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters.\n In addition,       the command only uses supplies that are available in the voltage area or voltage area region.\n The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations.\n Netlist changes caused by the command do not introduce new isolation or voltage violations.\n To specify a buffer tree, use the -from option with the name of a net or driver pin.\n If you specify a net name, its driver pin is used.\n In both cases, the driver pin defines a full or partial buffer tree.\n Wildcards are supported.\n The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells.\n By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations.\n However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area.\n If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order:  A cell from the same library as the original library cell  A cell from a library with a name similar to the original library  A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells.\n Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells.\n However, the command does not change level-shifter library cells.\n To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up Multivoltage Designs"}, {"role": "assistant", "content": "Use the commands and application options described in this topic to create constraints for auto floorplanning.\n Commands Use the following two commands to set and report auto floorplanning constraints.\n These two commands do not affect explicit floorplanning.\n  set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile.\n For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8  report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command.\n To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands:  Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin  Pin placement constraints set_block_pin_constraints set_individual_pin_constraints  Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning.\n  compile.auto_floorplan.initialize (default: auto  auto : Creates missing floorplan information.\n The tool exits with an error when inconsistent information is provided.\n  true : Always creates the core and boundary.\n  false : Never creates the core and boundary; uses only existing information.\n The tool exits with an error when encountering missing or inconsistent information.\n       By default, the following objects are preserved:  Existing placement of fixed macros  Existing placement of pins and pads  Existing shaping of voltage areas  compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped  all : Always places and shapes objects even if they are fixed.\n Unplaced and unshaped objects will always be placed and shaped.\n  unfixed : Places and shapes objects that are not fixed.\n Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify.\n Unplaced and unshaped objects will always be placed and shaped.\n  unplaced, unshaped : Never places or shapes objects when they are already placed.\n Unplaced and unshaped objects will always be placed and shaped.\n  none : Never places or shapes objects even if they are not already placed.\n This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning.\n Application option setting Fixed objects Placed objects Unplaced objects all    unfixed    unplaced, unshaped    none     compile.auto_floorplan.keep_bounds (default: auto        auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas  true : Keeps existing bounds.\n  false : Removes existing bounds.\n  compile.auto_floorplan.keep_placement_blockages (default: auto  auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas  true : Keeps existing placement blockages.\n  false : Removes existing placement blockages.\n Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped  # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Advanced PG Net Checks"}, {"role": "assistant", "content": "For advanced technology nodes, to improve the routability of areas with high pin densities by redistributing the cells, enable pin optimization during legalization by setting the place.legalize.optimize_pin_access_using_cell_spacing application option to true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Self-Gating Options"}, {"role": "assistant", "content": "To set up the block for self-gating, perform the following steps before you run the compile_fusion command: 1.\n Enable self-gating by setting the compile.clockgate.self_gating application option to true fc_shell> set_app_options -name compile.clockgate.self_gating \\ -value true 2.\n Apply switching activity by using the read_saif or set_switching_activity command.\n 3.\n (Optional) Specify self-gating settings using the set_self_gating_options command.\n For more information, see Setting Self-Gating Options 4.\n (Optional) Override the tool's default behavior of selecting self-gating objects by using the set_self_gating_objects command.\n For more information, see Controlling the Selection of Self-Gating Objects"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Configuring an ICV Heat Map"}, {"role": "assistant", "content": "An ICV heat map displays the density of signoff DRC violations in a block.\n You can use the heat map to locate problematic areas in your design.\n       Note: This feature requires version P-2019.06 or later of the IC Validator tool and an IC Validator NXT license.\n To view the ICV heat map, 1.\n Enable the ICV heat map by setting the signoff.check_drc.enable_icv_explorer_mode application option to true fc_shell> set_app_options -name signoff.check_drc.enable_icv_explorer_mode \\ -value true 2.\n Perform signoff design rule checking as described in Running the signoff_check_drc Command 3.\n In the GUI, choose View > Map > ICV Heatmap.\n  shows an ICV heat map.\n        ICV Heat Map"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Configuring Distributed Processing"}, {"role": "assistant", "content": "Multithreading performs tasks in parallel by using multiple cores on the same machine, using a single process memory image.\n When using multithreading, each parallel task is called a thread.\n For the best performance during multithreading, you should limit the number of threads to the number of available cores, which is the number of CPUs in the machine times the number of cores per CPU.\n The following commands support multithreading configured by the set_host_options command:  place_opt  clock_opt        check_legality, when advanced legalization is enabled by setting the place.legalize.enable_advanced_legalizer application option to true  insert_via_ladders  route_auto route_global route_track route_detail, and route_eco Note: When you run routing with a single thread, the result is deterministic; if you start with the same block, you always get the same result.\n However, if you use multiple threads, the routing results are not deterministic; the final routing is slightly different between runs due to the varying division of tasks between threads.\n Global routing supports a deterministic mode for multicore routing.\n To enable this mode, set the route.global.deterministic application option to on  route_opt  signoff_check_drc  signoff_fix_drc  signoff_create_metal_fill  signoff_fix_isolated_via  write_def By default, all commands use a single thread.\n To enable multithreading for those commands that support it, set the -max_cores option of the set_host_options command to a value greater than one and less than or equal to the number of cores available on your machine, which is the number of CPUs in the machine times the number of cores per CPU.\n The number of cores specified by the -max_cores option applies to all commands that support multithreading.\n When you enable multithreading, multithreaded commands create and use the specified number of threads, even if the number is more than the number of available cores.\n You must set an appropriate number of threads, so that the command does not try to use more resources than it has.\n Overthreading can reduce performance because the extra threads compete for resources.\n For best performance, do not run more than one thread per available core.\n For example, if your machine has two CPUs and each CPU has three cores, specify six as the maximum number of threads: fc_shell> set_host_options -max_cores 6"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating Via Ladder Rules for Performance Via Ladders"}, {"role": "assistant", "content": "Instead of explicitly defining via ladder rules for electromigration via ladders, you can use the generate_via_ladder_template command to generate via ladder rules and constraints based on a configuration file.\n The configuration file is an XML file that provides information about the via ladder rules, as well as the association between the via ladder rules and specific pins.\n You must specify the name of the configuration file by using the -config_file option.\n The command generates two script files:  A script file that defines the via ladder rules, which is called the template script file This script file contains a create_via_rule command for each template defined in the configuration file, as well as set_attribute commands to set the appropriate via rule attributes.\n By default, the file is named auto_gen_via_ladder_template.tcl.\n To specify a different file name, use the -template_file option.\n  A script file that defines the via ladder constraints, which is called the association script file This script file contains set_via_ladder_candidate commands for the pins specified in the configuration file, as well as set_attribute commands to set the is_em_via_ladder_required attribute for the pins to true By default, the file is named auto_gen_via_ladder_association.tcl.\n To specify a different file name, use the -association_file option.\n       The configuration file has the following syntax: <EmRule> <!\n template definition > <Template name=\" rule_name \"> <Layer name=\" layer_name \" row_number=\" cuts_per_row [max_stagger_tracks=\" count \"] [upper_cut_x_min_spacing=\" x_spacing \"] [upper_cut_y_min_spacing=\" y_spacing \"] />...\n more layers </Template> \u2026 more templates  <!\n Pin to template association > <Pin name=\" pin_name \"> <Template name=\" rule_name \"/> </Pin>...\n more associations </EmRule> Each Template section specifies the template for a via ladder rule.\n You can specify one or more Template sections.\n Within a template section, you specify the via ladder structure by specifying the number of cuts per row for each metal layer involved in the via ladder.\n The command uses the information in the configuration file and associated information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file  The cut layers that connect the specified metal layers  The cut names  The minimum required length for each metal layer Note: You must open the block before running the generate_via_ladder_template command to ensure that the command has access to the technology data for the block.\n Each Pin section specifies the template associated with a pin, where the pin name can include the asterisk wildcard character (*).\n You can specify one or more Pin sections.\n The template specified in the Pin section's Template attribute must be one of the templates specified in the Template sections.\n For example, assume you have a configuration file named vl_config that has the following contents: <EmRule> <Template name=\"template_1_3231\"> <Layer name=\"M1\" row_number=\"3\"/> <Layer name=\"M2\" row_number=\"2\"/> <Layer name=\"M3\" row_number=\"3\"/>       <Layer name=\"M4\" row_number=\"1\"/> </Template> <Pin name=\"*/BCELLD5A11*/Z\"> <Template name=\"template_1_3231\"/> </Pin> </EmRule> To generate the script files to define the via ladder rules and constraints, use the following command: fc_shell> generate_via_ladder_template -config_file vl_config Example 17 shows the template script file generated by this command.\n Example 18 shows the association script file generated by this command.\n Example 17 Template Script File create_via_rule -name template_1_3231 \\ -cut_layer_names {VIA1 VIA2 VIA3} -cut_names {V1S V2S V3S} \\ -cut_rows {2 3 1} -cuts_per_row {3 2 3} set viaRule [get_via_rules template_1_3231] set_attribute $viaRule upper_metal_min_length_table {0.3 0.2 0.4} set_attribute $viaRule for_electro_migration true Example 18 Association Script File foreach_in_collection pin [get_lib_pins -quiet */BCELLD5A11*/Z] { set_attribute -quiet $pin is_em_via_ladder_required true set_via_ladder_candidate $pin -ladder_name \"template_1_3231\"  See Also  Defining Via Ladder Rules  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Applying Compression to Groups With Straddling Leaf Cells"}, {"role": "assistant", "content": "To control the tiling of objects within a relative placement group, use the set_rp_group_options -tiling_type command with the settings shown in the following table.\n Table 58 Controlling Placement With the set_rp_group_options -tiling_type Command To do this Use this setting       bit_slice    horizontal_compression   vertical_compression        Bit-Slice Placement Versus Horizontal or Vertical Compression           Bit-slice placement                     Vertical compression Horizontal compression The setting of the -tiling_type option is not propagated from a parent group to child groups."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Tap Cells"}, {"role": "assistant", "content": "The Fusion Compiler tool provides chip finishing and design for manufacturing and yield capabilities that you can apply throughout the various stages of the design flow to address process design issues encountered during chip manufacturing.\n For information about the chip finishing and design for manufacturing features, see the following topics:  Inserting Tap Cells  Performing Boundary Cell Insertion  Finding and Fixing Antenna Violations  Inserting Redundant Vias  Optimizing Wire Length and Via Count  Reducing Critical Areas  Inserting Metal-Insulator-Metal Capacitors  Inserting Filler Cells  Inserting Metal Fill"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Clock-Gating Results"}, {"role": "assistant", "content": "If sequential clock gating is enabled, the report_clock_gating command automatically displays a summary table, similar to the following: Sequential Clock Gating Summary  | | Bitwidth |  |No of sequential clock gates | 2 | | | | | | |No of fanin-based sequential clock gates | 2 (100.0%) | | | | | | |No of sequentially-gated registers | 7 (21.2%) | 7 (21.2%) | | | | | |No of fanin-based sequentially-gated regs | 7 (21.2%) | 7 (21.2%) | | | | | |No of registers not sequentially gated | 26 (78.8%) | 26 (78.8%) | | | | | |Total number of registers | 33 | 33 |  Use the report_clock_gating -ungated command to report the reasons why sequential clock gating is not implemented.\n The report is similar to the following: fc_shell> report_clock_gating -ungated   Not fanin-based sequentially gated registers  Register | Reason for not gating | What's next?\n  q2_reg[0] | Register contains object different than edge-triggered flip-flops in its transitive fanin | Check the register transitive fanin q2_reg[4] | Register contains object different than edge-triggered flip-flops in its transitive fanin | Check the register transitive fanin u/reg1_reg[2] | Register enable function is not a cover of the transitive fanin enable function | Check the register enable condition  Total 7"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Selecting and Multiplexing Logic"}, {"role": "assistant", "content": "The Fusion Compiler tool can map combinational logic representing multiplexers in the HDL code directly to a single multiplexer (MUX) or a tree of multiplexer cells from the target logic library.\n Multiplexers are commonly modeled with if and case statements.\n To implement the mutliplexer logic, the HDL Compiler uses SELECT_OP cells, which the Fusion Compiler tool map to combinational logic or multiplexers in the logic library.\n       User-specified Tool evaluated Implemented using MUX gates Implemented using MUX or non MUX gates based on area costing analyze elaborate Infers Select_OP cells compile_fusion"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Transferring to Back End"}, {"role": "assistant", "content": "When performing concurrent clock and data optimization using the compile_fusion command, you can give a higher priority to the WNS optimization of  Certain path groups by specifying them by using the ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2} If a path group you specify with this application option is also specified as a path group to skip with the ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization.\n        Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell> set_app_options \\ -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified path groups.\n  The worst 300 timing paths by setting the ccd.enable_top_wns_optimization application option to true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Routing Guides"}, {"role": "assistant", "content": "To find routing guides, use the get_routing_guides command.\n For example, to get all the routing guides in your block, use the following command: fc_shell> get_routing_guides * To find the routing guides in a specific location, use the get_objects_by_location -classes routing_guide command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Pin Connections"}, {"role": "assistant", "content": "When a pin is defined as a must-join pin, the router connects all terminals of the pin as a single net.\n The terminals of a must-join pin are specified with the must_join_port library pin attribute.\n By default, Zroute connects must-join pins using a random structure, as shown in the following figure:  Default Must-Join Pin Connection To achieve better electromagnetic results, Zroute can use the via ladder insertion capabilities to connect the must-join pins with a simplified structure, which is referred to as a pattern-based must-join connection.\n       The following figure shows the simplified structure:  Single-Level Pattern-Based Must-Join Pin Connection The single-level structure shown in is the default structure used for a pattern- based must-join connection.\n To use a multi-level structure, which is shown in set the route.auto_via_ladder.pattern_must_join_over_pin_layer application option to 2.\n  Multi-Level Pattern-Based Must-Join Pin Connection Zroute automatically uses a pattern-based must-join pin connection when a library cell pin has a pattern_must_join attribute and you use one of the following commands to perform the routing: route_auto route_group, or route_eco To query cells with the pattern_must_join attribute, use the following command: fc_shell> get_attribute \\ [get_lib_pins -all -of_objects */*/frame ] pattern_must_join To get a list of pins that are marked with the pattern_must_join attribute, use the following command: fc_shell> get_lib_pins -all \\ -of_objects */*/frame -filter \"pattern_must_join==true\" By default, a via ladder is not inserted if there are fixed shapes on higher layers that block the insertion.\n To increase the insertion rate, you can allow staggering of the vias on each level of the via ladder to avoid the fixed shapes.\n To specify the maximum number of tracks allowed for staggering on each level, set the route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks application option.\n You can specify a value between 0 and 9 for each level; the default is 0, which disables staggering.\n       For example, to allow staggering of up to three tracks on the first level, use the following command: fc_shell> set_app_options -name \\ route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks \\ -value {3 0}  shows the possible solutions to avoid a blockage on the M3 layer when you allow staggering of up to three tracks.\n  Pattern-Based Must-Join Pin Connection With Staggering By default, the pattern-based must-join connections are updated each time you run the route_auto route_group, or route_eco command.\n  During the route_group command, the updates are restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true  To disable all updates during each of these routing commands, set the route.auto_via_ladder.update_pattern_must_join_during_route application option to false If Zroute cannot create a pattern-based must-join connection, it reports a \"Needs pattern must join pin connection\" DRC violation.\n See Also  Inserting Via Ladders"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Interior Tap Walls"}, {"role": "assistant", "content": "An exterior tap wall is a row or column of tap cells that is placed outside the boundary of a block, macro, or hard placement blockage.\n The tap cells in the tap wall are placed linearly without any gaps between cells.\n To insert an exterior tap wall, use the create_exterior_tap_walls command.\n You must specify the following information:  The tap cell used in the tap wall (the -lib_cell option) By default, the command inserts the tap cells with R0 orientation.\n To place the cells with a different orientation, use the -orientation option.\n If the design has a FinFET grid, follow these guidelines when selecting the tap cell to ensure proper insertion of the tap wall:  For horizontal tap walls, ensure that the cell's width in the specified orientation is an integer multiple of the x-pitch of the FinFET grid  For vertical tap walls, ensure that the cell's height in the specified orientation is an integer multiple of the y-pitch of the FinFET grid By default, the tool uses the following naming convention for inserted tap cells: extTapWall__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number  The side along which to insert the tap wall (the -side option) You can specify only a single side, top bottom right, or left.\n To insert a tap wall on more than one side, run the command multiple times.\n  The tap insertion region (the -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} The bounding box must span a portion of the object's edge on the specified side along which to insert the tap wall.\n If the bounding box spans multiple edges along the specified side, the command inserts the tap wall along the longest edge.\n If the bounding box does not span any edges of the specified side, the command issues an error message.\n       By default, a horizontal tap wall starts at the left edge of the specified bounding box and abuts the top or bottom boundary edge; a vertical tap wall starts at the bottom edge of the specified bounding box and abuts the left or right boundary edge.\n To specify margins for the tap wall insertion, use the -x_margin and -y_margin options.\n If the specified region, including the margins, is too small to fit a tap wall, the command does not insert tap cells.\n You should ensure that the insertion region does not contain any placement blockages, fixed cells, or macros.\n These obstructions can prevent the insertion of the tap cells and result in an incomplete or missing tap wall.\n When inserting the tap wall, the command does not honor the standard cell rows or sites and does not cross the object boundary.\n After insertion, the command fixes the placement of the inserted tap cells."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Settings for Clock Latency Adjustments"}, {"role": "assistant", "content": "The timing of a design can be improved by reducing signal integrity issues on clock nets.\n To do so, the tool can derive nondefault routing rules with larger spacing requirements and assign them to the clock nets in regions without routing congestion.\n       To enable this feature, use the following application option setting: fc_shell> set_app_options \\ -name cts.optimize.enable_congestion_aware_ndr_promotion -value true When the tool derives a new nondefault routing rule for a clock net, the new spacing requirement is dependent on the spacing requirement of the existing routing rule of that net.\n If the existing routing rule is  A nondefault routing rule with a spacing requirement of less than or equal to two times the default spacing, the spacing requirement is doubled The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n  A nondefault routing rule with a spacing requirement of more than two times the default spacing, the spacing requirement is increased by one default spacing The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n  The default routing rule, the spacing requirement is doubled The name of this new nondefault rule is default_rule_equivalent_ndr_double_spacing."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Corner Type"}, {"role": "assistant", "content": "The Custom Router bus routing application options allow you to specify:  Corner Type  Intra-shield Placement  Pin-Trunk Offset  Trunk Splitting  Tapoffs"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining the Net Priority"}, {"role": "assistant", "content": "To add shielding on the selected nets to reduce crosstalk or parasitic effects, run the create_net_shielding command.\n You need to specify the following information:  The name of the constraint group If you do not specify a name, the command names the constraint group shielding_ where is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the -force option.\n  The nets, bundles, and topology edges to which the constraint group applies Use the -for option.\n  The constraints for shielding styles and layer-specific requirements To define the net shielding constraints that are applied per layer to the trunk and override any settings on the individual bits, use the options listed in Table 55       Table 55 Net Shielding Constraints Option Description -shield_net    -shield_net_2    -via_defs   -gap   -max_gap   -width  -layer_gaps   -layer_max_gaps   -layer_widths  -min_segment  -sharing  unset, true and false -group_shield   -enclose_pins  -enclose_pins  -group_shield  unset, true, and false -enclose_vias  unset, true, and false -disabled_layers        The following example creates a constraint group and specifies constraints for adding shields on the nets whose names start with pr.\n The minimum spacing is 3 microns for the M2 layer and 5 microns for the M3 layer.\n All constituent objects can share the shield; the M5 and M6 layers cannot be used for shielding.\n fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*] \\ -disabled_layers {M5 M6} -sharing true -layer_gaps {M2 3 M3 5} {shielding_4}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Self-Gating Flow"}, {"role": "assistant", "content": "The tool supports self-gating optimization, which occurs at the compile_fusion command.\n This feature reduces dynamic power consumption by turning off the clock signal of certain registers during clock cycles when the data remains unchanged.\n        Example of a Self-Gating Cell CLK   Registers with an enable condition that cannot be inferred from the existing logic can only be gated using the self-gating technique.\n They cannot be gated using traditional clock gating.\n By default, the tool supports self-gating only on registers that are not gated.\n You can use the set_self_gating_options command to allow self-gating on these registers.\n However, the time duration that the clock signal is turned off might increase for these registers,.\n To ensure QoR improvements, the self-gating algorithm takes timing and power into consideration.\n A self-gating cell is inserted for the registers if  There is enough timing slack available in the register's data pin.\n For designs with multiple scenarios, the algorithm considers the timing of the worst case among active scenarios enabled for setup.\n  Internal dynamic power of the circuit is reduced.\n For designs with mutiple scenarios, the algorithm uses the average internal dynamic power among active scenarios enabled for dynamic power.\n To minimize the area and power overhead, a self-gating cell can be shared across a few registers by creating a combined enable condition with a tree of comparator cells.\n If the self-gated registers are driven by synchronous set or synchronous clear signals, these signals are also included in the construction of the enable signal so that the circuit remains functionally unchanged.\n is an example of a self-gating cell that is shared across two registers (4 bits).\n Note that one of the self-gated registers is a multibit register and the other register is a single-bit register.\n The tool can also self-gate a group of multibit registers or a group of single-bit registers.\n        Self-Gating Tree CLK D0 Q0 D2 Q2 D1 Q1   EN The tool does not support the following types of sequential cells for self-gate insertion:  Level-sensitive sequential cells  Level-sensitive scan design registers  Master-slave flip-flops  Retention registers  Single-bit and multibit registers that belong to shift registers  Multibit registers with multiple clock paths For more information, see the following topics:  Self-Gating Flow  Library Requirements for Self-Gating  Setting Up for Self-Gating  Reporting and Querying Self-Gating Cells"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up Libraries"}, {"role": "assistant", "content": "The Fusion Compiler tool uses a search path to look for files that are specified with a relative path or with no path.\n To specify the search path, use the set_app_var command to set the search_path application variable to the list of directories, in order, in which to look for files.\n When the tool looks for a file, it starts searching in the leftmost directory specified in the search_path variable and uses the first matching file it finds.\n You can also use the Tcl lappend command to add your directories to the default search path, which is the directory from which you invoked the tool.\n For example, fc_shell> lappend search_path./mylibdir"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Near 100 Percent Redundant Via Insertion"}, {"role": "assistant", "content": "Soft-rule-based redundant via insertion can improve the redundant via rate by reserving space for the redundant vias during routing.\n You can use concurrent soft-rule-based redundant via insertion during both initial routing and ECO routing.\n The actual via insertion is not done during routing; you must still perform postroute redundant via insertion by using the add_redundant_vias command.\n Note: Reserving space during routing increases the routing runtime.\n You should use this method only when needed to improve the redundant via rate beyond that provided by postroute redundant via insertion and the postroute approach resulted in a redundant via rate of at least 80 percent.\n       To perform concurrent soft-rule-based redundant via insertion, 1.\n (Optional) Define the via mapping table as described in Defining a Customized Via Mapping Table 2.\n Enable concurrent soft-rule-based redundant via insertion.\n By default, concurrent redundant via insertion is disabled.\n  To enable concurrent soft-rule-based redundant via insertion during initial routing, set the route.common.concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during initial routing, set the route.common.concurrent_redundant_via_effort_level application option.\n By default, Zroute uses low effort.\n The higher effort levels result in a better redundant via conversion rate at the expense of runtime.\n The low and medium efforts affect only global routing and track assignment, while high effort also affects detail routing, which can impact design rule convergence.\n Note: If you enable the route.common.concurrent_redundant_via_mode option before running the place_opt command, the redundant vias are considered during congestion estimation.\n  To enable concurrent soft-rule-based redundant via insertion during ECO routing, set the route.common.eco_route_concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.eco_route_concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during ECO routing, set the route.common.eco_route_concurrent_redundant_via_effort_level application option.\n Note: Using concurrent soft-rule-based redundant via insertion during ECO routing can impact timing and design rule convergence.\n In general, you should use this method only when you used near 100 percent redundant via insertion during initial routing.\n       3.\n Route the block.\n During routing, Zroute reserves space for the redundant vias and fixes hard design rule violations.\n 4.\n Perform postroute redundant via insertion.\n During postroute redundant via insertion, Zroute inserts the redundant vias in the reserved locations."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Mapping of Synchronous Reset or Preset Registers"}, {"role": "assistant", "content": "During test-ready compile, the tool replaces regular flip-flops with flip-flops that contain logic for testability.\n The following figure shows an example of how a D flip-flop is replaced with a scan register during test-ready compile.\n This type of architecture, a multiplexed flip- flop, incorporates a 2-input MUX at the input of the D flip-flop.\n The select line of the MUX enables two modes\u2014functional mode (normal data input) and test mode (scanned data input).\n In this example, the scan-in pin is si, the scan-enable pin is se, and the scan-out pin, so, is shared with the functional output pin, Q.\n        si  Clk se   Q/so When you run the compile_fusion command,  The tool maps all sequential cells directly to scan registers in your library  The scan pins, such as scan enable and scan out, are unconnected  The scan output pin of a scan register is used for scan connections Use the seqmap.bind_scan_pins application option to hold the scan enable pin inactive If the library contains no scan registers, the tool uses nonscan cells for mapping and issues a warning.\n Set the dont_use attribute on all scan registers in the library to map to nonscan cells"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Timing-Driven Power Grid Augmentation"}, {"role": "assistant", "content": "Before you run the signoff_create_pg_augmentation command, configure the run by setting the application options shown in Table 48.\n To set the application options, use the set_app_options command.\n To see the current settings, use the report_app_options command.\n Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff.\n create_pg_augmentation.\n ground_net_name     signoff.\n create_pg_augmentation.po wer_net_name    signoff.\n create_pg_augmentation.\n run_dir     signoff_create_pg_augmentation            Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff.\n create_pg_augmentation.\n user_defined_options"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Constructing Faster Clock Tree to Specific Endpoints"}, {"role": "assistant", "content": "By default, the Fusion Compiler tool uses the default routing rule and any available routing layers to route the clock trees.\n You can specify the minimum and maximum routing layers for clock nets as described in Specifying the Routing Resources.\n These routing layer constraints are used during RC estimation, congestion analysis, and routing.\n       To reduce the wire delays in the clock trees, you can use wide wires and higher metal layers instead.\n routing rulenondefault, defined Wide wires are represented by nondefault routing rules.\n To use nondefault routing rules on the clock nets, you must first define the routing rules and assign them to the clock nets as described in Using Nondefault Routing Rules"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Real Metal Fill Extraction"}, {"role": "assistant", "content": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes.\n  To change the boundary of a metal fill shape, use the set_attribute command to modify its bbox attribute.\n  To add a metal fill shape in the top-level fill cell, use the create_shape -shape_use area_fill command.\n  To add a metal fill shape in a specific fill cell, use the create_shape -fill_cell command.\n  To remove a metal fill shape, use the remove_shapes command.\n You can also modify metal fill shapes in the GUI.\n To select or modify fill shapes in the GUI, 1.\n Select \"Multiple Levels Active\" ( ) in the View Settings panel.\n 2.\n In the \"Hierarchy Settings\" panel, set \"View level\" to a minimum of 2 and select \"Fill Cell\" in \"Expanding cell types.\""}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling the Tiling Within Relative Placement Groups"}, {"role": "assistant", "content": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option.\n However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option.\n The following example creates a relative placement group named rp1 that is right aligned.\n It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement.\n        Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Associating Checkpoints and Checkpoint Behaviors"}, {"role": "assistant", "content": "You can define two types of checkpoint behaviors: reports and actions.\n Define a checkpoint report to generate one or more reports supported by the tool or custom reports you create yourself.\n Define a checkpoint action to execute any kind of flow change before,       after, or in place of the code block enwrapped by a checkpoint.\n For example, you might set an application option to a specific value before a particular checkpoint.\n Define these behaviors in your checkpoint.config.tcl file, which is automatically sourced by the checkpoint system.\n Defining Checkpoint Reports To define a checkpoint report, use the create_checkpoint_report command in your checkpoint.config.tcl file.\n Specify a unique name for the report and define the Tcl commands to generate the report.\n The following example defines a checkpoint report named timing, which writes the output of the report_qor and report_timing commands to disk: create_checkpoint_report timing { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position]  report_qor -nosplit >./checkpoint/$name.$pos.qor.rpt report_qor -summary -nosplit >>./checkpoint/$name.$pos.qor.rpt  report_timing -nosplit -max_paths 10 \\ >./checkpoint/$name.$pos.path.rpt  Notice the use of the get_current_checkpoint command with the -name and -position options to give the generated reports a meaningful name.\n When these reports are generated, their names reflect the checkpoint that triggered them get_current_checkpoint -name ), as well as whether they were generated before or after the checkpoint ( get_current_checkpoint -position ).\n For example, if this checkpoint report is executed after a checkpoint named checkpoint_A, the generated reports are saved to the checkpoint directory, and the name of the QoR report is checkpoint_A.after.qor.rpt.\n The next example defines a checkpoint report named app_options, which writes all your non-default application options to disk: create_checkpoint_report app_options { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position]  report_app_options -non_default \\ >./checkpoint/$name.$pos.app_options.rpt  Defining Checkpoint Actions To define a checkpoint action, use the create_checkpoint_action command in your checkpoint.config.tcl file.\n Specify a unique name for the action and define the Tcl commands that constitute the action.\n       The following example defines a checkpoint action named gropto, which enables global- route based buffering: create_checkpoint_action gropto { set_app_options -name place_opt.initial_drc.global_route_based \\ -value true  The next example defines a checkpoint action named placer_high_effort_cong, which runs high-effort congestion reduction: create_checkpoint_action placer_high_effort_cong { set placer_command [get_current_checkpoint -script] set cong_option \"-congestion_effort high\" eval $placer_command $cong_option  Notice the use of the get_current_checkpoint -script command and option, which retrieves the command originally enwrapped by the checkpoint and sets its congestion effort to high ( -congestion_effort high ).\n The -script option is typically used to define actions that replace the contents of a command.\n In this example, the action modifies the -congestion_effort option of the command that is enwrapped by the checkpoint associated with this action."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Wire Length Aware Power-Driven Relocation"}, {"role": "assistant", "content": "You can enable clock tree power reduction techniques by using the cts.compile.power_opt_mode application option as shown in the following table.\n Table 26 Settings for the cts.compile.power_opt_mode Application Option To do this Use this setting   gate_relocation  low_power_targets       Table 26 Settings for the cts.compile.power_opt_mode Application Option (Continued) To do this Use this setting   all"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Fixing DRC Violations Caused by Pin Access Issues"}, {"role": "assistant", "content": "The recommended flow for performing postroute logic optimization consists of multiple iterations of the route_opt command with different settings.\n However, you can reduce       the number of postroute optimization iterations by using a single iteration of the hyper_route_opt command.\n The postroute optimization flow using the hyper_route_opt command consists of the following steps: 1.\n Enable different settings for postroute optimization using the same settings as for the route_opt command.\n For example, you can  Specify the path-based analysis (PBA) mode by using the time.pba_optimization_mode application option  Enable concurrent clock and data optimization by using the route_opt.flow.enable_ccd application option  Enable power optimization by using the route_opt.flow.enable_power application option 2.\n (Optional) Specify settings for metal fill insertion, PG augmentation, and so on that should to be performed during the different stages of optimization and ECO routing within the hyper_route_opt command by using the snps_hyper_route_opt_post_eco Tcl-callback procedure.\n 3.\n (Optional) To improve the timing QoR, the hyper_route_opt command can debank sequential multibit registers.\n To enable this feature, set the route_opt.flow.enable_multibit_debanking application option to true.\n By default, the route_opt.flow.enable_multibit_debanking application option is set to false 4.\n Run postroute optimization using the hyper_route_opt command.\n 5.\n (Optional) Specify endpoints to target by using the set_route_opt_target_endpoints command and optimize these endpoints by using the route_opt command if there are any violating endpoints remaining after the hyper_route_opt command.\n 6.\n (Optional) Fix any remaining route DRC violations by using the route_detail -incremental command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Sequential Mapping"}, {"role": "assistant", "content": "You need to have multiplexer cells in the logic library and also require to use multiplexing logic from the cell library.\n The following section describes library requirements to implement multiplexer cells for multiplexer optimization or to implement multiplexing logic from the cell library to control MUX mapping:  Understanding Library Cell Requirements for Multiplexer Optimization  Implementing Multiplexing Logic From Cell Library Understanding Library Cell Requirements for Multiplexer Optimization The multiplexer optimization requires the presence of at least a 2:1 multiplexer cell in the logic library.\n The inputs or outputs of this cell can be inverted.\n If a 2:1 multiplexer primitive cell does not exist in the library, you see the following warning message: Warning: Target library does not contain any 2-1 multiplexer.\n (OPT-853) An implementation of the MUX_OP cell from the target library is created, but it might not be the best implementation possible.\n All multiplexer cells in the target library can be used to construct the implementation of the MUX_OP cell except  Enabled multiplexer cells  Bused output multiplexer  Multiplexers larger than 32 : 1 For Fusion Compiler to make the best use of the multiplexer cells available in your logic library, recompile the library or obtain a library compiled with version V3.4a or later from your ASIC vendor.\n Implementing Multiplexing Logic From Cell Library During logic synthesis, the tool implements multiplexing logic from the cell library using one of the following methods:  AND, OR, and INV gates  MUX gates The tool evaluates the area effect of both methods and selects the solution with the smallest area.\n       You can specify that the tool uses MUX gates to implement specific multiplexing logic by applying the map_to_mux attribute on the corresponding SELECT_OP WVGTECH cells in the block, as shown in Example 16 Example 16 Using map_to_mux attribute to implement specific multiplexing logic # Apply the map_to_mux attribute on the SELECT_OP cell named C10 set_attribute -objects [get_cells C10] -name map_to_mux -value true  # Query if the attribute is set as required on C10 get_attribute -objects [get_cells C10] -name map_to_mux  #Run the compile step compile_fusion  #Identify the cell created using the map_to_mux attribute get_cells -hier -filter \"map_to_mux==true &&!infer_mux_override\""}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling the Adjustment of I/O Clock Latencies"}, {"role": "assistant", "content": "By default, the tool focuses on fixing setup violations during concurrent clock and data optimization.\n However, if your design has hold violations that are difficult to fix, you can increase the effort for hold fixing by setting the ccd.hold_control_effort application option to medium high, or ultra.\n The default is low Increasing the priority of hold violations reduces the number of setup violations that are fixed.\n Therefore, the hold priority should be increased only if the hold timing is critical.\n This setting affects concurrent clock and data optimization performed during the final_opt stage of the clock_opt command and the route_opt command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Validating DEF Files"}, {"role": "assistant", "content": "If the site names used in the DEF file do not match the site names defined in the technology file, use the -convert_sites option to specify the site name mapping.\n For example, if the DEF file uses a site named CORE, but the technology file defines only a site named unit, use the following command to convert the site names when reading the DEF file: fc_shell> read_def -convert_sites { {CORE unit} } block.def"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Multivoltage Cells"}, {"role": "assistant", "content": "To remove voltage areas from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_voltage_areas command.\n To remove all voltage areas from a block, use the -all option.\n To remove specific voltage areas from a block, specify the voltage area names."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Abstract Inclusion Reasons"}, {"role": "assistant", "content": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations.\n The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation.\n You can use the following application options to:  Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to true The data paths to these registers are not retained.\n By default, this application is set to false  Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack.\n This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Improving the Banking Ratio"}, {"role": "assistant", "content": "To report a summary of the multibit banking ratio, a list of reasons for not banking or debanking cells, and the number of cells for each reason, use the report_multibit command, as shown in the following example: fc_shell> report_multibit **************************************** Report : report_multibit...\n...\n  ****************************************  Total number of sequential cells: 4020 Number of single-bit flip-flops: 3149 Number of single-bit latches: 29 Number of multi-bit flip-flops: 842 Number of multi-bit latches: 0        Total number of single-bit equivalent cells: 853 (A) Single-bit flip-flops: 3149 (B) Single-bit latches: 29 (C) Multi-bit flip-flops: 5352 (D) Multi-bit latches: 0  Sequential cells banking ratio ((C+D)/(A+B+C+D)): 62.74% Flip-flop cells banking ratio ((C)/(A+C)): 62.96% BitsPerflop: 2.13  Reasons for sequential cells not mapping to multibit during RTL Banking:  Explanations: r12: Cell is single bit because its parent multibit cell was debanked due to improve timing (Number of cells: 91) r31: Cell cannot be banked to multibit because it is assigned to use single-bit lib cell (Number of cells: 63)   Reasons for multibit sequential cells not debanking to single bit cells during RTL Debanking:  Explanations:: r45: Multibit cell cannot be debanked because it is not critical enough (Number of cells: 478) To report all the cells that are ignored during banking and debanking, use the -ignored_cells option with the report_multibit command.\n To report the compatible multibit and single-bit library cells that can be used for banking and debanking, use the check_multibit_library command.\n The following example generates a compatible library cell report for RTL banking and debanking: fc_shell> check_multibit_library -stage RTL \\ -banking -debanking **************************************** Report : check_multibit_library Flow : RTL BANKING ****************************************  Single bit Lib cell Compatibility Multi bit Lib cell  SB_reg1 PIN ORDER MISMATCH MB_reg1 SB_reg2 COMPATIBLE MB_reg2  Singlebit with NO Multibit Equivalents  SB_reg3        **************************************** Report : check_multibit_library Flow : RTL DEBANKING ****************************************  Multi bit Lib cell Compatibility Single bit Lib cell  MB_reg2 COMPATIBLE SB_reg2 MB_reg1 PIN ORDER MISMATCH SB_reg1  Multibit with NO Singlebit Equivalents  MB_reg3"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Deriving the Clock Trees"}, {"role": "assistant", "content": "This section details the information required to analyze and define each clock tree before running clock tree synthesis.\n Before you run clock tree synthesis, analyze each clock tree in the block and determine  What the clock root is  What the required clock sinks and clock tree exceptions are  Whether the clock tree contains preexisting cells, such as clock-gating cells  Whether the clock tree converges, either with itself (a convergent clock path, definedclockconvergent convergent clock path) or with another clock tree (an overlaping clock path, definedclockoverlaping overlapping clock path)  Whether the clock tree has timing relationships with other clock trees in the block, such as interclock skew requirements Use this information to define the clock trees and validate that the tool has the correct clock tree definitions.\n The Fusion Compiler tool derives the clock trees based on the clocks defined in the block.\n If the derived clock trees do not meet your requirements, you can define clock trees as described in the following topics:  Deriving the Clock Trees  Defining Clock Tree Exceptions  Restricting Optimization on the Clock Network  Copying Clock Tree Exceptions Across Modes        Deriving Clock Tree Exceptions From Ideal Clock Latencies  Handling Endpoints With Balancing Conflicts"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Incomplete UPF Information"}, {"role": "assistant", "content": "To load the power intent and apply it to a multivoltage design, 1.\n Read the UPF file by using the load_upf command.\n fc_shell> load_upf block.upf 2.\n If you are using the golden UPF flow and have a name-mapping file, read the file by using the read_name_map command.\n fc_shell> read_name_map block.nmf 3.\n (Optional) Verify the UPF consistency and identify any PG conflicts among the netlist, floorplan, and power intent.\n To verify the UPF consistency and identify PG conflicts, use the resolve_pg_nets -check_only command.\n This command identifies any issues and reports the changes that are made to resolve these issues when you commit the power intent.\n If you prefer to resolve the issues differently, you can use manual editing commands to resolve the issues before running the commit_upf command.\n 4.\n Commit the power intent by using the commit_upf command.\n fc_shell> commit_upf The commit_upf command performs global checks for UPF consistency; resolves PG conflicts among the netlist, floorplan, and UPF specification; and associates power strategies with existing multivoltage cells.\n For more information about associating       power strategies with existing multivoltage cells, see Associating Power Strategies With Existing Multivoltage Cells 5.\n Report the associations made for the multivoltage cells by using the report_mv_path command.\n If the tool failed to associate any multivoltage cells, the command reports the causes for these failures.\n You must successfully commit the power intent before you continue with the design flow.\n Note: After successfully running the commit_upf command, the tool issues an error message if you try to use additional UPF commands, except for the set_related_supply_net connect_supply_net set_design_attributes set_port_attributes find_objects, and set_scope commands.\n To modify the power intent after running the commit_upf command, you must remove the existing UPF specification by using the reset_upf command and then reload the power intent."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Multibit Optimization Performed During the clock_opt"}, {"role": "assistant", "content": "Applying useful skew techniques during datapath optimization to improve the timing QoR by taking advantage of the positive slack and adjusting the clock arrival times of registers is referred to as concurrent clock and data (CCD) optimization.\n By default, the tool performs concurrent clock and data optimization during the clock_opt command.\n To disable concurrent clock and data optimization for the clock_opt command, set the clock_opt.flow.enable_ccd application option to false You can change the default behavior of concurrent clock and data optimization during the clock_opt command by performing any of the following optional steps: 1.\n (Optional) Limit the latency adjustment values for concurrent clock and data optimization as described in Limiting the Latency Adjustment Values 2.\n (Optional) Control the latency adjustment of boundary registers for concurrent clock and data optimization as described in Excluding Boundary Paths 3.\n (Optional) Ignore specific path groups during concurrent clock and data optimization as described in Excluding Specific Path Groups       4.\n (Optional) Ignore specific scenarios during concurrent clock and data optimization as described in Excluding Specific Scenarios 5.\n (Optional) Ignore specific sinks during concurrent clock and data optimization as described in Excluding Specific Sinks 6.\n (Optional) Control the effort of timing optimization performed during concurrent clock and data optimization as described in Controlling Timing Optimization Effort 7.\n (Optional) Control the effort of hold timing optimization performed during concurrent clock and data optimization as described in Controlling Hold Time Optimization Effort 8.\n (Optional) Control the adjustment of I/O clock latencies performed during concurrent clock and data optimization as described in Controlling the Adjustment of I/O Clock Latencies 9.\n (Optional) Analyze the effects of concurrent clock and data optimization as described in Reporting Concurrent Clock and Data Timing"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Implementing MSCTS Multiple H-Tree"}, {"role": "assistant", "content": "The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n  Regular Multisource Clock Tree With an H-Tree-Only Global Clock Structure To implement a regular multisource clock tree structure with an H-tree-only global clock tree structure, 1.\n Specify your clock tree constraints and settings.\n 2.\n Perform the following steps for multivoltage designs: a.\n Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to true b.\n Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to true c.\n Run the check_mv_design command and fix all multivoltage issues.\n 3.\n Enable cell electromigration fixing by setting the cts.multisource.cell_em_aware application option to true 4.\n Specify the required settings by using the set_regular_multisource_clock_tree_options command and       perform tap insertion and global clock tree (H-tree) synthesis by using the synthesize_regular_multisource_clock_trees command, as described in Performing Automated Tap Insertion and H-Tree Synthesis 5.\n Specify options and settings for tap assignment, as described in Specifying Tap Assignment Options and Settings 6.\n Perform tap assignment by using the synthesize_multisource_clock_taps command, which  Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks  Assigns endpoints to the closest tap driver and splits cells along the path honoring any sink groups defined  Copies the UPF and SDC constraints and the user-specified attributes onto the newly created cells across the active scenarios 7.\n Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell> clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers.\n It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n For more information about the clock_opt command, see Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command 8.\n Analyze the clock tree results, as described in Analyzing the Clock Tree Results"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Naming Convention for Boundary Cells"}, {"role": "assistant", "content": "By default,  When you run the compile_boundary_cells command, the tool places the boundary cells in their default orientation around the core area, hard macros, and hard placement blockages.\n  When you run the compile_targeted_boundary_cells command, the tool places the boundary cells in their default orientation around the specified objects.\n To flip the boundary cell orientations, use one or more of the following options with the set_boundary_cell_rules command: -mirror_left_boundary_cell -mirror_right_boundary_cell -mirror_left_outside_corner_cell -mirror_right_outside_corner_cell -mirror_left_inside_corner_cell -mirror_right_inside_corner_cell -mirror_left_inside_horizontal_abutment_cell, and -mirror_right_inside_horizontal_abutment_cell.\n You cannot flip the orientation of the top and bottom boundary cells.\n In addition, when you use the compile_boundary_cells command, you can modify the following aspects of the default placement behavior:  Swapping of the top and bottom inside corner cells on flipped rows Use the -do_not_swap_top_and_bottom_inside_corner_cell option with the set_boundary_cell_rules command to prevent the command from using the bottom inside corner cell on the top inside corner of flipped rows and the top inside corner cell on the bottom inside corner of flipped rows.\n  Consideration of voltage areas Use the -at_va_boundary option with the set_boundary_cell_rules command to insert horizontal boundary cells on both sides of the voltage area boundaries.\n  Existence of one-unit-tile gaps Use the -no_1x option with the set_boundary_cell_rules command to prevent boundary cell insertion from creating one-unit-tile gaps.\n When you use this option, the command does not insert boundary cells on a row when the row length equals two times the corner cell width plus one unit tile width.\n Note that if the row length equals two times the corner cell width, the command does insert boundary cells.\n  Distance between tap cells Use the -tap_distance option with the set_boundary_cell_rules command to specify the distance in microns between the tap cells inserted on the top and bottom boundary rows.\n        Insertion of boundary cells on short rows Use the -min_row_width option with the set_boundary_cell_rules command to prevent insertion of boundary cells on short rows.\n This option defines the width threshold for inserting boundary cells on a row.\n If the row width is less than the specified value, the command does not insert boundary cells on the row.\n  Insertion of boundary cells in child blocks Use the -insert_into_blocks option with the set_boundary_cell_rules command to recursively insert boundary cells in the child blocks.\n By default, the tool does not insert boundary cells in the child blocks."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges"}, {"role": "assistant", "content": "To insert rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this object type, the command creates one or more rectangular metal shapes parallel to each preferred-direction boundary edge.\n The metal shapes are floating; they are not connected to any logical nets.\n  If your technology does not specify a maximum area for these floating shapes, you can insert continuous metal shapes along the preferred-direction boundary edges, as described in Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges  If your technology specifies a maximum area for these floating shapes or you need more flexibility in placing the metal shapes, insert multiple metal shapes, called metal stubs, along the preferred-direction boundary edges, as described in Inserting Metal Stubs Parallel to Preferred-Direction Edges In addition to inserting metal shapes along the preferred-direction edges, you can insert short metal shapes perpendicular to the nonpreferred-direction edges, as described in Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges       Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges To insert continuous rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this option, the command creates a single rectangular metal shape parallel to each preferred-direction boundary edge.\n By default,  The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n  The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n  The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  The metal shapes abut the nonpreferred-direction edges To specify an offset from the nonpreferred-direction edges, use the -spacing_from_boundary option.\n Use the following format to specify the offset for each layer: {{ layer_name offset_value }...} The offset value must be a positive value.\n  The metal shapes are placed on the closest wire track to the preferred-direction edge  shows the metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed on the closest track to the edge.\n W is the default width for the layer and S is the spacing specified for the layer by the -spacing_from_boundary option.\n        Continuous Metal Shape Perimeter Constraint Objects          Inserting Metal Stubs Parallel to Preferred-Direction Edges To insert metal stubs along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred and -stub options.\n When you specify both of these options, the command creates rectangular metal shapes parallel to each preferred-direction boundary edge based on the parameters you specify with the -stub option.\n Use the following format to specify the shape parameters in microns: offset_value start_value length_value spacing_value By default,  The metal shapes are offset from the preferred-direction edge by the value specified in the offset_value argument The offset value is measured from the block edge to the center of the metal shape.\n It can be a positive value, zero, or a negative value.\n The absolute value of a negative value must be greater than the stub width.\n A positive value must be less than half of the smaller of the width or height of the block boundary.\n  The first metal shape is offset from the nonpreferred-direction edge by the value specified in the start_value argument The start value must be greater than or equal to 0 and less than the smaller of the width or height of the block boundary.\n For horizontal shapes, the metal shapes start at the left edge.\n For vertical shapes, the metal shapes start at the bottom edge.\n Note: When you use the -stub option, the command uses the specified start_value and ignores the -spacing_from_boundary option.\n        The metal shapes have the length specified by the length_value argument The length value must be greater than 0 and less than or equal to the smaller of the width or height of the block boundary.\n  The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  The metal shapes are separated the space specified by the spacing_value argument The spacing value must be greater than or equal to 0.\n  The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n  The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n  shows the metal stubs inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed at the specified offset, O, from the horizontal (preferred-direction) edge, where O is measured from the boundary to the center of the shape.\n The first metal stub is placed at the specified offset, S, from the vertical (nonpreferred-direction) edge.\n Each metal shape has a width of W, the default width for the layer and the specified length, L.\n The spacing between metal stubs is the specified spacing, SP.\n  Metal Stub Perimeter Constraint Objects      SP SP SP  SP SP SP SP SP           Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges To insert additional short metal shapes in the preferred direction perpendicular to the nonpreferred-direction boundary edges,  Specify the length of the metal shapes by using the -short_metal_length option  Specify the distance between the metal shapes by using the -metal_spacing option For both of these options, you use the following format to specify the value for each layer: {{ layer_name value }...}  shows the short metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape has a width of W, which is the default width for the layer, and a length of L, which is the length specified for the layer by the -short_metal_length option.\n The offset from the nonpreferred-direction edge is S, which is the spacing specified for the layer by the -spacing_from_boundary option.\n The distance between short metal shapes is SS, which is specified for the layer by the -metal_spacing option.\n  Metal Shape Perimeter Constraint Objects With Additional Short Shapes        SS"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting the Rerouting Mode"}, {"role": "assistant", "content": "If a pin has a via ladder, by default, Zroute connects to the topmost layer of a via ladder and not directly to the existing pin geometry.\n To modify the connection constraints, set the following application options:  route.detail.via_ladder_upper_layer_via_connection_mode To allow vias to connect to the top level of a via ladder from below, set this application option to any  route.detail.allow_default_rule_nets_via_ladder_lower_layer_connection To allow nets with default routing rules to connect directly to the pin or to any layer of the via ladder, set this application option to true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Optimizing Wire Length and Via Count"}, {"role": "assistant", "content": "After redundant via insertion, whether concurrent or postroute, Zroute generates a redundant via report that provides the following information:  The via conversion rate for nondefault vias The via conversion rate for nondefault vias is listed at the top of the report as the total optimized via conversion rate.\n        The optimized via conversion rate for each layer The optimized via conversion rate includes both double vias and DFM-friendly bar vias, which have a single cut but a larger metal enclosure.\n The tool reports two values for the via conversion rate:  The total optimized via conversion rate This value is computed based on the total via count, which includes both fixed vias and routed vias.\n Fixed vias are vias that cannot be optimized by the router, such as unrouted vias and user-defined vias.\n  The optimized via conversion rate based on the total routed via count This value is computed based only on the routed via count, which includes only those vias that can be optimized by the router.\n Note: The optimized via conversion rate is not useful if you are using bar vias.\n  The distribution of optimized vias by weight for each layer To determine the via conversion rate for conversions above a certain weight, you must add the reported conversion rates for those weights.\n For example, in Example 29, the via conversion rate for weight 5 and above for layer V03 is 10.75+64.50=75.25%.\n Note: The conversion rate for unweighted vias is reported as \"Un-optimized.\"  The total double via conversion rate for the block Note: The redundant via rate reported by the report_design command differs from the redundant via rate reported by Zroute during redundant via insertion or the check_routes command.\n This difference occurs because the report_design command reports the double via rate for both PG vias and signal vias, while Zroute reports the double via rate only for signal vias.\n In addition, Zroute bases the conversion rate only on the redundant via mapping.\n Example 29 shows an example of the redundant via report.\n Example 29 Redundant Via Report Total optimized via conversion rate = 96.94% (1401030 / 1445268 vias) Layer V01 = 41.89% (490617 / 1171301 vias) Weight 10 = 9.64% (112869 vias) Weight 5 = 32.25% (377689 vias) Weight 1 = 0.01% (59 vias) Un-optimized = 58.11% (680684 vias)       Layer V02 = 76.20% (1567822/ 2057614 vias) Weight 10 = 43.51% (895270 vias) Weight 5 = 28.62% (588805 vias) Weight 1 = 4.07% (83747 vias) Un-optimized = 23.80% (489792 vias) Layer V03 = 81.87% (687115 / 839297 vias) Weight 10 = 64.50% (541369 vias) Weight 5 = 10.75% (90224 vias) Weight 1 = 6.62% (55522 vias) Un-optimized = 18.13% (152182 vias) Layer V04 = 81.60% (226833 / 277977 vias) Weight 10 = 81.45% (226418 vias) Weight 1 = 0.15% (415 vias) Un-optimized = 18.40% (51144 vias)...\n Layer V09 = 85.47% (1329 / 1555 vias) Weight 10 = 85.47% (1329 vias) Un-optimized = 14.53% (226 vias)  Total double via conversion rate = 46.69% (2158006 / 4622189 vias)"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Gating in the Compile Log File"}, {"role": "assistant", "content": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs.\n The naming convention is as follows: prefix_base-name[_index]  The prefix is clock_gate by default.\n To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option.\n  The base name is the most frequent instance name among the registers gated by the clock gate.\n The base name does not include bus bit indexes.\n  If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0.\n For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg.\n If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0.\n However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Saving UPF Information"}, {"role": "assistant", "content": "The UPF constraints for physical-only cells can cause issues when the UPF file is read into other tools that do not support physical-only cells, such as verification tools.\n Therefore, surround the UPF constraints for physical-only cells with the syntax shown in the following example: if {[info exists snps_handle_physical_only] && \\ $snps_handle_physical_only} {  /* Supply net connections for filler cells */ connect_supply_net VDDS -ports [get_pins FILLER*/VDD]   By default, the snps_handle_physical_only variable is set to true in the Fusion Compiler tool.\n Therefore, when you load and commit the UPF file, the constraints are applied to the physical-only cells.\n When you save a UPF file with the save_upf command, the tool uses the same syntax for the user-specified and tool-derived UPF constraints for physical-only cells.\n Therefore, these UPF constraints are ignored by any tool that does not have the snps_handle_physical_only variable set to true To create a UPF file that contains commands only for specific types of cells, use the -include or -exclude option with the save_upf command.\n These options accept arguments such as diode_cells pad_cells, and physical_only_cells.\n See the save_upf command man page for the complete list of arguments.\n Command filtering for specified cell types applies to the connect_supply_net set_related_supply_net create_power_domain, and set_isolation commands.\n You can apply command filtering to both block-level and full-chip UPF files."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Spreading Repeater Cells During Placement"}, {"role": "assistant", "content": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells.\n  Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in   The upper category consists of the top one percent of the total number of cells with the highest voltage drop values.\n During placement, the tool spreads these cells the most.\n  The middle category consists of the next five percent of the cells.\n During placement, the tool spreads these cells less than those in the upper category.\n  The lower category consists of the rest of the cells.\n The tool does not spread these cells.\n       You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options.\n The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false.\n They are true by default.\n The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa.\n The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\       -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command.\n The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Minimizing Large Displacements During Legalization"}, {"role": "assistant", "content": "The tool performs legalization at various points during the design flow.\n The following topics describe settings for controlling legalization:  Minimizing Large Displacements During Legalization  Optimizing Pin Access During Legalization  Enabling Advanced PG Net Checks        Enabling Advanced Legalization Algorithms  Setting Up for Variant-Aware Legalization  Checking if Library Cells Are Legally Placeable"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Analyzing and Fixing Signal Electromigration Violations"}, {"role": "assistant", "content": "In advanced process nodes, the distance between pins decreases, which can result in DRC violations caused by pin access issues.\n These types of DRC violations can be fixed by using keepout margins to increase the spacing between cells.\n       If your postroute design has DRC violations, analyze the violations to determine if they are caused by pin access issues.\n If so, run the optimize_routability command to increase the spacing between cells where the DRC violations occur.\n The optimize_routability command performs the following tasks:  Analyzes the cells with DRC violations to find violations where cells abut By default, the command considers all DRC violations.\n To consider only specific DRC violations, use the -drc_rules option.\n To consider only violations on specific layers, use the -layer_rules option.\n To preview the number of DRC violations and affected cells, use the -check_drc_rules option.\n When you use this option, the command generates a report but does not move any cells.\n  Sets keepout margins on these cells on the side of the cell where the error occurs By default, the command uses the site width as the keepout width.\n To specify a keepout width in microns, use the -keepout_width option.\n Note: These keepout margins are in addition to any existing keepout margins on the cells; the command does not modify the existing keepout margins.\n To try to fix the DRC violations by flipping the cells instead of adding keepout margins, use the -flip option.\n  Legalizes the affected cells You must use one of the following methods to complete the routes for the cells moved by the optimization:  Run ECO routing by using the route_eco command.\n  Run ECO routing by using the -route option with the optimize_routability command.\n To fix the DRC in the areas that have changes, set the route.common.eco_fix_drc_in_changed_area_only application option to on When you use this option, the command runs the route_eco and check_routes commands after completing the optimization.\n After moving the cells and performing ECO routing, remove the keepout margins from the cells by using the optimize_routability -remove_keepouts command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Global Routing"}, {"role": "assistant", "content": "Before you route the signal nets, all clock nets must be routed without violations.\n You can route the signal nets by using one of the following methods:  Use the task-specific commands to perform the standalone routing tasks.\n  To perform global routing, use the route_global command.\n For details see, Global Routing  To perform track assignment, use the route_track command.\n For details see, Track Assignment  To perform detail routing, use the route_detail command.\n For details see, Detail Routing When you run a standalone routing command, such as route_global or route_detail, Zroute reads in the block at the beginning of each routing command and updates the block at the end of each command.\n The router does not check the input data.\n For example, if the track assignment step is skipped and you run detail routing directly, Zroute might generate bad routing results.\n If you need to customize your routing flow or you need to run a large block step-by- step, you might want to use the standalone routing commands instead of automatic routing.\n  Use automatic routing (the route_auto command).\n The route_auto basic command performs global routing, track assignment, and detail routing.\n For details, see Routing Signal Nets by Using Automatic Routing When you run route_auto, Zroute reads the block before starting routing and updates the block when all routing steps are done.\n If you stop automatic routing before it performs detail routing, Zroute checks the input data when you restart routing with this command.\n Use the route_auto command when you run routing to verify convergence, congestion, and design rule quality-of-results (QoR).\n You also might want to use route_auto if congestion QoR is your main goal, rather than timing QoR.\n Zroute can insert redundant vias during signal routing.\n For information about this capability, see Inserting Redundant Vias on Signal Nets"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Voltage Driven Power Switch Cell Sizing"}, {"role": "assistant", "content": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow.\n By default, the analyze_rail command uses a single process to perform RedHawk rail analysis.\n To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run.\n You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session.\n This allows you to run multiple RedHawk analyses with only one Fusion Compiler license.\n Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key.\n To examine the generated analysis result, first run the open_rail_result command to load the result that is saved in the directory you specify.\n You can then investigate the problematic areas in the map and check for violations in a text file or in an error view.\n You can open one result context at a time.\n To load the rail context generated in another analysis run, first close the current rail result using the close_rail_result command, and then open the desired rail result (see Displaying Maps in the GUI ).\n License Requirement By default, the number of required licenses is the number of script files or configurations specified with the -multiple_script_files option during distributed processing mode.\n If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message.\n To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the analyze_rail run, set the rail.license_checkout_mode application option to wait.\n If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately.\n By default, the rail.license_checkout_mode application option is set to nowait When the analysis is finished, run the remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses.\n fc_shell> remove_licenses SNPS_INDESIGN_RH_RAIL       In, the rail.license_checkout_mode application option is set to wait.\n There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses.\n In this case, the tool first checks out two licenses and waits for other licenses to become available.\n When a script finishes the job, the tool reuses its license immediately to submit other scripts.\n  Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6       Set rail.license_checkout_mode to wait The tool first submits two scripts to the farm machines, because there are only two licenses available.\n  ...\n The tool checks for available licenses during the analyze_rail run.\n When a license becomes available, the tool reuses it.\n  Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1.\n Define the distributed processing configuration by using the set_host_options command.\n You can specify one or more of the following options: Option Description -submit_protocol  rsh    -target  -timeout        Option Description -submit_command    -max_cores   2.\n Run the analyze_rail command with the following options: Option Description -submit_to_other_machines  -multiple_script_files\\ directory_name script_name   Example 51 %> rsh myMachine ls test1 CSHRC DESKTOP > set_host_options \"myMachine\" -target RedHawk \\ -max_cores 2 -timeout 100 > analyze_rail -submit_to_other_machines \\ -voltage_drop static -nets {VDD VDDG VDDX VDDY VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only.\n Timeout value is 100 and the number of cores to use is 2.\n Example 52 > set_host_options -submit_protocol sge \\ -submit_command { qsub -P normal } > analyze_rail -submit_to_other_machines -voltage_drop \\ static -nets {VDD VSS} The above example enables job submission to a machine on the SGE farm machine.\n Example 53 > set_host_options -submit_protocol lsf \\ -submit_command {bsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{result1 RH1.tcl} {result2 RH2.tcl}}  > open_rail_result result1       > close_rail_result > open_rail_result result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2.\n Example 54 > set_app_options -name rail.license_checkout_mode \\ -value wait > set_host_options -submit_protocol sge \\ -submit_command {qsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{ result1 RH1.tcl} {result2 RH2.tcl} \\ {result3 RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the analyze_rail run."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Restricting the Target Libraries Used"}, {"role": "assistant", "content": "By default, the Fusion Compiler tool can use all of the library cells available in the cell libraries when performing optimization or clock tree synthesis on the block.\n To restrict the cell usage, use the set_lib_cell_purpose command after the block is in memory.\n The command has a block scope and is persistent across tool sessions.\n The specified settings are restored when the block is reopened.\n To specify how the tool can or cannot use library cells, use the -include and -exclude options with the set_lib_cell_purpose command.\n Both of these options accept one or more of the following values: all cts hold optimization none  The -include option sets the included_purposes attribute on the specified library cells.\n  The -exclude option sets the excluded_purposes attribute on the specified library cells.\n       Note: If a library cell has a dont_use attribute, it is excluded from all uses, which is the same as if you specified set_lib_cell_purpose -include none for that cell.\n When the tool performs optimization, which includes setup, hold, and logical DRC fixing, it can use library cells that have an included purpose of optimization hold, or both.\n When the tool performs clock tree synthesis, it can use library cells that have an included purpose of cts For example, to disallow the use of a set of library cells for all uses, use the following command: fc_shell> set_lib_cell_purpose -include none lib_cells To allow a set of library cells to be used only for clock tree synthesis, use the following commands: fc_shell> set_lib_cell_purpose -include none lib_cells fc_shell> set_lib_cell_purpose -include cts lib_cells To allow a set of library cells to be used for all uses except clock tree synthesis, use the following command: fc_shell> set_lib_cell_purpose -exclude cts lib_cells To use the asterisk wildcard character (*) to query a collection of cells, you must use the get_lib_cells command.\n However, the set_lib_cell_purpose command excludes synthetic modules by default.\n Therefore, you should use the set_synlib_dont_use command to exclude synthetic modules.\n For example, fc_shell> set_lib_cell_purpose \\ -include none [get_lib_cells */*01_*_AB] Warning: The'set_lib_cell_purpose' command cannot be used on synthetic library cell'standard:*OPMOD.DW01_ADD_AB.timing'.\n (NDMUI-511)"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Changing the Structures of Relative Placement Groups"}, {"role": "assistant", "content": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option.\n The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns.\n This application option helps the relative placement engine know about the distance between the tap columns.\n       This helps in better placement and structures of relative placement groups in the design.\n You must use this application option for n5 and older technical nodes.\n For n3 and beyond designs, the distance between tap columns is calculated automatically.\n place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Layout-Versus-Schematic Checking"}, {"role": "assistant", "content": "Calibre interface You can perform design rule checking with the Calibre tool, convert the Calibre DRC error file to an Fusion Compiler error data file, and then report or view the errors in the Fusion Compiler tool.\n To convert the Calibre DRC error file to an Fusion Compiler error data file, use the read_drc_eror_file comandcomandsread_drc_eror_file read_drc_error_file command.\n For example, fc_shell> read_drc_error_file -file Calibre_error_file By default, the command generates an error data file named cell_name.err, where cell_name is derived from the Calibre error report.\n You can specify a name for the error data file by using the -error_data option.\n Note: The read_drc_error_file command supports only flat Calibre DRC error files; it does not support Calibre hierarchy DRC error files.\n You can load the error data file created by the read_drc_error_file command into the error browser to report or display the DRC violations.\n For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Minimizing Glitches on Asynchronous Set and Reset Lines of"}, {"role": "assistant", "content": "Specifying synthesis constraints specific to DFT insertion for certain registers must be mapped to non-scan versions and the core wrapper reuse threshold.\n To specify the DFT configurations: 1.\n Execute compile_fusion -from initial_map -to logic_opto 2.\n Specify the DFT configurations such as DFT signals, chain counts, test modes, and so on.\n 3.\n Complete the DFT insertion.\n For more information about DFT insertion, see the TestMAX DFT User Guide.\n 4.\n Execute compile_fusion -from initial_place Note: You must create scan test and scan in and scan out ports before importing floorplan information.\n In addition, the floorplan must contain the physical locations of the test and scan ports.\n Scan-Only Script Example # Set up the library...\n # Read the design...\n # Specify any registers that should not be mapped to scan equivalent, and also to be excluded from any scan chains set_scan_element false <registers that should not be mapped to scan equivalent> # Run compile_fusion to logic_opto step compile_fusion -to logic_opto # DFT Specifications: # Scan chain setup set_scan_configuration -chain_count sc # DFT signals # Clocks and asynchronous resets       set_dft_signal -view existing -type ScanClock \\ -port clk -timing [list 45 55] set_dft_signal -view existing -type Reset \\ -port reset_n -active_state0 # Scan in, scan out, scan enable set_dft_signal -view spec -type ScanDataIn -port SI set_dft_signal -view spec -type ScanDataOut -port SO set_dft_signal -view spec -type ScanEnable -port SE # Scan Synthesis steps create_test_protocol dft_drc preview_dft insert_dft # Continue from initial_place step compile_fusion -from initial_place -to initial_opto # Perform post dft_drc dft_drc -test_mode Internal_scan # Generate post dft_drc verbose report report_dft_drc_violations -test_mode Internal_scan -rule all # Write out Scandef write_scan_def design.scan.def # Write out test model write_test_model -output design.ctl # Save output for TetraMAX write_test_protocol -output design.scan.spf  -test_mode Internal_scan write_verilog -hierarchy all design.v"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Via Ladder Candidates for Library Pins"}, {"role": "assistant", "content": "A via ladder is a stacked via that starts from the pin layer and extends into the upper routing layers.\n Using via ladders during optimization improves the performance and electromigration robustness of a design.\n The tool can automatically insert via ladders for cell pins on timing-critical paths during the compile_fusion and clock_opt commands.\n To perform via ladder insertion during preroute optimization, 1.\n Ensure that the via ladder rules are defined as described in Defining Via Ladder Rules 2.\n Specify the via ladders that can be used for specific library pins by using the set_via_ladder_candidate command, as described in Specifying Via Ladder Candidates for Library Pins 3.\n (Optional) Enable high-performance and electromigration via ladder insertion for critical paths by setting the opt.common.enable_via_ladder_insertion application option to true 4.\n (Optional) Enable the insertion of global-route-based via ladders on pins with via ladder constraints by setting the route.global.insert_gr_via_ladders application option to true 5.\n Perform optimization using the compile_fusion or clock_opt command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Placing Group Repeaters For Multibit Registers"}, {"role": "assistant", "content": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command.\n place_group_repeaters \\ -cells cell_list | -repeater_groups group_id_list [-lib_cell_input pin_name ] \\ [-lib_cell_output pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting the Policy for Early Data Checks"}, {"role": "assistant", "content": "The tool can identify issues and violations in data during the early stages of design.\n You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data.\n Table 64 describes the predefined checks for top-level closure.\n Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view        error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location           error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary              error, tolerate, repair MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort           error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame     error, tolerate TOP hier.block.inst ance_with_desig n_type_macro     error, tolerate TOP hier.top.estima ted_corner     error, tolerate TOP hier.block.miss ing_leaf_cell_l ocation             error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary              error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion                  error, tolerate, repair MID       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary               error, tolerate, repair MID hier.block.port _mismatch_betwe en_views             error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs     error, tolerate MID BOT hier.block.inst ance_unlinked           error TOP hier.block.abst ract_type_non_t iming    error MID BOT hier.block.abst ract_target_use _non_implementa tion     error MID BOT hier.block.miss ing_core_area     error MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic     error MID BOT Where  BOT signifies bottom level design.\n  MID signifies intermediate level design, which instantiates BOT.\n  TOP signifies the top-level design, which instantiates MID."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Horizontal and Vertical Spacing for Repeater Groups"}, {"role": "assistant", "content": "Use one of the following mutually exclusive options to control cutting for repeater groups:  -layer_cutting_spacing specifies the cut space of the routes to the driver pin.\n The cut starts from the driver side.\n  -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Local Skew Optimization"}, {"role": "assistant", "content": "By default, clock tree synthesis tries to achieve the best skew and latency for all clocks.\n However, this can lead to area, power, and runtime overhead for low frequency clocks, which have relaxed skew and latency targets.\n  To specify a skew target, use the -target_skew option with the set_clock_tree_options command.\n  To specify a latency target, use the -target_latency option with the set_clock_tree_options command.\n By default, when you define skew and latency targets, they apply to all clocks in all corners.\n To define targets for specific clocks, use the -clocks option.\n To define targets for specific corners, use the -corners option.\n To report the user-defined skew and latency targets, use the report_clock_tree_options command.\n To remove user-defined skew or latency targets, use the remove_clock_tree_options command.\n To remove all skew and latency targets, use the -all option; otherwise, use the appropriate -target_skew -target_latency -clocks, and -corners options to remove the specific targets."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Via Ladder Rule Files"}, {"role": "assistant", "content": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the setup_performance_via_ladder command to generate the via ladder rules and associations.\n By default, this command  Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the -max_layer attribute.\n       The command uses information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file:  The cut layers that connect the specified metal layers  The cut names  The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block.\n The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules.\n For details about these files, see Via Ladder Rule Files You can also generate these files by using the generate_via_rules_for_performance command.\n  Associates via ladder rules with the pins of all library cells that do not have a dont_use attribute To include the pins of library cells that have a dont_use attribute, use the -dont_use option.\n To associate via ladder rules only with specific pins, use the -lib_pins option.\n The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations.\n For details about this file, see Via Ladder Association File You can also generate this file by using the associate_performance_via_ladder command.\n  Runs the generated script files See Also  Defining Via Ladder Rules  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running the signoff_check_drc Command"}, {"role": "assistant", "content": "IC Validator In-Design signoff design rule checking (DRC) runs the IC Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry signoff runset.\n You can perform signoff design rule checking by  Running the signoff_check_drc command  Using the Live DRC feature in the Fusion Compiler GUI After place and route, use the signoff_check_drc command to perform signoff design rule checking on the entire block.\n After engineering change orders (ECO), use either method to perform incremental signoff design rule checking on the modified portions of the block.\n See Also  Automatically Fixing Signoff DRC Violations"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Checking the Routing Results"}, {"role": "assistant", "content": "Shielding is needed around sensitive nets to reduce noise and crosstalk.\n When you perform custom routing by using the route_custom command, the tool automatically creates shields for the nets based on the constraints you specify by using the create_net_shielding command.\n To add shielding to the selected nets in a separate run, use the create_custom_shields command.The following example creates shields for net1 and net2.\n fc_shell> create_custom_shields -nets {net1 net2} To remove the shielding created by the create_custom_shields command, use the remove_custom_shields command.\n Doing this also removes the shielding created by the route_custom command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying a Keepout Margin"}, {"role": "assistant", "content": "The Fusion Compiler tool supports the following orientations for relative placement groups:  R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top.\n  R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom.\n  MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation.\n  MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation.\n  shows how the column and row positions in a relative placement group are placed for the four orientations.\n        Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length.\n You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command.\n For example, the following command sets the relative placement group orientation to MY.\n fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy.\n       Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Ensuring Clock Tree Exceptions are Valid"}, {"role": "assistant", "content": "To define one or more pins as ignore pins, use the following syntax: set_clock_balance_points [-clock clock -consider_for_balancing false -balance_points pins The -clock option is not required.\n If you do not use it, all user-defined ignore pins apply to all clocks.\n       For the CLK clock tree shown in, assume that you want to ignore all branches of the clock tree beyond the U2 cell.\n To do so, you would use the following command: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins U2/A]  User-Defined Ignore Pin CLK   U2 To report the user-defined ignore pins, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins report_clock_balance_points command.\n This command reports both the user-defined sink pins and the user-defined ignore pins.\n During clock tree synthesis, the tool adds guide buffers and isolates ignore pins from the rest of the clock network.\n During subsequent data path optimization, the tool fixes any existing DRC violations beyond the guide buffers.\n To remove the ignore pin definition from a pin, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins remove_clock_balance_points command.\n For example, to remove the ignore pin definition from pin U2/CLK for the CLK clock, use the following command: fc_shell> remove_clock_balance_points -clock [get_clocks CLK] \\ -balance_points [get_pins U2/CLK]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Routing Blockages"}, {"role": "assistant", "content": "To find routing blockages, use the get_routing_blockages command.\n For example, to get all the routing blockages in a block, use the following command: fc_shell> get_routing_blockages * To find the routing blockages for specific nets, use the -of_objects option to specify the nets of interest.\n For example, to find the routing blockages for the n1 net, use the following command: fc_shell> get_routing_blockages -of_objects [get_nets n1] To find the routing blockages in a specific location, use the get_objects_by_location -classes routing_blockage command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Adding Buffers in a Specified Configuration"}, {"role": "assistant", "content": "When you use the add_buffer_on_route command, you must specify the following:  The net on which to add buffers  The type of buffers to add and where to add them on the net by using one of the following methods:  Adding Buffers in a Specified Configuration  Adding Buffers at Specified Locations  Adding Buffers at a Specified Interval  Adding Buffers at an Interval That is a Ratio of the Net Length  Adding Buffers on a Bus in a Specified Pattern"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Replacing Clock Gates"}, {"role": "assistant", "content": "To insert clock gating logic in an RTL design and to synthesize the design with the clock- gating logic, follow these steps: 1.\n Read the RTL design.\n 2.\n (Optional) Use the insert_dft command to insert test cells into the design.\n 3.\n Use the compile_fusion command to compile the design.\n During the compile process, the tool inserts clock gates on the registers qualified for clock-gating.\n By default, during clock-gate insertion, the compile_fusion command uses the clock gating default settings and also honors the setup, hold, and other constraints specified in the logic libraries.\n To override the setup and hold values specified in the library, use the set_clock_gating_check command before compiling the design.\n The default settings are suitable for most designs.\n The compile_fusion command automatically connects the scan enable and test ports or pins of the integrated clock-gating cells, as needed.\n 4.\n Use the report_clock_gating command to report the registers and the clock-gating cells in the design.\n Use the report_power command to get information about the dynamic power used by the design after clock-gate insertion.\n The following example illustrates a typical command sequence for clock using default settings: fc_shell> read_verilog design.v fc_shell> create_clock -period 10 -name CLK fc_shell> compile_fusion fc_shell> insert_dft       fc_shell> report_clock_gating fc_shell> report_power"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Movement When Legalizing Relative Placement"}, {"role": "assistant", "content": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed.\n When a relative placement cell is removed during optimization, the relative       placement information of the instance is also removed, disrupting the relative placement structure.\n To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting  all_opt  size_only  size_in_place  no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Importing the Floorplan Information"}, {"role": "assistant", "content": "During early design development, frequent design updates can cause incomplete or inconsistent data, such as pin mismatches between a block-level design and the reference to it from a top-level design.\n To enable the tool to successfully link a block even if it has certain types of design mismatch, set a mismatch configuration for the block.\n By default, the tool cannot link any block with inconsistent or mismatching data.\n When you set mismatch configurations, the tool either ignores or fixes several different types of mismatching data and continues the linking process.\n Blocks linked with mismatching data can be used only for feasibility analysis.\n To learn how to mitigate design mismatches, see the Fusion Compiler Data Model User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Prerequisites for Routing"}, {"role": "assistant", "content": "shows the basic Zroute flow, which includes clock routing, signal routing, DFM optimizations, and route verification.\n  Basic Zroute Flow"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Applying Required Settings for High Performance Cores"}, {"role": "assistant", "content": "To apply placement, legalization, routing, and extraction setting specific to 12 or 7 nanometer technology nodes, use the set_technology command with the -node 12 or -node 7 option.\n       When using this command, perform the following steps before placement, optimization, and routing: 1.\n Load and link the design.\n 2.\n Apply the settings required for the technology nodes by using the set_technology -node command, as shown in the following example: fc_shell> set_technology -node 7 3.\n (Optional) Report the technology-node settings by using the set_technology -report_only command.\n 4.\n Apply your design-specific application option or command settings to override the generic setting of the set_technology command.\n When you save the design library with the save_lib command, the technology-node setting is saved.\n Note: After you specify a technology node with the set_technology command, you cannot change it.\n For more information about which ASIC technologies are supported by this command, contact Synopsys Support."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Merging Clock Gates"}, {"role": "assistant", "content": "If you load a SAIF file, the Fusion Compiler tool analyzes the switching activity to evaluate whether to expand a tool-inserted clock gate.\n This analysis prevents the insertion of unnecessary clock gates.\n For example, in, clock gates A1 and A2 are each common to two paths and are therefore candidates for multilevel expansion.\n  Before Clock-Gate Level Expansion       However, if clock gate A2 is always enabled, it has a toggle rate of 0 and a static probability of 1.\n Adding another clock-gate level does not provide any benefit in this case.\n The final configuration is shown in  After Clock-Gate Level Expansion If clock-gate level expansion is enabled, the Fusion Compiler tool performs activity- driven analysis by default.\n If a SAIF file is not available, disable this feature by setting the compile.clockgate.enable_activity_drivel_level_expansion application option to false (the default is true ).\n If clock-gate level expansion is disabled, the tool ignores the compile.clockgate.enable_activity_driven_level_expansion application option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling IR-Drop-Aware Placement"}, {"role": "assistant", "content": "During placement, the tool can use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values, which reduces the power density of such areas.\n To perform IR-drop-aware placement, use the following steps: 1.\n Place and legalize the block.\n 2.\n Set up for RedHawk Fusion and perform static or dynamic voltage drop analysis by using the analyze_rail -voltage_drop command as shown in the following example: fc_shell> source redhawk_setup.tcl fc_shell> analyze_rail -voltage_drop static -nets {VDD VSS} For more information, see Performing Voltage Drop Analysis 3.\n Enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true       4.\n (Optional) Specify additional settings for IR-drop-aware placement, as described in Controlling IR-Drop-Aware Placement 5.\n Rerun placement.\n Note: To perform IR-drop-aware placement, you must have Digital-AF and SNPS_INDESIGN_RH_RAIL license keys."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating Constraints for Auto Floorplanning"}, {"role": "assistant", "content": "During early design stages, a design often undergoes many iterations due to changes such as adding features and macros; as a result, the floorplan contains limited or no physical information.\n Automatic floorplanning can generate high-quality floorplans and create missing physical information early in the design cycle, which allows you to  Achieve better correlation between the results of RTL synthesis and design implementation  Identify and fix design issues early in the design cycle  Generate a better starting point for place and route, eliminating costly iterations During automatic floorplanning, the compile_fusion command performs the following tasks:  Creates the die, rows, and tracks  Shapes and places voltage areas  Places macros  Places pins and I/Os By default, the top-level floorplan is created with a core utilization of 0.7.\n For information about setting constraints for automatic floorplanning, see Creating Constraints for Auto Floorplanning"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Clock Tree Design Rule Constraints"}, {"role": "assistant", "content": "Before you synthesize the clock trees, use the check_clock_tre comandcomandscheck_clock_tre check_clock_trees command to verify that the clock trees are properly defined.\n For example, to verify that the CLK clock tree is properly defined, use the following command: fc_shell> check_clock_trees -clocks [get_clocks CLK] If you do not specify the -clock option, the tool checks all clocks in the current block.\n The check_clock_trees command checks for the following issues:  Clock (master or generated) with no sinks  Loops in the clock network  Multiple clocks reach the same register because of overlapping clocks, but multiple- clocks-per-register propagation is not enabled  Ignored clock tree exceptions  Stop pin or float pin defined on an output pin  Buffers with multiple timing arcs used in clock tree references  Situations that cause an empty buffer list        Generated clock without a valid master clock source A generated clock does not have a valid master-clock source in the following situations:  The master clock specified in create_generated_clock does not exist  The master clock specified in create_generated_clock does not drive the source pin of the generated clock  The source pin of the generated clock is driven by multiple clocks, and some of the master clocks are not specified with create_generated_clock For example, in, the GEN_REG/Q pin is driven by both CLKA and CLKB.\n If only CLKA is specified as a master clock in a create_generated_clock command, GEN_CLK does not have a valid master clock source.\n  Generated Clock With Invalid Master Clock Source     REG1 REG2     GEN_REG CLKA CLKB GEN_CLK For multicorner-multimode designs, the check_clock_trees command checks all active scenarios for the following issues:  Conflicting per-clock exception settings  Conflicting balancing settings Before you implement the clock trees, you should manually fix the reported issues.\n Each message generated by the check_clock_trees command has a detailed man page that describes how to fix the identified issue.\n You can improve the clock tree and timing QoR by fixing all the issues identified by the check_clock_trees command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Sorting and Filtering the Data"}, {"role": "assistant", "content": "By default, the comparison tables show the QoR values for all runs.\n For example, the NVE number for the following run is 2374: To cycle through different display styles of the data, right-click anywhere in the table.\n You can view the data  as a percentage delta against the baseline  as an absolute delta against the baseline (shown in For example, as a percentage delta, the NVE number shows 2.7% fewer failing endpoints than the baseline: As an absolute delta, the NVE number shows 65 fewer failing endpoints than the baseline: See Also  Sorting and Filtering the Data  Exploring the Detailed Comparison Data"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Checking Designs With Abstracts for Top-Level-Closure Issues"}, {"role": "assistant", "content": "Before you can perform synthesis, placement, optimization, clock tree synthesis, and routing at the top level, you must perform the following tasks:  Apply the top-level-timing constraints and settings.\n You can split the chip-level constraints in to separate top- and block-level constraints by using the split_constraints command.\n  Review and specify the relationship between the top- and block-level modes, corners, and clocks by using the set_block_to_top_map command.\n  If the pre-clock tree implemented blocks, which have undergone CCD optimization, are used for top-level placement and optimization, then the ideal clock latencies adjusted dynamically by different engines such as CCD and clock-gate estimation on the clock pins of registers or integrated clock gating (ICG) cells inside the blocks might not be seen at the top-level leading to timing inaccuracies at the top-level.\n Promote these clock latency constraints from block-level to the top-level by using the promote_clock_data -latency_offset -auto_clock connected command.\n  Apply the top-level clock tree synthesis settings and exceptions.\n  If the top-level exceptions do not include the balance points on the pins within lower-level blocks, promote the balance points from the lower levels by using the promote_clock_data -auto_clock connected -balance_points command.\n  If concurrent clock and data (CCD) optimization is performed at the block level, the tool derives median clock latencies for the block-level clock ports, which accounts for the latency adjustments that were derived for the block-level registers during concurrent clock and data optimization.\n Promote these block-level clock latencies as clock balance point delays for the block-level clock pins by using the promote_clock_data -auto_clock connected -port_latency command.\n  If the lower-level blocks contain clock-meshes, promote the mesh annotations (annotated transitions and delays) by using the promote_clock_data -mesh_annotations command.\n  If you need to promote clock data for a specific top-level clock, use the promote_clock_data -clocks {top_clock} -port_latency command.\n The command also promotes clock-independent exceptions.\n If any of the given top-level clocks has no mapping to any block-level clock in any mode, the tool issues a warning.\n  If there are any active modes, corners, or clocks at the top-level, which cannot be mapped to corresponding modes, corners, or clocks in the block-level, you can still promote the clock data for other mapped modes, corners, or clocks using the promote_clock_data -balance_points -force command.\n This command issues errors for the unmapped modes, or corners, or clocks.\n        Apply the top-level UPF constraints, which you can create from the full-chip UPF constraints by using the split_constraints command.\n The tool promotes the required UPF constraints from the lower-level blocks to the top level."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Querying Placement Blockages"}, {"role": "assistant", "content": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type allow_buffer_only -blocked_percentage 70       Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Tapoffs"}, {"role": "assistant", "content": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split.\n  custom.route.bus_split_ignore_width  custom.route.bus_split_even_bits The custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section.\n The custom.route.bus_split_even_bits application option requires that you set the custom.route.bus_split_ignore_width application option.\n If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes).\n In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set.\n The spacing between the power and ground rails can accommodate three bits only.\n a shows the two possible results when the custom.route.bus_split_even_bits application option is turned off.\n b shows the result when the custom.route.bus_split_even_bits application option is turned on.\n  Splitting Bus Trunk to Route Through Power and Ground Rails"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Creating a Multibit Register Bank From Specific Single-Bit"}, {"role": "assistant", "content": "To perform integrated multibit register optimization during the compile_fusion command, 1.\n Enable multibit register optimization by setting the compile.flow.enable_multibit application option to true When you do so, by default, the tool performs the following multibit optimizations during different stages of the compile_fusion command:  Combines single registers or smaller register banks at the RTL level to create larger register banks during the initial_map stage To disable this feature, set the compile.flow.enable_rtl_multibit_banking application option to false  Splits multibit register banks created at the RTL level if the register bank includes registers on critical timing paths during the logic_opto stage To disable this feature, set the compile.flow.enable_rtl_multibit_debanking application option to false  Creates multibit register banks considering placement during the initial_opto stage To disable this feature, set the compile.flow.enable_physical_multibit_banking application option to false You can enable placement-based multibit banking during the final_place stage of the compile_fusion command, instead of the initial_opto stage, by setting the compile.flow.enable_second_pass_multibit_banking application option to true and the compile.flow.enable_physical_multibit_banking application option to false You should enable placement-based multibit banking either during the initial_opto stage or the final_place stage; not both.\n  Splits multibit register banks, if it improves total negative slack (TNS), during the initial_opto and final_opto stages To disable this feature, set the compile.flow.enable_multibit_debanking application option to false 2.\n (Optional).\n       3.\n Specify settings for multibit register banking by using the set_multibit_options command.\n For example, the following command excludes the reg[1] cell from multibit optimization during the RTL-banking stage: fc_shell> set_multibit_options -exclude [get_cells \"reg[1]\"] \\ -stage rtl The following command specifies that during the physical-banking stage, the tool banks only registers that are connected to the same bus: fc_shell> set_multibit_options -bus_registers_only \\ -stage physical 4.\n (Optional) Control multibit register optimization using application options as shown in the following table.\n Table 22 General Application Options for Controlling Multibit Register Optimization To do this Set this application option   multibit.banking.enable_strict_scan_check  true    multibit.banking.lcs_consider_multi_si_cells  true        multibit.banking.across_equivalent_icg true    dont_touch legalize_only size_only  mv.cells.enable_multibit_pm_cells true size_only   multibit.common.exclude_size_only_cells  false  compile_fusion  compile.flow.enable_multibit_rewiring true       To do this Set this application option   logic_opto  compile.flow.enable_toggle_aware_rtl_multibit_ reordering true      initial_opto (compile_fusion) final_place final_opto (compile_fusion/place_opt)   logic_opto compile_fusion  opt.common.enable_multibit_feature true 5.\n (Optional) Create a multibit register bank from specific single-bit registers as described in Creating a Multibit Register Bank From Specific Single-Bit Registers 6.\n (Optional) Control the naming style used for multibit banking as described in Specifying Naming Styles for Multibit Registers 7.\n Perform optimization by using the compile_fusion command.\n 8.\n (Optional) Report multibit information.\n To report the multibit register banks inferred by the tool, use the report_transformed_registers -multibit command, as described in Reporting Multibit Registers To report multibit statistics such as the total number of single-bit and multibit registers, the multibit banking ratio, and so on, use the report_multibit command.\n For more information about how to determine why multibit register banking is not performed for specific cells, see Identifying Why Multibit Banking Is Not Performed 9.\n (Optional) Analyze the multibit banking components in the GUI as described in Viewing Multibit Components in the GUI"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Aligning by Pin Location"}, {"role": "assistant", "content": "To align a group by aligning the right edges, use the -alignment right option of the set_rp_group_options command.\n Note: For hierarchical relative placement groups, the bottom-right alignment does not propagate through the hierarchy.\n  shows cells that are right aligned.\n        Bottom-Right-Aligned Relative Placement Group U4 U3 U2 U1 row 3 row 2 row 1 row 0 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Exploring the Detailed Comparison Data"}, {"role": "assistant", "content": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further.\n To sort and filter the data, see the following topics:  Sorting the Data  Filtering Metrics  Filtering Runs  Example Analysis See Also  Exploring the Detailed Comparison Data       Sorting the Data Click any column header to sort the data using that metric.\n The first click performs an ascending sort, while the second click performs a descending sort.\n For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom:       Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly.\n For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in  Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column.\n For example, to display only the first four runs in a table, select the runs as shown in   Choose Baseline and Visible Runs Dialog Box       Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further.\n Suppose you open the comparison report shown in and set the util60_aspect1%1_layerM9 run as the base run.\n  Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer.\n This suggests that restricting the metal layers significantly impacts timing.\n       You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs.\n You could restrict your analysis to your lower-utilization runs by turning off the       visibility of your higher-utilization runs as shown in, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals.\n  Displaying Lower-Utilization Runs"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Clock-Gate Enable Signals"}, {"role": "assistant", "content": "After compiling your design, you can check the results using the report_clock_gating command.\n An example is shown in  Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics.\n The term \"pre-existing clock gates\" refers to user-instantiated clock gates.\n The preexisting category also includes registers that are gated by a tool-inserted clock gate.\n This includes registers that are gated by both preexisting and tool-inserted clock-gating cells.\n By default, the tool reports multilevel statistics.\n This includes the maximum level of clock- gating cells in the design.\n Clock-gate levels are counted from the clock source toward the register.\n If multibit flip-flops are found in the design, multibit composition is automatically reported.\n        Example of a Multibit Composition Report To report the details on ungated registers, use the -ungated option for report_clock_gating.\n For details on the gated registers, use the -gated option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating Via Ladder Rules for Electromigration Via Ladders"}, {"role": "assistant", "content": "A via ladder rule defines the number of rows and the number of cuts in each row for each layer in a via ladder.\n Via ladder rules can be defined in the technology file or by using the create_via_rule command.\n For example, each of the following methods creates an identical via ladder rule:  Define the rule in the technology file.\n ViaRule \"VL1\" { cutLayerNameTblSize = 2 cutLayerNameTbl = (VIA1, VIA2) # via layer names cutNameTbl = (CUT1A, CUT2A) # cut names numCutRowsTbl = (2, 2) # rows in ladder numCutsPerRowTbl = (2, 2) # columns in ladder upperMetalMinLengthTbl = (L1, L2) # minimum length rule cutXMinSpacingTbl = (X1, X2) # X-direction spacing cutYMinSpacingTbl = (Y1, Y2) # Y-direction spacing maxNumStaggerTracksTbl = (S1, S2) # maximum staggering forHighPerformance = 0       forElectromigration = 1  For details about defining via ladder rules in the technology file, see the \"Via Ladder Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  Define the rule on the command line by using the create_via_rule command with a detailed specification and then specifying additional details by setting its attributes.\n fc_shell> create_via_rule -name VL1 -cut_layer_names {VIA1 VIA2} \\ -cut_names {CUT1A CUT2A} -cut_rows {2 2} -cuts_per_row {2 2} fc_shell> set_attribute [get_via_rules VL1] \\ upper_metal_min_length_table {L1 L2} fc_shell> set_attribute [get_via_rules VL1] \\ cut_x_min_spacing_table {X1 X2} fc_shell> set_attribute [get_via_rules VL1] \\ cut_y_min_spacing_table {Y1 Y2} fc_shell> set_attribute [get_via_rules VL1] \\ max_num_stagger_tracks_table {S1 S2} fc_shell> set_attribute [get_via_rules VL1] \\ for_high_performance false fc_shell> set_attribute [get_via_rules VL1] \\ for_electro_migration true  Define the rule on the command line by creating an empty via rule with the create_via_rule command and then specifying the details by setting its attributes.\n fc_shell> create_via_rule -name VL1 fc_shell> set_attribute [get_via_rules VL1] \\ cut_layer_name_table_size 2 fc_shell> set_attribute [get_via_rules VL1] \\ cut_layer_name_table {via1 via2} fc_shell> set_attribute [get_via_rules VL1] \\ cut_name_table {CUT1A CUT2A} fc_shell> set_attribute [get_via_rules VL1] \\ num_cuts_per_row_table {2 2} fc_shell> set_attribute [get_via_rules VL1] num_cut_rows_table {2 2} fc_shell> set_attribute [get_via_rules VL1] \\ upper_metal_min_length_table {L1 L2} fc_shell> set_attribute [get_via_rules VL1] \\ cut_x_min_spacing_table {X1 X2} fc_shell> set_attribute [get_via_rules VL1] \\ cut_y_min_spacing_table {Y1 Y2} fc_shell> set_attribute [get_via_rules VL1] \\ max_num_stagger_tracks_table {S1 S2} fc_shell> set_attribute [get_via_rules VL1] \\ for_high_performance false fc_shell> set_attribute [get_via_rules VL1] \\ for_electro_migration true       The tool treats the via rules the same, regardless of the method used to create them.\n You can perform the following tasks for via rules:  Create a collection of via rules by using the get_via_rules command  Remove via rules by using the remove_via_rules command  Display detailed information about the via rules by using the report_via_rules command  Set or query via rule attributes To see the attributes supported on via rule objects, use the list_attributes -application -class via_rule command.\n  Save the via rules in a technology file by using the write_tech_file command See Also  Generating Via Ladder Rules for Electromigration Via Ladders"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing the Threshold-Voltage Filler Cell Information"}, {"role": "assistant", "content": "By default, the create_vtcell_fillers command fills all empty space in the horizontal standard-cell rows of the entire block.\n You can control the following aspects of the filler cell insertion:  The region in which to insert the filler cells  Use the -region option to restrict filler cell insertion to the specified regions.\n  Use the -voltage_area option to restrict filler cell insertion to the specified voltage areas.\n  The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name number To identify the filler cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix filler_library_cell_name number To change the separator character from the default exclamation mark (!), use the -separator option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Displaying ECO Shapes in the GUI"}, {"role": "assistant", "content": "When analysis is complete, the tool saves the design data and analysis results (*.result) in the in-design.redhawk/ design_name.result directory under the RedHawk working directory.\n You must run the open_rail_result command to load the analysis results before displaying a map in the Fusion Compiler GUI.\n Table 70 lists the map types that are supported in the RedHawk Fusion analysis flow.\n Table 70 Analysis Maps Supported in RedHawk Fusion Flow Map Type Description       Note:                                Table 70 Analysis Maps Supported in RedHawk Fusion Flow (Continued) Map Type Description                      To display maps in the Fusion Compiler GUI, 1.\n To load the rail analysis result using the GUI, choose Task > Rail Analysis > 2D Rail Analysis.\n The Block Level 2D Rail Analysis window appears.\n In the window, click the open_rail_result link.\n Alternatively, run the open_rail_result command to load the design data and analysis results (*.result) saved in the design_name directory under the RedHawk working directory when analysis is complete.\n 2.\n In the GUI layout window, choose View > Map and select the map to display.\n In the map, problem areas are highlighted in different colors.\n Move the pointer over an instance to view more information in the InfoTip.\n By default, the tool displays information for all instances in the block.\n To examine information of one specific instance, deselect all the instances and then select the instance to display from the list.\n Use the options in the map panel to change map display:  Value: Sets the type of map to display  Bins: Changes the number of unique bins used to display the map  From: and To: Sets the range of density values displayed in the power density map  Text: Displays the calculated values in the layout; if the values are not visible, zoom in to view them       Examples The following examples show how to display various types of maps in the GUI:  shows how to display a rail instance effective voltage drop map and check for hotspots in the instance effective voltage drop map.\n  shows how to display a rail map for the switch cells in the block and examine the voltage information of the selected switch cell.\n  shows how to display a power density map for the block.\n        Displaying a Rail Instance Effective Voltage Drop Map Hover over the red spot to see the voltage drop number on the instance Select the instance to display Choose Rail Instance Effective Voltage Drop Click \"Zoom to Critical\" to examine the critical area Histogram for the range of map values (in volts) Options for map display control        Displaying Maps for Switch Cells Choose Rail Instance Switch Cell.\n Select the instance to Choose the type of map to display The tool shows the switch cells display on the selected power domain in the map.\n In the map, hover over a switch cell to examine its voltage information        Displaying a Power Density Map Choose Rail Power Choose Density to display power density values See Also  Specifying RedHawk and RedHawk-SC Working Directories"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Voltage Areas"}, {"role": "assistant", "content": "A floating logical supply net is a power or ground net that is not connected to any logical pin or port in the block.\n For example, a power feedthrough net created during power planning is a floating supply net.\n To create a floating supply net with the connect_pg_net command, use the following steps: 1.\n Specify the supply net type in the UPF file by using the supply_net_pg_type attribute, as shown in the following UPF file example:  create_supply_net VDD   set_design_attributes -elements VDD \\ -attribute supply_net_pg_type power  2.\n Enable floating supply nets by setting the mv.pg.create_floating_pg application option to true before you create supply nets with the connect_pg_net command, as shown in the following script example:   # Apply the UPF load_upf $upf_input_file_name commit_upf   # create logical supply nets set_app_options -as_user_default \\ -name mv.pg.create_floating_pg -value true connect_pg_net -automatic  check_mv_design The tool creates the logical supply nets in the topmost hierarchy of the current UPF scope for domain-independent supply nets.\n For domain-dependent supply nets, the tool creates the logical supply nets in the topmost hierarchy of the domain.\n The tool does not create a logical supply net in the following situations:  There is a conflict between the connection and the supply net type specified with the supply_net_pg_type attribute.\n  The supply net is connected to a PG pin of an instance.\n  The connect_pg_net command is not specified in the current or parent physical hierarchy."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock-Gating Enable Source Selection"}, {"role": "assistant", "content": "You can enable or disable clock gating on certain design objects by overriding all necessary conditions set by the clock-gating style.\n The set_clock_gating_objects command specifies the design objects on which clock gating should be enabled or disabled during the compile_fusion command.\n The following example excludes all registers in the subdesign ADDER, except the out1_reg bank.\n The out1_reg bank is clock gated according to the specified clock-gating style: fc_shell> set_clock_gating_objects -exclude ADDER \\ -include ADDER/out1_reg[*]       The following example sets and then removes the inclusion and exclusion criteria specified by the -include -exclude, and -clear options: fc_shell> set_clock_gating_objects -include ADDER/out1_reg[*] \\ -exclude ADDER/out2_reg[*] fc_shell> set_clock_gating_objects \\ -clear {ADDER/out1_reg[*] ADDER/out2_reg[*]}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Identifying the Clock Endpoints"}, {"role": "assistant", "content": "The Fusion Compiler tool uses the clock sources defined by the create_clock command, which can be either input ports or internal hierarchical pins, as the clock roots.\n For nested clock trees with generated clocks, which are defined by the create_generated_clock command, the tool considers the master-clock source to be the clock root, and the clock endpoints of the nested clock tree are considered endpoints of the master-clock source.\n For example, for the netlist shown in, the tool considers the CLK port to be the clock root for the genclk1 generated clock.\n        Nested Clock Tree With a Generated Clock   CLK QN clk1 genclk1 If the block contains generated clocks, ensure that the master-clock sources are correctly defined, as incorrect definitions can result in poor skew and timing QoR.\n In particular,  If the tool cannot trace back to the master-clock source, it cannot balance the sink pins of the generated clock with the sink pins of its source.\n  If the master-clock source is not a clock source defined by the create_clock or create_generated_clock command, the tool cannot synthesize a clock tree for the generated clock or its source.\n Use the check_clock_trees command to verify that your master-clock sources are correctly defined, as described in Verifying the Clock Trees Specifying the Clock Root Timing Characteristics To get realistic clock tree synthesis results, you must ensure that the timing characteristics of the clock roots are correctly modeled.\n  If the clock root is an input port without an I/O pad cell, you must accurately specify the driving cell of the input port.\n If you specify a weak driving cell, the tool might insert extra buffers to try to meet the clock tree design rule constraints, such as maximum transition time and maximum capacitance.\n If you do not specify a driving cell (or drive strength), the tool assumes that the port has infinite drive strength.\n For example, if the CLK1 port is the root of the CLK1 clock tree, use the following command to set its driving cell as the CLKBUF cell in the mylib cell library: fc_shell> set_driving_cell -lib_cell mylib/CLKBUF [get_ports CLK1]  If the clock root is an input port with an I/O pad cell, you must accurately specify the input transition time of the input port.\n       For example, if the CLK1 port is the root of the CLK1 clock tree and the I/O pad cell has already been inserted, use the following commands to set its input transition time to 0.3 for rising delays and 0.2 for falling delays: fc_shell> set_input_transition -rise 0.3 [get_ports CLK1] fc_shell> set_input_transition -fall 0.2 [get_ports CLK1]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Advanced Logic Restructuring"}, {"role": "assistant", "content": "For designs that cannot be legalized due to areas of high utilization, you can specify that the tool perform area recovery in regions where the utilization is high by setting the opt.common.small_region_area_recovery application option to true When you enable this feature, the tool performs the area recovery during the compile_fusion and clock_opt commands.\n However, doing so can slightly degrade the timing QoR."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Cross-Probing Information for Optimized Registers"}, {"role": "assistant", "content": "To optimize the design by reducing area, the tool can automatically detect and remove constant registers and unloaded registers.\n You can control this behavior as described in the following topics: Removing Constant Registers Certain registers in a design might never change state because they have constant values on one or more input pins.\n These constant values can either be directly at the input or result from the optimization of fanin logic that eventually leads to a constant input of the register.\n Eliminating such registers can improve area significantly.\n By default, the compile_fusion command removes constant registers and prints an information message in the compile log file.\n This table lists cases in which a sequential element can be eliminated.\n Type of register Data Preset Reset                          Type of register Data Preset Reset           To disable constant register removal for the entire block you are synthesizing, set the compile.seqmap.remove_constant_registers application option to false, changing it from its default of true.\n To control constant register removal for a specific cell or module, use the set_constant_register_removal command.\n For example, the following settings prevent the tool from removing the constant register named reg11: fc_shell> set_constant_register_removal reg11 false The following settings globally disables constant register removal for the entire block except for the module named sub5 : fc_shell> set_app_option -name compile.seqmap.remove_constant_registers -value false  fc_shell> set_constant_register_removal [get_module sub5] true Information about removed constant registers is written to the verification guidance.svf file and the compile log file.\n To report the constant registers removed during compile, use the report_constant_registers command.\n Removing Unloaded Registers During optimization, the tool deletes registers with outputs that do not drive any load.\n The combinational logic cone associated with the input of the register can also be deleted if the cell is not used in the design.\n Register outputs can become unloaded because of redundancy in the circuit or as a result of constant propagation.\n In some designs where the registers have been instantiated, the outputs might already be unloaded.\n By default, the compile_fusion command removes unloaded registers in the design and prints an information message in the compile log file.\n To disable this capability for the block you are synthesizing, set the compile.seqmap.remove_unloaded_registers application option to false, changing it from its default of true.\n To control unloaded register removal for a specific cell or module, use the set_unloaded_register_removal command.\n       For example, the following settings prevent the tool from removing the unloaded register named reg22: fc_shell> set_unloaded_register_removal reg22 false The following settings globally disables unloaded register removal for the entire block except for the module named sub5 : fc_shell> set_app_option -name compile.seqmap.remove_unloaded_registers -value false  fc_shell> set_unloaded_register_removal [get_module sub5] true To report the unloaded registers that were removed during compile, use the report_unloaded_registers command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Clock Trees"}, {"role": "assistant", "content": "To prevent the Fusion Compiler tool from modifying them, you can mark existing clock trees in your design as synthesized clock tree by using the mark_clock_trees command as shown in Table 27 Table 27 Using the mark_clock_trees Command To do this Use this option   create_clock create_generated_clock  -clocks clock_list   -synthesized   -clear dont_touch   -dont_touch dont_touch   -clear -dont_touch  set_clock_routing_rules  -routing_rules  set_clock_cell_spacing  -clock_cell_spacing  -fix_sinks  -freeze_routing The tool traverses the clock trees and marks the clock trees as specified.\n Clock tree traversal continues until it finds an exception pin or a default sink pin."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Tracing Minimum Path Resistance Using the Mouse Tool"}, {"role": "assistant", "content": "When the analysis is complete, run the report_rail_result -type minimum_path_resistance command to display a minimum path resistance map, write the results to an output file, or query the attributes on the cell instances or pins.\n The following example writes the calculated minimum path resistances for the VDD net to an output file called minres.rpt.\n fc_shell> open_rail_result fc_shell> report_rail_result -type minimum_path_resistance \\ -supply_nets { vdd } minres.rpt fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669 The output minres.rpt report includes the entire resistance information.\n fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669       To write out a detailed minimum resistance path report for a cell instance, run the report_rail_minimum_path command and specify the net and the cell to report.\n To see the segment-by-segment resistance of that minimum resistance path shown in the GUI, use the -error_cell option of the report_rail_minimum_path command to save the geometries on the path of the minimum path resistance to an error cell.\n You can then open the error cell in an error browser and check the minimum resistance path from the pin of the cell to the nearest tap and trace each go-through geometries.\n In the following example, all geometries on the minimum resistance path are traced and written to the error cell named test.err.\n fc_shell> open_rail_result fc_shell> report_rail_minimum_path -cell U19 -net VDD -error_cell Shown in, each geometry is classified by layer in the error browser.\n Click a geometry to check for detailed information, such as IR drop, resistance, bounding box, and so on.\n In the GUI, the traced path is highlighted in yellow in the design layout (see ).\n  Displaying Error Cells in the Error Browser        Traced Segment is Highlighted in the Design Layout See Also  Displaying Maps in the GUI  Writing Analysis and Checking Reports  Querying Attributes"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using the Global Router During Initial Clock Tree Synthesis"}, {"role": "assistant", "content": "You can specify a name prefix for the cells added on the clock network during clock tree synthesis by using the cts.common.user_instance_name_prefix application option.\n The following example specifies CTS_ as the name prefix for the cells added on the clock network during clock tree synthesis: fc_shell> set_app_options \\ -name cts.common.user_instance_name_prefix -value \"CTS_\" To specify a name prefix for the cells added on the data nets during optimization, including during the clock_opt command, use the opt.common.user_instance_name_prefix application option, as described in Specifying a Cell Name Prefix for Optimization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generic ECO Flow for Timing or Functional Changes"}, {"role": "assistant", "content": "An engineering change order (ECO) is an incremental change made to a complete or nearly complete design.\n You can use ECOs to fix functional, timing, noise, and crosstalk violations without synthesizing, placing and routing the entire design.\n You can also use ECOs to implement late-arriving design changes while maintaining design performance.\n The following topics describe the various ECO flows supported in the Fusion Compiler tool, and tasks you perform in these flows:  Generic ECO Flow for Timing or Functional Changes  Freeze Silicon ECO Flow  Signoff ECO Flow  Incremental Signoff ECO Flow  ECO Fusion Flow  ECO Fusion Power Integrity Flow  Manually Instantiating Spare Cells  Automatically Adding Spare Cells  Adding Programmable Spare Cells  Making ECO Changes Using the eco_netlist Command  Making ECO Changes Using Netlist Editing Commands  Resizing Cells  Adding Buffers on Nets  Adding Buffers on Routed Nets  Optimizing the Fanout of a Net  Reporting Available Sites for Placing ECO Cells  Identifying and Reverting Nonoptimal ECO Changes  Placing ECO Cells        Placing and Mapping ECO Cells to Spare Cells  Updating Supply Nets for ECO Cells  Recording the Changes Made to a Layout  Performing Prerequisite Check for Group Repeater Insertion and Placement  Adding a Group of Repeaters  Querying Group Repeater  Swapping Variant Cell  Fixing Multivoltage Violations"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Adding Cells Within a Predefined Relative Placement Area"}, {"role": "assistant", "content": "To add a blockage within relative placement groups, use the -blockage option with the add_to_rp_group command.\n When you add a blockage using this command, you can specify  The column and row position within the relative placement group by using the -column and -row options.\n If you do not specify a position, the tool adds the blockage to position (0,0).\n  The size of the blockage by using the -height and -width options.\n If you do not specify the -height or -width option, the tool determines the size based on the tiling type of the relative placement group as follows:  For a tiling type setting of bit_slice, the height default to the height of site row and the width to width of the column.\n  For a tiling type setting of compression, the height default to the height of site row and the width to the width of one site.\n  That the blockages can overlap with other relative placement blockages or other objects that are not relative placement cells by using the -allow_overlap option.\n The following example adds a blockage named gap1 to the rp1 relative placement group at position (0,2) that is one site row high and five site rows wide: fc_shell> add_to_rp_group rp1-blockage gap1 \\ -column 0 -row 2 -width 5 -height 1"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Redundant Vias"}, {"role": "assistant", "content": "You can fix antenna violations after detail routing by explicitly specifying which violations to fix and providing constraints for fixing them.\n Based on the specified constraints and the setting of the route.detail.diode_insertion_mode application option, Zroute either inserts new diodes or reuses existing spare diodes to fix the specified violations.\n To insert diodes after detail routing, use the create_diodes command.\n When you use this command, you must use the -options option to specify the location of each antenna violation to fix by specifying the port and cell instance, the reference cell for the diode, the number of diodes to insert, the highest allowed routing layer used for connecting the diode, and the maximum distance from the specified pin that the diode can be inserted.\n If a diode cannot be inserted or reused within the specified distance, the tool does not insert a diode for that violation.\n Use the following format to specify these values: port_name instance_name diode_reference number_of_diodes max_routing_layer max_routing_distance Note: You can use this command to insert diodes for top-level ports by specifying the name of the top-level block for the cell instance.\n       The create_diodes command uses the following application options to control diode insertion:  To control whether Zroute inserts new diodes or reuses spare diodes, set the route.detail.diode_insertion_mode application option.\n  To control whether Zroute can reuse filler cell locations, set the route.detail.reuse_filler_locations_for_diodes application option.\n  To specify the logic hierarchy in which to insert the diodes for top-level ports, set the route.detail.use_lower_hierarchy_for_port_diodes application option.\n For example, to insert 2 Adiode diode cells to fix an antenna violation on the A port of the CI cell instance, where the diodes must be inserted using no higher layer than M5 and within 2.5 microns of the port, enter the following command: fc_shell> create_diodes {{A CI Adiode 2 M5 2.5}}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Abutting Standard Cells With Specific Filler Cells"}, {"role": "assistant", "content": "a single constrained cell group, use the -constraint_fillers option.\n To specify the replacement cells, use the -non_constraint_fillers option.\n Note: If you use both methods, the command uses only the information specified in the -refill_table option.\n For example, the following command identifies and fixes maximum horizontal length violations where the horizontal length exceeds 70 um: fc_shell> replace_fillers_by_rules \\ -replacement_rule od_horiztonal_distance -max_constraint_length 70 \\ -refill_table { {{VT1_FILL1} {VT1_DECAP4 VT1_DECAP2}} {{VT2_FILL1} {VT2_DECAP4 VT2_DECAP2}} }  shows the original row, which violates this rule, and the resulting row, which uses unconstrained filler cells to fix the violation.\n The constrained cells are shown in red, while the unconstrained cells are shown in green.\n        Fixing a Maximum Vertical Edge Length Violation Maximum Stacking for Small Filler Cells Rule The maximum stacking for small filler cells rule restricts the stacking height of small filler cells.\n To select this rule, use the -replacement_rule small_filler_stacking option with the replace_fillers_by_rules command.\n When you select this rule, you must specify  The maximum stacking height To specify the maximum stacking height, use the -max_constraint_length option.\n  The cells considered for the check To specify the small filler cells to consider for the check, use the -small_fillers option.\n  The filler cells that can be used to replace the violating filler cells To specify the filler cells that can be used to replace the violating filler cells, use the -replacement_fillers option.\n If the vertical stacking of the small filler cells specified in the -small_fillers option exceeds the height specified in the -max_constraint_length option, the command replaces two or three consecutive filler cells adjacent to the violating cell with one of the large filler cells specified in the -replacement_fillers option.\n If it is not possible to replace the filler cells, the command reorders the filler cells to fix the violation.\n The command maintains the threshold voltage at the location of the violating filler cell; however, the threshold voltage at the location of non-violating filler cells might change.\n The command does not check for threshold voltage violations caused by these changes.\n       For example, the following command identifies and fixes maximum stacking violations where the stacking height exceeds 10 um: fc_shell> replace_fillers_by_rules \\ -replacement_rule small_filler_stacking -max_constraint_length 10 \\ -small_fillers {FILL1 FILL2} -replacement_fillers {FILL3 FILL4} \\ The following figures illustrate the replacement and reordering techniques used to fix maximum stacking violations.\n In these figures, the small filler cells are shown in red, while the large filler cells are shown in green.\n  shows the original stack, which violates this rule, and the resulting stack, which uses a replacement filler cell to fix the violation.\n  Fixing Maximum Stacking Violation by Replacement FILL1  vt1 FILL3 vt1 FILL1  vt1 FILL2  vt1 FILL1  vt1 FILL1  vt1 FILL1  vt1 10um FILL2  vt1  shows the original stack, which violates this rule, and the resulting stack, which uses reordering to fix the violation.\n Note that the threshold voltage of the FILL3 cell is changed so that the vt2 threshold voltage is maintained in the original location.\n  Fixing Maximum Stacking Violation by Reordering FILL1  vt1 FILL1  vt1 FILL2  vt1 10um FILL2  vt1 FILL3 vt1 FILL3 vt2 FILL2  vt2 FILL2  vt2       Maximum Vertical Edge Length Rule The maximum vertical edge length rule restricts the vertical length of a stack of certain filler cells and standard cells.\n To select this rule, use the -replacement_rule max_vertical_constraint option with the replace_fillers_by_rules command.\n When you select this rule, you must specify  The maximum vertical length To specify the maximum vertical length, use the -max_constraint_length option.\n  The cells considered for the check These cells are called constrained cells.\n To specify the constrained filler cells, use the -constraint_fillers option.\n By default, all standard cells are constrained.\n To exclude specific standard cells from consideration, use the -exception_cells option.\n To ignore the length violation when a constrained cell abuts an exception cell, use the -no_violation_along_exception_cells option.\n  The filler cells that can be used to replace the violating filler cells These filler cells are called unconstrained cells ; they are not considered when measuring the stack height.\n  To specify the filler cells that can be used to break a continuous edge of constrained cells, use the -non_constraint_fillers option.\n  To specify the filler cells whose left side can be used to break a continuous edge of constrained cells, use the -non_constraint_left_fillers option.\n  To specify the filler cells whose right side can be used to break a continuous edge of constrained cells, use the -non_constraint_right_fillers option.\n Note: Any filler cells that are not identified as constrained, unconstrained, or exception cells are considered constrained cells.\n For example, the following command identifies and fixes maximum vertical edge length violations where the vertical length exceeds 180 um: fc_shell> replace_fillers_by_rules \\ -replacement_rule max_vertical_constraint -max_constraint_length 180 \\ -constraint_fillers {DECAP8 DECAP4} -non_constraint_fillers {FILL1} \\ -exception_cells {BUF1 TAP1}  shows the original stack, which violates this rule, and the resulting stack, which uses unconstrained filler cells to fix the violation.\n The constrained cells are shown in red, while the unconstrained cells are shown in green.\n        Fixing a Maximum Vertical Edge Length Violation Tap Cell Spacing Rule The tap cell spacing rule restricts the distance between a target tap cell's oxide diffusion (OD) layer and the OD layers of its neighboring cells on the left and right sides.\n To select this rule, use the -replacement_rule od_tap_distance option with the replace_fillers_by_rules command.\n When you select this rule, you must specify  The disallowed spacing range The spacing distance is specified as the number of sites.\n To specify the disallowed spacing range, use the -tap_distance_range option.\n  The tap cells considered for the check These cells are called target cells.\n To specify the target tap cells, use the -tap_cells option.\n  The tap cells used to replace the violating tap cells These cells are called replacement cells  To specify the replacement tap cell for left-side violations, use the -left_violation_tap option.\n  To specify the replacement tap cell for right-side violations, use the -right_violation_tap option.\n  To specify the replacement tap cell for both-side violations, use the -both_violation_tap option.\n Note: The target and replacement tap cells must all have the same size.\n       By default, the command measures the distance to the cells that abut the target tap cell.\n If the tap cells abut library cells that do not have an OD layer, use the -adjacent_non_od_cells option to specify these library cells.\n The command skips the specified non-OD cells and measures to distance from the target tap cell to the first neighbor with an OD layer.\n For example, the following command replaces tap cells named TAP that have a separation distance of three sites: fc_shell> replace_fillers_by_rules -replacement_rule od_tap_distance \\ -tap_cells {TAP} -tap_distance_range {3 3} \\ -left_violation_tap {TAPl} -right_violation_tap {TAPr} \\ -both_violation_tap {TAPb}  shows the original row, which violates this rule, and the resulting row, which uses the replacement filler cells to fix the violations.\n The target filler cells are shown in red, while the replacement filler cells are shown in green.\n  Fixing a Tap Cell Spacing Violation Random Filler Cell Replacement To randomly replace existing filler cells, use the -replacement_rule random option with the replace_fillers_by_rules command.\n When you select this rule, you must specify  The filler cells to be replaced and their replacements The filler cells to be replaced are called target cells.\n To specify the target filler cells and their replacements, use the following syntax with the -random_replace option: { { target_cell refill_cell 1a refill_cell 1b...}}...\n } To ignore filler cells that have a physical_status attribute of fixed or locked"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Placement When Using the place_eco_cells Command"}, {"role": "assistant", "content": "For the unconstrained ECO flow, place the ECO cells by using the place_eco_cells command.\n This command derives the placement of each ECO cell based on the connectivity and the delays associated with the cell.\n The tool then legalizes each ECO cell to the closest unoccupied site.\n The existing cells are untouched to minimize the impact to their placement.\n To place  All unplaced cells, use the -unplaced_cells option.\n  Specific cells, use the -cells option.\n  Only the cells that have changed due to ECO operations, use the -eco_changed_cells option.\n A cell is considered changed if the eco_change_status attribute of the cell has one of the following values:  create_cell  change_link  add_buffer  size_cell When you run the eco_netlist command, the tool automatically sets the eco_change_status attribute on the changed cells.\n If you update the design without using the eco_netlist command, you can manually set the eco_change_status attribute by using the set_attribute command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Optimizing Datapaths"}, {"role": "assistant", "content": "All the extracted datapath elements and the synthetic operators are implemented by the DesignWare datapath generator in Fusion Compiler.\n The DesignWare datapath generator uses the smart generation technology to perform the following tasks:  Implement datapath blocks using context-driven optimizations  Revisit high-level optimization decisions for a given timing context  Consider logic library characteristics Use these commands and application option for datapath implementation:  set_datapath_architecture_options This command controls the strategies used to generate the datapath cells for arithmetic and shift operators.\n The following example specifies to use Booth-encoded architectures to generate multiplexers: fc_shell> set_datapath_architecture_options -booth_encoding true  set_implementation This command specifies the implementation to use for dividers and synthetic library cell instances with a specified name.\n The following example specifies to use the cla3 implementation for the instantiated DesignWare cell U1.\n fc_shell> set_implementation cla3 U1  set_synlib_dont_use       This command prevents using specific implementation.\n The following example specifies not to use the rpl implementation.\n fc_shell> set_synlib_dont_use \\ {dw_foundation/DW_div/cla standard/DW_div/rpl}  compile.datapath.ungroup By default, all DesignWare cells and datapath blocks are ungrouped during timing optimization.\n To disable the ungrouping, set the compile.datapath.ungroup application option to false, changing from its default of true.\n For example, fc_shell> set_app_options \\ -name compile.datapath.ungroup -value false"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Placement-Aware Clock Gating"}, {"role": "assistant", "content": "In the Fusion Compiler flow, clock gating works in conjunction with multibit register mapping.\n The multibit packing ratio has a higher precedence than clock gating.\n The following command enables multibit mapping: fc_shell> set_app_options -name compile.flow.enable_multibit -value true Clock-gating cells are not inserted to gate preinstantiated multibit registers.\n For more information on clock gating reports, see Reporting Clock-Gating Results"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Datapath Implementation"}, {"role": "assistant", "content": "Datapath extraction transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks to be implemented by a datapath generator.\n This transformation improves the quality of results (QoR) by using carry-save arithmetic.\n       Carry-save arithmetic does not fully propagate carries but stores results in an intermediate form.\n The carry-save adders are faster than the conventional carry-propagate adders because the carry-save adder delay is independent of bit-width.\n These adders use significantly less area than carry-propagate adders because they do not use full adders for the carry.\n The following example shows the code for the a * b + c + d = z expression.\n As shown in, the conventional implementation of the expression use three carry-propagate adders, whereas the carry-save arithmetic requires only one carry-propagate adder and two carry-save adders.\n The figure also shows the timing and area numbers for both implementations.\n module dp (a, b, c, d, e); input [15:0] a, b; input [31:0] c, d; output [31:0] Z; assign Z = (a * b) + c + d; endmodule  Conventional Carry-Propagate Adder Versus Carry-Save Adder       The tool supports extraction of the following components:  Arithmetic operators that can be merged into one carry-save arithmetic tree  Operators extracted as part of a datapath: *, +, -, >, <, <=, >=, ==,!=, and MUXes  Variable shift operators (<<, >>, <<<, >>> for Verilog and sll, srl, sla, sra, rol, ror for VHDL)  Operations with bit truncation The datapath flow can extract these components only if they are directly connected to each other, that is, no nonarithmetic logic between components.\n Keep the following points in mind:  Extraction of mixed signed and unsigned operators is allowed only for adder trees  Instantiated DesignWare components cannot be extracted"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing With the Custom Router"}, {"role": "assistant", "content": "You use the custom.route.balance_mode application option in interposer designs to reduce the skews caused by wire length and via cut count differences.\n This topic describes how to set the custom.route.balance_mode application option and provides examples to demonstrate its use.\n To route using the balance mode: Set the custom.route.balance_mode application option to true.\n set_app_options -name custom.route.balance_mode -value true When custom.route.balance_mode is true:  The Custom Router creates feedthrough routes between two \u03bcbumps and a C4 bump on the same net.\n  The wire lengths between the \u03bcbumps and the C4 bump are equal.\n  The number of via cuts is the same in all related \u03bcbump-C4 bump connections.\n Example 1 shows how the custom.route.balance_mode option is used when routing \u03bcbumps to a C4 bump.\n The designated routing layers are M1 through M5.\n The M2 and M4       layers are used for horizontal connections; and the M1, M3, and M5 layers are used for vertical connections.\n The number of via cuts and the array dimensions are also defined.\n Example 42 Routing with custom.route.balance_mode turned on create_routing_rule skew -widths {M1 6 M2 6 M3 6 M4 6 M5 25} -vias {{VIA12_1cut 3x3 R} {VIA23_1cut 3x3 R} {VIA34_1cut 3x3 R} {VIA45_1cut 2x5 R}} set_routing_rule $nets_to_route -rule skew -max_routing_layer M5 -min_routing_layer M1 set_attribute [get_layers \"M2 M4\"] routing_direction horizontal set_attribute [get_layers \"M1 M3 M5\"] routing_direction vertical set_ignored_layers -min_routing_layer M1 -max_routing_layer M5 set_app_options -list {custom.route.balance_mode true} route_custom -nets $nets_to_route The results from the example show that the wire lengths and the number of vias are the same in each of the four \u03bcbump-to-C4 bump connections."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock-Gate Multilevel Expansion"}, {"role": "assistant", "content": "The number of clock-gate levels is the count of clock gates between a clock source and a register.\n Standard clock-gate insertion provides one level of clock-gate insertion.\n However, designs often contain preexisting clock gates, in which case the design might contain multiple levels of clock gates.\n       You can modify the default clock-gate insertion operation by allowing additional levels of clock gating, by limiting the number of clock-gate levels, or both."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Routing Secondary Power and Ground Pins"}, {"role": "assistant", "content": "To route a group of critical nets before routing the rest of the nets in the block, use the route_group command.\n To specify the nets to route, use one of the following options:  -nets Use this option to specify the nets on the command line: fc_shell> route_group -nets collection_of_critical_nets  -from_file Use this option to specify the nets in a file: fc_shell> route_group -from_file file_name If the specified nets are associated with a routing corridor, the nets are routed within the defined region.\n Note that global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations.\n By default, the route_group command ignores existing global routes, reuses dangling wires and existing detail routes on the specified nets, and runs global routing, track assignment, and detail routing on the specified nets.\n  To perform incremental global routing, set the -reuse_existing_global_route option to true Note: You cannot use the -reuse_existing_global_route true option when routing the nets in a routing corridor.\n If you use this option, the global router ignores the routing corridors.\n  To disable the reuse of dangling wires, set the -utilize_dangling_wires option to false  To stop after global routing, set the -stop_after_global_route option to true By default, the detail router performs a maximum of 40 iterations search and repair iterations.\n If Zroute determines before then that all violations have been fixed or that it cannot fix the remaining violations, it stops.\n To change the maximum number of detail routing iterations, use the -max_detail_route_iterations option.\n By default, the route_group command does not fix soft DRC violations, such as bridge rule violations.\n To enable the fixing of soft DRC violations after the final detail routing       iteration, set the route.common.post_group_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_group_route_fix_soft_violations \\ -value true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Diodes After Detail Routing"}, {"role": "assistant", "content": "One way to protect gates from antenna effects is to provide a discharge path for the accumulated charge to leave the net.\n However, the discharge path should not allow current to flow during normal chip operation.\n Discharging can be accomplished by inserting a reverse-biased diode on the net close to the gate that is being protected.\n To enable diode insertion during detail routing, set the route.detail.insert_diodes_during_routing application option to true To control diode insertion, set the following application options:  To specify a preference for fixing antenna violations by using diode insertion rather than layer hopping, set the route.detail.antenna_fixing_preference application option to use_diodes  To require fixing of antenna violations by using diode insertion, disable layer hopping by setting the route.detail.hop_layers_to_fix_antenna application option to false  By default, when you enable diode insertion, Zroute can fix an antenna violation either by adding a new diode or by using an existing spare diode.\n Zroute determines which method to use, based on which is closest to the required location: an empty location for a new diode or an existing spare diode.\n  To specify a preference for using a new diode or using an existing spare diode, set the route.detail.diode_preference application option to new or spare respectively.\n To reset the diode preference to the default behavior, set the route.detail.diode_preference application option to none  If you want Zroute to use only one of these methods, set the route.detail.diode_insertion_mode application option to new to force the insertion of new diodes or to spare to force the use of existing spare diodes.\n To reset the diode insertion method to the default behavior, set the route.detail.diode_insertion_mode application option to new_and_spare Note: To take advantage of spare diodes for antenna violation fixing, you need to add the spare diodes either before or after standard-cell placement and before routing the areas where antenna violations might occur.\n  When inserting new diodes, Zroute selects the diodes from the reference libraries and inserts them into existing open spaces.\n To control which diodes are used, set the route.detail.diode_libcell_names application option.\n When you specify the diode library cells, use only the cell names.\n If you include the library name, the tool does not recognize the diode cells.\n        By default, Zroute reuses existing filler cell locations for diode insertion.\n To prevent Zroute from reusing these locations, set the route.detail.reuse_filler_locations_for_diodes application option to false Zroute considers voltage areas when inserting diode cells and also observes the logic hierarchy assignments for diode cells.\n  If a pin has an antenna violation, the diode cells are inserted at the same level of logic hierarchy as the violating pin.\n  If a top-level port has an antenna violation, by default, the diode cells are inserted at the top level.\n However, if the port belongs to a voltage area, you can insert the diode cells in the logic hierarchy associated with the voltage area by setting the route.detail.use_lower_hierarchy_for_port_diodes application option to true To remove the redundant diodes during routing, set the route.detail.delete_redundant_diodes_during_routing application option to true"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining a Customized Via Mapping Table"}, {"role": "assistant", "content": "By default, Zroute reads the default contact codes from the technology file and generates an optimized via mapping table.\n To see the default mapping table, use the add_redundant_vias -list_only true command.\n In most cases you achieve better results if you use a customized mapping table rather than the default mapping table.\n For information about defining a customized mapping table, see Defining a Customized Via Mapping Table If you have not previously defined a customized mapping table for the block, you can see the default mapping table by using the add_redundant_vias -list_only true command.\n Note: After you have created a customized mapping table by using the method described in Defining a Customized Via Mapping Table, this command shows the customized mapping table.\n       Example 27 shows an example of a default via mapping table.\n Example 27 Default Via Mapping Table fc_shell> add_redundant_vias -list_only...\n Redundant via optimization will attempt to replace the following vias:  VIA12SQ_C -> VIA12SQ_C_2x1 VIA12SQ_C_2x1(r) VIA12SQ_C_1x2 VIA12SQ_ C_1x2(r) VIA12SQ_C(r) -> VIA12SQ_C_2x1 VIA12SQ_C_2x1(r) VIA12SQ_C_1x2 VIA12SQ_ C_1x2(r)...\n VIA89(r) -> VIA89_C_1x2(r) VIA89_1x2(r) VIA89_1x2 VIA89_C_1x2 VIA89_C_2x1(r) VIA89_2x1(r) VIA89_2x1 VIA89_C_2x1 VIA9RDL -> VIA9RDL_2x1 VIA9RDL_1x2"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Querying Group Repeater"}, {"role": "assistant", "content": "To remove a group of repeaters, use the remove_eco_repeater command.\n The nets are restored to their original names and routes shapes."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Physical Constraints for Placement and Legalization"}, {"role": "assistant", "content": "By default, the tool identifies preexisting clock-gating cells during the execution of the analyze and elaborate commands.\n During compile, the tool inserts one more level of clock-gating cells at the leaf level and implements clock-gating logic using the default       clock-gating settings if you do not specify any clock-gating constraints.\n You cannot disable clock gating.\n Before you set up clock-gating constraints, load your design and libraries in memory and then use the following commands to set up the constraints:  The set_clock_gate_style command To select the type of integrated clock-gating cell, specify the following options: Option Description -test_point  none before after -observation_output  -target  pos_edge_flip_flop neg_edge_flip_flop -objects   The set_clock_gating_options command To define the netlist structure of the inserted clock-gating cells, specify the following options: Option Description minimum_bitwidth   max_fanout    The set_clock_gating_objects command To control clock gating for specified objects and override the default clock-gating behavior that is set during compile, specify the following options.\n An object can be a hierarchical cell, register, power domain, or module.\n Option Description -include   -exclude        Option Description -clear   -reset  set_clock_gating_objects   The default During clock-gating optimization, the tool uses the following setup defaults: Setup Default         For more information, see Setting Up Clock Gating"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Making Changes to a Block After Creating an Abstract"}, {"role": "assistant", "content": "In the Fusion Compiler tool, the create_abstract command includes netlist objects such as the cells, nets, and pins in the abstract view at both the top-level and block-level.\n This command reports the reasons for the inclusion of netlist objects.\n       To report the reasons for including specific netlist objects in the abstract view, you can use the report_abstract_inclusion_reason command for objects across all hierarchies in the abstract.\n For each reason reported, a reason code is displayed.\n These reason codes correspond to the valid reasons for inclusion in the abstract.\n There can be multiple reasons for the same netlist object.\n Note: The report_abstract_inclusion_reason command does not report reasons for the hierarchical cells or pins on hierarchical cells.\n You can perform reason reporting from the top-level design, where the abstract is instantiated, without having the abstract as the current block.\n The following example reports the reasons for abstract inclusion for the pins in abstract view: fc_shell> report_abstract_inclusion_reason [get_pins -of_object [get_cells -filter \"is_hierarchical==false\" -hierarchical *]]  Legend mv - MV Logic comp - Compact interface logic cell - Cell inclusion  Pin name Reason(s) for inclusion  AINV_P_260/I comp, cell AINV_P_260/VDD cell AINV_P_260/VSS cell AINV_P_260/ZN comp, cell AINV_P_262/I comp, cell AINV_P_262/VDD cell AINV_P_262/VSS cell AINV_P_262/ZN comp, cell AINV_P_263/I mv, comp, cell A legend is displayed at the beginning of the report for the queried objects, specifying the detailed reason for each reason code."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Cell Spacing Constraints"}, {"role": "assistant", "content": "Cell spacing constraints control the spacing between a standard cell and another standard cell or a boundary (the chip boundary, a hard macro, a hard macro keepout margin, a hard placement blockage, or a voltage area guard band).\n You assign library cells to groups (the boundaries are in a predefined group named SNPS_BOUNDARY), and then define the required spacing between cells in these groups.\n By default, there are no spacing constraints between standard cells during legalization.\n To enhance yield, you can define the valid spacing between standard cells or between a standard cell and a boundary.\n Note: The support for spacing constraints between standard cells and power or ground nets depends on how the net is represented in the block.\n If the power or ground net is defined as a complete blockage, the legalizer and the check_legality command ignore spacing rule violations between standard cells and the power or ground net.\n If the power or ground net is defined as a partial blockage, the legalizer and the check_legality command check for spacing rule violations between standard cells and the power or ground net.\n Cell spacing constraints are implemented by attaching labels, which are similar to attributes, to the left and right sides of library cells, assuming that the cell is in its north orientation, and specifying the invalid spacings between these labels.\n To define cell spacing constraints, 1.\n Add labels to the library cells that have spacing constraints by using the set_placement_spacing_label command.\n You must specify the following information for each label:  The label name (the -name option)  The library cells to which to apply the label (the -lib_cells option)  The sides of the library cells to which to apply the label (the -side option, which can take a value of right left, or both The label definitions are additive; you can specify the same label to be used on the right side of some cells and the left side of other cells.\n For example, to assign a label named X to the right side of the cellA library cell and the left side of the cellB and cellC library cells, use the following commands: fc_shell> set_placement_spacing_label -name X \\ -lib_cells {cellA} -side right       fc_shell> set_placement_spacing_label -name X \\ -lib_cells {cellB cellC} -side left You can assign multiple labels to a side of a library cell.\n For example, to assign labels named Y and Z to the right side of the cellB library cell, use the following commands: fc_shell> set_placement_spacing_label -name Y \\ -lib_cells {cellB} -side right fc_shell> set_placement_spacing_label -name Z \\ -lib_cells {cellB} -side right 2.\n Define the spacing requirements between the labels by using the set_placement_spacing_rule command.\n You must specify the following information for each rule:  The labels being constrained (the -labels option) You must specify exactly two labels in each set_spacing_label_rule comandcomandset_spacing_label_rule set_placement_spacing_rule command.\n You can specify any of the labels defined by the set_placement_spacing_label command or the predefined SNPS_BOUNDARY label, which includes the chip boundary, hard macro boundaries, a hard macro keepout margins, hard placement blockages, and voltage area guard bands.\n The two labels can be the same or different.\n  The range of invalid spacings, in number of unit tiles For example, to specify that there must be at least one unit tile between labels X and Y (they cannot abut), use the following command: fc_shell> set_placement_spacing_rule -labels {X Y} {0 0} To specify that there must be at least one unit tile between X labels and any boundary, use the following command: fc_shell> set_placement_spacing_rule \\ -labels {X SNPS_BOUNDARY} {0 0} To specify that two X labels cannot have a spacing of two unit tiles, use the following command: fc_shell> set_placement_spacing_rule -labels {X X} {2 2} To specify that labels X and Z must have a spacing of less than two unit tiles or more than four unit tiles, use the following command: fc_shell> set_placement_spacing_rule -labels {X Z} {2 4}       Caution: The cell spacing constraints are not saved with the block; they apply only to the current session and must be redefined in each session."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Restricting the Target Libraries Used"}, {"role": "assistant", "content": "To ensure that the tool resize preexisting gates in the clock network during clock tree synthesis and optimization, you must specify equivalent cells as clock references.\n Not specifying a complete list of equivalent cells for preexisting gates can affect clock tree QoR.\n You can automatically derive equivalent cells for all the preexisting clock tree cells and specify them as clock references by using the derive_clock_cell_references command.\n       When you run this command, the tool sets the valid_purpose attribute to true on equivalent library cells of the preexisting clock tree cells that are not buffers or inverters.\n This command does not derive equivalent library cells for preexisting buffers and inverters, Therefore, you must manually specify the buffers and inverters to use for clock tree synthesis, as shown in the following example: fc_shell> set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell> derive_clock_cell_references fc_shell> synthesize_clock_trees Instead of automatically specifying the equivalent library cells of the preexisting clock tree cells as clock tree references, you can generate a Tcl script that specifies the equivalent library cells of the preexisting clock tree cells as clock tree references.\n To do so, use the -output option.\n fc_shell> derive_clock_cell_references -output cts_leq_cells.tcl You can the output file, source it, and then run clock tree synthesis, as shown in the following example: fc_shell> set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell> source cts_leq_cells.tcl fc_shell> synthesize_clock_trees"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Automatically Fixing Double-Patterning Odd-Cycle Violations"}, {"role": "assistant", "content": "By default, the signoff_fix_drc command performs the following tasks: 1.\n Runs the signoff_check_drc command to generate the initial signoff DRC results, as described in Checking for DRC Violations If you have already run the signoff_check_drc command, you can use the existing signoff DRC results instead of rerunning signoff design rule checking.\n To reuse the existing results, specify the directory that contains the results by setting the signoff.fix_drc.init_drc_error_db application option.\n You can specify either a relative path or an absolute path.\n If you specify a relative path, it is relative to the current working directory.\n For example, to use the results from the default signoff_check_drc run directory, use the following commands: fc_shell> set_app_options \\ -name signoff.fix_drc.init_drc_error_db \\ -value signoff_check_drc_run fc_shell> signoff_fix_drc Note: To use existing signoff DRC results as input to the signoff_fix_drc command, you must use the signoff DRC application options described in Generating Input for the Automatic Fixing Flow 2.\n Runs two repair loops to fix the DRC violations In each repair loop, the signoff_fix_drc command performs the following tasks; a.\n Tries to fix the DRC violations detected in the previous IC Validator signoff DRC run, as described in Fixing DRC Violations b.\n Runs IC Validator signoff design rule checking on the modified block, as described in Checking for DRC Violations To change the number of repair loops, use the -max_number_repair_loop option; you can specify an integer between 1 and 10.\n If no signoff DRC violations remain after a loop, the tool does not perform additional repair loops.\n As the repair loop number increases, so does the physical scope of the rerouting performed by that repair loop.\n To change the scope, increase the number of the initial repair loop by using the -start_repair_loop option.\n Note that increasing the initial loop number might cause a greater disturbance to the block, which would require additional design rule checking and fixing by Zroute.\n       3.\n Writes a summary report of the results For information about the summary report, see Summary Report for Automatic Design Rule Fixing Fixing DRC Violations In each repair loop, the signoff_fix_drc command tries to fix the DRC violations detected in the previous signoff DRC run.\n  For the first loop, the tool uses the IC Validator data in the directory specified by the signoff.fix_drc.init_drc_error_db application option (or the signoff_drc_run_init directory if you do not use this option).\n  For successive loops, the tool uses the IC Validator DRC data from the previous loop, which is stored in the directory specified by the signoff.fix_drc.run_dir application option (or the signoff_fix_drc_run directory if you do not use this option).\n When fixing DRC violations, the signoff_fix_drc command has the following default behavior:  Tries to fix all design rule violations detected in the previous signoff DRC run except those design rules that have more than 1000 violations  Performs DRC fixing on data nets for the whole block To modify the regions for design rule fixing, use one or both of the following options:  -coordinates This option restricts design rule fixing to the specified regions.\n  -excluded_coordinates This option prevents design rule fixing in the specified regions.\n If you specify this option with the -coordinates option, the command does not fix design rules in the overlapping regions.\n To specify the coordinates, use the following format: {{x } {x }...\n {x }} Note that there must be a space between each set of coordinates.\n       To prevent fixes that might impact timing-critical nets, use one or both of the following options:  -nets This option explicitly specifies the critical nets.\n  -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold.\n The unit for the slack threshold setting is the library time unit.\n  Performs five iterations of detail routing after DRC fixing to fix any DRC violations introduced during DRC fixing  Saves the modified block in a design view named block _ADR_# To change the default behavior, use the following options:  signoff.fix_drc.max_errors_per_rule This application option specifies the error threshold for ignoring a design rule.\n  signoff.fix_drc.fix_detail_route_drc This application option controls the scope of DRC fixing.\n To reduce runtime by performing DRC fixing only in areas near the signoff DRC violations, set this application option to local  signoff.fix_drc.target_clock_nets This application option controls whether DRC fixing targets data nets or clock nets.\n To target clock nets, set this application option to true  signoff.fix_drc.max_detail_route_iterations This application option specifies the number of detail routing iterations; you can specify an integer between 0 and 1000.\n Checking for DRC Violations When performing signoff design rule checking, the signoff_fix_drc command has the following default behavior:  Reads the design view for the top-level block and library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances For information about changing the view used for specific cells, see Reading Blocks for Signoff Design Rule Checking  After the initial run, performs design rule checking only on those portions of the design affected by design rule fixing       To perform signoff design rule checking on the entire block for the last repair loop, set the signoff.fix_drc.last_run_full_chip application option to true.\n Setting this option to true increases accuracy but also increases runtime.\n To perform signoff design rule checking on the entire block for all repair loops, set the signoff.fix_drc.check_drc application option to global.\n Setting this option to global increases accuracy but can greatly increase runtime.\n  Does not check for violations in child blocks  Excludes rules that are not suitable for automatic design rule fixing To explicitly specify the design rules checked by the IC Validator tool, set the -select_rules rules and -unselect_rules rules application options.\n  Stores the IC Validator results in the signoff_fix_drc_run directory To use a different run directory, set the signoff.fix_drc.run_dir application option.\n Note: The IC Validator results for the initial signoff DRC run are stored in the signoff_drc_run_init directory.\n In addition, you can specify options to add to the IC Validator command line by setting the signoff.fix_drc.user_defined_options application option.\n See Also  Performing Signoff Design Rule Checking"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating a Congestion Report"}, {"role": "assistant", "content": "You can analyze the routing results by reporting on the cell placement and routing statistics.\n The following topics describe how to perform these tasks:  Generating a Congestion Report  Generating a Congestion Map  Performing Design Rule Checking Using Zroute  Performing Signoff Design Rule Checking  Performing Design Rule Checking in an External Tool  Performing Layout-Versus-Schematic Checking  Reporting the Routing Results  Reporting the Wire Length  Using the DRC Query Commands"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Commands and Examples"}, {"role": "assistant", "content": "Use the reports generated by Fusion Compiler to analyze and debug your design.\n You can generate reports before and after you compile your design.\n Generate reports before compile to check that you have set attributes, constraints, and design rules properly.\n Generate reports after compile to analyze the results and debug your design.\n This section includes the following topics:  Reporting Commands and Examples  Measuring Quality of Results  Comparing QoR Data  Reporting Logic Levels in Batch Mode  Querying Specific Message IDs"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Primary Corner for Clock Tree Synthesis"}, {"role": "assistant", "content": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths.\n If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design.\n However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design.\n During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths.\n To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the synthesize_clock_trees and clock_opt commands, set the cts.compile.enable_local_skew and cts.optimize.enable_local_skew application options to true fc_shell> set_app_options -list {cts.compile.enable_local_skew true} fc_shell> set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you       specify with the set_clock_tree_options -target_skew command.\n To prevent the tool from deriving skew targets, use the following application option setting: fc_shell> set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Resolving Overlapping Voltage Areas"}, {"role": "assistant", "content": "To merge the voltage area shapes into a minimum set of disjoint shapes, use the -merge_regions option with the create_voltage_area create_voltage_area_shape or set_voltage_area command.\n  When you use the create_voltage_area -merge_regions command, the merges the shapes specified with the -region option.\n  When you use the create_voltage_area_shape -merge_regions command, the merges the shape specified with the -region option and the existing shapes of the specified voltage area.\n  When you use the set_voltage_area -merge_regions command, the tool merges all existing shapes of the specified voltage area.\n The tool merges the voltage area shapes based on their stacking order.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The merged shape replaces the top shape of a set of abutting or overlapping shapes; the other shapes in the set are removed and are no longer associated with the voltage area.\n       For example, assume that you use the following command to create a voltage area comprising three rectangle shapes, as shown on the left side of fc_shell> create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } {PD1} fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_1 VOLTAGE_AREA_SHAPE_2 VOLTAGE_AREA_SHAPE_3} After you use the -merge_regions option to merge these shapes, the voltage area consists of a single rectilinear shape, as shown on the right side of.\n The merged voltage area shape is named VOLTAGE_AREA_SHAPE_3, which was the last voltage area shape defined when the voltage area was created.\n fc_shell> set_voltage_area PD1 -merge_regions Information: Merging abutted and overlapping shapes in voltage_area 'PD1'.\n (NDMUI-154)  fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_3}  Merging Voltage Area Shapes To report the stacking order of the voltage area shapes, use the report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in Modifying the Stacking Order"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Clock-Tree Layer Constraints"}, {"role": "assistant", "content": "To remove net-specific routing layer constraints, use the set_routing_rule -clear command.\n Note that when you use this command, it also removes any nondefault routing rules assigned to the specified nets."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Datapath Optimization"}, {"role": "assistant", "content": "You can control boundary optimization across user-specified logical boundaries and match the interface boundary of a physical block with the RTL module interface.\n Boundary optimization allows you to use RTL floorplanning DEF files during block implementation.\n The following figure shows how constants, equal-opposite logic, logic phase, and unloaded ports are propagated through the logical boundaries without and with boundary optimization.\n        Constant propagation  Phase inversion Unloaded propagation Equal-opposite logic propagation Disabled Enabled Disabled Disabled Disabled Enabled Enabled Enabled Disabled: without boundary optimization Enabled: with boundary optimization Global Control By default, all types of boundary optimization are enabled during compile.\n To control boundary optimization globally, use the compile.flow.boundary_optimization application option.\n When you set the compile.flow.boundary_optimization application option to false  The tool disables propagation of equal-opposite logic and phase inversion.\n  Constants and unloaded ports continue to propagate across hierarchies.\n To disable constant propagation and unloaded propagation globally, set the compile.flow.constant_and_unloaded_propagation_with_no_boundary_opt application option to false.\n The default is true.\n The setting does not affect object-level specifications.\n Controlling Specific Types of Boundary Optimization To control the level of boundary optimization for hierarchical cell pins, hierarchical cells, or blocks, use the set_boundary_optimization command.\n The tool uses the following order of precedence to determine the setting to use during optimization: 1.\n Setting applied on pins of hierarchical cell instances 2.\n Setting applied on hierarchical cell instances, which applies to its pins as well 3.\n Setting applied on modules, which applies to all its cells and pins as well       The following table shows the level of boundary optimization you can specify with the set_boundary_optimization command and the types of boundary optimization that are enabled for each level.\n Table 20 Levels of Boundary Optimization and the Corresponding Types of Boundary Optimization Performed Level of boundary optimization Constant propagation Unloaded propagation Equal-opposite logic propagation Phase inversion all     auto     none     You can control the specific types of boundary optimization allowed for an object by using the -constant_propagation -unloaded_propagation -equal_opposite_propagation, and -phase_inversion options.\n These options are mutually exclusive with the boundary optimization level specified by using all auto, or none and cannot be used on the same object in a single command invocation.\n If you use the set_boundary_optimization command multiple times on the same object, the effect is additive.\n Based on the types of boundary optimization you enable or disable, the tool sets the constant_propagation unloaded_propagation equal_opposite_propagation, and phase_inversion read-only attributes of the specified object to true or false.\n If you  Enable all four types, the tool sets the boundary_optimization read-only attribute to true  Disable at least one type, the tool sets the boundary_optimization read-only attribute to false To report boundary optimization settings, use the report_boundary_optimization command.\n To remove them, use the remove_boundary_optimization command.\n The following example  Disables all boundary optimization for the U1 cell instance  Disables equal-opposite logic propagation and phase inversion for the U2 cell instance  Disables constant propagation and phase inversion for the U3/in1 cell pin fc_shell> set_boundary_optimization [get_cells U1] none fc_shell> set_boundary_optimization [get_cells U2] auto fc_shell> set_boundary_optimization [get_pins U3/in1] \\ -constant_propagation false       fc_shell> set_boundary_optimization [get_pins U3/in1] \\ -phase_inversion false Controlling Phase Inversion To prevent boundary optimization from moving inverters across hierarchical boundaries, set the compile.optimization.enable_hierarchical_inverter application option to false.\n By default, the application option is set to true to allow phase inversion.\n This application option is only effective when boundary optimization is enabled."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Enabling Leakage Power Optimization for the compile_fusion"}, {"role": "assistant", "content": "The leakage power of a block is scaled based on the switching probability of its supply nets, which represents the fraction of time a supply net is in the on state.\n You can specify the switching probability for one or more supply nets by using the set_supply_net_probability -static_probability command.\n By default, the switching probability is applied to the current scenario and the corresponding mode and corner.\n To specify modes, corners, or scenarios in which to apply the setting, use the -modes -corners, or -scenarios option.\n To get the switching probability of a supply net, use the get_supply_net_probability command, and to reset the value, use the reset_supply_net_probability command.\n By default, the tool propagates supply net activity through power switches and determines the static probability of the switched supply net based on the UPF power switch constraint.\n For example, consider the following UPF power switch constraint: create_power_switch my_switch \\ -output_supply_port {vout VDDS} \\ -input_supply_port {vin VDD} \\ -control_port {ms_sel ctrl1} \\ -control_port {ms_ctrl ctrl2} \\ -on_state {on vin {ms_ctrl &&!ms_sel}}       The tool derives the static probability of the supply net named VDDS, which is connected to the output of the power switch, based on the probability of the power switch being on This is derived based on the following:  The Boolean function specified with the -on_state option, which is ms_ctrl &&!\n ms_sel, and the switching activity (static probability) of the nets connected to the corresponding control ports, which are nets named ctrl1 and ctrl2.\n  The switching probability of the supply net connected to the input supply port specified with the -on_state option, which is the supply net named VDD.\n The following application options control whether dynamic and leakage power are scaled based on the supply switching activity:  The power.scale_dynamic_power_at_power_off option controls whether dynamic power is scaled.\n The default is false (no scaling).\n  The power.scale_leakage_power_at_power_off option controls whether leakage power is scaled.\n The default is true (scaling is performed)."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Tree Synthesis"}, {"role": "assistant", "content": "DFT wrapper clock gates refer to those clock gates that drive only DFT wrapper cells.\n The clock gating engine prefixes dft_wrapper_ to the names of all DFT wrapper clock gates       clock gates irrespective of their origin.\n This helps to identify specific clock gates driving wrapper cells during automatic test pattern generation (ATPG).\n Table 24 Commands and their expected return values Command Expected Return Value get_clock_gates -gating_wrapper_cells_only  dft_wrapper_ICG  dft_wrapper_clock_gate_reg get_clock_gates -gating_wrapper_cells_only -origin tool_inserted   dft_wrapper_clock_gate_reg  get_clock_gates -gating_wrapper_cells_only -origin pre_existing   dft_wrapper_ICG  get_clock_gates {ICG clock_gate_reg} -gating_wrapper_cells_only   get_clock_gates {ICG dft_wrapper_clock_gate_reg} -gating_wrapper_cells_only    dft_wrapper_clock_gate_reg get_clock_gates {*clock_gate_reg} -gating_wrapper_cells_only    dft_wrapper_clock_gate_reg This feature works only when you enable clock gate support for DFT wrapper cells.\n To enable clock gate support for DFT wrapper cells, set the following variable to true compile.clockgate.enable_dft_wrapper_cell_support       The following figures show how a clock gate can be split so that different clock gates can gate internal cells and wrapper cells separately:  Splitting a Clock Gate to Internal Cells and Wrapper Cells  Gating Internal Cells and Wrapper Cells Separately       Note: The clock gates cloned to gate wrapper cells alone, inherit their names from parent clock gates and have dft_wrapper_ appended to their names.\n This is not applicable to the names of self-gates that drive wrapper cells only.\n Table 25 shows how different types of clock gates are renamed.\n Table 25 How different clock gate types are renamed Clock Gate Type Name New Name  clock_gate_reg dft_wrapper_clock_gate_reg  icg_0 dft_wrapper_icg_0 Use the -gating_wrapper_cells_only option with the get_clock_gates command to return all clock gates (except self-gates) that drive wrapper cells only.\n This option can be used in conjunction with the already existing options.\n Use the compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option to restrict the renaming of pre-existing clock gates (driving wrapper cells only).\n This option accepts a list of strings as values.\n The clock gates matching any of the substrings provided in the application option are not renamed.\n Note: The compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option does not have any effect on the -gating_wrapper_cells_only querying option.\n Consider the following example: set_app_options -name compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs -value {clk_gate_ctl clk_gate_snps} This prevents the renaming of any pre-existing clock gates that have the clk_gate_ctl or clk_gate_snps pattern in their name but can still be queried using the get_clock_gates -gating_wrapper_cells_only command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling Standard Filler Cell Insertion"}, {"role": "assistant", "content": "The standard filler cell insertion flow uses the create_stdcell_fillers command to insert filler cells in the block and the remove_stdcell_fillers_with_violation command to perform design rule checking on the filler cells and remove filler cells with violations.\n During filler cell insertion, the create_stdcell_fillers command uses the placement legalizer to ensure that the inserted filler cells honor advanced node placement rules and physical constraints such as placement blockages and keepout margins.\n When the place.legalize.enable_advanced_legalizer application option is set to true the command uses the advanced legalization algorithms for 2D rule checking and cell interaction, which can reduce filler cell insertion runtime.\n To insert filler cells in your block, 1.\n Ensure that the block is legalized by using the check_legality command.\n When verifying that a block is fillable, the check_legality command assumes that all standard cells that have a design_type attribute of filler can be used as filler cells.\n However, the create_stdcell_fillers command inserts only the cells specified in       the -lib_cells option.\n This difference might result in unfillable gaps after filler cell insertion even though the check_legality command did not report any issues.\n 2.\n (Optional) Insert required filler cells to abut specific standard cells by using the create_left_right_filler_cells command, as described in Abutting Standard Cells With Specific Filler Cells 3.\n (Optional) Enable multithreaded filler cell insertion by using the set_host_options command to specify the multicore configuration.\n fc_shell> set_host_options -max_cores The create_stdcell_fillers command uses the multicore configuration only when the technology file contains minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules.\n Note: The multicore configuration specified with the set_host_options command applies to all Fusion Compiler commands that support multicore processing.\n 4.\n Insert metal filler cells by using the create_stdcell_fillers command.\n Use the -lib_cells option to specify the metal filler library cells to insert.\n The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n To determine the filler cells available in a cell library, use the following command: fc_shell> get_lib_cells ref_lib /* -filter \"design_type==filler\" To sort the filler cells by decreasing size, use the sort_collection command, as shown in the following example: fc_shell> set FILLER_CELLS \\ [get_object_name [sort_collection -descending \\ [get_lib_cells ref_lib /* -filter \"design_type==filler\"] area]] For more information, see Controlling Standard Filler Cell Insertion 5.\n Connect the inserted filler cells to the power and ground (PG) network by using the connect_pg_net -automatic command.\n 6.\n Remove the metal filler cells with DRC violations by using the remove_stdcell_fillers_with_violation command.\n Removing the filler cells can expose new violations; therefore, you must sometimes run this command multiple times to remove all violating filler cells.\n For more information, see Checking for Filler Cell DRC Violations       7.\n Insert nonmetal filler cells by using the create_stdcell_fillers command.\n Use the -lib_cells option to specify the nonmetal filler library cells to insert.\n The tool tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n For more information, see Controlling Standard Filler Cell Insertion 8.\n Connect the inserted filler cells to the PG network by using the connect_pg_net -automatic command.\n See Also  Generic ECO Flow for Timing or Functional Changes  Removing Filler Cells"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing Preroute Shielding"}, {"role": "assistant", "content": "Before you perform shielding, you must 1.\n Define the shielding rules.\n To define shielding rules, use the -shield_spacings and -shield_widths options of the create_routing_rule command.\n For example, to specify a shielding rule that uses spacing of 0.1 microns and width of 0.1 microns for metal1 through metal5 and spacing of 0.3 microns and width of 0.3 microns for metal6, use the following command: fc_shell> create_routing_rule shield_rule \\ -shield_widths {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} \\ -shield_spacings {M1 0.1 M2 0.1 M3 0.1 M4 0.1 M5 0.1 M6 0.3} For more information about the create_routing_rule command, see Using Nondefault Routing Rules       2.\n Assign shielding rules to the nets to be shielded.\n To avoid congestion issues and achieve the best balance of DRC convergence and timing closure, you should apply shielding rules only to high-frequency or critical clock nets and apply double-spacing rules to the lower-frequency clock nets.\n  To assign shielding rules to clock nets, use the set_clock_routing_rules command.\n Note: You can use the set_clock_routing_rules command only before clock tree synthesis.\n  To assign shielding rules to signal nets, use the set_routing_rule command.\n For more information about these commands, see Assigning Nondefault Routing Rules to Nets"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Removing Taps"}, {"role": "assistant", "content": "If the specified location for a tap is invalid, use the -snap_distance option of the create_taps command to find a substitute location for the tap.\n The command searches the nearby layout shapes within the specified snap distance both horizontally and vertically on the same layer as defined by the -layer option.\n The tap is reinserted at the corner of a valid shape which is within the minimum distance to the specified location.\n Note: You can search for a substitute location only for the invalid taps that are specified by the -point and -layer options.\n For example, fc_shell> create_taps -point {50,50} -layer {M1} \\ -snap_distance 100 Snap tap point from original location (50.000, 50.000) to new location (90.000, 65.910) As shown in, the specified tap location does not touch any layout shape.\n The red rectangle is the shape closest to the specified location and its lower-right corner has       the minimum distance among all the other rectangles.\n The tool reinserts the tap at the lower-right corner of the red rectangle.\n  Finding a Substitute Location for an Invalid Tap Original {x,y} 100 100 100 100 Snapped tap"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Automatic Floorplanning"}, {"role": "assistant", "content": "The read_def command extracts physical constraint information from DEF files and annotates it on the block.\n However, only the following physical constraints are extracted and annotated:  Placement Area  Port Locations  Cell Locations  Placement Blockages        Site Rows  Routing Tracks  Placement Bounds  Routing Blockages  Preroutes To visually inspect the extracted physical constraints, use the layout view in the GUI.\n All physical constraints extracted from the DEF file are automatically added to the layout view.\n Placement Area Placement area is computed based on the site array information.\n Port Locations For each port with the location specified in the DEF file, the tool sets the location on the corresponding port in the block.\n Note: If the DEF file does not contain port-location information, the tool inherits the port locations from the locations of the pad cells, as described in.\n Example 1 DEF Port Location Information PINS 2 ; -Out1 + NET Out1 + DIRECTION OUTPUT + USE SIGNAL + LAYER M3 (0 0) (4200 200) + PLACED (80875 0) N; -Sel0 + NET Sel0 + DIRECTION INPUT + USE SIGNAL + LAYER M4 (0 0)(200 200) + PLACED (135920 42475) N; END PINS Ports with changed names and multiple layers are supported.\n Example 2 DEF Port Locations With Changed Names and Multiple Layers PINS 2 ; - sys_addr\\[23\\].extra2 + NET sys_addr[23] + DIRECTION INPUT +USE SIGNAL + LAYER METAL4 ( 0 0 ) ( 820 5820 ) + FIXED ( 1587825 2744180 ) N ; - sys_addr[23] + NET sys_addr[23] + DIRECTION INPUT + USE SIGNAL + LAYER METAL3 ( 0 0 ) ( 820 5820 ) + FIXED ( 1587825 2744180 ) N ; END PINS Example 3 DEF Port Orientation Information PINS 1; - OUT + NET OUT + DIRECTION INPUT + USE SIGNAL + LAYER m4 ( -120 0 ) ( 120 240 )       + FIXED ( 4557120 1726080 ) S ; END PINS Cell Locations For each cell with a location and the FIXED attribute specified in the DEF file, the tool sets the location on the corresponding cell in the block.\n Example 4 shows DEF macro location and orientation information, where the letters E and W denote east rotation and west rotation respectively.\n Example 4 DEF Cell Location Information COMPONENTS 2 ; - macro_cell_abx2 + FIXED ( 4350720 8160 ) E ; - macro_cell_cdy1 + FIXED ( 4800 8160 ) W ; END COMPONENTS Placement Blockages The read_def command imports hard, soft, and partial placement blockages defined in the DEF file.\n Note: DEF versions before version 5.7 did not support partial blockages.\n In addition, if your floorplanning tool creates a DEF file with DEF version 5.6, you need to manually add the #SNPS_SOFT_BLOCKAGE pragma to specify a soft blockage, as shown in Example 7 Example 5 DEF Hard Placement Blockage Information BLOCKAGES 50 ;...\n - PLACEMENT RECT ( 970460 7500 ) ( 3247660 129940 )...\n END BLOCKAGES Example 6 DEF Version 5.7 Soft Placement Blockage Information BLOCKAGES 50 ;...\n - PLACEMENT + SOFT RECT ( 970460 7500 ) ( 3247660 129940 ) ;...\n END BLOCKAGES Example 7 DEF Version 5.6 Soft Placement Blockage Information BLOCKAGES 50 ;...\n - PLACEMENT RECT ( 970460 7500 ) ( 3247660 129940 ) ; #SNPS_SOFT_BLOCKAGE...\n END BLOCKAGES       Example 8 DEF Partial Placement Blockage Information BLOCKAGES 50 ;...\n - PLACEMENT + PARTIAL 80 RECT ( 970460 7500 ) ( 3247660 129940 ) ;...\n END BLOCKAGES Site Rows Site row information in the DEF file defines the placement area.\n Example 9 DEF Site Row Information ROW ROW_0 core 0 0 N DO 838 BY 1 STEP 560 0; Routing Tracks The track information in the DEF file defines the routing grid for designs based on standard cells.\n This information can be used during routing, and track support can enhance congestion evaluation and reporting to make it match more closely with the routing results.\n Example 10 DEF Routing Track Information TRACKS X 330 DO 457 STEP 660 LAYER METAL1 ; TRACKS Y 280 DO 540 STEP 560 LAYER METAL1 ; Placement Bounds If REGIONS defining bounds exist in the DEF file, the read_def command imports those placement bounds.\n Also, if any cells in the related GROUP are attached to the region, fuzzy cell matching occurs between these cells and the ones in the block.matched cells are attached to the bounds in the following ways:  If there are regions in the block with the same name as in the DEF, the cells in the related group are attached to the region by the add_to_bound command in incremental mode.\n  If the region does not exist in the block, it is created with the same name as in the DEF file by applying the create_bound command; matched cells in the related group are also attached.\n Example 11 DEF Placement Bound Information REGIONS 1 ; - c20_group ( 201970 40040 ) ( 237914 75984 ) + TYPE FENCE ; END REGIONS GROUPS 1 ; - c20_group cell_abc1 cell_sm1 cell_sm2       + SOFT + REGION c20_group ; END GROUPS Routing Blockages Routing blockages are extracted similar to the way that placement blockages are extracted.\n Preroutes The tool extracts preroutes that are defined in the DEF file.\n Example 12 DEF Preroute Information SPECIALNETS 2 ; - vdd + ROUTED METAL3 10000 + SHAPE STRIPE ( 10000 150000 ) ( 50000 * ) + USE POWER ;...\n END SPECIALNETS"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Skewing Latch and Discrete Clock Gates"}, {"role": "assistant", "content": "To copy concurrent clock and data (CCD) offsets to the new scenarios for consistent timing or QoR reports, use the copy_useful_skew command.\n During CCD, when a pin's CTS balance point offsets are derived in only a subset of the active scenarios, use this command to copy the offsets to the in-active scenarios and active scenarios that do not have the CCD offsets.\n The copy_useful_skew command also ensures that the corresponding constraints of the set_clock_latency command are set on all the pins and scenarios, where a new offset value is computed.\n The average value of the offset is computed across all scenarios, where a balance point offset is defined.\n The average value is then scaled back in each active scenario using the scaling factor of the scenario corner."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Custom Router in the Fusion Compiler"}, {"role": "assistant", "content": "Custom Router is a shape-based router that supports gridded or gridless routing for custom digital, mixed signal, and analog routing needs.\n In the Fusion Compiler environment, you can use Custom Router to create interconnects (or routes) for critical signals between blocks and continue with the Fusion Compiler tool to complete the physical implementation.\n You can also preroute critical signals or clock nets by using a set of custom routing constraints.\n In the Fusion Compiler environment, Custom Router provides the following features:  Prerouting in the batch mode  Tcl-based routing constraint management  Automatic routing with custom routing constraints  Hybrid flow for prerouting  Double Data Rate (DDR) net routing flow Custom Router is fully integrated with the Fusion Compiler tool, and supports advanced design rules for 20 nm and below technologies.\n To learn about using Custom Router in the Fusion Compiler environment, see the following topics:  Using Custom Router in the Fusion Compiler Tool  Before Using Custom Router  Defining Routing Constraints  Managing Constraint Groups  Using Custom Routing Application Options  Routing With the Custom Router  Shielding the Nets  Checking the Routing Results        Using a Hybrid Routing Flow  Using a DDR Routing Flow These topics describe how to use Custom Router to create custom routes in the Fusion Compiler environment.\n For detailed information about Custom Router, see the Custom Compiler Custom Router User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Options for Signoff Design Rule Checking"}, {"role": "assistant", "content": "To perform signoff design rule checking by running the signoff_check_drc command, 1.\n Set up the IC Validator environment as described in Setting Up the IC Validator Environment 2.\n (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing       3.\n Set the application options for signoff design rule checking.\n At a minimum, you must specify the foundry runset to use for design rule checking by setting the signoff.check_drc.runset application option.\n For information about the options for command-based signoff design rule checking, see Setting Options for Signoff Design Rule Checking 4.\n Save the block to disk.\n When you run signoff design rule checking, the IC Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the save_block command to save the current state of the block before running signoff design rule checking.\n 5.\n Run signoff design rule checking by using the signoff_check_drc command.\n By default, the signoff_check_drc command performs the following tasks: 1.\n Loads the block into the IC Validator tool, as described in Reading Blocks for Signoff Design Rule Checking 2.\n Performs signoff design rule checking, as described in Signoff Design Rule Checking 3.\n Generates an error data file and IC Validator results files, as described in Signoff DRC Results Files You can use the results files to view the violations in the error browser, as described in Using the Error Browser, or to perform automatic design rule fixing, as described in Automatically Fixing Signoff DRC Violations You can use the following methods to analyze the DRC violations reported by the signoff_check_drc command:  View the violations in the error browser, as described in Using the Error Browser.\n  View the density of violations in a heat map, as described in Viewing the Violations in an ICV Heat Map See Also  Checking Signoff Design Rules Interactively in the GUI"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Copying Clock Tree Exceptions Across Modes"}, {"role": "assistant", "content": "To set a size-only setting on a cell, use the set_size_only command.\n The following command sets a size-only setting on a cell: fc_shell> set_size_only [get_cells cell_name ] true To report all the size-only settings set on the current block, use the report_size_only command.\n fc_shell> report_size_only -all"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Generating Hotspots"}, {"role": "assistant", "content": "When rail analysis is complete, there might be hundreds to thousands of voltage drop violations reported in the analysis report, which might make it difficult to identify the root causes for the violations.\n Use the voltage hotspot analysis capability to generate hotspots for a power or ground net by dividing the whole chip into small grid boxes, and report rail-related information for the generated grid boxes.\n In addition, you can query cell- or geometry-based rail results only for the specific analysis type by using the get_instance_result and get_geometry_result commands.\n       Hotspot analysis provides the following features:  Identify the root cause of aggressors with high voltage drop, such as large current from the aggressor itself or from the neighboring cells due to simultaneous switching by the overlapping timing windows.\n  Determine which design technique to use for fixing voltage violations based on the report, such as choosing a candidate reference cell for cell sizing replacement, moving or relocating cells to reduce voltage drops, or applying PG augmentation to solve a voltage drop issue.\n This section contains the following topics:  Generating Hotspots  Reporting Hotspots  Removing Hotspots  Voltage Hotspot Analysis Examples To write rail results only for the cell instances or geometries that reside in the hotspot area, use the get_instance_result and get_geometry_result commands.\n For more information, see Generating Instance-Based Analysis Reports and Generating Geometry- Based Analysis Reports"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Excluding Specific Sinks"}, {"role": "assistant", "content": "To exclude a specific scenarios from concurrent clock and data optimization, use the ccd.ignore_scenarios application option and specify the name of the scenarios you want to ignore.\n For example, to ignore the scenario named scnB, use the following command: fc_shell> set_app_options -name ccd.ignore_scenarios \\ -value {scnB}} This setting affects concurrent clock and data optimization performed during the place_opt clock_opt, and route_opt commands."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining the Clock Trees"}, {"role": "assistant", "content": "This topic details the prerequisites required before running the clock tree synthesis.\n Before you run clock tree synthesis on a block, it should meet the following requirements:  The clock sources are identified with the create_clock or create_generated_clock commands.\n  The block is placed and optimized.\n Use the check_legality -verbose command to verify that the placement is legal.\n Running clock tree synthesis on a block that does not have a legal placement might result in long runtimes and reduced QoR.\n The estimated QoR for the block should meet your requirements before you start clock tree synthesis.\n This includes acceptable results for  Congestion If congestion issues are not resolved before clock tree synthesis, the addition of clock trees can increase congestion.\n If the block is congested, you can rerun the       create_placement command with the -congestion and -congestion_effort high options, but the runtime can be long.\n  Timing  Maximum capacitance  Maximum transition time  The power and ground nets are prerouted.\n  High-fanout nets, such as scan enables, are synthesized with buffers.\n  The active scenarios are defined.\n By default, the Fusion Compiler tool synthesizes and optimizes all clocks in all active scenarios that are enabled for setup or hold analysis."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Identifying Redundancies, Outliers, Equivalences, and Gaps in"}, {"role": "assistant", "content": "When a family of cells with the same function is ordered in terms of increasing drive strength, specific cell property values should be monotonically increasing or decreasing.\n For example, when a family is ordered in terms of increasing drive strength, the area of cells should be monotonically increasing, power should be increasing, and delay (for the same output load and input slew) should be decreasing.\n       The following figure shows a monotonic distribution of cell area versus timing for a family of cells with the same function.\n  Monotonic Distribution in Library Cell Family       A cell is considered redundant if all its metrics, such as area, delay, power, and so on, are equal or worse than another cell, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n  Redundant Cell in Library Cell Family       A cell is considered an outlier if its metrics has a very large deviation from the expected values, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n  Outlier Cell in Library Cell Family       Cells are considered equivalent if all their properties are the same for all process, voltage, and temperature (PVT) values, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n  Equivalent Cells in Library Cell Family       A gap is when there is a large difference between two successive drive strengths, as shown in the following plot of cell area versus timing for a family of cells with the same function.\n  Gap in Library Cell Family"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Library Cells as Repeaters"}, {"role": "assistant", "content": "Use one of the following mutually exclusive options to control spacing for repeater groups:  -horizontal_repeater_spacing specifies the horizontal spacing between repeaters by cell site width.\n  -vertical_repeater_spacing specifies the vertical spacing between repeaters by site row height."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining the Bus Routing Style"}, {"role": "assistant", "content": "The Fusion Compiler tool provides a set of application options to control custom routing results.\n The application options are applied globally.\n See Using Custom Routing Application Options You can also define net-specific routing constraints that override the routing application options.\n Routing constraints provide guidance during routing.\n In the Fusion Compiler environment, Custom Router honors both the Custom Router constraints and the Fusion Compiler nondefault routing rules.\n Note: You must apply net-specific routing constraints to physical nets.\n When specifying nets that will be constrained, use the get_nets -physical_context command to ensure the physical net is returned.\n For example: fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*]\\ -disabled_layers {M5 M6} -sharing true \\ -layer_gaps {M2 3 M3 5} {shielding_4} Table 52 lists the commands to define the Custom Router constraints by creating constraint groups.\n For information about the supported Fusion Compiler nondefault routing rules, see Using Nondefault Routing Rules To check or remove the created constraint groups, use the report_constraint_groups or remove_constraint_groups command.\n For more information about checking or removing constraint groups, see Managing Constraint Groups Table 52 Commands to Define Custom Router Routing Constraints Command Description create_bus_routing_style    create_differential_group         Table 52 Commands to Define Custom Router Routing Constraints (Continued) Command Description create_wire_matching    create_length_limit    create_net_shielding   create_net_priority"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Checking Options"}, {"role": "assistant", "content": "Note: Missing via and unconnected pin checking is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n Before you check for missing vias and unconnected pins, make sure you have the required input files as described in Preparing Design and Input Data for Rail Analysis Check for missing vias or unconnected pins in the block during voltage drop analysis or in a separate run.\n For example, you can perform the checking after completing the power       structure and before running the place_opt command.\n This allows you to find power network errors in the design before rail analysis.\n By default, RedHawk/RedHawk-SC Fusion detects the following types of power network errors:  Unconnected pin shapes: Pin shapes that are not contiguously and physically connected to an ideal voltage source.\n  Missing vias: If two overlapping metal shapes do not contain a via within their overlapping area, it is considered a potential missing via error.\n To check for and fix missing vias or unconnected pins, 1.\n Define configuration options by using the set_missing_via_check_options command, as described in Setting Checking Options 2.\n Save the block by using the save_block command.\n 3.\n Perform the checking by using the analyze_rail -check_missing_via command, as described in Checking Missing Vias and Unconnected Pins.\n In the RedHawk-SC Fusion flow, you must specify the -check_missing_via option together with the -voltage_drop option.\n 4.\n Examine the checking results by opening the generated error files in the error browser or writing the checking results to an output file, as described in Viewing Error Data and Writing Analysis and Checking Reports 5.\n Insert PG vias to fix the reported missing vias, as described in Fixing Missing Vias"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Clock Gates in an RTL Design"}, {"role": "assistant", "content": "In a multivoltage design, the different hierarchies of the design might have different operating conditions and use different target library subsets.\n When inserting clock-gating cells in a multivoltage design, the tool chooses the appropriate library cells based on the specified clock-gating style as well as the operating conditions that match the operating conditions of the hierarchical cell of the design.\n If you do not specify a clock-gating style, the tool uses a default style where the test point is before and the observation output is false If the tool does not find a library cell that suits the clock-gating style and the operating conditions, the tool issues a warning message and does not insert a clock-gating cell.\n To check whether there are integrated clock-gate cells available for clock-gate insertion, use the check_clock_gate_library_cell_availability command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Troubleshooting"}, {"role": "assistant", "content": "Use the add_group_repeaters and place_group_repeaters commands to display the summary report for variant cell swapping in command cell collections."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Clock Gate Efficiency Reporting"}, {"role": "assistant", "content": "A clock gate often has an enable signal that is a Boolean expression comprising of one or more of the following reference (or invariant) points:  Hierarchical ports  Sequential output pins  Black box output pins To report the clock gate enable signal as a Boolean function, use the report_clock_gating_enable_condition command.\n You must specify a collection of clock gates to be reported."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting the Routing Results"}, {"role": "assistant", "content": "To perform layout-versus-schematic (LVS) checking, which checks for inconsistencies in the physical layout, use the check_lvs command.\n By default, the check_lvs command performs the following checks for all signal, clock, and PG nets:  Shorted nets A shorted net occurs when a net shapes from different nets touch or intersect.\n By default, the command  Checks for shorts between net shapes in the top-level design, including shapes in top-level blockages To disable checking for shapes in top-level blockages, use the -check_top_level_blockages false option.\n  Does not check for shorts between net shapes in the top-level design and net- shapes in child cells To enable this checking, use the -check_child_cells true option.\n To exclude certain types of child cells from checking, use the -exclude_child_cell_types       option to specify one or more of the following cell types: abstract analog black_box corner cover diode end_cap fill filler flip_chip_driver flip_chip_pad lib_cell macro module pad pad_spacer physical_only and well_tap  Does not check for shorts with zero-spacing blockages To enable this checking, use the -check_zero_spacing_blockages true option.\n Note: The check_lvs command supports only default routing blockages that apply to all net types and have a blockage group ID of 0.\n If the blockage applies only to specific net types or has a nonzero blockage group ID, the command ignores the blockage.\n In addition, the command ignores corridor routing blockages (which are created when you use the -reserve_for_top_level_routing option with the create_routing_blockage command) and boundary routing blockages (which are created when you use the -boundary_internal or -boundary_external options with the create_routing_blockage command).\n  Open nets An open net occurs when the pins of a net are not connected by its net shapes.\n By default, the command  Treats power and ground terminals as unconnected voltage sources To treat power and ground terminals as connected, use the -treat_terminal_as_voltage_source true option.\n For example, assume your block contains the layout shown in.\n By default, the check_lvs command reports two opens for this layout.\n If you use the -treat_terminal_as_voltage_source true option, no opens are reported.\n        Layout With Power and Ground Terminals  Reports open nets as the bounding box of the open net and does not report floating pins To report detailed open locations, use the -open_reporting detailed option.\n Note that using this option might increase the runtime.\n To report the floating pins, use the -report_floating_pins true option.\n  Floating net shapes A floating net shape occurs when a net shape is not physically connecting to a pin of its net.\n To perform a subset of these checks, use the -checks option to specify one or more of the following checks: short (shorted nets), open (open nets), and floating_routes (floating net shapes).\n To check only specific nets, use the -nets option to specify the nets of interest.\n By default, the check_lvs command reports a maximum of 20 violations for each type of error.\n To change this limit, use the -max_errors option.\n To report all violations, specify the maximum number of violations as zero ( -max_errors 0 ).\n You can view the violations reported by the check_lvs command in the GUI by using the error browser.\n For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide To reduce the runtime required by the check_lvs command, enable multithreading by using the set_host_options command, as described in Enabling Multicore Processing"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Running Tasks in Parallel"}, {"role": "assistant", "content": "To remove the multicore configurations defined by the set_host_options command, use the remove_host_options command.\n To remove all multicore configurations, use the -all option.\n To remove a specific multicore configuration, specify the configuration name with the -name option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reporting Multicore Configurations"}, {"role": "assistant", "content": "Distributed processing performs tasks in parallel by using multiple machines; each process uses its own process memory image.\n When using distributed processing, each parallel task is called a process.\n For the best performance during distributed processing, you should limit the number of processes to the number of available cores, which is the sum of the number CPUs times the number of cores per CPU for each host machine.\n The following commands support distributed processing configured by the set_host_options command:  analyze_rail  create_placement -floorplan  signoff_check_drc  signoff_fix_drc  signoff_create_metal_fill  signoff_fix_isolated_via When you configure distributed processing, you can specify one or more of the following settings:  The job submission command (the -submit_command option) If you do not specify this option, the tool uses the rsh command to submit the parallel processes.\n  The list of host machines (the host_names argument)  The maximum number of processes (the -num_processes option) By default, the tool assigns a name to each configuration you define with the set_host_options command.\n To specify the configuration name, use the -name option.\n You use the configuration name to select the configuration to use for specific commands and to remove a configuration.\n For example, to specify a distributed processing configuration that uses the qsub command to submit the parallel processes, use the following command: fc_shell> set_host_options -name dp_config \\ -submit_command [list qsub -P bnormal -cwd]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Balance Mode Option"}, {"role": "assistant", "content": "To create single-loops to extend wires for length matching, use the Custom Router single- loop matching application options.\n Single-loop matching is typically used in DDR routing flows  Adding Single Loops to Extend Wires Application Option Description custom.route.single_loop_match        Application Option Description custom.route.single_loop_match_max_spacing   custom.route.single_loop_match_min_spacing   custom.route.single_loop_match_offset_layer"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Analyzing the Clock Tree Results"}, {"role": "assistant", "content": "In a structural multisource clock tree, the local subtrees are directly driven by the clock mesh.\n You can synthesize these local subtrees by using the synthesize_multisource_clock_subtrees command.\n Before you synthesize the local subtrees, you must 1.\n Build the global clock distribution structure.\n 2.\n Model the clock mesh net with a realistic annotated delay and transition values using the set_annotated_delay and set_annotated_transition commands.\n 3.\n Remove dont_touch size_only fixed, and locked attributes setting on the clock cells that are not required.\n These settings prevent the synthesize_multisource_clock_subtrees command from merging or splitting clock cells, if necessary.\n 4.\n Specify settings for local subtree synthesis by using the set_multisource_clock_subtree_options command.\n You must specify  The clock for synthesizing the subtrees by using the -clock option.\n  The drivers of the subtrees to be synthesized by using the -driver_objects option.\n The clock specified with the -clock option should pass through each drivers specified with the -driver_objects option.\n Optionally you can  Prevent the tool from merging specific clock tree cells by using the -dont_merge_cells option.\n  Balance the levels of the local subtree by using the -balance_levels true option and specify a target number of levels, which applies to all sinks of the local subtree, by using the -target_level option.\n Optionally, you can apply a different target number of levels to specific sink pins and clock balance points by using the set_multisource_clock_subtree_constraints command with the -pins and -target_level options.\n  Specify a maximum total wire delay from any subtree driver to any of its sinks by using the -max_total_wire_delay option and the corner it applies to by using the -corner option.\n        Enable the reordering of clock-gating cells by using the -enable_icg_reordering true option.\n When you enable this feature, the tool swaps the position of a clock-gating cell with the buffer that is driving the clock-gating cell.\n Then, the buffer is gated by the clock- gating cell, thereby reducing the dynamic power consumption.\n To perform reordering, you must  Enable scenarios used for structural multisource clock tree synthesis for dynamic power optimization  Annotate switching activity for the enable pins of the clock-gating cells You can prevent specific clock-gating cells from being reordered by using the set_multisource_clock_subtree_constraints command with the -cells and -ignore_for_icg_reordering options.\n To report the settings you specified, use the report_multisource_clock_subtree_options command.\n To remove the settings you specified, use the remove_multisource_clock_subtree_options command.\n 5.\n (Optional) Enable multicorner optimization by setting the cts.multisource.enable_multi_corner_support application option to true.\n The default is false By default, the tool uses the worst corner associated with the mode in which the subtree options are defined.\n When you enable this feature, the tool considers all corners associated with the mode in which the subtree options are defined.\n 6.\n (Optional) Ignore the maximum capacitance, maximum fanout, or both constraints of the clock drivers by using the cts.multisource.ignore_drc_on_subtree_driver application option.\n When you synthesize multisource clock subtrees, by default, the tool considers the maximum transition, capacitance, and fanout constraints of the clock drivers you specify.\n However, the clock drivers typically have relaxed or no maximum capacitance or maximum fanout constraint, which can affect the multisource clock tree QoR.\n The following example ignores both the maximum capacitance and maximum fanout constraints of the clock drivers: fc_shell> set_app_options \\ -name cts.multisource.ignore_drc_on_subtree_driver \\ -value \"max_fanout max_capacitance\" 7.\n (Optional) Enable fishbone routing for the subtree clock nets by using the cts.multisource.subtree_routing_mode application option.\n       fc_shell> set_app_options \\ -name cts.multisource.subtree_routing_mode -value fishbone 8.\n (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during local subtree synthesis by using the following application options:  cts.multisource.subtree_merge_cell_name_prefix  cts.multisource.subtree_merge_cell_name_suffix  cts.multisource.subtree_split_cell_name_prefix  cts.multisource.subtree_split_cell_name_suffix  cts.multisource.subtree_split_net_name_prefix  cts.multisource.subtree_split_net_name_suffix When you run the synthesize_multisource_clock_subtrees command the tool performs the following steps: 1.\n Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks.\n 2.\n Optimizes the subtree by splitting, sizing, and relocating the clock cells, and snaps the first level of clock cells to the clock straps.\n 3.\n Routes the clock nets.\n By default, it global routes the nets.\n However, if you enable fishbone routing by using the cts.multisource.subtree_routing_mode application option, the tool creates a mix of detail routed fishbone trunks and fingers, and global comb routes to connect the net loads to the fishbone fingers, as shown in You can control the fishbone routing by using the following application options:  cts.routing.fishbone_max_tie_distance  cts.routing.fishbone_max_sub_tie_distance  cts.routing.fishbone_bias_threshold  cts.routing.fishbone_bias_window  cts.routing.fishbone_horizontal_bias_spacing  cts.routing.fishbone_vertical_bias_spacing 4.\n Refines the clock trees by sizing and relocating cells based on the routing.\n        Detail Fishbone Routes and Global Comb Routes Global comb route Fishbone trunk Fishbone finger You can run specific steps of the synthesize_multisource_clock_subtrees command by using the -from and -to options and specifying merge optimize route_clock, or refine Structural subtrees that you build by using the synthesize_multisource_clock_subtrees command are not changed or removed when you subsequently run any clock tree synthesis command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Analyzing Signal Electromigration"}, {"role": "assistant", "content": "The Fusion Compiler tool supports the following formats for specifying electromigration constraints:  Interconnect Technology File (ITF) An ITF file can contain the following types of electromigration constraints: delta temperature, duration and duty ratio, via size, via direction, metal length, and via-to-via spacing relaxation.\n The Fusion Compiler tool supports both unencrypted and encrypted ITF files.\n  Advanced Library Format (ALF) An ALF file can contain the following types of electromigration constraints: temperature, metal width, and contact area.\n The electromigration constaints are stored in the design library as a lookup table.\n The tool determines the limit values by looking up the values in the lookup table and then using linear interpolation or extrapolation.\n To load the signal electromigration constaints into the design library, use the read_signal_em_constraints command.\n By default, the command reads an unencrypted ITF file.\n To read an encrypted ITF file, use the -encrypted option.\n To read an ALF file, use the -format ALF option.\n The constraints loaded by the read_signal_em_constraints command overwrite any existing signal electromigration constraints in the design library.\n For example, to read an unencrypted ITF file, use the following command: fc_shell> read_signal_em_constraints em.itf For example, to read an encrypted ITF file, use the following command: fc_shell> read_signal_em_constraints -encrypted em.itf.enc To read an ALF file, use the following command: fc_shell> read_signal_em_constraints -format ALF em.alf"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying Settings for the Freeze Silicon ECO Flow"}, {"role": "assistant", "content": "For multivoltage designs, to  Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the add_buffer_on_route command.\n  Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format.\n When you use this option, you must also use the -lib_cell option.\n  Specify different single-rail and dual-rail library cells for different voltage areas, use the -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format.\n       When you use this option, you must also use the -lib_cell option.\n For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option.\n For the default voltage area, specify DEFAULT_VA as the voltage area name.\n  Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the -allow_physical_feedthrough_buffer option.\n This option can only be used with the -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area.\n After you run the add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command.\n  Add cells within gas stations of specified supply nets, use the -respect_gas_station option and specify the supply net.\n Gas stations are areas with a constant power supply.\n These areas used for buffering nets that go through power domains that are powered down.\n To specify the maximum allowed distance from the gas station to the added buffer, use the -max_distance_route_to_gas_station option."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Blockages That Allow Buffers Only"}, {"role": "assistant", "content": "To define partial blockages that allow relative placement cells only, specify the boundary, type ( -type allow_rp_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to defines a partial blockage that allows relative placement cells only, with a maximum allowed cell density of 80 percent (a blocked percentage of 20), and enclosed by the rectangle with corners at (10, 20) and (100,200), use the following command: create_placement_blockage -name rp_only -type allow_rp_only \\ -boundary {10 20 100 200} -blocked_percentage 20 These blockages allows the tool to place relative placement groups, which are usually large structures, without disturbing the placement of other cells.\n After the tool places and legalizes the relative placement groups, you can remove these blockages and allow the tool to place other cells in them.\n Note: Relative-placement-cells-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Merging Voltage Area Shapes"}, {"role": "assistant", "content": "A voltage area is a physical placement area for the cells associated with a power domain.\n For multivoltage designs, the power domains are defined in the UPF specification.\n For single-voltage designs, the tool creates a default power domain when you read the Verilog netlist and associates it with a default voltage area, which comprises the core area of the block.\n The placer treats a voltage area the same as an exclusive move bound; it must place the cells in a voltage area within a specified region and it must place all other cells outside of the voltage area.\n Voltage areas can be rectangular or rectilinear.\n In addition, they can be disjoint, nested, or overlapping.\n For overlapping voltage areas, the effective shape of each voltage area is determined by the stacking order of the voltage area shapes.\n To define a voltage area, use the create_voltage_area command.\n When you define a voltage area, at a minimum, you must specify the power domains associated with the voltage area.\n To specify the power domains, use the -power_domains option.\n You can specify one or more power domains; however, all specified power domains must have the same primary supply net.\n If you specify a single power domain, the name of the voltage area is derived from the name of the power domain.\n If you specify multiple power domains, you must specify a name for the voltage area by using the -name option.\n A voltage area consists of one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping.\n To define the boundaries of these shapes, use the -region option with the create_voltage_area command (if you are creating a new voltage area) or the create_voltage_area_shape command (if you are adding shapes to an existing voltage area).\n Note that you can specify one or more shapes when using the create_voltage_area command, but only a single shape in each create_voltage_area_shape command.\n  To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly } { urx ury }}  To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 } { x2 y2 } { x3 y3 } { x4 y4 }...} If a voltage area consists of multiple abutting or overlapping shapes, you can merge the shapes into a minimum set of disjoint shapes based on the stacking order of the shapes.\n For information about how to merge the voltage area shapes, see Merging Voltage Area Shapes The tool also uses the stacking order to resolve overlapping shapes from different voltage areas.\n For information about resolving overlapping voltage areas, see Resolving Overlapping Voltage Areas       To ensure that no shorts occur at the boundaries of the voltage areas, you can define guard bands for the voltage areas, which act as hard keepout margins surrounding the voltage areas.\n If you define guard bands for a voltage area shape, the guard bands are included in the effective boundary of the shape; however, they are not included in the effective placement area of the voltage area.\n For information about defining guard bands, see Defining Guard Bands To modify an existing voltage area, use the set_voltage_area command, as described in Modifying Voltage Areas Multivoltage designs typically have power domains that are shut down and powered up during the operation of the chip while other power domains remain powered up.\n When dealing with shutdown domains, there can be some situations in which certain cells in the shutdown portion need to continuously stay active, such as for implementing retention registers, isolation cells, retention control paths, and isolation enable paths.\n These cells are referred to as always-on cells.\n To define a special placement area for always-on cells (an always-on well) within a voltage area, define an exclusive move bound within the boundary of the voltage area.\n For information about defining exclusive move bounds, see Defining Move Bounds After creating the voltage areas, run the check_mv_design command to verify that the design does not have any multivoltage violations."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Timing Driven Sink Transition Target"}, {"role": "assistant", "content": "I/O ports are usually constrained using real or virtual clocks.\n After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate.\n When you run clock tree synthesis with the clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports.\n You can control these latency adjustments by using the set_latency_adjustment_options command.\n The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell> set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the synthesize_clock_trees command, the tool does not automatically update the clock latencies.\n To do so, use the compute_clock_latency command after clock tree synthesis.\n This command honors the settings you specify with the set_latency_adjustment_options command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Datapath Extraction"}, {"role": "assistant", "content": "Datapath design is commonly used in applications that contain extensive data manipulation, such as 3-D, multimedia, and digital signal processing (DSP).\n By default, when you run the compile_fusion command, datapath optimization is enabled and both standard and DesignWare Foundation libraries are automatically linked.\n During datapath optimization, the tool performs the following tasks:  Shares (or reverses the sharing) of datapath operators  Uses the carry-save arithmetic technique  Extracts the data path  Performs high-level arithmetic optimization on the extracted data path  Explores better solutions that might involve a different resource-sharing configuration  Makes tradeoffs between resource sharing and datapath optimization Topics in this section  Datapath Extraction Transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks.\n  Datapath Implementation Uses a datapath generator to generate the best implementations for the extracted components.\n  Optimizing Datapaths"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Querying Voltage Areas"}, {"role": "assistant", "content": "Gas stations are small voltage areas that are created for the purpose of minimizing the use of dual-rail buffers on physical feedthrough paths.\n Only single-rail repeaters are allowed in gas stations, and only optimization steps can add cells to gas stations.\n You create gas stations by using the create_voltage_area command during the design planning stage.\n The tool recognizes gas stations automatically and uses them by trading off the cost of a routing detour with the cost of using a dual-rail cell.\n Use the -nwell and -pwell options of the create_voltage_area command to specify n-well and p-well supply nets for a voltage area.\n Defining well supplies for gas station voltage areas provides flexibility for using gas stations for different design styles.\n If you do not use these options for a voltage area, the well bias values are assumed to be the same as the domain supply values.\n The report_voltage_areas command lists the n-well and p-well supply nets regardless of whether they are explicitly set."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Verifying the Clock Trees"}, {"role": "assistant", "content": "In some blocks, the clocks have endpoints that are structurally impossible to balance.\n The Fusion Compiler tool can automatically detect endpoints with balancing conflicts and derive an ignore pin to resolve the conflict.\n This capability is enabled by default for the synthesize_clock_trees and clock_opt commands.\n To disable this capability, set the cts.common.enable_auto_exceptions application option to false       With this capability, the tool detects and fixes the following types of balancing conflicts:  Internal sink pins of modules that have a combinational clock path If a module contains both internal sink pins and combinational clock paths, it is impossible to balance the internal sink pins.\n To resolve the balancing conflict, the tool defines the internal sink pins as ignore pins.\n For example, assume that you have a module that contains a combinational path in the clock network, as shown in figure (a) in, which is represented by the extracted timing model (ETM) shown in figure (b).\n  Module With Combinational Clock Path  Clk_out  Clk (a) Netlist (b) ETM with check pin Clk   Clk_out Clk_check_pin_1 Combinational delay In this case, the internal check pin inside the ETM has delays coming from the ETM timing library; these delays are considered by clock tree synthesis as sinks and are balanced with other sinks at the top level.\n If the path to the check pin is the shortest path, top-level clock tree synthesis cannot insert buffers on the shortest path and therefore leaves a large skew at the top level.\n Setting the internal check pin as an ignore pin resolves the skew issue coming from the ETM.\n  Sink pins that cannot be balanced simultaneously If a block contains two clocks that drive common sinks, one of which is a clock pin that is the parent of another sink, due to a generated clock, it is impossible to simultaneously balance the parent and child clock pins with another common sink.\n To resolve the balancing conflict, the tool defines the parent clock pin as an ignore pin.\n For example, in, FF_gen/CLK and FF0_1-10/CLK are sinks of clkb, FF1_1-10/CLK and FF0_1-10/CLK are sinks of clka, and FF_gen/CLK is the parent of       FF1_1-10/CLK.\n In this case, the tool defines FF_gen/CLK as an ignore pin for clkb to resolve the balancing conflict.\n  Clock Pins That Cannot Be Balanced Simultaneously"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Inserting Via Ladders"}, {"role": "assistant", "content": "To define a custom via, use the following create_via_def syntax: create_via_def -shapes { { layer coordinates } [ mask_constraint ]}...\n } [-lower_mask_pattern alternating | uniform] [-upper_mask_pattern alternating | uniform] [-force] via_def_name In the -shapes option, you must specify shapes for one via layer and two metal layers, which are the enclosure layers for the via.\n You can specify multiple shapes per layer.\n For example, to create a custom via definition, use a command similar to the following: fc_shell> create_via_def design_H_shape_via \\ -shapes { {VIA12 {0.035 -0.035} {0.100 0.035}} {VIA12 {-0.100 -0.035} {-0.035 0.035}} {METAL1 {-0.130 -0.035} {0.130 0.035}} {METAL2 {-0.100 -0.065} {-0.035 0.065}} {METAL2 {0.035 -0.065} {0.100 0.065}} {METAL2 {-0.100 -0.035} {0.100 0.035}} } To overwrite an existing via definition, use the -force option; otherwise, the command fails if the specified via definition already exists.\n       If you are using double-patterning technology, you can assign mask constraints to the shapes or the enclosure layers, but not both.\n  To assign mask constraints to the shapes, use the mask_one mask_two, or mask_three keywords for the mask_constraint arguments when specifying the -shapes option.\n You would use this method if the mask constraints follow an arbitrary pattern.\n When you create a via with the create_via command, the via shapes inherit the mask constraints specified in the via definition.\n If the mask constraint you specify for an enclosure layer when you create a via differs from the mask constraint specified for the first shape in the via definition, the specified mask constraint determines the mask-shift used for all shapes on that layer.\n For example, fc_shell> create_via_def VIA12 \\ -shapes { {M1 {-0.037 -0.010} {-0.017 0.01} mask_two} {M1 {0.017 -0.010} {0.037 0.01} mask_one} {VIA1 {-0.037 -0.01} {0.037 0.01} mask_two} {M2 {-0.044 -0.010} {0.044 0.010} mask_one} } fc_shell> create_via -net n1 -via_def VIA12 \\ -origin {100.100 200.320}  To assign mask constraints to the enclosure layers, use the -lower_mask_pattern and -upper_mask_pattern options.\n You can specify either uniform or alternating as the mask pattern.\n In either case, you specify the mask constraint for the first shape when you create a via with the create_via command.\n If you specify uniform, all shapes on the layer use the specified mask constraint.\n If you specify alternating, the colors alternate from shape to shape after the first shape.\n For example, fc_shell> create_via_def VIA12 \\ -shapes { {M1 {-0.010 -0.030} {0.027 0.050}} {M1 {0.047 -0.030} {0.084 0.050}} {VIA1 {0.000 0.000} {0.074 0.020}} {M2 {-0.030 0.000} {0.104 0.020}} } \\ -lower_mask_pattern uniform fc_shell> create_via -via_def VIA12 -origin {000.100 200.320} -lower_mask_constraint mask_two To report information about the via definitions, use the report_via_defs command.\n This command reports the shapes that comprise the via definition but does not report the upper and lower mask patterns."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Useful Skew"}, {"role": "assistant", "content": "Changing clock latencies can balance the slack in successive timing path stages to optimize clock and data paths.\n This capability is called concurrent clock and data (CCD) optimization, which can reduce total negative slacks (TNS), worst negative slacks (WNS), area, and leakage power.\n In addition, it can improve correlation between physical synthesis and place-and-route."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Performing On Route Placement of Repeaters"}, {"role": "assistant", "content": "Use the preplace_group_repeaters command to place the group repeaters before the routing.\n This command places the group repeaters either in an ascending or descending order, default is ascending.\n The ascending order means that the command places the cells in a group from the lowest or left-most available track to the highest or right-most track.\n Note: A FAA-Base-Beta license is required to run the preplace_group_repeaters command.\n You must specify either the cell collections or group IDs of the group repeaters.\n The following example places group repeaters when the cell collections are specified.\n fc_shell> preplace_group_repeaters \\ -repeater_group_locations { { $cellGroup1, M2, {720 363.5}, \\ north, descending} {$cellGroup2, M2, {920 363.5}, east, ascending} \\       {$cellGroup3, M2, {1230 328.5}, east, ascending} \\ {$cellGroup4, M2, {1430 328.5}}, east} The following example places group repeaters when the group ID is specified.\n fc_shell> preplace_group_repeaters \\ -repeater_group_locations { { 1,M2, {720 363.5}, south, ascending} \\ {2, M2, {920 363.5},west, ascending} {3, M2, {1230 328.5}, \\ south, ascending} {4, M2, {1430 328.5}, west, descending}}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using ECO Scripts for Netlist Editing"}, {"role": "assistant", "content": "If the ECO changes are minimal, you can update the design by using netlist editing commands given.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true, before you run the netlist editing commands.\n For a list of netlist editing commands, see the Common Design Objects topic in the Fusion Compiler Data Model User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Synthesizing a Subblock"}, {"role": "assistant", "content": "To partition and plan the top-level design and create the lower-level blocks for subsequent bottom-up synthesis, when the floorplans of subblock and top-level design are available, perform the following steps:  Hierarchical Synthesis Flow When Floorplans are Available 1.\n Read in the full chip design and apply constraints as shown in the following example: fc_shell> set REF_LIBS \"stdcell.ndm macro.ndm\" fc_shell> create_lib TOP -technology techfile \\ -ref_libs $REF_LIBS fc_shell> analyze -format verilog $rtl_files fc_shell> elaborate TOP fc_shell> set_top_module TOP  fc_shell> load_upf fullchip.upf fc_shell> read_sdc fullchip.sdc 2.\n For the design partitions, split the constraints as shown in the following example: fc_shell> set_budget_options -add_blocks {BLOCK1 BLOCK2} fc_shell> split_constraints 3.\n Create the subblock design libraries with design information and enable block-specific reference library setup as shown in the following example: fc_shell> copy_lib -to_lib BLOCK1.nlib -no_design fc_shell> copy_lib -to_lib BLOCK2.nlib -no_design fc_shell> set_attribute -objects BLOCK1.nlib \\       -name use_hier_ref_libs -value true fc_shell> set_attribute -objects BLOCK2.nlib \\ -name use_hier_ref_libs -value true fc_shell> save_lib -all 4.\n Create the subblock design partitions as shown in the following example: fc_shell> commit_block -library BLOCK1.nlib BLOCK1 fc_shell> commit_block -library BLOCK2.nlib BLOCK2 fc_shell> save_lib -all 5.\n Load the UPF and SDC constraints for the unmapped subblocks as well as the top- level, which are generated by the split_constraints command earlier as shown in the following example: fc_shell> set_constraint_mapping_file./split/mapfile fc_shell> load_block_constraints -all_blocks -type SDC \\ -type UPF -type CLKNET fc_shell> save_lib -all 6.\n Load the floorplan for the subblocks and top-level design.\n 7.\n Run the compile_fusion command until logic optimization for the subblocks and top- level design is complete as shown in the following example: fc_shell> compile_fusion -to logic_opto 8.\n Perform standard cell placement followed by the pin assignment, timing estimation and budgeting.\n 9.\n After completing the design planning operations, rebuild the subblock and top-level design by opening the elaborated RTL NDM, loading floorplan, feedthroughs and budgets.\n Note: For details about each of the design planning operation, see the Design Planning User Guide"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I UPF Flows"}, {"role": "assistant", "content": "The UPF language establishes a set of commands to specify the low-power design intent for electronic systems.\n Using UPF commands, you can specify the supply network, switches, isolation, retention, and other aspects relevant to power management of a chip design.\n The same set of low-power design specification commands is to be used throughout the design, analysis, verification, and implementation flow.\n Synopsys tools are designed to follow the official IEEE 1801 UPF standard.\n The UPF language provides a way to specify the power requirements of a design, but without specifying explicitly how those requirements are implemented.\n The language specifies how to create a power supply network for each design element, the behavior of supply nets with respect to each other, and how the logic functionality is extended to support dynamic power switching to design elements.\n It does not contain any placement or routing information.\n In the UPF language, a power domain is a group of elements in the design that share a common set of power supply needs.\n By default, all logic elements in a power domain use the same primary supply and primary ground.\n Other power supplies can be defined for a power domain as well.\n A power domain is typically implemented as a contiguous voltage area in the physical chip layout, although this is not a requirement of the language.\n Each power domain has a scope and an extent.\n The scope is the level of logic hierarchy designated as the root of the domain.\n The extent is the set of logic elements that belong to the power domain and share the same power supply needs.\n The scope is the hierarchical level at which the domain is defined and is an ancestor of the elements belonging to the power domain, whereas the extent is the actual set of elements belonging to the power domain.\n Each scope in the design has supply nets and supply ports at the defined hierarchical level of the scope.\n A supply net is a conductor that carries a supply voltage or ground throughout a given power domain.\n A supply net that spans more than one power domain is said to be \"reused\" in multiple domains.\n A supply port is a power supply connection point between two adjacent levels of the design hierarchy, between the parent and child blocks of the hierarchy.\n A supply net that crosses from one level of the design hierarchy to the next passes through a supply port.\n supply set is an abstract collection of supply nets, consisting of two supply functions, power and ground.\n A supply set is domain-independent, which means that the power and ground in the supply set are available to be used by any power domain defined within the scope where the supply set was created.\n However, each power domain can be restricted to limit its usage of supply sets within that power domain.\n You can use supply sets to define power intent at the RTL level, so you can synthesize a design even before you know the names of the actual supply nets.\n A supply set is an abstraction of the supply nets and supply ports needed to power a design.\n Before such a       design can physically implemented (placed and routed), its supply sets must be refined, or associated with actual supply nets.\n supply set handle is an abstract supply set created for a power domain.\n By default, a power domain has supply set handles for the domain's primary supply set, a default isolation supply set, and a default retention supply set.\n These supply set handles let you synthesize a design even before you create any supply sets, supply nets, and supply ports for the power domain.\n Before such a design can be physically implemented, its supply set handles must be refined, or associated with actual supply sets; and those supply sets must be refined so that they are associated with actual supply nets.\n power switch (or simply switch ) is a device that turns on and turns off power for a supply net.\n A switch has an input supply net, an output supply net that can be switched on or off, and at least one input signal to control switching.\n The switch can optionally have multiple input control signals and one or more output acknowledge signals.\n A power state table lists the allowed combinations of voltage values and states of the power switches for all power domains in the design.\n level shifter must be present where a logic signal leaves one power domain and enters another at a substantially different supply voltage.\n The level shifter converts a signal from the voltage swing of the first domain to that of the second domain.\n An isolation cell must be present where a logic signal leaves a switchable power domain and enters a different power domain.\n The level shifter generates a known logic value during shutdown of the domain.\n If the voltage levels of the two domains are substantially different, the interface cell must be able to perform both level shifting (when the domain is powered up) and isolation (when the domain is powered down).\n A cell that can perform both functions is called an enable level shifter In a power domain that has power switching, any registers that must retain data during shutdown must be implemented as retention registers.\n A retention register has a separate, always-on supply net, sometimes called the backup supply, which keeps the data stable in the retention register while the primary supply of the domain is shut down."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Reading Designs Using the -autoread Option"}, {"role": "assistant", "content": "Use the analyze and elaborate commands followed by the set_top_module command.\n The analyze command automatically creates HDL template libraries on disk based on the name of the library provided by the -hdl_library option.\n The location of the HDL template libraries is controlled by the hdlin.hdl_library.default_dirname application option.\n When the -hdl_library option is not specified, the default library name is WORK.\n To specify a different default library name, use the hdlin.hdl_library.default_name application option.\n Note: All of the application options that control the RTL reading behavior have the hdlin prefix.\n The elaborate command builds the module specified without linking the rest of the design.\n Design linking can be performed only after the entire design is in memory, so linking is not performed by the elaborate command.\n This allows multiple elaborate commands to be run before performing the single linking of the entire design.\n The top-level module must be one of the modules that is elaborated.\n Linking of the design and setting the top-level module is done using the set_top_module command.\n The top-level module is given as an argument to the set_top_module command.\n The top-level module must be a module that was previously elaborated with the elaborate command.\n The set_top_module command sets the specified module to be       the top-level design, links the entire design, and creates a single block to be used for the remainder of the synthesis flow.\n The following script reads VHDL files using template libraries and creates a block called top.\n You do not need to specify the location of the template libraries on disk, which is automatically created by the analyze command based on the -hdl_library option.\n analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top If the top-level design is analyzed to an HDL template library other than the default library, you should provide the HDL template library name for the top-level design using the -hdl_library option.\n For example, analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl -hdl_library TOP_HDL_LIB top.vhd elaborate -hdl_library TOP_HDL_LIB top set_top_module top You can optionally specify the location of the HDL template libraries on disk by using the define_hdl_library command.\n For example, define_hdl_library BOT_HDL_LIB -path./TEMPLATES/BOT_HDL_LIB define_hdl_library MID_HDL_LIB -path./TEMPLATES/MID_HDL_LIB define_hdl_library WORK -path./TEMPLATES/WORK analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Controlling How Buffers are Added"}, {"role": "assistant", "content": "To add buffers to the individual nets of a bus in a specific pattern, use the following steps: 1.\n Define buffer patterns for the nets of a bus by using the create_eco_bus_buffer_pattern command.\n This command allows you to define patterns for staggering buffers on bused nets, which prevent clumping and overlapping of buffers.\n Table 72 Commands Associated With Bus Patterns To do this Use this command  create_eco_bus_buffer_pattern       To do this Use this command  report_eco_bus_buffer_patterns  get_eco_bus_buffer_patterns  remove_eco_bus_buffer_patterns The following example creates the buffer pattern shown in for a horizontal bus, where the first buffer is placed on the topmost net.\n The buffers are staggered by a distance of 2, starting from the left, and the pattern is repeated after every three buffers.\n fc_shell> create_eco_bus_buffer_pattern -name top_left \\ -first_buffer top -measure_from left -distance 2 -repeat_after 3  Buffer Patterns for a Horizontal Bus   First buffer The following example creates the buffer pattern shown in for a vertical bus, where the first buffer is placed on the rightmost net.\n Starting from the top, the second buffer is staggered by a distance of 2 from the first, the third a distance of 3 from the second, and the fourth a distance 2 from the third.\n After that, the pattern is repeated.\n fc_shell> create_eco_bus_buffer_pattern -name right_top \\ -first_buffer right -measure_from top \\ -user_specified_distance {2 3 2}        Buffer Patterns for a Vertical Bus   First buffer  2.\n Add buffers on the nets of the bus by using the add_buffer_on_route -user_specified_bus_buffers command.\n For each group of buffers that you add on the bused nets, use the {buffer_pattern_name library_cell_name x y....\n } format with the -user_specified_bus_buffers option to specify the  Name of the buffer pattern that you defined using the create_eco_bus_buffer_pattern command  Library cell to use  Coordinates of the location of the first buffer in the pattern The following example adds a group of buffers of type BUF2 on the bus named data_A, using a buffer pattern named BP1.\n The first buffer of the pattern is placed at location (100, 70).\n fc_shell> add_buffer_on_route [get_net data_A*] \\ -user_specified_bus_buffers {BP1 BUF2 100 70}"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Adding Hard Macro Cells"}, {"role": "assistant", "content": "You can specify orientations for leaf cells when you add them to a relative placement group.\n If you do not specify a leaf cell orientation, the tool automatically assigns a legal orientation for the leaf cells.\n To specify the orientation for leaf cells, use one of the following two methods:  Use the -orientation option with a list of possible orientations when you add the cells to the group with the add_to_rp_group command.\n  Set the rp_orientation attribute on leaf cells by using the set_attribute command.\n physopt_rp_enable_orient_opt variablevariablesphysopt_rp_enable_orient_opt The tool chooses one legal orientation from the list of orientations that you provide."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying the Clock Tree Synthesis Settings"}, {"role": "assistant", "content": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis:  clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the set_max_capacitance command.\n If you do not specify this constraint, the clock tree synthesis default is 0.6 pF.\n  clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the set_max_transition command.\n If you do not specify this constraint, the clock tree synthesis default is 0.5 ns.\n By default, these constraints apply to all corners associated with the current mode.\n To set the constraint for a specific mode, use the -mode option with the get_clocks command to identify the clocks.\n To set the constraint for specific corners associated with the specified mode, use the -corners option with the constraint command.\n Be careful to apply the correct constraints across all the modes and their associated corners.\n For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell> set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the -mode option with the get_clocks command to specify the mode and use the -corners option to specify the corner.\n For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell> set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell> set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell> set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]]"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Using Hierarchical Relative Placement for Straddling"}, {"role": "assistant", "content": "To create a hierarchical relative placement group by adding a group to another group, use the -rp_group option with the add_to_rp_group command.\n Specify the column and row position within the relative placement group by using the -column and -row options.\n The group you specify with the -rp_group option must be in the same design as the hierarchical group in which you are including it.\n When you include a relative placement group in a hierarchical group, it is as if the included group is directly embedded within its parent group.\n An included group can be used only in a group of the same design and only one time.\n However, a group that contains an included group can be further included in another group in the same design or can be instantiated in a group of a different design.\n The script in Example 43 creates a hierarchical group (rp4) that contains three included groups (rp1, rp2, and rp3).\n Groups rp1, rp2, rp3, and rp4 are all in the design top.\n The contents of groups rp1, rp2, and rp3 are treated as leaf cells when they are included in group rp4.\n You can further include group rp4 in another group in the design top, or you can instantiate group rp4 in a group of a different design.\n The resulting hierarchical relative placement group is shown in Example 43 Including Groups in a Hierarchical Group create_rp_group -name rp1 -columns 2 -rows 1 add_to_rp_group rp1 -cells U1 -column 0 -row 0 add_to_rp_group rp1 -cells U4 -column 1 -row 0  create_rp_group -name rp2 -columns 2 -rows 1 add_to_rp_group rp2 -cells U2 -column 0 -row 0 add_to_rp_group rp2 -cells U5 -column 1 -row 0        create_rp_group -name rp3 -columns 2 -rows 1 add_to_rp_group rp3 -cells U3 -column 0 -row 0 add_to_rp_group rp3 -cells U6 -column 1 -row 0  create_rp_group -name rp4 -columns 1 -rows 3 add_to_rp_group rp4 -rp_group rp1  -column 0 -row 0 add_to_rp_group rp4 -rp_group rp2  -column 0 -row 1 add_to_rp_group rp4 -rp_group rp3  -column 0 -row 2  Including Groups in a Hierarchical Group rp3 rp2 rp1 U3 U2 U4 U5 U6 U1 rp4 rp1 U4 U1 U3 U6 rp2 U2 U5 rp3 col 0 col 1 col 0 col 1 col 0 col 1 row 0 row 0 row 0 row 2 row 0 row 1 col 0"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Keepout Margins"}, {"role": "assistant", "content": "During placement and legalization, the floorplan information dictates where cells are placed.\n The following topics describe how to specify additional physical constraints that affect placement and legalization:  Defining Keepout Margins  Defining Area-Based Placement Blockages  Defining Placement Bounds  Defining Placement Attractions  Specifying Locations for Unmapped Cells  Defining Cell Spacing Constraints for Legalization"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Summary Report for Automatic Design Rule Fixing"}, {"role": "assistant", "content": "If your block uses double-patterning technology, you must perform separate signoff DRC fixing runs for the non-double-patterning routing rules and the double-patterning routing rules.\n To perform automatic fixing of the signoff DRC violations for a block that uses double- patterning technology, 1.\n Perform automatic fixing for the non-double-patterning signoff DRC violations by using the process described in Automatically Fixing Signoff DRC Violations When you run the signoff_check_drc and signoff_fix_drc commands, use the -unselect_rules option to ignore the double-patterning rules during signoff design rule checking.\n fc_shell> signoff_check_drc -unselect_rules { list_of_dpt_rules Note: To determine the double-patterning rules for your technology, see the design rule manual (DRM) provided by your vendor.\n 2.\n Perform automatic fixing for the double-patterning odd-cycle violations by using the process described in Automatically Fixing Signoff DRC Violations Before you run the signoff_fix_drc command, set the signoff.fix_drc.custom_guidance application option to dpt fc_shell> set_app_options \\ -name signoff.fix_drc.custom_guidance -value dpt When you run the signoff_check_drc and signoff_fix_drc commands, use the -select_rules option to consider only the double-patterning rules during signoff design rule checking.\n fc_shell> signoff_check_drc -select_rules { list_of_dpt_rules 3.\n Perform signoff design rule checking to verify the results by using the process described in Performing Signoff Design Rule Checking"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Previewing Repeater Groups"}, {"role": "assistant", "content": "The crosstalk management is only supported in the create_group_repeaters_guidance and add_group_repeaters commands flow.\n       The flow to avoid crosstalk during group repeater insertion is as follows: 1.\n Use the following command to query interleaving groups: create_group_repeaters_guidance -net -number_of_interleaving_groups number By default, the number argument is set to 1.\n For example, if the value of the number is 2, one net group is separated into two interleaving net groups.\n 2.\n Use the following command to manage crosstalk during group repeater insertion: add_group_releaters -nets | -bundles -first_distance_of_net_groups { {group_id1 $first_dist1} {group_id2 $first_dist2} \u2026} -repeater_distance $dist or add_group_releaters -nets | -bundles -cutlines_of_net_groups { {group_id1 $cutline_list1} {group_id2 $cutline_list2} \u2026}  If the option -first_distance_of_net_groups is specified, the command groups the nets based on the existing group IDs on nets and inserts repeaters based on the specified first distance for the various net groups.\n The repeater distance is same for all net groups.\n  If the option -cutlines_of_net_groups is specified, the command groups the nets based on the existing group IDs of the nets and inserts repeaters based on the cutlines for the various net groups."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Setting Up the IC Validator Environment"}, {"role": "assistant", "content": "The following topics describe the tasks you must perform before you run the IC Validator In-Design commands:  Setting Up the IC Validator Environment  Enabling IC Validator Multicore Processing  Defining the Layer Mapping for IC Validator In-Design Commands"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Mapping ECO Cells to Specific Spare Cells"}, {"role": "assistant", "content": "You can define mapping rules for programmable spare cells to control the  Overlapping of spare cells and PG nets  Splitting of multiple-height and merging of single-height spare cells  Compatibility of the different types of spare cells To do so, use the set_programmable_spare_cell_mapping_rule command before you run the place_freeze_silicon command.\n To report or remove the mapping rules you specify, use the report_programmable_spare_cell_mapping_rule command."}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Defining Routing Blockages"}, {"role": "assistant", "content": "Routing constraints provide guidance during routing.\n Table 29 describes the types of guidance provided by the routing constraints.\n Table 29 Routing Constraints Guidance Description                                 onWireTrack onGrid      physical_status  locked                 Table 29 Routing Constraints (Continued) Guidance Description                           derive_metal_cut_route_guides"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Specifying RedHawk and RedHawk-SC Working Directories"}, {"role": "assistant", "content": "To run RedHawk Fusion or RedHawk-SC Fusion features, enable the features and specify the location of the RedHawk or RedHawk-SC executable by setting the rail.product and rail.redhawk_path application options.\n For example, fc_shell> set_app_options -name rail.product -value redhawk|redhawk_sc fc_shell> set_app_options -name rail.redhawk_path \\ -value /tools/RedHawk_Linux64e5_V19.0.2p2/bin You must ensure that the specified executable is compatible with the Fusion Compiler version that you are using.\n See Also  Specifying RedHawk and RedHawk-SC Working Directories"}]}
{"messages": [{"role": "system", "content": "You are a chip design assistant. You should help the user to answer their question."}, {"role": "user", "content": "How do I Viewing Your Checkpoint History"}, {"role": "assistant", "content": "To return a list of all the checkpoints or checkpoint behaviors in the current session, or to return detailed information for any checkpoint or checkpoint behavior, use the get_checkpoint_data command.\n  To return a list of all the checkpoints that have been executed, specify the -list_names option: fc_shell> get_checkpoint_data -list_names remove_buffers place_opt_to_initial_drc incr_placement place_opt_to_initial_opto place_opt_to_final_opto  To return detailed information for a checkpoint, specify the checkpoint with the -name option.\n The tool returns the output as a Tcl dictionary: fc_shell> get_checkpoint_data -name place_opt_to_initial_drc memory 173.85 start_time 2.34 end_time 2.34 before_runtime 2.34 before_report_runtime 0.00 after_report_runtime 0.00 self_runtime       0.00 before_reports {} after_reports {app_options timing} before_actions {gropto} after_actions {} replace_actions {}  To return a list of all the checkpoint behaviors defined in your configuration, specify the -list_reports or -list_actions option: fc_shell> get_checkpoint_data -list_reports timing app_options  fc_shell> get_checkpoint_data -list_actions gropto placer_high_effort_congestion  To return the contents and associations of a checkpoint report or action, specify the report or action with the -report or -action option: fc_shell> get_checkpoint_data -report app_options contents { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position]  report_app_options -non_default \\ >./checkpoint/$name.$pos.app_options.rpt } before_patterns {*} after_patterns {} See Also  Viewing Your Checkpoint History"}]}
