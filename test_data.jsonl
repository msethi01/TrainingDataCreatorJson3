{"instruction": "How do I Using Incomplete UPF Information", "input": "", "output": "To load the power intent and apply it to a multivoltage design, 1. Read the UPF file by using the load_upf command. fc_shell> load_upf block.upf 2. If you are using the golden UPF flow and have a name-mapping file, read the file by using the read_name_map command. fc_shell> read_name_map block.nmf 3. (Optional) Verify the UPF consistency and identify any PG conflicts among the netlist, floorplan, and power intent. To verify the UPF consistency and identify PG conflicts, use the resolve_pg_nets -check_only command. This command identifies any issues and reports the changes that are made to resolve these issues when you commit the power intent. If you prefer to resolve the issues differently, you can use manual editing commands to resolve the issues before running the commit_upf command. 4. Commit the power intent by using the commit_upf command. fc_shell> commit_upf The commit_upf command performs global checks for UPF consistency; resolves PG conflicts among the netlist, floorplan, and UPF specification; and associates power strategies with existing multivoltage cells. For more information about associating power strategies with existing multivoltage cells, see Associating Power Strategies With Existing Multivoltage Cells 5. Report the associations made for the multivoltage cells by using the report_mv_path command. If the tool failed to associate any multivoltage cells, the command reports the causes for these failures. You must successfully commit the power intent before you continue with the design flow. Note: After successfully running the commit_upf command, the tool issues an error message if you try to use additional UPF commands, except for the set_related_supply_net connect_supply_net set_design_attributes set_port_attributes find_objects, and set_scope commands. To modify the power intent after running the commit_upf command, you must remove the existing UPF specification by using the reset_upf command and then reload the power intent."}
{"instruction": "How do I Deriving Routing Guides", "input": "", "output": "To remove routing guides from the current block, use the remove_routing_guides command. To remove specific routing guides, specify the routing rules, either as a list or collection, such as that returned by the get_routing_guides command. To remove all routing guides, specify the -all option. For example, to remove the new_width_rule routing rule, use the following command: fc_shell> remove_routing_rules new_width_rule"}
{"instruction": "How do I Mapping of Synchronous Reset or Preset Registers", "input": "", "output": "During test-ready compile, the tool replaces regular flip-flops with flip-flops that contain logic for testability. The following figure shows an example of how a D flip-flop is replaced with a scan register during test-ready compile. This type of architecture, a multiplexed flip- flop, incorporates a 2-input MUX at the input of the D flip-flop. The select line of the MUX enables two modes\u2014functional mode (normal data input) and test mode (scanned data input). In this example, the scan-in pin is si, the scan-enable pin is se, and the scan-out pin, so, is shared with the functional output pin, Q. si Clk se Q/so When you run the compile_fusion command, The tool maps all sequential cells directly to scan registers in your library The scan pins, such as scan enable and scan out, are unconnected The scan output pin of a scan register is used for scan connections Use the seqmap.bind_scan_pins application option to hold the scan enable pin inactive If the library contains no scan registers, the tool uses nonscan cells for mapping and issues a warning. Set the dont_use attribute on all scan registers in the library to map to nonscan cells"}
{"instruction": "How do I Enabling Enhanced Delay Optimization to Improve Total Negative", "input": "", "output": "In most cases, you can achieve better timing QoR by enabling high-effort timing mode for compile. To enable this mode, set the compile.flow.high_effort_timing application option to Running high-effort timing mode during compile can increase runtime because the tool performs multiple passes of placement and optimization to obtain optimal timing results."}
{"instruction": "How do I Setting Up Libraries", "input": "", "output": "The Fusion Compiler tool uses a search path to look for files that are specified with a relative path or with no path. To specify the search path, use the set_app_var command to set the search_path application variable to the list of directories, in order, in which to look for files. When the tool looks for a file, it starts searching in the leftmost directory specified in the search_path variable and uses the first matching file it finds. You can also use the Tcl lappend command to add your directories to the default search path, which is the directory from which you invoked the tool. For example, fc_shell> lappend search_path./mylibdir"}
{"instruction": "How do I Updating Supply Nets for ECO Cells", "input": "", "output": "When the tool maps an ECO cell, it looks for a spare cell with the same library cell name. If it is unable to find such a spare cell, the ECO cells remains unmapped. To identify and map such ECO cells to logically equivalent (LEQ) spare cells, use the following steps: 1. Identify the ECO cells that do not have matching spare cells by using the check_freeze_silicon command. 2. Find logically equivalent spare cells for these ECO cells by using the create_freeze_silicon_leq_change_list command. Specify The names of the unmapped ECO cells by using the -cells option A name for the output file by using the -output option This output file is a Tcl script with netlist editing commands. The commands replace each ECO cell with logically equivalent spare cells, which can be a Single spare cell with the same logical functionality, but a different library cell name Combination of up to two spare cells that give the same logical functionality 3. View the output Tcl file to ensure that the ECO mapping is satisfactory, and it if necessary. 4. Source the Tcl file in the tool to replace the ECO cells with their logical equivalents."}
{"instruction": "How do I Setting the Rerouting Mode", "input": "", "output": "If a pin has a via ladder, by default, Zroute connects to the topmost layer of a via ladder and not directly to the existing pin geometry. To modify the connection constraints, set the following application options: route.detail.via_ladder_upper_layer_via_connection_mode To allow vias to connect to the top level of a via ladder from below, set this application option to any route.detail.allow_default_rule_nets_via_ladder_lower_layer_connection To allow nets with default routing rules to connect directly to the pin or to any layer of the via ladder, set this application option to true"}
{"instruction": "How do I Querying Placement Blockages", "input": "", "output": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage. For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type allow_buffer_only -blocked_percentage 70 Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Saving UPF Information", "input": "", "output": "The UPF constraints for physical-only cells can cause issues when the UPF file is read into other tools that do not support physical-only cells, such as verification tools. Therefore, surround the UPF constraints for physical-only cells with the syntax shown in the following example: if {[info exists snps_handle_physical_only] && \\ $snps_handle_physical_only} { /* Supply net connections for filler cells */ connect_supply_net VDDS -ports [get_pins FILLER*/VDD] By default, the snps_handle_physical_only variable is set to true in the Fusion Compiler tool. Therefore, when you load and commit the UPF file, the constraints are applied to the physical-only cells. When you save a UPF file with the save_upf command, the tool uses the same syntax for the user-specified and tool-derived UPF constraints for physical-only cells. Therefore, these UPF constraints are ignored by any tool that does not have the snps_handle_physical_only variable set to true To create a UPF file that contains commands only for specific types of cells, use the -include or -exclude option with the save_upf command. These options accept arguments such as diode_cells pad_cells, and physical_only_cells. See the save_upf command man page for the complete list of arguments. Command filtering for specified cell types applies to the connect_supply_net set_related_supply_net create_power_domain, and set_isolation commands. You can apply command filtering to both block-level and full-chip UPF files."}
{"instruction": "How do I Inserting Multivoltage Cells", "input": "", "output": "To remove voltage areas from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_voltage_areas command. To remove all voltage areas from a block, use the -all option. To remove specific voltage areas from a block, specify the voltage area names."}
{"instruction": "How do I Adding Cells Within a Predefined Relative Placement Area", "input": "", "output": "To add a blockage within relative placement groups, use the -blockage option with the add_to_rp_group command. When you add a blockage using this command, you can specify The column and row position within the relative placement group by using the -column and -row options. If you do not specify a position, the tool adds the blockage to position (0,0). The size of the blockage by using the -height and -width options. If you do not specify the -height or -width option, the tool determines the size based on the tiling type of the relative placement group as follows: For a tiling type setting of bit_slice, the height default to the height of site row and the width to width of the column. For a tiling type setting of compression, the height default to the height of site row and the width to the width of one site. That the blockages can overlap with other relative placement blockages or other objects that are not relative placement cells by using the -allow_overlap option. The following example adds a blockage named gap1 to the rp1 relative placement group at position (0,2) that is one site row high and five site rows wide: fc_shell> add_to_rp_group rp1-blockage gap1 \\ -column 0 -row 2 -width 5 -height 1"}
{"instruction": "How do I Removing Routing Blockages", "input": "", "output": "To find routing blockages, use the get_routing_blockages command. For example, to get all the routing blockages in a block, use the following command: fc_shell> get_routing_blockages * To find the routing blockages for specific nets, use the -of_objects option to specify the nets of interest. For example, to find the routing blockages for the n1 net, use the following command: fc_shell> get_routing_blockages -of_objects [get_nets n1] To find the routing blockages in a specific location, use the get_objects_by_location -classes routing_blockage command."}
{"instruction": "How do I Enabling Leakage Power Optimization for the compile_fusion", "input": "", "output": "The leakage power of a block is scaled based on the switching probability of its supply nets, which represents the fraction of time a supply net is in the on state. You can specify the switching probability for one or more supply nets by using the set_supply_net_probability -static_probability command. By default, the switching probability is applied to the current scenario and the corresponding mode and corner. To specify modes, corners, or scenarios in which to apply the setting, use the -modes -corners, or -scenarios option. To get the switching probability of a supply net, use the get_supply_net_probability command, and to reset the value, use the reset_supply_net_probability command. By default, the tool propagates supply net activity through power switches and determines the static probability of the switched supply net based on the UPF power switch constraint. For example, consider the following UPF power switch constraint: create_power_switch my_switch \\ -output_supply_port {vout VDDS} \\ -input_supply_port {vin VDD} \\ -control_port {ms_sel ctrl1} \\ -control_port {ms_ctrl ctrl2} \\ -on_state {on vin {ms_ctrl &&!ms_sel}} The tool derives the static probability of the supply net named VDDS, which is connected to the output of the power switch, based on the probability of the power switch being on This is derived based on the following: The Boolean function specified with the -on_state option, which is ms_ctrl &&! ms_sel, and the switching activity (static probability) of the nets connected to the corresponding control ports, which are nets named ctrl1 and ctrl2. The switching probability of the supply net connected to the input supply port specified with the -on_state option, which is the supply net named VDD. The following application options control whether dynamic and leakage power are scaled based on the supply switching activity: The power.scale_dynamic_power_at_power_off option controls whether dynamic power is scaled. The default is false (no scaling). The power.scale_leakage_power_at_power_off option controls whether leakage power is scaled. The default is true (scaling is performed)."}
{"instruction": "How do I Defining Custom Vias", "input": "", "output": "To define a simple via or via array, use the following create_via_def syntax: create_via_def -cut_layer layer -cut_size { width height -upper_enclosure { width height -lower_enclosure { width height [-min_rows number_of_rows [-min_columns number_of_columns [-min_cut_spacing distance [-cut_pattern cut_pattern [-is_default] [-force] via_def_name You do not need to specify the enclosure layers; the tool determines them from the technology file by getting the metal layers adjacent to the specified via layer. By default, when you define a simple via, it is a single-cut via. To define a via array, specify the minimum number of rows and columns for the array ( -min_rows and -min_columns options), as well as the minimum cut spacing ( -min_cut_spacing option). By default, the cut pattern is a full array of cuts. To modify the cut pattern, use the -cut_pattern option. To overwrite an existing via definition, use the -force option; otherwise, the command fails if the specified via definition already exists. For example, to create a single-cut via definition named design_via1_HV for the VIA12 via layer, use the following command: fc_shell> create_via_def design_via1_HV \\ -cut_layer VIA12 -cut_size {0.05 0.05} \\ -lower_enclosure {0.02 0.0} -upper_enclosure {0.0 0.2} \\ To create a via definition with an alternating 2x2 cut pattern in which the lower-left cut is omitted, use the following command: fc_shell> create_via_def design_via12 -cut_pattern \"01 10\" To report information about the user-defined via definitions, use the report_via_defs command."}
{"instruction": "How do I Specifying Settings for Clock Latency Adjustments", "input": "", "output": "The timing of a design can be improved by reducing signal integrity issues on clock nets. To do so, the tool can derive nondefault routing rules with larger spacing requirements and assign them to the clock nets in regions without routing congestion. To enable this feature, use the following application option setting: fc_shell> set_app_options \\ -name cts.optimize.enable_congestion_aware_ndr_promotion -value true When the tool derives a new nondefault routing rule for a clock net, the new spacing requirement is dependent on the spacing requirement of the existing routing rule of that net. If the existing routing rule is A nondefault routing rule with a spacing requirement of less than or equal to two times the default spacing, the spacing requirement is doubled The name of this new nondefault rule is the original name with an _ext_spacing postfix. A nondefault routing rule with a spacing requirement of more than two times the default spacing, the spacing requirement is increased by one default spacing The name of this new nondefault rule is the original name with an _ext_spacing postfix. The default routing rule, the spacing requirement is doubled The name of this new nondefault rule is default_rule_equivalent_ndr_double_spacing."}
{"instruction": "How do I Constraint-Based Via Ladder Insertion", "input": "", "output": "The command generates a script file that defines the association between the library cell pins and the via ladder rules. This script file contains set_via_ladder_candidate commands for the library cell pins. By default, the generated script file is named auto_perf_via_ladder_association.tcl. To specify a different file name, use the -association_file option."}
{"instruction": "How do I Mapping ECO Cells to Logically Equivalent Spare Cells", "input": "", "output": "To map an ECO cell to a specific spare cell, use the map_freeze_silicon command. Specify the ECO cell name and the corresponding spare cell name by using the -eco_cell and -spare_cell options. The following example maps the ECO cell named ECO1 to the spare cell named spare_1: fc_shell> map_freeze_silicon -eco_cell ECO1 -spare_cell spare_1 You can specify the ECO cell to spare cell mapping by using a map file and specifying this map file name by using the -map_file option with the map_freeze_silicon command. The map file has the following format: ECO_cell_1 spare_cell_1 ECO_cell_2 spare_cell_2......"}
{"instruction": "How do I Threshold-Voltage-Based Filler Cell Insertion", "input": "", "output": "If your technology requires specific filler cells on the left or right sides of certain standard cells, use the create_left_right_filler_cells command to insert these filler cells. After you run the create_left_right_filler_cells command, perform standard filler cell insertion to fill the remaining gaps in the design. You must use the -lib_cells option to specify the rules for filler cell insertion. Each rule uses the following format: standard_cells } { left_filler_cells } { right_filler_cells For the standard_cells argument, You must specify a list of one or more standard cells You can use wildcards to specify the cell names If you specify multiple rules for the same standard cell, the command uses only the last rule specified for that cell. For the left_filler_cells and right_filler_cells arguments, At least one of these arguments must contain one or more filler library cells If only one of the arguments contains filler library cells, the tool inserts filler cells only on that side of the standard cells. The specified filler cells must meet the following requirements: They must have a design_type attribute of lib_cell or filler They must use the same site definition as the standard cells. The height of the standard cells must be an integer multiple of the filler cell heights. The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest. You can use wildcards for the filler cell names. When you use wildcards, the order of the cells is the same as that returned by the get_lib_cells command. The following example inserts filler cells on the left and right sides of the SC1 standard cells and only on the left side of the SC2 standard cells. The left and right filler cells are specified in decreasing size order, so that the command inserts the largest possible filler cell. fc_shell> create_left_right_filler_cells \\ -lib_cells { { {mylib/SC1} {mylib/LF4X mylib/LF2X} {mylib/RF2X mylib/RF1X} } { {mylib/SC2} {mylib/LF2X mylib/LF1X} {} } } When the create_left_right_filler_cells command inserts the filler cells, It checks for legal locations for the filler cells, but does not check advanced rules such as minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules. It inserts the filler cells immediately next to the standard cells; it does not consider the intercell spacing rules. See Also Standard Filler Cell Insertion Controlling Cell-Based Filler Cell Insertion You can control the following aspects of the filler cell insertion with the create_left_right_filler_cells command: The region in which to insert the filler cells By default, the command inserts filler cells next to the specified standard cells in the entire block. Use the -boundaries option to restrict filler cell insertion to the specified regions. You can specify one or more rectangular or rectilinear regions. Use the -voltage_areas option to restrict filler cell insertion to the specified voltage areas. The orientation of the filler cells By default, the command uses the allowable orientations of the row to place the filler cells. To use the same orientation as the standard cell, use the -follow_stdcell_orientation option. When you use this option, the tool swaps the right and left filler cells when the cell is flipped. The handling of one-unit-tile gaps By default, the command does not consider the one-unit-tile rule. To prevent the tool from inserting filler cells that would leave a one-unit-tile gap, use the -rules no_1x option. When you enable this rule, do not include filler library cells with a width of one- unit tile in the -lib_cells option; otherwise, the tool ignores this rule. The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller! filler_library_cell_name number To identify the filler cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the command uses the following naming convention: xofiller! prefix filler_library_cell_name number"}
{"instruction": "How do I Routing Secondary Power and Ground Pins", "input": "", "output": "To route a group of critical nets before routing the rest of the nets in the block, use the route_group command. To specify the nets to route, use one of the following options: -nets Use this option to specify the nets on the command line: fc_shell> route_group -nets collection_of_critical_nets -from_file Use this option to specify the nets in a file: fc_shell> route_group -from_file file_name If the specified nets are associated with a routing corridor, the nets are routed within the defined region. Note that global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations. By default, the route_group command ignores existing global routes, reuses dangling wires and existing detail routes on the specified nets, and runs global routing, track assignment, and detail routing on the specified nets. To perform incremental global routing, set the -reuse_existing_global_route option to true Note: You cannot use the -reuse_existing_global_route true option when routing the nets in a routing corridor. If you use this option, the global router ignores the routing corridors. To disable the reuse of dangling wires, set the -utilize_dangling_wires option to false To stop after global routing, set the -stop_after_global_route option to true By default, the detail router performs a maximum of 40 iterations search and repair iterations. If Zroute determines before then that all violations have been fixed or that it cannot fix the remaining violations, it stops. To change the maximum number of detail routing iterations, use the -max_detail_route_iterations option. By default, the route_group command does not fix soft DRC violations, such as bridge rule violations. To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_group_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_group_route_fix_soft_violations \\ -value true"}
{"instruction": "How do I Setting Up Multivoltage Designs", "input": "", "output": "Use the commands and application options described in this topic to create constraints for auto floorplanning. Commands Use the following two commands to set and report auto floorplanning constraints. These two commands do not affect explicit floorplanning. set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile. For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8 report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command. To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands: Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin Pin placement constraints set_block_pin_constraints set_individual_pin_constraints Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning. compile.auto_floorplan.initialize (default: auto auto : Creates missing floorplan information. The tool exits with an error when inconsistent information is provided. true : Always creates the core and boundary. false : Never creates the core and boundary; uses only existing information. The tool exits with an error when encountering missing or inconsistent information. By default, the following objects are preserved: Existing placement of fixed macros Existing placement of pins and pads Existing shaping of voltage areas compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped all : Always places and shapes objects even if they are fixed. Unplaced and unshaped objects will always be placed and shaped. unfixed : Places and shapes objects that are not fixed. Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify. Unplaced and unshaped objects will always be placed and shaped. unplaced, unshaped : Never places or shapes objects when they are already placed. Unplaced and unshaped objects will always be placed and shaped. none : Never places or shapes objects even if they are not already placed. This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning. Application option setting Fixed objects Placed objects Unplaced objects all unfixed unplaced, unshaped none compile.auto_floorplan.keep_bounds (default: auto auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing bounds. false : Removes existing bounds. compile.auto_floorplan.keep_placement_blockages (default: auto auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing placement blockages. false : Removes existing placement blockages. Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}
{"instruction": "How do I Controlling Sequential Mapping", "input": "", "output": "You need to have multiplexer cells in the logic library and also require to use multiplexing logic from the cell library. The following section describes library requirements to implement multiplexer cells for multiplexer optimization or to implement multiplexing logic from the cell library to control MUX mapping: Understanding Library Cell Requirements for Multiplexer Optimization Implementing Multiplexing Logic From Cell Library Understanding Library Cell Requirements for Multiplexer Optimization The multiplexer optimization requires the presence of at least a 2:1 multiplexer cell in the logic library. The inputs or outputs of this cell can be inverted. If a 2:1 multiplexer primitive cell does not exist in the library, you see the following warning message: Warning: Target library does not contain any 2-1 multiplexer. (OPT-853) An implementation of the MUX_OP cell from the target library is created, but it might not be the best implementation possible. All multiplexer cells in the target library can be used to construct the implementation of the MUX_OP cell except Enabled multiplexer cells Bused output multiplexer Multiplexers larger than 32 : 1 For Fusion Compiler to make the best use of the multiplexer cells available in your logic library, recompile the library or obtain a library compiled with version V3.4a or later from your ASIC vendor. Implementing Multiplexing Logic From Cell Library During logic synthesis, the tool implements multiplexing logic from the cell library using one of the following methods: AND, OR, and INV gates MUX gates The tool evaluates the area effect of both methods and selects the solution with the smallest area. You can specify that the tool uses MUX gates to implement specific multiplexing logic by applying the map_to_mux attribute on the corresponding SELECT_OP WVGTECH cells in the block, as shown in Example 16 Example 16 Using map_to_mux attribute to implement specific multiplexing logic # Apply the map_to_mux attribute on the SELECT_OP cell named C10 set_attribute -objects [get_cells C10] -name map_to_mux -value true # Query if the attribute is set as required on C10 get_attribute -objects [get_cells C10] -name map_to_mux #Run the compile step compile_fusion #Identify the cell created using the map_to_mux attribute get_cells -hier -filter \"map_to_mux==true &&!infer_mux_override\""}
{"instruction": "How do I Setting Checking Options", "input": "", "output": "Note: Missing via and unconnected pin checking is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows. Before you check for missing vias and unconnected pins, make sure you have the required input files as described in Preparing Design and Input Data for Rail Analysis Check for missing vias or unconnected pins in the block during voltage drop analysis or in a separate run. For example, you can perform the checking after completing the power structure and before running the place_opt command. This allows you to find power network errors in the design before rail analysis. By default, RedHawk/RedHawk-SC Fusion detects the following types of power network errors: Unconnected pin shapes: Pin shapes that are not contiguously and physically connected to an ideal voltage source. Missing vias: If two overlapping metal shapes do not contain a via within their overlapping area, it is considered a potential missing via error. To check for and fix missing vias or unconnected pins, 1. Define configuration options by using the set_missing_via_check_options command, as described in Setting Checking Options 2. Save the block by using the save_block command. 3. Perform the checking by using the analyze_rail -check_missing_via command, as described in Checking Missing Vias and Unconnected Pins. In the RedHawk-SC Fusion flow, you must specify the -check_missing_via option together with the -voltage_drop option. 4. Examine the checking results by opening the generated error files in the error browser or writing the checking results to an output file, as described in Viewing Error Data and Writing Analysis and Checking Reports 5. Insert PG vias to fix the reported missing vias, as described in Fixing Missing Vias"}
{"instruction": "How do I Controlling Threshold-Voltage-Based Filler Cell Insertion", "input": "", "output": "In the threshold-voltage-based flow, the tool selects the filler cells by using user-defined insertion rules, which are based the threshold-voltage types of the cells that border the gap. This flow is typically used only for established foundry nodes. To perform threshold-voltage-based filler cell insertion, 1. Ensure that the block is legalized by using the check_legality command. 2. Annotate the threshold-voltage types on the reference cells by using the set_cell_vt_type command. For example, to specify that all cells whose names end with _vtA have a threshold voltage type of vtA and the invx1 cell has a threshold voltage type of default, use the following commands: fc_shell> set_cell_vt_type -lib_cells \"*/*_vtA\" -vt_type vtA fc_shell> set_cell_vt_type -lib_cells \"mylib/invx1\" -vt_type default 3. Define the rules for inserting the filler cells by using the set_vt_filler_rule command. You define the rules by specifying the filler cells to insert based on the threshold- voltage types of the cells on the left and right of the gap being filled. For example, to specify that filler2x or filler1x cells can be inserted in a gap that has default threshold-voltage cells on the left and right sides and fillerA2x and fillerA1x cells can be inserted in a gap that has vtA threshold-voltage cells on the left and right sides, use the following commands: fc_shell> set_vt_filler_rule -vt_type {default default} \\ -filler_cells {myLib/filler2x myLib/filler1x} fc_shell> set_vt_filler_rule -vt_type {vtA vtA} \\ -filler_cells {myLib/fillerA2x myLib/fillerA1x} 4. Insert the filler cells by using the create_vtcell_fillers command."}
{"instruction": "How do I Specifying a Keepout Margin", "input": "", "output": "The Fusion Compiler tool supports the following orientations for relative placement groups: R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top. R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom. MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation. MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation. shows how the column and row positions in a relative placement group are placed for the four orientations. Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length. You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command. For example, the following command sets the relative placement group orientation to MY. fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy. Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}
{"instruction": "How do I Inserting Exterior Tap Walls", "input": "", "output": "ad_tap_cel_aray comandcomandsad_tap_cel_aray To add a tap cell array with specific placement, use the create_cell_array command. You must specify the name of the library cell to use for tap cell insertion ( -lib_cell option), and the x- and y-pitches. For example, fc_shell> create_cell_array -lib_cell myreflib/mytapcell \\ -x_pitch 10 -y_pitch 10 By default, the create_cell_array command inserts a tap cell in each location in the specified grid for the entire block. The tool starts inserting the tap cells at the bottom-left of the core area and uses the specified x- and y-pitches to determine the location of the subsequent tap cells. The inserted tap cells are snapped to the site rows and placed in the default orientation for the site row. If a location is occupied by a fixed cell, hard macro, soft macro, or power-switch cell, the command does not insert a tap cell at that location. You can modify the following aspects of the default behavior: The region in which to insert tap cells Use the -voltage area option to restrict the tap cell insertion to the specified voltage areas. Use the -boundary option to restrict the tap cell insertion to the specified region. If you use both options, the command inserts tap cells only in the overlapping region. The offset from the insertion region boundary Use the -x_offset option to shift the pattern startpoint to the right by the specified distance in microns. Use the -y_offset option to shift the pattern startpoint up by the specified distance in microns. The insertion pattern Use the -checkerboard option to insert a tap cell in every other location in the specified grid. To place a tap cell in the lower-left corner, use the -checkerboard even option. To keep the lower-left corner empty, use the -checkerboard odd option. In some design methodologies, you must insert a tap cell in empty spaces in the checkerboard pattern that are above or below specific cells, such as critical area breaker cells or boundary cells. To enable the insertion of these extra tap cells, use the -preserve_boundary_row_lib_cells option to specify the affected library cells. The snapping behavior To disable snapping of the inserted tap cells to the site rows, set the -snap_to_site_row false option. When you set this option to false, the tool uses R0 as the default orientation for the inserted cells. The orientation of the inserted tap cell instances To specify the orientation of the inserted tap cells, use the -orient option to specify one of the following orientation values: R0 R90 R180 R270 MX MY MXR90, or MYR90 The naming convention used to identify the inserted tap cell instances By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number"}
{"instruction": "How do I Changing the Structures of Relative Placement Groups", "input": "", "output": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option. The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns. This application option helps the relative placement engine know about the distance between the tap columns. This helps in better placement and structures of relative placement groups in the design. You must use this application option for n5 and older technical nodes. For n3 and beyond designs, the distance between tap columns is calculated automatically. place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}
{"instruction": "How do I Configuring Distributed Processing", "input": "", "output": "Multithreading performs tasks in parallel by using multiple cores on the same machine, using a single process memory image. When using multithreading, each parallel task is called a thread. For the best performance during multithreading, you should limit the number of threads to the number of available cores, which is the number of CPUs in the machine times the number of cores per CPU. The following commands support multithreading configured by the set_host_options command: place_opt clock_opt check_legality, when advanced legalization is enabled by setting the place.legalize.enable_advanced_legalizer application option to true insert_via_ladders route_auto route_global route_track route_detail, and route_eco Note: When you run routing with a single thread, the result is deterministic; if you start with the same block, you always get the same result. However, if you use multiple threads, the routing results are not deterministic; the final routing is slightly different between runs due to the varying division of tasks between threads. Global routing supports a deterministic mode for multicore routing. To enable this mode, set the route.global.deterministic application option to on route_opt signoff_check_drc signoff_fix_drc signoff_create_metal_fill signoff_fix_isolated_via write_def By default, all commands use a single thread. To enable multithreading for those commands that support it, set the -max_cores option of the set_host_options command to a value greater than one and less than or equal to the number of cores available on your machine, which is the number of CPUs in the machine times the number of cores per CPU. The number of cores specified by the -max_cores option applies to all commands that support multithreading. When you enable multithreading, multithreaded commands create and use the specified number of threads, even if the number is more than the number of available cores. You must set an appropriate number of threads, so that the command does not try to use more resources than it has. Overthreading can reduce performance because the extra threads compete for resources. For best performance, do not run more than one thread per available core. For example, if your machine has two CPUs and each CPU has three cores, specify six as the maximum number of threads: fc_shell> set_host_options -max_cores 6"}
{"instruction": "How do I Setting Skew and Latency Targets", "input": "", "output": "You can restrict the libraries used during clock tree synthesis for the top level or a lower level of the logical hierarchy of a design by using the set_target_library_subset -clock command. To enable the use of the target library subset, you must set the opt.common.enable_target_library_subset_opt application option to The following example specifies the buf1 and buf2 cells from the HVT_lib and LVT_lib libraries as clock tree references. However, it restricts the lower-level block named TSK_BLK to use only the cells from the LVT_lib library for its clock nets. Therefore, only buf1 and buf2 cells from the LVT_lib library are used as clock references for that block. fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} fc_shell> set_target_library_subset -clock {LVT_lib} \\ -objects [TOP/TSK_BLK] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1"}
{"instruction": "How do I Clock Tree Synthesis", "input": "", "output": "DFT wrapper clock gates refer to those clock gates that drive only DFT wrapper cells. The clock gating engine prefixes dft_wrapper_ to the names of all DFT wrapper clock gates clock gates irrespective of their origin. This helps to identify specific clock gates driving wrapper cells during automatic test pattern generation (ATPG). Table 24 Commands and their expected return values Command Expected Return Value get_clock_gates -gating_wrapper_cells_only dft_wrapper_ICG dft_wrapper_clock_gate_reg get_clock_gates -gating_wrapper_cells_only -origin tool_inserted dft_wrapper_clock_gate_reg get_clock_gates -gating_wrapper_cells_only -origin pre_existing dft_wrapper_ICG get_clock_gates {ICG clock_gate_reg} -gating_wrapper_cells_only get_clock_gates {ICG dft_wrapper_clock_gate_reg} -gating_wrapper_cells_only dft_wrapper_clock_gate_reg get_clock_gates {*clock_gate_reg} -gating_wrapper_cells_only dft_wrapper_clock_gate_reg This feature works only when you enable clock gate support for DFT wrapper cells. To enable clock gate support for DFT wrapper cells, set the following variable to true compile.clockgate.enable_dft_wrapper_cell_support The following figures show how a clock gate can be split so that different clock gates can gate internal cells and wrapper cells separately: Splitting a Clock Gate to Internal Cells and Wrapper Cells Gating Internal Cells and Wrapper Cells Separately Note: The clock gates cloned to gate wrapper cells alone, inherit their names from parent clock gates and have dft_wrapper_ appended to their names. This is not applicable to the names of self-gates that drive wrapper cells only. Table 25 shows how different types of clock gates are renamed. Table 25 How different clock gate types are renamed Clock Gate Type Name New Name clock_gate_reg dft_wrapper_clock_gate_reg icg_0 dft_wrapper_icg_0 Use the -gating_wrapper_cells_only option with the get_clock_gates command to return all clock gates (except self-gates) that drive wrapper cells only. This option can be used in conjunction with the already existing options. Use the compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option to restrict the renaming of pre-existing clock gates (driving wrapper cells only). This option accepts a list of strings as values. The clock gates matching any of the substrings provided in the application option are not renamed. Note: The compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs application option does not have any effect on the -gating_wrapper_cells_only querying option. Consider the following example: set_app_options -name compile.clockgate.substring_list_for_dft_wrapper_dont_rename_icgs -value {clk_gate_ctl clk_gate_snps} This prevents the renaming of any pre-existing clock gates that have the clk_gate_ctl or clk_gate_snps pattern in their name but can still be queried using the get_clock_gates -gating_wrapper_cells_only command."}
{"instruction": "How do I Inserting Dense Tap Arrays", "input": "", "output": "tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window. A tap mesh is typically inserted outside of a place and route block, but you can insert one in any area that is either completely inside or completely outside the core area. To insert a tap mesh, use the create_tap_meshes command. You must specify the following information: The tap cell used in the tap mesh (the -lib_cell option) By default, the command inserts the tap cells with R0 orientation. To place the cells with a different orientation, use the -orientation option. By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number The tap insertion region (the -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} The mesh window (the -mesh_window option) You specify the size of the mesh window by specifying an integer value for the pitch in the x- and y-directions. -mesh_window { x_pitch y_pitch The mesh window is aligned with the lower-left corner of the tap insertion region. When inserting the tap mesh, the command does not honor the standard cell rows or sites. It places a tap cell in the lower-left corner of each mesh window. If that location is blocked, the command uses the closest available location, which is measured as the Manhattan distance to the lower-left corner of the mesh window. If there is no available location, the command issues a warning and does not place a tap cell in that mesh window. After insertion, the command fixes the placement of the inserted tap cells."}
{"instruction": "How do I Highlighting Violations From the Error Browser Onto an ICV Heat", "input": "", "output": "You can select or unselect violation types from the heat map, as shown in figure and Violation Type Violation Type in ICV Heat Map To control the opacity of the heat map squares, adjust the Alpha percentage value. Set this percentage to 100% to create a completely filled block. The lower you set the percentage, the more transparent the block becomes, as shown in and Completely Filled Block You can adjust the range of colored squares by modifying the Bins value, as shown in and Bins Value Set to 5 Bins Value Set to 8 You can select or unselect layers from the heat map, as shown in and Selecting Layers Selecting Layers in the ICV Heatmap You can modify the squares of the heat map by right-clicking the colored squares and selecting Set Style. See and Set Style Select Style"}
{"instruction": "How do I Detail Routing", "input": "", "output": "Before you run track assignment, Define the common routing application options For information about the common routing application options, see the route.common_options man page. Define the global routing application options For information about the track assignment application options, see the route.track_options man page. Complete global routing To perform standalone track assignment, run the route_track command. The main task of track assignment is to assign routing tracks for each global route. During track assignment, Zroute performs the following tasks: Assigns tracks in horizontal partitions. Assigns tracks in vertical partitions. Reroutes overlapping wires. After track assignment finishes, all nets are routed but not very carefully. There are many violations, particularly where the routing connects to pins. Detail routing works to correct those violations. Note: Because track assignment replaces the global routes with actual metal shapes, the block no longer contains global routes after track assignment completes. By default, the route_track command is not timing-driven or crosstalk-driven. To enable timing-driven mode, set the route.track.timing_driven application option. To enable crosstalk-driven mode, set the route.track.crosstalk_driven and time.si_enable_analysis application options to true At the end of track assignment, Zroute reports a summary of the wire length and via count. Example 20 shows a track assignment report. Example 20 Track Assignment Report Wire length and via report: Number of M1 wires: 215327 : 0 Number of M2 wires: 1124740 VIA12SQ_C: 1067462... Total number of wires: 2508734 vias: 2769482 Total M1 wire length: 924480.9 Total M2 wire length: 4147032.0... Total wire length: 21281278.0 Longest M1 wire length: 1541.7 Longest M2 wire length: 926.0..."}
{"instruction": "How do I Generating Interclock Delay Balancing Constraints Automatically", "input": "", "output": "To define interclock delay balancing constraints, use the create_clock_balance_group command. At a minimum, you must specify a name for the clock balance group and the clocks in the group. To specify a name for the clock balance group, use the -name option. To specify the clock trees in the group, use the -objects option with the get_clocks command. By default, the clock balance group is defined for the clocks in the current mode. To define a clock balance group for the clocks of a specific mode, use the -objects option with the get_clocks -mode command. For example, to define a clock balance group named group1 that contains the clocks named clk1 and clk2 in the current mode, use the following command: fc_shell> create_clock_balance_group -name group1 \\ -objects [get_clocks {clk1 clk2}] To define a clock balance group named group2 that contains all the clocks in the mode named m2, use the following command: fc_shell> create_clock_balance_group -name group2 \\ -objects [get_clocks -mode m2] By default, the tool has a goal of zero delay offset between clocks. All clocks are balanced with the same insertion delay which usually is the longest insertion delay among the clocks. To specify a delay offset between clocks in the group, use the -offset_latencies option. By default, the delay offset applies to the current corner. To apply the delay offset to a specific corner, use the -corner option. For example, assume the design has three clocks named clk1, clk2, and clk3. If you want the insertion delay of clk1 and clk2 to be the same and the insertion delay of clk3 to be 100 less than that of clk1 and clk2, use the following command: fc_shell> create_clock_balance_group -name group3 \\ -objects [get_clocks {clk1 clk2 clk3}] \\ -offset_latencies {0 0 -100} Reporting Clock Balance Groups To report clock balance groups, use the report_clock_balance_groups command. The report lists the clock balance groups for all modes in all active scenarios. Removing Clock Balance Groups To remove clock balance groups, use the remove_clock_balance_groups command. You can either remove specific clock balance groups by specifying the clock balance groups or all clock balance groups by using the -all option. If you specify the clock balance groups to remove, they are removed from the current mode. However, if a specified group does not exist in the current mode, but does exist in another mode, it is removed from that mode. If you use the -all option, the clock balance groups are removed from all modes. For example, to remove a previously defined clock balance group named group1 from the current mode, use the following command: fc_shell> remove_clock_balance_groups group1 To remove all clock balance groups from all modes, use the following command: fc_shell> remove_clock_balance_groups -all"}
{"instruction": "How do I Specifying the Tapering Method", "input": "", "output": "Pin tapering is the method used to connect wires with nondefault routing rules to pins. Zroute supports pin tapering for both hard and soft nondefault routing rules; the tapering implementation is the same for both types of nondefault routing rules. Note: By default, if a net has both a nondefault routing rule defined by the create_routing_rule command and voltage-based spacing rules defined in the technology file, Zroute performs pin tapering on that net based on the nondefault routing rule. To disable pin tapering on these nets, set the route.detail.enable_ndr_tapering_on_voltage_rule application option to false You can specify the method used for pin tapering and control the tapering width, as described in the following topics: Specifying the Tapering Method Controlling the Tapering Width"}
{"instruction": "How do I Optimizing Datapaths", "input": "", "output": "All the extracted datapath elements and the synthetic operators are implemented by the DesignWare datapath generator in Fusion Compiler. The DesignWare datapath generator uses the smart generation technology to perform the following tasks: Implement datapath blocks using context-driven optimizations Revisit high-level optimization decisions for a given timing context Consider logic library characteristics Use these commands and application option for datapath implementation: set_datapath_architecture_options This command controls the strategies used to generate the datapath cells for arithmetic and shift operators. The following example specifies to use Booth-encoded architectures to generate multiplexers: fc_shell> set_datapath_architecture_options -booth_encoding true set_implementation This command specifies the implementation to use for dividers and synthetic library cell instances with a specified name. The following example specifies to use the cla3 implementation for the instantiated DesignWare cell U1. fc_shell> set_implementation cla3 U1 set_synlib_dont_use This command prevents using specific implementation. The following example specifies not to use the rpl implementation. fc_shell> set_synlib_dont_use \\ {dw_foundation/DW_div/cla standard/DW_div/rpl} compile.datapath.ungroup By default, all DesignWare cells and datapath blocks are ungrouped during timing optimization. To disable the ungrouping, set the compile.datapath.ungroup application option to false, changing from its default of true. For example, fc_shell> set_app_options \\ -name compile.datapath.ungroup -value false"}
{"instruction": "How do I Guided Power Grid Augmentation", "input": "", "output": "Timing-driven power grid augmentation inserts PG augmentation shapes in the specified regions of the block, except around timing-critical nets. By default, the tool does not perform timing-driven PG augmentation. To perform timing-driven power grid augmentation, 1. Ensure that the block is fully routed with very few or no DRC violations. 2. Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis The IC Validator tool uses the results of this voltage drop analysis to drive the power grid augmentation. 3. Set up the IC Validator environment as described in Setting Up the IC Validator Environment 4. (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 5. Set the application options for performing power grid augmentation, as described in Setting Options for Power Grid Augmentation At a minimum, you must define the power and ground nets on which to perform PG augmentation. To specify the power net, set the signoff.create_pg_augmentation.power_net_name application option. To specify the ground net, set the signoff.create_pg_augmentation.ground_net_name application option. If your design contains more than one power net, you must perform PG augmentation once for each power net. 6. Save the block to disk. When you run the signoff_create_pg_augmentation command, the IC Validator tool uses the on-disk information for the block, not the information in memory. To ensure accurate information, use the save_block command to save the current state of the block before running the signoff_create_pg_augmentation command. 7. Perform timing-driven power grid augmentation by using the signoff_create_pg_augmentation command with one or both of the following options: -nets This option explicitly specifies the critical nets. -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold. The unit for the slack threshold setting is the library time unit. You must also specify the technology node for which to perform the augmentation by using the -node option. If you must perform incremental PG augmentation because your design contains more than one power net, use the -mode add command on subsequent runs to append the PG augmentation shapes to the existing shapes. 8. Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis This second voltage drop analysis run measures the voltage drop after power grid augmentation. During timing-driven PG augmentation, the signoff_create_pg_augmentation command 1. Performs timing analysis, including multicorner-multimode analysis, to minimize timing impact 2. Identifies timing-critical nets based on the options you specify 3. Removes existing PG augmentation shapes By default, the command removes the PG augmentation shapes from the entire block. To keep the existing PG augmentation shapes, use the -mode add option. 4. Inserts PG augmentation shapes for the specified regions, except in the areas around the critical nets 5. Saves the updated block to disk 6. Generates a summary report See Also Standard Power Grid Augmentation Guided Power Grid Augmentation Removing PG Augmentation Shapes"}
{"instruction": "How do I Associating Checkpoints and Checkpoint Behaviors", "input": "", "output": "You can define two types of checkpoint behaviors: reports and actions. Define a checkpoint report to generate one or more reports supported by the tool or custom reports you create yourself. Define a checkpoint action to execute any kind of flow change before, after, or in place of the code block enwrapped by a checkpoint. For example, you might set an application option to a specific value before a particular checkpoint. Define these behaviors in your checkpoint.config.tcl file, which is automatically sourced by the checkpoint system. Defining Checkpoint Reports To define a checkpoint report, use the create_checkpoint_report command in your checkpoint.config.tcl file. Specify a unique name for the report and define the Tcl commands to generate the report. The following example defines a checkpoint report named timing, which writes the output of the report_qor and report_timing commands to disk: create_checkpoint_report timing { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position] report_qor -nosplit >./checkpoint/$name.$pos.qor.rpt report_qor -summary -nosplit >>./checkpoint/$name.$pos.qor.rpt report_timing -nosplit -max_paths 10 \\ >./checkpoint/$name.$pos.path.rpt Notice the use of the get_current_checkpoint command with the -name and -position options to give the generated reports a meaningful name. When these reports are generated, their names reflect the checkpoint that triggered them get_current_checkpoint -name ), as well as whether they were generated before or after the checkpoint ( get_current_checkpoint -position ). For example, if this checkpoint report is executed after a checkpoint named checkpoint_A, the generated reports are saved to the checkpoint directory, and the name of the QoR report is checkpoint_A.after.qor.rpt. The next example defines a checkpoint report named app_options, which writes all your non-default application options to disk: create_checkpoint_report app_options { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position] report_app_options -non_default \\ >./checkpoint/$name.$pos.app_options.rpt Defining Checkpoint Actions To define a checkpoint action, use the create_checkpoint_action command in your checkpoint.config.tcl file. Specify a unique name for the action and define the Tcl commands that constitute the action. The following example defines a checkpoint action named gropto, which enables global- route based buffering: create_checkpoint_action gropto { set_app_options -name place_opt.initial_drc.global_route_based \\ -value true The next example defines a checkpoint action named placer_high_effort_cong, which runs high-effort congestion reduction: create_checkpoint_action placer_high_effort_cong { set placer_command [get_current_checkpoint -script] set cong_option \"-congestion_effort high\" eval $placer_command $cong_option Notice the use of the get_current_checkpoint -script command and option, which retrieves the command originally enwrapped by the checkpoint and sets its congestion effort to high ( -congestion_effort high ). The -script option is typically used to define actions that replace the contents of a command. In this example, the action modifies the -congestion_effort option of the command that is enwrapped by the checkpoint associated with this action."}
{"instruction": "How do I Using Custom Router in the Fusion Compiler", "input": "", "output": "Custom Router is a shape-based router that supports gridded or gridless routing for custom digital, mixed signal, and analog routing needs. In the Fusion Compiler environment, you can use Custom Router to create interconnects (or routes) for critical signals between blocks and continue with the Fusion Compiler tool to complete the physical implementation. You can also preroute critical signals or clock nets by using a set of custom routing constraints. In the Fusion Compiler environment, Custom Router provides the following features: Prerouting in the batch mode Tcl-based routing constraint management Automatic routing with custom routing constraints Hybrid flow for prerouting Double Data Rate (DDR) net routing flow Custom Router is fully integrated with the Fusion Compiler tool, and supports advanced design rules for 20 nm and below technologies. To learn about using Custom Router in the Fusion Compiler environment, see the following topics: Using Custom Router in the Fusion Compiler Tool Before Using Custom Router Defining Routing Constraints Managing Constraint Groups Using Custom Routing Application Options Routing With the Custom Router Shielding the Nets Checking the Routing Results Using a Hybrid Routing Flow Using a DDR Routing Flow These topics describe how to use Custom Router to create custom routes in the Fusion Compiler environment. For detailed information about Custom Router, see the Custom Compiler Custom Router User Guide"}
{"instruction": "How do I Inserting Via Ladders", "input": "", "output": "To define instance-specific via ladder constraints, use the set_via_ladder_constraints command. You must specify the instance pins and the via ladder templates that can be used for those pins. For example, to enable the use of the VL1, VL2, and VL3 via ladder templates for the u1/i1 and u2/i2 pins, use the following command: fc_shell> set_via_ladder_constraints -pins {u1/i1 u2/i2} \\ {VL1 VL2 VL3} To report the via ladder constraints, use the report_via_ladder_constraints command. To remove via ladder constraints, use the remove_via_ladder_constraints command."}
{"instruction": "How do I Selecting and Multiplexing Logic", "input": "", "output": "The Fusion Compiler tool can map combinational logic representing multiplexers in the HDL code directly to a single multiplexer (MUX) or a tree of multiplexer cells from the target logic library. Multiplexers are commonly modeled with if and case statements. To implement the mutliplexer logic, the HDL Compiler uses SELECT_OP cells, which the Fusion Compiler tool map to combinational logic or multiplexers in the logic library. User-specified Tool evaluated Implemented using MUX gates Implemented using MUX or non MUX gates based on area costing analyze elaborate Infers Select_OP cells compile_fusion"}
{"instruction": "How do I Validating DEF Files", "input": "", "output": "If the site names used in the DEF file do not match the site names defined in the technology file, use the -convert_sites option to specify the site name mapping. For example, if the DEF file uses a site named CORE, but the technology file defines only a site named unit, use the following command to convert the site names when reading the DEF file: fc_shell> read_def -convert_sites { {CORE unit} } block.def"}
{"instruction": "How do I Querying Metal Fill", "input": "", "output": "The signoff_create_metal_fill command stores the output files in the run directory specified by the signoff.create_metal_fill.run_dir application option (or the signoff_fill_run directory if you do not use this option). For each fill run, the command creates a subdirectory named icv_run_# that contains the files generated for that run. When you perform metal fill insertion, the tool writes the following files to the output directory: block.LAYOUT_ERRORS, which contains details about the detected errors block.RESULTS, which contains a summary of the run results signoff_create_metal_fill.log, which contains a summary of the run environment icv_config_out, which contains the paths to the top-level block and the cell libraries layer.map, which contains the generated layer mapping file metal_fill_params.rh, which contains the metal fill parameters and options that you specified metal_fill_compress_params.rh, which contains the storage commands and indicates whether the compression mode was flat (NONE) or hierarchical (AUTO)./run_details directory, which contains all the data generated by the IC Validator tool for the metal fill insertion run"}
{"instruction": "How do I Using Hierarchical Relative Placement for Straddling", "input": "", "output": "To create a hierarchical relative placement group by adding a group to another group, use the -rp_group option with the add_to_rp_group command. Specify the column and row position within the relative placement group by using the -column and -row options. The group you specify with the -rp_group option must be in the same design as the hierarchical group in which you are including it. When you include a relative placement group in a hierarchical group, it is as if the included group is directly embedded within its parent group. An included group can be used only in a group of the same design and only one time. However, a group that contains an included group can be further included in another group in the same design or can be instantiated in a group of a different design. The script in Example 43 creates a hierarchical group (rp4) that contains three included groups (rp1, rp2, and rp3). Groups rp1, rp2, rp3, and rp4 are all in the design top. The contents of groups rp1, rp2, and rp3 are treated as leaf cells when they are included in group rp4. You can further include group rp4 in another group in the design top, or you can instantiate group rp4 in a group of a different design. The resulting hierarchical relative placement group is shown in Example 43 Including Groups in a Hierarchical Group create_rp_group -name rp1 -columns 2 -rows 1 add_to_rp_group rp1 -cells U1 -column 0 -row 0 add_to_rp_group rp1 -cells U4 -column 1 -row 0 create_rp_group -name rp2 -columns 2 -rows 1 add_to_rp_group rp2 -cells U2 -column 0 -row 0 add_to_rp_group rp2 -cells U5 -column 1 -row 0 create_rp_group -name rp3 -columns 2 -rows 1 add_to_rp_group rp3 -cells U3 -column 0 -row 0 add_to_rp_group rp3 -cells U6 -column 1 -row 0 create_rp_group -name rp4 -columns 1 -rows 3 add_to_rp_group rp4 -rp_group rp1 -column 0 -row 0 add_to_rp_group rp4 -rp_group rp2 -column 0 -row 1 add_to_rp_group rp4 -rp_group rp3 -column 0 -row 2 Including Groups in a Hierarchical Group rp3 rp2 rp1 U3 U2 U4 U5 U6 U1 rp4 rp1 U4 U1 U3 U6 rp2 U2 U5 rp3 col 0 col 1 col 0 col 1 col 0 col 1 row 0 row 0 row 0 row 2 row 0 row 1 col 0"}
{"instruction": "How do I Creating and Specifying Rail Scenarios for Rail Analysis", "input": "", "output": "By default, RedHawk or RedHawk-SC Fusion analyzes only the current design scenario for a multicorner-multimode design. To specify a different design scenario for rail analysis, use the rail.scenario_name application option. The tool honors the specified design scenario for the IR-driven features in power integrity flow, such as IR-driven placement, IR- driven concurrent clock and data optimization, and IR-driven optimization.\u200b Here is a script example: open_lib open_block set_app_option -name rail.technology -value 7 set_app_options -name rail.tech_file -value./Apache.tech set_app_options -name rail.lib_files -value {\\ A.lib \\ B.lib } set_app_options -name rail.switch_model_files -value {./switch_cells.txt } source./test_taps.tcl current_scenario func_max set_app_options -name rail.scenario_name -value func_typ analyze_rail -voltage_drop"}
{"instruction": "How do I Making Changes to a Block After Creating an Abstract", "input": "", "output": "In the Fusion Compiler tool, the create_abstract command includes netlist objects such as the cells, nets, and pins in the abstract view at both the top-level and block-level. This command reports the reasons for the inclusion of netlist objects. To report the reasons for including specific netlist objects in the abstract view, you can use the report_abstract_inclusion_reason command for objects across all hierarchies in the abstract. For each reason reported, a reason code is displayed. These reason codes correspond to the valid reasons for inclusion in the abstract. There can be multiple reasons for the same netlist object. Note: The report_abstract_inclusion_reason command does not report reasons for the hierarchical cells or pins on hierarchical cells. You can perform reason reporting from the top-level design, where the abstract is instantiated, without having the abstract as the current block. The following example reports the reasons for abstract inclusion for the pins in abstract view: fc_shell> report_abstract_inclusion_reason [get_pins -of_object [get_cells -filter \"is_hierarchical==false\" -hierarchical *]] Legend mv - MV Logic comp - Compact interface logic cell - Cell inclusion Pin name Reason(s) for inclusion AINV_P_260/I comp, cell AINV_P_260/VDD cell AINV_P_260/VSS cell AINV_P_260/ZN comp, cell AINV_P_262/I comp, cell AINV_P_262/VDD cell AINV_P_262/VSS cell AINV_P_262/ZN comp, cell AINV_P_263/I mv, comp, cell A legend is displayed at the beginning of the report for the queried objects, specifying the detailed reason for each reason code."}
{"instruction": "How do I Querying Group Repeater", "input": "", "output": "To remove a group of repeaters, use the remove_eco_repeater command. The nets are restored to their original names and routes shapes."}
{"instruction": "How do I Setting Clock Gating Transformations", "input": "", "output": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage. The tool looks for clock-gating cells that share a common clock and enable signal. This feature is on by default. The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching. Note that the the tool also checks clock-gating style and multivoltage constraints. Clock-gating cells with the dont_touch or size_only constraints are not optimized. To disable this feature, use the set_clock_gate_transformations command."}
{"instruction": "How do I Performing IR-Drop-Aware Placement During the clock_opt", "input": "", "output": "If you enable concurrent clock and data optimization for the clock_opt command, the tool performs clock power recovery on clock cells and registers during the final_opt stage. If you do not enable concurrent clock and data optimization, you can enable clock power recovery by using the following application option setting: fc_shell> set_app_options \\ -name clock_opt.flow.enable_clock_power_recovery \\ -value power Before you perform power recovery using this technique, you must 1. Enable scenarios for dynamic, leakage, or total power optimization by using the -dynamic_power and - leakage_power options of the set_scenario_status command 2. (Optional) Provide a switching activity by using the read_saif command If you do not provide switching activity, the tool uses default switching activity for dynamic power recovery. Instead of power recovery, you can enable area recovery on the clock cells and registers during the final_opt stage clock_opt command by using the following application option setting: fc_shell> set_app_options \\ -name clock_opt.flow.enable_clock_power_recovery \\ -value area"}
{"instruction": "How do I Enabling Local Skew Optimization", "input": "", "output": "By default, clock tree synthesis tries to achieve the best skew and latency for all clocks. However, this can lead to area, power, and runtime overhead for low frequency clocks, which have relaxed skew and latency targets. To specify a skew target, use the -target_skew option with the set_clock_tree_options command. To specify a latency target, use the -target_latency option with the set_clock_tree_options command. By default, when you define skew and latency targets, they apply to all clocks in all corners. To define targets for specific clocks, use the -clocks option. To define targets for specific corners, use the -corners option. To report the user-defined skew and latency targets, use the report_clock_tree_options command. To remove user-defined skew or latency targets, use the remove_clock_tree_options command. To remove all skew and latency targets, use the -all option; otherwise, use the appropriate -target_skew -target_latency -clocks, and -corners options to remove the specific targets."}
{"instruction": "How do I Exploring the Detailed Comparison Data", "input": "", "output": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further. To sort and filter the data, see the following topics: Sorting the Data Filtering Metrics Filtering Runs Example Analysis See Also Exploring the Detailed Comparison Data Sorting the Data Click any column header to sort the data using that metric. The first click performs an ascending sort, while the second click performs a descending sort. For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom: Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly. For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column. For example, to display only the first four runs in a table, select the runs as shown in Choose Baseline and Visible Runs Dialog Box Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further. Suppose you open the comparison report shown in and set the util60_aspect1%1_layerM9 run as the base run. Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer. This suggests that restricting the metal layers significantly impacts timing. You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs. You could restrict your analysis to your lower-utilization runs by turning off the visibility of your higher-utilization runs as shown in, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals. Displaying Lower-Utilization Runs"}
{"instruction": "How do I Abutting Standard Cells With Specific Filler Cells", "input": "", "output": "Some mask design rules are not handled during filler cell insertion because they have a low probability of occurrence and they require extensive computation time if handled during insertion. After filler cell insertion, use the replace_fillers_by_rules command to fix these design rule violations. You must specify the rule to fix by using the -replacement_rule option. Table 41 lists the design rules supported by this command and the keywords used to specify these rules. Table 41 Design Rules Supported by the replace_fillers_by_rules Command Design rule Description -replacement_rule keyword end_orientation half_row_adjacency Table 41 Design Rules Supported by the replace_fillers_by_rules Command (Continued) Design rule Description -replacement_rule keyword illegal_abutment od_horiztonal_distance horizontal_edges_distance small_filler_stacking max_vertical_constraint od_tap_distance random End Orientation Rule The end orientation rule searches for a continuous horizontal sequence of cells and modifies the orientation of the leftmost or rightmost filler cells if they are in the specified list of target filler cells. To select this rule, use the -replacement_rule end_orientation option with the replace_fillers_by_rules command. When you select this rule, you must specify The target filler cells To specify the target filler cells, use the -target_fillers option. The orientation modification To change the orientation for the leftmost filler cells, use the -left_end option. To change the orientation for the rightmost filler cells, use the -right_end option. To change the orientation for both the leftmost and rightmost filler cells, use both options. The valid values for these options are inverse, which flips the cell from its existing orientation R0_or_MX, which changes an MY orientation to R0 or an R180 orientation to MX MY_or_R180, which changes an R0 orientation to MY or an MX orientation to R180 To report the cells whose orientation would be changed, without actually changing the orientations, use the -check_only option. This option is valid only for the end orientation rule. Half Row Adjacency Rule The half row adjacency rule searches for half-height filler cells and replaces them based on the types of their neighboring standard cells. The standard cells are classified as one of the following types: Inbound The top or bottom boundary of an inbound standard cell is at the half-height location of the cell rows. When a half-height filler cell abuts an inbound cell, the abutting side of the half-height filler cell must have inbound-cell interaction polygons (ICIP). Regular The top and bottom boundaries of a regular standard cell are at the full-height location of the cell rows. When a half-height filler cell abuts a regular cell, the abutting side of the half-height filler cell must not have inbound-cell interaction polygons (ICIP). The replacement filler cells have the same height, width, and threshold voltage as the original filler cells. The cell libraries include both p-type and n-type replacement filler cells with inbound-cell interaction polygons (ICIP). For p-type half-height filler cells, the inbound- cell interaction polygons (ICIP) are at the bottom corners. For n-type half-height filler cells, the inbound-cell interaction polygons (ICIP) are at the top corners. shows the replacement of the half-height filler cells using the half row adjacency rule. Half-Height Filler Cell Replacement With Half Row Adjacency Rule Regular height Inbound height Inbound height FILL2_P FILL4_N Regular height Inbound height Inbound height FILL2_PR FILL4_NR Inbound-cell interaction polygons To select this rule, use the -replacement_rule half_row_adjacency option with the replace_fillers_by_rules command. The following table lists the options used to specify the replacement half-height filler cells. Each list can contain only one cell of each size. Table 42 Half-Height Replacement Filler Cells Abutting inbound standard cells Option to specify replacement filler cells -p_none -n_none -p_left -n_left -p_right -n_right -p_left_right -n_left_right -p_left_center_right -n_left_center_right Illegal Abutment Rule The illegal abutment rule restricts the filler cells that can abut certain other filler cells. To select this rule, use the -replacement_rule illegal_abutment option with the replace_fillers_by_rules command. When you select this rule, you must specify The filler cells considered for the check and their replacements The filler cells considered for the check are called target cells. To specify the target filler cells and their replacements, use the following syntax with the -replace_abutment option: { { target_cell refill_cell }... } To ignore filler cells that have a physical_status attribute of fixed or locked, use the -skip_fixed_cells option with the replace_fillers_by_rules command. The filler cells that cannot abut the target filler cells These filler cells are called illegal cells. To specify the illegal cells, use the -illegal_abutment option. Note that the target filler cells specified in the -replace_abutment option are also considered illegal cells. For example, the following command fixes illegal abutment violations where the FILL1a and FILL1b filler cells cannot abut the FILLx and FILLy cells: fc_shell> replace_fillers_by_rules -replacement_rule illegal_abutment \\ -replace_abutment { {FILL1a CFILL1a} {FILL1b CFILL1b} } \\ -illegal_abutment {FILLx FILLy} shows the original row, which violates this rule, and the resulting row, which uses the replacement filler cells to fix the violations. The target filler cells are shown in red, while the replacement filler cells are shown in green. Fixing an Illegal Abutment Violation Maximum Horizontal Edge Length Rule The maximum horizontal edge length rule restricts the horizontal length of a sequence of abutted objects on a specific layer. To select this rule, use the -replacement_rule horizontal_edges_distance option with the replace_fillers_by_rules command. When you select this rule, you must specify The maximum horizontal length To specify the maximum length, use the -max_constraint_length option. The layer to check To specify the layer, use the -layer option. The cells considered for the check and the filler cells that can be used to replace the violating filler cells The filler cells considered for the check are called constrained cells. The filler cells considered to replace violating cells are called unconstrained cells To specify multiple constrained cell groups and their replacement cells, use the following syntax with the -refill_table option: { {{ refill_cell constrained_cells }}... } You can use this syntax to fix violations for threshold-voltage-based filler cells. To specify a single constrained cell group, use the -constraint_fillers option. To specify the replacement cells, use the -non_constraint_fillers option. Note: If you use both methods, the command uses only the information specified in the -refill_table option. For example, the following command identifies and fixes maximum horizontal edge length violations where the horizontal length on the M2 layer exceeds 30 um: fc_shell> replace_fillers_by_rules \\ -replacement_rule horizontal_edges_distance \\ -max_constraint_length 30 -layer M2 \\ -refill_table { {{VT1_FILL1} {VT1_DECAP4 VT1_DECAP2}} {{VT2_FILL1} {VT2_DECAP4 VT2_DECAP2}} } Maximum Horizontal Length Rule The maximum horizontal length rule restricts the horizontal length of a sequence of abutted filler cells. To select this rule, use the -replacement_rule od_horiztonal_distance option with the replace_fillers_by_rules command. When you select this rule, you must specify The maximum horizontal length To specify the maximum length, use the -max_constraint_length option. The cells considered for the check and the filler cells that can be used to replace the violating filler cells The filler cells considered for the check are called constrained cells. The filler cells considered to replace violating cells are called unconstrained cells To specify multiple constrained cell groups and their replacement cells, use the following syntax with the -refill_table option: { {{ refill_cell constrained_cells }}... } You can use this syntax to fix violations for threshold-voltage-based filler cells. To specify a single constrained cell group, use the -constraint_fillers option. To specify the replacement cells, use the -non_constraint_fillers option. Note: If you use both methods, the command uses only the information specified in the -refill_table option. For example, the following command identifies and fixes maximum horizontal length violations where the horizontal length exceeds 70 um: fc_shell> replace_fillers_by_rules \\ -replacement_rule od_horiztonal_distance -max_constraint_length 70 \\ -refill_table { {{VT1_FILL1} {VT1_DECAP4 VT1_DECAP2}} {{VT2_FILL1} {VT2_DECAP4 VT2_DECAP"}
{"instruction": "How do I Synthesizing, Optimizing, and Routing Clock Trees With the", "input": "", "output": "To perform standalone clock tree synthesis, use the synthesize_clock_trees command, as shown in the following example: fc_shell> synthesize_clock_trees When you use this command, the tool performs the following tasks: 1. Clock tree synthesis Before clock tree synthesis, the tool performs virtual routing of the clock nets and uses RC estimation to determine the clock net timing. 2. Clock tree optimization Before clock tree optimization, the tool performs global routing on the clock nets and uses RC extraction to determine the clock net timing. During clock tree optimization, the tool performs incremental global routing on clock nets modified during optimization. Note: This command does not detail route the clock trees. By default, this command works on all clocks in all active scenarios that are enabled for setup or hold analysis. You can specify the clocks to be built by using the -clock option. For example, to build only the CLK clock tree, use the following command: fc_shell> synthesize_clock_trees -clocks [get_clocks CLK] After clock tree synthesis, the tool sets the clocks in all modes of all active scenarios as propagated."}
{"instruction": "How do I Specifying Boundary Cell Placement Rules", "input": "", "output": "Boundary cells include both end-cap cells placed on the left, right, top, and bottom boundaries, and inside and outside corner cells. You can specify different library cells for each boundary cell type. To specify the library cells, use the following options with the set_boundary_cell_rules command: -left_boundary_cell and -right_boundary_cell These options specify a single library cell that is used for the end-cap cells for the left and right boundaries, respectively. -top_boundary_cells and -bottom_boundary_cells These options specify a list of library cells that are used for the end-cap cells for the top and bottom boundaries, respectively. The command inserts the cells in the specified order. If the remaining space is smaller than the current cell, the command inserts the next cell in order that fits in the remaining space. For a vertical-row block, rows start at the bottom and end at the top, so the top boundary is along the left side of the block and the bottom boundary is along the right side of the block. For the flipped rows in a double-back block, the top boundary cells are used on the bottom boundaries and the bottom boundary cells are used on the top boundaries. -top_tap_cell and -bottom_tap_cell These options specify a single library cell that is used for the tap cells on the top and bottom boundary rows, respectively. The tool inserts the tap cells to ensure that the end-cap cells inserted on the top and bottom boundary rows comply with the maximum diffusion-to-tap distance limit. -top_left_outside_corner_cell -top_right_outside_corner_cell -bottom_left_outside_corner_cell, and -bottom_right_outside_corner_cell These options specify a single library cell that is used for each outside corner location. -top_left_inside_corner_cells -top_right_inside_corner_cells -bottom_left_inside_corner_cells, and -bottom_right_inside_corner_cells These options specify a list of library cells for each inside corner location. The tool inserts the first corner cell that matches the size of the inside corner. If none matches exactly, it inserts the first cell that can be placed without violating any rules. shows the boundary and corner cell locations for a horizontal-row block with two hard macros or blockages. Note that the cell locations are flipped when the row is flipped. Boundary Cell Locations"}
{"instruction": "How do I Improving the Banking Ratio", "input": "", "output": "To report a summary of the multibit banking ratio, a list of reasons for not banking or debanking cells, and the number of cells for each reason, use the report_multibit command, as shown in the following example: fc_shell> report_multibit **************************************** Report : report_multibit...... **************************************** Total number of sequential cells: 4020 Number of single-bit flip-flops: 3149 Number of single-bit latches: 29 Number of multi-bit flip-flops: 842 Number of multi-bit latches: 0 Total number of single-bit equivalent cells: 853 (A) Single-bit flip-flops: 3149 (B) Single-bit latches: 29 (C) Multi-bit flip-flops: 5352 (D) Multi-bit latches: 0 Sequential cells banking ratio ((C+D)/(A+B+C+D)): 62.74% Flip-flop cells banking ratio ((C)/(A+C)): 62.96% BitsPerflop: 2.13 Reasons for sequential cells not mapping to multibit during RTL Banking: Explanations: r12: Cell is single bit because its parent multibit cell was debanked due to improve timing (Number of cells: 91) r31: Cell cannot be banked to multibit because it is assigned to use single-bit lib cell (Number of cells: 63) Reasons for multibit sequential cells not debanking to single bit cells during RTL Debanking: Explanations:: r45: Multibit cell cannot be debanked because it is not critical enough (Number of cells: 478) To report all the cells that are ignored during banking and debanking, use the -ignored_cells option with the report_multibit command. To report the compatible multibit and single-bit library cells that can be used for banking and debanking, use the check_multibit_library command. The following example generates a compatible library cell report for RTL banking and debanking: fc_shell> check_multibit_library -stage RTL \\ -banking -debanking **************************************** Report : check_multibit_library Flow : RTL BANKING **************************************** Single bit Lib cell Compatibility Multi bit Lib cell SB_reg1 PIN ORDER MISMATCH MB_reg1 SB_reg2 COMPATIBLE MB_reg2 Singlebit with NO Multibit Equivalents SB_reg3 **************************************** Report : check_multibit_library Flow : RTL DEBANKING **************************************** Multi bit Lib cell Compatibility Single bit Lib cell MB_reg2 COMPATIBLE SB_reg2 MB_reg1 PIN ORDER MISMATCH SB_reg1 Multibit with NO Singlebit Equivalents MB_reg3"}
{"instruction": "How do I Tracing Minimum Path Resistance Using the Mouse Tool", "input": "", "output": "When the analysis is complete, run the report_rail_result -type minimum_path_resistance command to display a minimum path resistance map, write the results to an output file, or query the attributes on the cell instances or pins. The following example writes the calculated minimum path resistances for the VDD net to an output file called minres.rpt. fc_shell> open_rail_result fc_shell> report_rail_result -type minimum_path_resistance \\ -supply_nets { vdd } minres.rpt fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669 The output minres.rpt report includes the entire resistance information. fc_shell> sh cat minres.rpt FEED0_14/vbp 518.668 INV61/vdd 158.268 ARCR0_1/vbp 145.582 FEED0_5/vdd 156.228 INV11/vbp 518.669 To write out a detailed minimum resistance path report for a cell instance, run the report_rail_minimum_path command and specify the net and the cell to report. To see the segment-by-segment resistance of that minimum resistance path shown in the GUI, use the -error_cell option of the report_rail_minimum_path command to save the geometries on the path of the minimum path resistance to an error cell. You can then open the error cell in an error browser and check the minimum resistance path from the pin of the cell to the nearest tap and trace each go-through geometries. In the following example, all geometries on the minimum resistance path are traced and written to the error cell named test.err. fc_shell> open_rail_result fc_shell> report_rail_minimum_path -cell U19 -net VDD -error_cell Shown in, each geometry is classified by layer in the error browser. Click a geometry to check for detailed information, such as IR drop, resistance, bounding box, and so on. In the GUI, the traced path is highlighted in yellow in the design layout (see ). Displaying Error Cells in the Error Browser Traced Segment is Highlighted in the Design Layout See Also Displaying Maps in the GUI Writing Analysis and Checking Reports Querying Attributes"}
{"instruction": "How do I Controlling IR-Drop-Aware Placement", "input": "", "output": "During placement, the tool can use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values, which reduces the power density of such areas. To perform IR-drop-aware placement, use the following steps: 1. Place and legalize the block. 2. Set up for RedHawk Fusion and perform static or dynamic voltage drop analysis by using the analyze_rail -voltage_drop command as shown in the following example: fc_shell> source redhawk_setup.tcl fc_shell> analyze_rail -voltage_drop static -nets {VDD VSS} For more information, see Performing Voltage Drop Analysis 3. Enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true 4. (Optional) Specify additional settings for IR-drop-aware placement, as described in Controlling IR-Drop-Aware Placement 5. Rerun placement. Note: To perform IR-drop-aware placement, you must have Digital-AF and SNPS_INDESIGN_RH_RAIL license keys."}
{"instruction": "How do I Setting Up the Executables", "input": "", "output": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished. You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished. To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command. When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database. By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed. However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results. Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not. When opening rail results, the tool does not detect if the result is generated with or without the -bg option. The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa. Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory. To check if the background analyze_rail process is active, use the report_background_jobs command."}
{"instruction": "How do I Creating Skew Groups", "input": "", "output": "To define clock cell spacing rules, use the set_clock_cell_spacing command. At a minimum, you must specify the minimum spacing in the x-direction or the y-direction; typically you would specify the minimum spacing in both directions. To specify the minimum spacing in microns in the X-direction, set the -x_spacing option to a nonzero value This value is usually dependent on the library cell's drive strength and clock frequency. Y-direction, set the -y_spacing option to a nonzero value This value is usually less than half a row height. Note: Using a large spacing value increases the skew because the cells are spaced further away from the intended clusters of sinks. By default, the specified cell spacing requirements apply to all clock cells. To restrict the clock cell spacing rules to specific Library cells, use the -lib_cells option Clocks, use the -clocks option If adjoining clock cells both have cell spacing rules for a given direction, the sum of the spacing values applies. For example, if two adjoining clock cells both have a minimum cell spacing of 5 microns in the x-direction, they are placed at least 10 microns apart in the x-direction. You can relax the adjoining cell spacing rule by setting the cts.placement.cell_spacing_rule_style application option to maximum, in which case the tool uses the larger of the spacing settings between two adjoining cells instead of the sum of the spacing settings. For example, the clock cells in the previous example are placed at least 5 microns apart in the x-direction, instead of 10 microns. The clock cell spacing rules defined by the set_clock_cell_spacing command are honored by the synthesize_clock_trees balance_clock_groups, and clock_opt commands. To report clock cell spacing rules, use the report_clock_cell_spacings command. To remove clock cell spacing rules, use the remove_clock_cell_spacings command. By default, this command removes all clock cell spacing rules. To remove specific clock cell spacing rules, use the -lib_cells option."}
{"instruction": "How do I Setting Self-Gating Options", "input": "", "output": "To set up the block for self-gating, perform the following steps before you run the compile_fusion command: 1. Enable self-gating by setting the compile.clockgate.self_gating application option to true fc_shell> set_app_options -name compile.clockgate.self_gating \\ -value true 2. Apply switching activity by using the read_saif or set_switching_activity command. 3. (Optional) Specify self-gating settings using the set_self_gating_options command. For more information, see Setting Self-Gating Options 4. (Optional) Override the tool's default behavior of selecting self-gating objects by using the set_self_gating_objects command. For more information, see Controlling the Selection of Self-Gating Objects"}
{"instruction": "How do I Synthesizing the Top-Level", "input": "", "output": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1. Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2. Apply any block-specific constraints and settings required for synthesizing the block. 3. Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command. 4. Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5. Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "By default, the Fusion Compiler tool can use all of the library cells available in the cell libraries when performing optimization or clock tree synthesis on the block. To restrict the cell usage, use the set_lib_cell_purpose command after the block is in memory. The command has a block scope and is persistent across tool sessions. The specified settings are restored when the block is reopened. To specify how the tool can or cannot use library cells, use the -include and -exclude options with the set_lib_cell_purpose command. Both of these options accept one or more of the following values: all cts hold optimization none The -include option sets the included_purposes attribute on the specified library cells. The -exclude option sets the excluded_purposes attribute on the specified library cells. Note: If a library cell has a dont_use attribute, it is excluded from all uses, which is the same as if you specified set_lib_cell_purpose -include none for that cell. When the tool performs optimization, which includes setup, hold, and logical DRC fixing, it can use library cells that have an included purpose of optimization hold, or both. When the tool performs clock tree synthesis, it can use library cells that have an included purpose of cts For example, to disallow the use of a set of library cells for all uses, use the following command: fc_shell> set_lib_cell_purpose -include none lib_cells To allow a set of library cells to be used only for clock tree synthesis, use the following commands: fc_shell> set_lib_cell_purpose -include none lib_cells fc_shell> set_lib_cell_purpose -include cts lib_cells To allow a set of library cells to be used for all uses except clock tree synthesis, use the following command: fc_shell> set_lib_cell_purpose -exclude cts lib_cells To use the asterisk wildcard character (*) to query a collection of cells, you must use the get_lib_cells command. However, the set_lib_cell_purpose command excludes synthetic modules by default. Therefore, you should use the set_synlib_dont_use command to exclude synthetic modules. For example, fc_shell> set_lib_cell_purpose \\ -include none [get_lib_cells */*01_*_AB] Warning: The'set_lib_cell_purpose' command cannot be used on synthetic library cell'standard:*OPMOD.DW01_ADD_AB.timing'. (NDMUI-511)"}
{"instruction": "How do I Analyzing Clock Trees in the GUI", "input": "", "output": "The timing characteristics of the clock network are important in any high-performance design. To obtain detailed information about the clock networks in the current block, use the report_clock_timing comandcomandsreport_clock_timing report_clock_timing command. You must use the -type option to specify the type of report to generate. The report_clock_timing command can generate the following types of reports: Single-clock local skew To generate a single-clock local skew report, use the -type skew option. Interclock skew To generate an interclock skew report, use the -type interclock_skew option. Latency To generate a latency report, use the -type latency option. Transition To generate a transition time report, use the -type transition option."}
{"instruction": "How do I Transferring to Back End", "input": "", "output": "When performing concurrent clock and data optimization using the compile_fusion command, you can give a higher priority to the WNS optimization of Certain path groups by specifying them by using the ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2} If a path group you specify with this application option is also specified as a path group to skip with the ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization. Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell> set_app_options \\ -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified path groups. The worst 300 timing paths by setting the ccd.enable_top_wns_optimization application option to true"}
{"instruction": "How do I Prerequisites for Routing", "input": "", "output": "shows the basic Zroute flow, which includes clock routing, signal routing, DFM optimizations, and route verification. Basic Zroute Flow"}
{"instruction": "How do I Running the signoff_fix_drc Command", "input": "", "output": "Before you run the signoff_fix_drc command, configure the run by setting the application options shown in Table 44. To set the application options, use the set_app_options command. To see the current settings, use the report_app_options command. Table 44 Application Options for Signoff DRC Fixing Application option Default Description signoff.fix_drc. advanced_guidance_for_rules all signoff_fix_drc all off signoff.fix_drc.check_drc local local global signoff.fix_drc. custom_guidance dpt Table 44 Application Options for Signoff DRC Fixing (Continued) Application option Default Description signoff.fix_drc. fix_detail_route_drc global signoff_fix_drc global local signoff.fix_drc. init_drc_error_db signoff_fix_drc signoff_check_drc signoff.fix_drc. last_run_full_chip false false true signoff.fix_drc. max_detail_route_iterations signoff.fix_drc. max_errors_per_rule signoff.fix_drc.run_dir signoff_fix_drc signoff.fix_drc. target_clock_nets false false true signoff.fix_drc. user_defined_options"}
{"instruction": "How do I Inserting Clock Gates in an RTL Design", "input": "", "output": "In a multivoltage design, the different hierarchies of the design might have different operating conditions and use different target library subsets. When inserting clock-gating cells in a multivoltage design, the tool chooses the appropriate library cells based on the specified clock-gating style as well as the operating conditions that match the operating conditions of the hierarchical cell of the design. If you do not specify a clock-gating style, the tool uses a default style where the test point is before and the observation output is false If the tool does not find a library cell that suits the clock-gating style and the operating conditions, the tool issues a warning message and does not insert a clock-gating cell. To check whether there are integrated clock-gate cells available for clock-gate insertion, use the check_clock_gate_library_cell_availability command."}
{"instruction": "How do I Enabling Advanced PG Net Checks", "input": "", "output": "For advanced technology nodes, to improve the routability of areas with high pin densities by redistributing the cells, enable pin optimization during legalization by setting the place.legalize.optimize_pin_access_using_cell_spacing application option to true"}
{"instruction": "How do I Specifying Ideal Voltage Sources as Taps", "input": "", "output": "RedHawk-SC Fusion provides application options and commands to read in user- customized python script files. The tool generates all design collaterals (including DEF, LEF, SPEF, TWF and PLOC) from the design library and adds them to the user-customized python script to run voltage drop analysis in a single iteration of analyze_rail. The user-customized python script file is supported in rail analysis with multiple rail scenarios, as well as other IR-driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization. To use a customized python script file for RedHawk-SC Fusion rail analysis, 1. Set the type of script file to python fc_shell> set_app_options -name rail.generate_file_type -value python 2. Set the rail.generate_file_variables application option to specify the variables for generating the input files (including DEF, LEF, SPEF, TWF and PLOC files) to add to the user-customized python script file. You do not need to set this application option if the customized python script file uses the same values as in RedHawk-SC Fusion. DEF File LEF File SPEF File TWF File PLOC File DEF LEF SPEF TWF PLOC def_files lef_files spef_files tw_files ploc For example, if you specify a test_def_file for the DEF variable to match with the DEF file specified in the customized python script file, set the following: fc_shell> set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files} 3. Create and specify rail scenarios for generating the necessary input files to add to the customized python script. Run the create_rail_scenario command to create a rail scenario and associate it with a design scenario in the current design. You can create multiple rail scenarios and associate them with the same scenario in the current design. Then run the set_rail_scenario -generate_file {LEF | TWF | DEF | SPEF | PLOC} command to specify the rail scenario and the type of input files to generate from the design library. Note: When running rail analysis using multicorner-multimode technology, you must create rail scenarios using the create_rail_scenario command before the set_rail_scenario command. The following example creates the T_low and T_high rail scenarios and generates input files for them: fc_shell> create_rail_scenario -name T_low -scenario func_cbest fc_shell> set_rail_scenario -name T_low -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py fc_shell> create_rail_scenario -name T_high -scenario func_cbest fc_shell> set_rail_scenario -name T_high -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py You can then use the customized.py file for multi-rail-scenario rail analysis or other IR- driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization. Examples The following example uses a customized python script for multi-rail-scenario rail analysis on a grid system. #Required. Specify the below options to enable multi-rail-scenario rail analysis. set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required. Set the type of the script file to python. set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python. set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} analyze_rail -rail_scenario {func.ss_125c func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for multi-rail-scenario rail analysis on a local machine. #Required. Specify the below options to enable multi-rail-scenario rail analysis. set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required. Set the type of the script file to python. set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python. set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_command {local} analyze_rail -rail_scenario {func.ss_125c func.ff_125c} The following example uses a customized python script for single-scenario rail analysis on a grid system. Required. Specify the below options to enable multi-rail-scenario rail analysis. set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required. Set the type of the script file to python. set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python. set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} analyze_rail -rail_scenario {func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for IR-driven placement on a grid system. Required. Specify the below options to enable multi-rail-scenario rail analysis. set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required. Set the type of the script file to python. set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python. set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} # Enable IR-driven placement before running clock_opt -from final_opto set_app_options -name opt.common.power_integrity -value true clock_opt -from final_opto The following example uses a customized python script for concurrent clock and data optimization on a multicorner and multimode design on a grid system. #Required. Specify the below options to enable MCMM-based optimization. set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail"}
{"instruction": "How do I Creating Hierarchical Relative Placement Groups", "input": "", "output": "Hierarchical relative placement allows relative placement groups to be embedded within other relative placement groups. The embedded groups then are handled similarly to leaf cells. You can use hierarchical relative placement to simplify the expression of relative placement constraints. With hierarchical relative placement, you do not need to provide relative placement information multiple times for a recurring pattern. Using hierarchical relative placement provides these benefits: Allows you to organize your relative placement in a manner that is easier to maintain and understand. For example, you can create the relative placement group to parallel your Verilog or VHDL organization. Allows reuse of a repeating placement pattern, such as an adder. Can reduce the number of lines of relative placement information you need to write. Allows integrating blocks. Provides flexibility for the configuration you want."}
{"instruction": "How do I Clock-Gate Multilevel Expansion", "input": "", "output": "The number of clock-gate levels is the count of clock gates between a clock source and a register. Standard clock-gate insertion provides one level of clock-gate insertion. However, designs often contain preexisting clock gates, in which case the design might contain multiple levels of clock gates. You can modify the default clock-gate insertion operation by allowing additional levels of clock gating, by limiting the number of clock-gate levels, or both."}
{"instruction": "How do I Controlling the Selection of Self-Gating Objects", "input": "", "output": "To specify self-gating settings, use the set_self_gating_options command with the following options: -min_bitwidth bitwidth Controls the minimum size for self-gating banks. The default is 4. -max_bitwidth bitwidth Controls the maximum size for self-gating banks. The default is 8. -interaction_with_clock_gating interaction_type Registers gated by user-instantiated clock-gating cells are candidates for self-gating. Valid arguments are none (skip registers gated by tool-inserted clock gates), insert (the default; insert self-gates on gated registers), and collapse (collapse tool-inserted clock gates if they are in the same hierarchy). -objects object_list Specifies that the options should be applied to the listed objects. Supported objects are hierarchical instances, power domains, and designs. By default, the settings apply to the entire design. -tree_type combinational_logic_type Uses the specified logic type to build the gated enable tree. Valid arguments are xor nand or, and auto (the default). To report self-gating options, use the report_self_gating_options command."}
{"instruction": "How do I Controlling Standard Filler Cell Insertion", "input": "", "output": "The standard filler cell insertion flow uses the create_stdcell_fillers command to insert filler cells in the block and the remove_stdcell_fillers_with_violation command to perform design rule checking on the filler cells and remove filler cells with violations. During filler cell insertion, the create_stdcell_fillers command uses the placement legalizer to ensure that the inserted filler cells honor advanced node placement rules and physical constraints such as placement blockages and keepout margins. When the place.legalize.enable_advanced_legalizer application option is set to true the command uses the advanced legalization algorithms for 2D rule checking and cell interaction, which can reduce filler cell insertion runtime. To insert filler cells in your block, 1. Ensure that the block is legalized by using the check_legality command. When verifying that a block is fillable, the check_legality command assumes that all standard cells that have a design_type attribute of filler can be used as filler cells. However, the create_stdcell_fillers command inserts only the cells specified in the -lib_cells option. This difference might result in unfillable gaps after filler cell insertion even though the check_legality command did not report any issues. 2. (Optional) Insert required filler cells to abut specific standard cells by using the create_left_right_filler_cells command, as described in Abutting Standard Cells With Specific Filler Cells 3. (Optional) Enable multithreaded filler cell insertion by using the set_host_options command to specify the multicore configuration. fc_shell> set_host_options -max_cores The create_stdcell_fillers command uses the multicore configuration only when the technology file contains minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules. Note: The multicore configuration specified with the set_host_options command applies to all Fusion Compiler commands that support multicore processing. 4. Insert metal filler cells by using the create_stdcell_fillers command. Use the -lib_cells option to specify the metal filler library cells to insert. The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest. To determine the filler cells available in a cell library, use the following command: fc_shell> get_lib_cells ref_lib /* -filter \"design_type==filler\" To sort the filler cells by decreasing size, use the sort_collection command, as shown in the following example: fc_shell> set FILLER_CELLS \\ [get_object_name [sort_collection -descending \\ [get_lib_cells ref_lib /* -filter \"design_type==filler\"] area]] For more information, see Controlling Standard Filler Cell Insertion 5. Connect the inserted filler cells to the power and ground (PG) network by using the connect_pg_net -automatic command. 6. Remove the metal filler cells with DRC violations by using the remove_stdcell_fillers_with_violation command. Removing the filler cells can expose new violations; therefore, you must sometimes run this command multiple times to remove all violating filler cells. For more information, see Checking for Filler Cell DRC Violations 7. Insert nonmetal filler cells by using the create_stdcell_fillers command. Use the -lib_cells option to specify the nonmetal filler library cells to insert. The tool tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest. For more information, see Controlling Standard Filler Cell Insertion 8. Connect the inserted filler cells to the PG network by using the connect_pg_net -automatic command. See Also Generic ECO Flow for Timing or Functional Changes Removing Filler Cells"}
{"instruction": "How do I Controlling Movement When Legalizing Relative Placement", "input": "", "output": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed. When a relative placement cell is removed during optimization, the relative placement information of the instance is also removed, disrupting the relative placement structure. To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting all_opt size_only size_in_place no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}
{"instruction": "How do I Controlling Legalization When Using the place_eco_cells", "input": "", "output": "The place_eco_cells command places and legalizes each ECO cell based on the connectivity and the delays associated with the cell. You can control the placement of the ECO cells as follows: To use the channels areas between macro cells for ECO placement, use the -channel_aware option. By default, the command avoids channel areas during ECO placement. To place ECO cells closer to fixed points, such as I/O pads or macro cells, specify a weight for the nets connected to the fixed cells by using the -fixed_connection_net_weight option. By default, nets connected to fixed cells have a weight of one. To place ECO cells closer to fixed points, specify an integer value greater than one for the corresponding net. To prioritize specific nets during ECO placement by specifying net weights, 1. Specify net weights by using the set_eco_placement_net_weight command. 2. Specify that the tool honors the net weights by using the -honor_user_net_weight option with the place_eco_cells command. To report the net weights you specify, use the report_eco_placement_net_weight command. To create virtual connections for ECO cells and use them during ECO placement, instead of the actual connections, 1. Create virtual connections by using the create_virtual_connection command 2. Use these virtual connections during ECO placement by using the -use_virtual_connection option with the place_eco_cells command. The following example creates virtual connections for the inputs and output of the cell named ECO17 and performs ECO placement using these virtual connections: fc_shell> create_virtual_connection -name VC_0 \\ -pins {U1/Y ECO17/A} fc_shell> create_virtual_connection -name VC_1 \\ -pins {U2/Y ECO17/B} fc_shell> create_virtual_connection -name VC_2 \\ -pins {ECO17/Y D17_OUT} -weight 3 fc_shell> place_eco_cells -cells ECO17 -use_virtual_connection To remove virtual connections you have created, use the remove_virtual_connections command. To query virtual connections, use the get_virtual_connections command. To ignore high-fanout nets connected to ECO cells that exceed a specific threshold, use the -max_fanout option with the place_eco_cells command. To ignore the connections of specific pins on ECO cells, use the -ignore_pin_connection option with the place_eco_cells command."}
{"instruction": "How do I Spreading Repeater Cells During Placement", "input": "", "output": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells. Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in The upper category consists of the top one percent of the total number of cells with the highest voltage drop values. During placement, the tool spreads these cells the most. The middle category consists of the next five percent of the cells. During placement, the tool spreads these cells less than those in the upper category. The lower category consists of the rest of the cells. The tool does not spread these cells. You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options. The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false. They are true by default. The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa. The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command. The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"instruction": "How do I Specifying the Net Names, Buffers Types, and Their Locations", "input": "", "output": "To add buffers or pairs of inverters on a fully routed net, use the add_buffer_on_route command as described in the following topics: Specifying the Net Names, Buffers Types, and Their Locations Controlling How Buffers are Added Specifying Settings for Multivoltage Designs Specifying Settings for the Freeze Silicon ECO Flow"}
{"instruction": "How do I Running the Hierarchical Synthesis Flow Using ETMs", "input": "", "output": "To minimize the number of iterations and obtain optimal results, you can perform feasibility analysis before running hierarchical synthesis, as shown in The hierarchical synthesis feasibility flow uses the following block-level information generated post compile_fusion Floorplanning information to generate the ETM in step 2 Power intent and test model (CTL) information for top-level synthesis in step 4 Hierarchical Synthesis Feasibility Analysis 1. Synthesize the block in the front- end tool compile_fusion RTL Block UPF (front end) Block CTL (front end) UPF SDC, floorplan SDC Design (ndm) Netlist UPF CTL SPEF Design (frame) 2. Create an ETM in the front-end tool extract_model Block_ETM (ndm) 3. Synthesize the top-level design in the front-end tool compile_fusion RTL Top-level UPF SDC, floorplan"}
{"instruction": "How do I Excluding Specific Sinks", "input": "", "output": "To exclude a specific scenarios from concurrent clock and data optimization, use the ccd.ignore_scenarios application option and specify the name of the scenarios you want to ignore. For example, to ignore the scenario named scnB, use the following command: fc_shell> set_app_options -name ccd.ignore_scenarios \\ -value {scnB}} This setting affects concurrent clock and data optimization performed during the place_opt clock_opt, and route_opt commands."}
{"instruction": "How do I Importing the Floorplan Information", "input": "", "output": "During early design development, frequent design updates can cause incomplete or inconsistent data, such as pin mismatches between a block-level design and the reference to it from a top-level design. To enable the tool to successfully link a block even if it has certain types of design mismatch, set a mismatch configuration for the block. By default, the tool cannot link any block with inconsistent or mismatching data. When you set mismatch configurations, the tool either ignores or fixes several different types of mismatching data and continues the linking process. Blocks linked with mismatching data can be used only for feasibility analysis. To learn how to mitigate design mismatches, see the Fusion Compiler Data Model User Guide"}
{"instruction": "How do I Automatically Fixing Double-Patterning Odd-Cycle Violations", "input": "", "output": "By default, the signoff_fix_drc command performs the following tasks: 1. Runs the signoff_check_drc command to generate the initial signoff DRC results, as described in Checking for DRC Violations If you have already run the signoff_check_drc command, you can use the existing signoff DRC results instead of rerunning signoff design rule checking. To reuse the existing results, specify the directory that contains the results by setting the signoff.fix_drc.init_drc_error_db application option. You can specify either a relative path or an absolute path. If you specify a relative path, it is relative to the current working directory. For example, to use the results from the default signoff_check_drc run directory, use the following commands: fc_shell> set_app_options \\ -name signoff.fix_drc.init_drc_error_db \\ -value signoff_check_drc_run fc_shell> signoff_fix_drc Note: To use existing signoff DRC results as input to the signoff_fix_drc command, you must use the signoff DRC application options described in Generating Input for the Automatic Fixing Flow 2. Runs two repair loops to fix the DRC violations In each repair loop, the signoff_fix_drc command performs the following tasks; a. Tries to fix the DRC violations detected in the previous IC Validator signoff DRC run, as described in Fixing DRC Violations b. Runs IC Validator signoff design rule checking on the modified block, as described in Checking for DRC Violations To change the number of repair loops, use the -max_number_repair_loop option; you can specify an integer between 1 and 10. If no signoff DRC violations remain after a loop, the tool does not perform additional repair loops. As the repair loop number increases, so does the physical scope of the rerouting performed by that repair loop. To change the scope, increase the number of the initial repair loop by using the -start_repair_loop option. Note that increasing the initial loop number might cause a greater disturbance to the block, which would require additional design rule checking and fixing by Zroute. 3. Writes a summary report of the results For information about the summary report, see Summary Report for Automatic Design Rule Fixing Fixing DRC Violations In each repair loop, the signoff_fix_drc command tries to fix the DRC violations detected in the previous signoff DRC run. For the first loop, the tool uses the IC Validator data in the directory specified by the signoff.fix_drc.init_drc_error_db application option (or the signoff_drc_run_init directory if you do not use this option). For successive loops, the tool uses the IC Validator DRC data from the previous loop, which is stored in the directory specified by the signoff.fix_drc.run_dir application option (or the signoff_fix_drc_run directory if you do not use this option). When fixing DRC violations, the signoff_fix_drc command has the following default behavior: Tries to fix all design rule violations detected in the previous signoff DRC run except those design rules that have more than 1000 violations Performs DRC fixing on data nets for the whole block To modify the regions for design rule fixing, use one or both of the following options: -coordinates This option restricts design rule fixing to the specified regions. -excluded_coordinates This option prevents design rule fixing in the specified regions. If you specify this option with the -coordinates option, the command does not fix design rules in the overlapping regions. To specify the coordinates, use the following format: {{x } {x }... {x }} Note that there must be a space between each set of coordinates. To prevent fixes that might impact timing-critical nets, use one or both of the following options: -nets This option explicitly specifies the critical nets. -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold. The unit for the slack threshold setting is the library time unit. Performs five iterations of detail routing after DRC fixing to fix any DRC violations introduced during DRC fixing Saves the modified block in a design view named block _ADR_# To change the default behavior, use the following options: signoff.fix_drc.max_errors_per_rule This application option specifies the error threshold for ignoring a design rule. signoff.fix_drc.fix_detail_route_drc This application option controls the scope of DRC fixing. To reduce runtime by performing DRC fixing only in areas near the signoff DRC violations, set this application option to local signoff.fix_drc.target_clock_nets This application option controls whether DRC fixing targets data nets or clock nets. To target clock nets, set this application option to true signoff.fix_drc.max_detail_route_iterations This application option specifies the number of detail routing iterations; you can specify an integer between 0 and 1000. Checking for DRC Violations When performing signoff design rule checking, the signoff_fix_drc command has the following default behavior: Reads the design view for the top-level block and library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances For information about changing the view used for specific cells, see Reading Blocks for Signoff Design Rule Checking After the initial run, performs design rule checking only on those portions of the design affected by design rule fixing To perform signoff design rule checking on the entire block for the last repair loop, set the signoff.fix_drc.last_run_full_chip application option to true. Setting this option to true increases accuracy but also increases runtime. To perform signoff design rule checking on the entire block for all repair loops, set the signoff.fix_drc.check_drc application option to global. Setting this option to global increases accuracy but can greatly increase runtime. Does not check for violations in child blocks Excludes rules that are not suitable for automatic design rule fixing To explicitly specify the design rules checked by the IC Validator tool, set the -select_rules rules and -unselect_rules rules application options. Stores the IC Validator results in the signoff_fix_drc_run directory To use a different run directory, set the signoff.fix_drc.run_dir application option. Note: The IC Validator results for the initial signoff DRC run are stored in the signoff_drc_run_init directory. In addition, you can specify options to add to the IC Validator command line by setting the signoff.fix_drc.user_defined_options application option. See Also Performing Signoff Design Rule Checking"}
{"instruction": "How do I Checking PG Electromigration Violations", "input": "", "output": "A PG electromigration map is a visual display of the color-coded electromigration values overlaid on the physical supply nets. For static analysis, the map displays average electromigration values. For dynamic analysis, the map displays average electromigration values, peak electromigration values, or root mean square electromigration values. shows an example of the electromigration map in which problem areas are highlighted in different colors. Use the options to investigate the problem areas by selecting layers or nets to display. For example, to examine the current value of one specific net, deselect all the nets and then select the net to display from the list. To analyze only the shapes on a layer, select the layer from the list. For a detailed procedure about how to display an electromigration map, see Displaying Maps in the GUI Displaying a PG Electromigration Map"}
{"instruction": "How do I Reporting the Wire Length", "input": "", "output": "To report statistics about the routing results, use the report_design -routing command. This command reports the following information: Final wiring statistics, including the Number of signal net shapes for each metal layer Signal wire length for each metal layer Number of PG net shapes for each metal layer PG wire length for each metal layer Horizontal and vertical wire distribution for each metal layer Total number of signal net shapes for the block Total signal wire length for the block Final via statistics, including the Simple vias used in each via layer, including the number of instances of each via Double via conversion rate for each via layer Double via conversion rate for the block Custom vias used in the block, including the number of instances of each user- defined via By default, this command reports the information only for the top-level block. To report the information for the entire physical hierarchy, use the -hierarchical option. See Also Defining Vias"}
{"instruction": "How do I Deriving Mask Colors", "input": "", "output": "To save the route information, use the write_routes command. This command generates a Tcl script that reproduces the metal shapes and vias for a block, including their attribute settings. Note that the write_routes command reproduces routes, but not routing blockages. To generate a Tcl script that reproduces routing blockages, use the write_floorplan command."}
{"instruction": "How do I Creating Constraints for Auto Floorplanning", "input": "", "output": "During early design stages, a design often undergoes many iterations due to changes such as adding features and macros; as a result, the floorplan contains limited or no physical information. Automatic floorplanning can generate high-quality floorplans and create missing physical information early in the design cycle, which allows you to Achieve better correlation between the results of RTL synthesis and design implementation Identify and fix design issues early in the design cycle Generate a better starting point for place and route, eliminating costly iterations During automatic floorplanning, the compile_fusion command performs the following tasks: Creates the die, rows, and tracks Shapes and places voltage areas Places macros Places pins and I/Os By default, the top-level floorplan is created with a core utilization of 0.7. For information about setting constraints for automatic floorplanning, see Creating Constraints for Auto Floorplanning"}
{"instruction": "How do I Grouping Variant Cell", "input": "", "output": "To set application option before using the add group repeaters and place_group_repeaters commands, use the set_app_option -name eco.placement.variant_cell_swapping -value true command. Based on the requirement, you can plan the variant cell flow. The rules of variant reference swapping differ in various variant cell flows. By default, the variant cell support in the eco_change_legal_reference command detects the variant mode and settings automatically. The eco_change_legal_reference command checks whether the current reference of the cell is legal or illegal for the placed location. If it is illegal, the command attempts to find a legal reference from its variant cell group defined to swap with the illegal one. To use the variant cell features directly for other cells, use the eco_change_legal_reference command. For complicated scenarios, you can switch the variant mode and tune the settings manually. Following are the new application options for variant cell support: To set variant mode for different customers and different design flows, use the set_app_options -name eco.placement.variant_cell_group_mode -value command. To honor the variant cell groups, which are not sharing timing view, use the set_app_options -name eco.placement.honor_cell_group_not_sharing_timing -value command."}
{"instruction": "How do I Performing Design Rule Checking Using Zroute", "input": "", "output": "To display the global route congestion map, choose View > Map > Global Route Congestion in the GUI. If the design library contains global route congestion information for the block, the tool generates the congestion map based on this information; otherwise, you must click Reload to generate the congestion map. When you click Reload, the tool opens a dialog box that contains the following command: route_global -congestion_map_only true Note: By default, only the hard congestion data is saved in the design library. To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing. When you click OK in this dialog box, the tool generates a new congestion map. If you want to use different options for the route_global command, you can modify this command before clicking OK. shows an example of a congestion map. Global Route Congestion Map By default, the congestion map displays only the hard congestion data. To display soft congestion data, select the desired rule level in the Rule level drop-down list. The rule level refers to the spacing weight level of the soft nondefault spacing rules. The congestion map displays the sum of the hard and soft congestion with a weight level of at least the selected rule level. The congestion map shows the borders between global routing cells highlighted with different colors that represent the congestion values. The congestion map supports two methods for calculating the congestion value: Sum of overflow for each layer (the default) In this mode, the tool calculates the congestion value as the sum of the overflow for all selected layers. Underflow is not considered; if a layer has underflow, it contributes zero overflow to the total overflow calculation. Total demand minus total supply In this mode, the tool calculates the congestion value by subtracting the supply for all selected layers from the demand for all selected layers. Note that because this calculation considers the underflow, it produces a more optimistic congestion result in regions that contain both overflow and underflow. For example, assume that the METAL2 layer is heavily congested with a demand of 13 routing tracks and a supply of only 7 tracks for an overflow of 6. The METAL4 is moderately congested with an overflow of 4, and the METAL6 layer is not congested and contains an underflow of 3. Other layers are not used in the congestion calculation in this example. The sum of overflow calculation results in a congestion value of 6+4=10. The underflow of 3 for the METAL4 layer is not used in the calculation. The total demand calculation results in a congestion value of 6+4-3=7. In this case, the underflow of 3 for the METAL4 layer is used in the calculation. To select the mode, select either \"Sum of overflow for each layer\" or \"Total demand minus total supply\" in the \"Congestion calculation\" section of the Map Mode panel. By default, all metal layers are selected in the congestion map, except those specified as ignored layers with the set_ignored_layers command. To display the congestion map for a subset of layers, select (or deselect) the layers on the Map Mode panel. For example, if the global routing report shows that the maximum overflow occurs on the METAL2 layer, you can deselect all layers, except for METAL2, to display only the METAL2 congestion. The Map Mode panel also displays a histogram showing the number of global routing cells in different ranges (bins) of congestion values for the selected layers. If your block contains global routing cells that have no available routing resources, an additional bin named Blocked is displayed that shows the number of global routing cells with no routing resources. You can select which bins to display in the congestion map by selecting or deselecting them on the Map Mode panel. If the block shows congested areas, zoom into the congested area to see the congestion value on the global routing cell. For example, in, the red highlight on the edge of the global routing cell shows 18/9. This means there are 9 wire tracks available, but 18 tracks are needed. Global Route Overflow on Global Routing Cell"}
{"instruction": "How do I Minimizing Large Displacements During Legalization", "input": "", "output": "The tool performs legalization at various points during the design flow. The following topics describe settings for controlling legalization: Minimizing Large Displacements During Legalization Optimizing Pin Access During Legalization Enabling Advanced PG Net Checks Enabling Advanced Legalization Algorithms Setting Up for Variant-Aware Legalization Checking if Library Cells Are Legally Placeable"}
{"instruction": "How do I Timing-Driven Power Grid Augmentation", "input": "", "output": "Before you run the signoff_create_pg_augmentation command, configure the run by setting the application options shown in Table 48. To set the application options, use the set_app_options command. To see the current settings, use the report_app_options command. Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff. create_pg_augmentation. ground_net_name signoff. create_pg_augmentation.po wer_net_name signoff. create_pg_augmentation. run_dir signoff_create_pg_augmentation Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff. create_pg_augmentation. user_defined_options"}
{"instruction": "How do I Making ECO Changes Using Netlist Editing Commands", "input": "", "output": "You can make ECO changes to a block by using the eco_netlist command. If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true before you run the eco_netlist command. When you use the eco_netlist command, use one of the following two methods to make the ECO changes: Specify a golden Verilog netlist that includes the ECO changes by using the -by_verilog_file option Specify a golden block that includes the ECO changes by using the -block option When you use the -block option, by default, The tool assumes the golden block is in the current design library. To specify a different design library, use the -golden_lib option. The tool makes the ECO changes to the current design. To make the ECO changes to a different design, use the -working_block option. To specify the design library that contains the design specified by the -working_block option, use the -working_lib option. The tool compares the working design to the input Verilog netlist or the golden design and generates a change file containing netlist editing Tcl commands that implements the functional changes. You must specify the name of the output file by using the -write_changes option. By default, the tool ignores the following: Differences in the physical-only cells To consider the differences in the physical-only cells, use the -compare_physical_only_cells option. Timing ECO changes, such as cells that are resized or repeaters that are added or removed. To consider the timing ECO changes, in addition to the functional ECO changes, use the -extract_timing_eco_changes option. Differences in power and ground objects. To make the ECO changes to the working design, source the change file that the eco_netlist command generates, as shown in the following example: fc_shell> eco_netlist -by_verilog_file eco.v \\ -compare_physical_only_cells -write_changes eco_changes.tcl fc_shell> source eco_changes.tcl"}
{"instruction": "How do I Self-Gating Flow", "input": "", "output": "The tool supports self-gating optimization, which occurs at the compile_fusion command. This feature reduces dynamic power consumption by turning off the clock signal of certain registers during clock cycles when the data remains unchanged. Example of a Self-Gating Cell CLK Registers with an enable condition that cannot be inferred from the existing logic can only be gated using the self-gating technique. They cannot be gated using traditional clock gating. By default, the tool supports self-gating only on registers that are not gated. You can use the set_self_gating_options command to allow self-gating on these registers. However, the time duration that the clock signal is turned off might increase for these registers,. To ensure QoR improvements, the self-gating algorithm takes timing and power into consideration. A self-gating cell is inserted for the registers if There is enough timing slack available in the register's data pin. For designs with multiple scenarios, the algorithm considers the timing of the worst case among active scenarios enabled for setup. Internal dynamic power of the circuit is reduced. For designs with mutiple scenarios, the algorithm uses the average internal dynamic power among active scenarios enabled for dynamic power. To minimize the area and power overhead, a self-gating cell can be shared across a few registers by creating a combined enable condition with a tree of comparator cells. If the self-gated registers are driven by synchronous set or synchronous clear signals, these signals are also included in the construction of the enable signal so that the circuit remains functionally unchanged. is an example of a self-gating cell that is shared across two registers (4 bits). Note that one of the self-gated registers is a multibit register and the other register is a single-bit register. The tool can also self-gate a group of multibit registers or a group of single-bit registers. Self-Gating Tree CLK D0 Q0 D2 Q2 D1 Q1 EN The tool does not support the following types of sequential cells for self-gate insertion: Level-sensitive sequential cells Level-sensitive scan design registers Master-slave flip-flops Retention registers Single-bit and multibit registers that belong to shift registers Multibit registers with multiple clock paths For more information, see the following topics: Self-Gating Flow Library Requirements for Self-Gating Setting Up for Self-Gating Reporting and Querying Self-Gating Cells"}
{"instruction": "How do I Track-Based Metal Fill Insertion", "input": "", "output": "Pattern-based metal fill insertion is the default mode for the signoff_create_metal_fill command. It inserts metal and via fill by using a foundry runset. Before running the signoff_create_metal_fill command, you must specify the runset by setting the signoff.create_metal_fill.runset application option. During pattern-based metal fill insertion, the signoff_create_metal_fill command performs the following tasks: 1. Loads the block into the IC Validator tool, as described in Reading Blocks for Signoff Metal Fill Insertion 2. Removes existing metal and via fill By default, the command removes the metal and via fill from the entire block. For information about performing incremental metal fill insertion, see Incremental Metal Fill Insertion 3. Inserts metal and via fill in the empty regions By default, the command uses the spacing rules defined in the technology file to perform metal fill insertion on all metal and via layers for the entire block. The command uses the metal fill mode specified in the runset file, which is either hierarchical or flat. To modify the default behavior, Set one or more of the following application options before running the signoff_create_metal_fill command: signoff.create_metal_fill.apply_nondefault_rules To enable the use of nondefault spacing rules in addition to the spacing rules defined in the technology file, set this application option to true signoff.create_metal_fill.flat To force the use of the flat metal fill mode, set this application option to true Use one or more of the following command options with the signoff_create_metal_fill command: -select_layers or -all_runset_layers To restrict the layers on which to insert metal fill, use these options, as described in Specifying the Layers for Metal Fill Insertion -coordinates and -excluded_coordinates To restrict the regions on which to insert metal fill, use these options, as described in Specifying the Regions for Metal Fill Insertion 4. Removes floating via fill from the specified via layers and from the via layers associated with the specified metal layers Floating via fill is via fill that does not have both an upper and lower metal enclosure. 5. Saves the fill data in the design view 6. Writes the result files to the run directory For information about the generated result files, see Signoff Metal Fill Result Files See Also Timing-Driven Metal Fill Insertion Reading Blocks for Signoff Metal Fill Insertion By default, the IC Validator tool reads the design view for the top-level block and the library cell instances, and the pin information from the frame view for the macro cell and I/O pad cell instances. To read the GDSII or OASIS data for specific reference cells, specify the stream files by setting the signoff.physical.merge_stream_files application option. When you use this option, the GDSII or OASIS data replaces the cell library view for the cells defined in the specified stream files, except for cells in the cell libraries specified with the signoff.physical.merge_exclude_libraries application option. To read the layout view for specific reference cells, specify the cells by setting the signoff.create_metal_fill.read_layout_views application option. The layout view is identical to the GDSII or OASIS data that was used to create them, but reduces the runtime for signoff design rule checking. Note: By default, layout views are not included in the cell libraries To save the layout views, you must set the lib.workspace.save_layout_views application option to true during library preparation, as described in the Library Manager User Guide To read the design view for specific reference cells, specify the cells by setting the signoff.create_metal_fill.read_design_views application option. Note: By default, design views are not included in the cell libraries To save the design views, you must set the lib.workspace.save_design_views application option to true during library preparation, as described in the Library Manager User Guide The order of precedence for child cell data is 1. GDSII or OASIS data specified with the signoff.physical.merge_stream_files application option 2. Layout views specified with the signoff.create_metal_fill.read_layout_views application option If the IC Validator tool cannot find a layout view and the cell is specified in the signoff.check_drc.read_design_views application option, it reads the design view. Otherwise, it reads the frame view. If it cannot find the frame view, the cell is ignored during design rule checking. 3. Design views specified with the signoff.create_metal_fill.read_design_views application option If the IC Validator tool cannot find a design view, it reads the frame view instead. If it cannot find the frame view, the cell is ignored during design rule checking. 4. Frame views Specifying the Layers for Metal Fill Insertion By default, the signoff_create_metal_fill command inserts metal fill on all the metal routing layers and via fill on all the via layers. To modify the layers for metal fill insertion, use one of the following options: -select_layers metal_fill_layers This option restricts metal fill insertion to the specified set of metal and via layers. -all_runset_layers true This option enables metal fill insertion on all the fill layers specified in the runset. This option applies only to pattern-based metal fill insertion. When you specify the layers for metal fill insertion, the signoff_create_metal_fill command 1. Removes the existing metal and via fill from the block By default, the command removes all existing metal and via fill. For incremental metal fill insertion, the command removes metal and via fill only from the specified layers. 2. Inserts metal and via fill only on the specified layers 3. Removes floating via fill from the specified via layers and from the via layers associated with the specified metal layers For example, if you specify -select_layers {M2}, the tool removes floating via fill from the V1 and V2 layers. Specifying the Regions for Metal Fill Insertion By default, the signoff_create_metal_fill command inserts metal and via fill for the whole chip. To modify the regions for metal fill insertion, use one or both of the following options: -coordinates This option restricts metal fill insertion to the specified regions. Note: The bounding box coordinates passed to the IC Validator tool in the METAL_FILL_SELECT_WINDOW parameter are enlarged by 1 um to avoid DRC violations on the boundary of the specified regions during metal fill insertion. The actual metal fill insertion occurs within the regions specified by the -coordinates option. In addition, when you use the -coordinates option, the signoff_create_metal_fill command always uses the flat metal fill mode. -excluded_coordinates This option prevents metal fill insertion in the specified regions. If you specify this option with the -coordinates option, the command does not perform metal fill insertion in the overlapping regions. To specify the coordinates, use the following format: {{x } {x }... {x }} Note that there must be a space between each set of coordinates. When you specify the regions for metal fill insertion, the signoff_create_metal_fill command 1. Removes all existing metal and via fill from the block For standard metal fill insertion, the command removes all existing metal and via fill. For incremental metal fill insertion, the command removes metal and via fill only from the specified regions. 2. Inserts metal and via fill only on the specified regions 3. Removes floating via fill from the specified regions For example, to remove all metal fill from the block and then fill all empty regions outside the bounding box with corners at (100,150) and (300,200), use the following command: fc_shell> signoff_create_metal_fill \\ -excluded_coordinates {{100 150} {300 200}}"}
