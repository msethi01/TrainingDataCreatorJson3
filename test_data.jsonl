{"instruction": "How do I Mapping ECO Cells to Specific Spare Cells", "input": "", "output": "To map an ECO cell to a specific spare cell, use the map_freeze_silicon command. Specify the ECO cell name and the corresponding spare cell name by using the -eco_cell and -spare_cell options. The following example maps the ECO cell named ECO1 to the spare cell named spare_1: fc_shell> map_freeze_silicon -eco_cell ECO1 -spare_cell spare_1 You can specify the ECO cell to spare cell mapping by using a map file and specifying this map file name by using the -map_file option with the map_freeze_silicon command. The map file has the following format: ECO_cell_1 spare_cell_1 ECO_cell_2 spare_cell_2...... 978 Updating Supply Nets for ECO Cells Feedback"}
{"instruction": "How do I Updating Via Ladders", "input": "", "output": "You can use the following methods to update existing via ladders in a design: Use the refresh_via_ladders command Automatic updates during the route_group route_auto, and route_eco commands is enabled by default by setting the route.auto_via_ladder.update_during_route application option to true Both of these methods perform the following tasks: Verifies the existing via ladders based on the current via ladder constraints Removes invalid via ladders Inserts via ladders where needed based on the settings of the route.auto_via_ladder application options By default, the tool Updates all pins with via ladder constraints, whether on signal nets or clock nets By default, during the route_group command, the via ladder updates is restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted about the pin layer be fully contained within the pin shape boundary, which includes 461 Inserting Via Ladders Feedback the pin shape and its extensions. To specify this requirement, set the following application options: route.auto_via_ladder.connect_within_metal This application option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join. To prevent changes to the pin shape boundary, set this application option to true route.auto_via_ladder.connect_within_metal_for_via_ladder This application option controls the via enclosures only for performance and electromigration via ladders. By default, the tool uses the global setting specified by the route.auto_via_ladder.connect_within_metal application option. To explicitly specify the behavior for performance and electromigration via ladders, set this application option to true or false Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion. In many cases, the via ladder rule specifies the maximum number of stagger tracks. To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, the route.auto_via_ladder.auto_stagger application option is set to true by default. Reports the via ladder insertion status for each target pin To limit the number of via ladders reported for each category to 40, set the route.auto_via_ladder.report_all_via_ladders application option to false See Also Inserting Via Ladders Verifying Via Ladders Querying Via Ladders Removing Via Ladders 462 Inserting Via Ladders Feedback"}
{"instruction": "How do I Creating Skew Groups", "input": "", "output": "During clock tree synthesis, you might want to balance a group of sinks only among each other, and not the rest of the sinks. To do so, define a skew group by using the create_clock_skew_group command. When you use this command, specify the sinks you want to group, by using the -objects option. Optionally, you can specify the following: A clock or generated clock for which to create the skew group by using the -clock option. A mode for which to create the skew group by using the -mode option. 364 Specifying the Clock Tree Synthesis Settings Feedback By default, the tool creates the skew group for the current mode. A name for the skew group by using the -name option. The following example creates a skew group named sg1 consisting of sinks reg1/CP, reg2/ CP, and reg3/CP: fc_shell> create_clock_skew_group -name sg1 \\ -objects {reg1/CP reg2/CP reg3/CP} To report skew groups, use the report_clock_skew_groups command. To remove skew groups, use the remove_clock_skew_groups command."}
{"instruction": "How do I Synthesizing a Subblock", "input": "", "output": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1. Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2. Apply any block-specific constraints and settings required for synthesizing the block. 822 Performing Hierarchical Synthesis Using Abstracts Feedback 3. Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command. 4. Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5. Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}
{"instruction": "How do I Running RedHawk Fusion Commands in the Background", "input": "", "output": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished. You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished. To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command. When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database. By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed. However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results. 874 Setting Up the Executables Feedback Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not. When opening rail results, the tool does not detect if the result is generated with or without the -bg option. The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa. Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory. To check if the background analyze_rail process is active, use the report_background_jobs command."}
{"instruction": "How do I Signoff ECO Flow", "input": "", "output": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool. You can also perform power or area recovery in the PrimeTime tool. 950 Signoff ECO Flow Feedback If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in Figure 217 Figure 217 Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations? PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1. Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands. 2. Update the placement by using the place_eco_cells command as shown in the following example: place_eco_cells -legalize_mode minimum_physical_impact \\ -eco_changed_cells -legalize_only -displacement_threshold 10 For more information about the place_eco_cells command, see Placing ECO Cells 3. Add filler cells to the empty spaces in the site array, as described in Inserting Filler Cells 951 Incremental Signoff ECO Flow Feedback To reduce runtime, use the -post_eco option when you Insert metal filler cells with the create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4. Update the routing by using the route_eco command, as described in Performing ECO Routing, or by manually rerouting the affected nets."}
{"instruction": "How do I Fixing Signal Electromigration Violations", "input": "", "output": "Before fixing signal electromigration violations, make sure that the block is detail routed, the signal electromigration constraints are defined in the design library, the switching activity is defined for all boundary nets, crosstalk analysis is enabled, and there are no timing or DRC violations. You can optionally use the report_signal_em command first to report electromigration violations before attempting to fix them. 557 Performing ECO Routing Feedback To fix signal electromigration violations, use the fix_signal_em command, which performs the following tasks: Runs signal electromigration analysis for nets by calculating the current on every edge of a net and comparing it with the constraints set by the read_signal_em_constraints command. Fixes violations by applying nondefault routing rules to widen the metal shapes and then performing ECO routing. The fix_signal_em command runs a single fixing iteration; if violations remain after running this command, you must rerun it to address the remaining violations. By default, the command fixes signal electromigration violations on all nets. To fix the violations only on specific nets, use the -nets option. See Also Analyzing Signal Electromigration Performing ECO Routing"}
{"instruction": "How do I Naming Convention for Tool-Inserted Clock Gates", "input": "", "output": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs. The naming convention is as follows: prefix_base-name[_index] The prefix is clock_gate by default. To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option. The base name is the most frequent instance name among the registers gated by the clock gate. The base name does not include bus bit indexes. If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0. For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg. If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0. However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register. 288 Introduction to Clock Gating Feedback"}
{"instruction": "How do I Troubleshooting", "input": "", "output": "Table 73 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters. Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error: The repeater group (%d) is invalid. Check if the input group id exists by running the report_repeater_g roups command. 999 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning: Failed to connect to route for %d object: {%s }. Check the pin shape of object and route shapes. The object as driver or load can be port, macro pin, and placed cell. place_group_repeat ers ECO-224 Error: The option -repeater_groups cannot be used when the app option eco.placement.eco_enable_ pipeline_register_placer is false. Check the pin shape of object and route shapes. The object as driver or load can be port, macro pin, and placed cell. place_group_repeat ers ECO-227 Warning: Failed to place %d repeaters for %d drivers in collection (%s), and failed cells are in collection (%s). Check the failed drivers by running the query_objects get_ports get_pins and get_cells commands. The driver can be port, macro pin, and placed cell. place_group_repeat ers ECO-228 Warning: Some repeaters from path driver (%s) have same repeater group id. The cells belonging to the path are {%s}. Check if the group id of cells are on the same path. The command skips to place some repeaters. The group id of cells on one path should be different. place_group_repeat ers ECO-229 Warning: Failed to find intersection of cutline %s and route for cell {%s}. place_group_repeat ers ECO-231 Error: The repeater group (%d) has no cutline or invalid cutline. Check the right cutline for this group. Set right cutline for this group using the set_repeater_gr oup command. 1000 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error: Cutline {{%s} {%s}} is invalid. Check the format of the cutline. The valid format of cutline is {{x1 y} {x2 y}} or {{x y1} {x y2}}. place_group_repeat ers unplace_group_repeat ers ECO-233 Error: The cells in collection (%s) are invalid since they have no target input pin name (%s) and output pin name (%s). Check the input and output pin name. The input pin name and output pin name can be specified by using the -lib_cell_input and -lib_cell_output options if needed, or filter out invalid cells from input. The default value for -lib_cell_input is D. The default value for -lib_cell_output is Q. place_group_repeat ers ECO-234 Warning: There is no repeater to be placed for the path driver (%s). place_group_repeat ers ECO-235 Warning: There is no route on driver net (%s). place_group_repeat ers ECO-236 Warning: There is no target load for path driver (%s). place_group_repeat ers ECO-237 Warning: Some cell to be placed has no load for path driver (%s). place_group_repeat ers ECO-239 Info:%s. Check the place and connection mode. Show the place mode (cutline/distance) and connection mode (virtual connection/real connection) on this command. 1001 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error: The option -cells cannot be used when the app option eco.placement.eco_enable_ virtual_connection is true. Check the command for virtual connection. Specify the -repeater_groups command if you need to use virtual connection. place_group_repeat ers ECO-241 Warning: The distance based placement does not support multi-fanout path driver(%s). Check the cutline based placement for the multi-fanout path driver. place_group_repeat ers unplace_group_repeat ers ECO-242 Warning: The cell (%s) has no driver or load (number of driver: %d, number of load: %d). place_group_repeat ers ECO-243 Error: The cells in collection (%s) are invalid since they have no driver or load. Check for invalid cells. Ensure the cell that is placed has both driver and load. Else, remove such cells from input. place_group_repeat ers ECO-244 Warning: The %s %s has no shape. Check if the top port or macro pin has shape. place_group_repeat ers ECO-246 Warning: Skip the path driver (%s) since the driver or load for the path has no shape. place_group_repeat ers ECO-251 Info: Place group repeaters successfully. Check if all the input cells are placed successfully. place_group_repeat ers ECO-252 Warning: Failed to place repeaters for repeater path which driver is %s. place_group_repeat ers ECO-253 Warning: The cutline information %s for cell %s is not on valid route. 1002 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning: Failed to cut route for cell %s. Check if the command failed to cut route for cell. place_group_repeat ers ECO-255 Warning: Gap %s between driver and nearest route is larger than placing distance %s Check if the route to the nearest pin distance is larger than placing distance for driver or load. place_group_repeat ers ECO-256 Warning: The first distance (%s) specified by command option is shorter than the gap (%s) between pin and route for driver (%s). (warning) The last distance (%s) specified by command option is shorter than the gap (%s) between pin and route for load (%s). Check if the -first_distance or -last_distance option specified is shorter than the gap between pin and route for driver or load. place_group_repeat ers ECO-257 Warning: Cannot find cutline information for cell %s. place_group_repeat ers ECO-258 Info: The app option about virtual connection is turned on. Please make sure the cells in repeater group keep in order. Check if the eco.placement.eco _enable_virtual_c onnection option is set to true and the place_group_repea ters -repeater_groups option is specified. place_group_repeat ers unplace_group_repeat ers ECO-259 Warning: The number of cells from repeater group (%d) is not consistent with the number of drivers from driver group (%s). place_group_repeat ers unplace_group_repeat ers ECO-260 Warning: The number of cells from repeater group (%d) is not consistent with the number of loads from load group (%s). 1003 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning: The number of path loads is less than the number of cells in group (%d), so skip these path loads. place_group_repeat ers unplace_group_repeat ers ECO-262 Warning: The number of path loads is not an integral multiple of the number of cells in group (%d), so use path loads in order. place_group_repeat ers ECO-265 Warning: The pin shape {%s} of %s (%s) is projected to route %s {%s}. Check if the route is far away from driver or loads. The tool projects the closest pin shape to the route. unplace_group_repeat ers ECO-266 Warning: The cells in collection %s which are not placed before cannot be unplaced by unplace_group_repeaters. Check if the cells are not placed. The cells that are not placed cannot be unplaced. Also, only the cells added by the add_group_repeat ers command and placed by the placed_group_repe aters command can be unplaced by the unplace_group_rep eaters command. unplace_group_repeat ers ECO-267 Error: Input and output routes are not merged after unplacing repeater %s since the routes are not aligned or not at the same layer. Check if the routes are merged after unplacing repeaters. This error occurs when the routes are not aligned or not at the same layer since they are not merged. 1004 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-268 Error: The cells in collection (%s) are invalid since they are placed before. Apply the command unplace_group_repeaters to unplace them."}
{"instruction": "How do I Inserting and Removing Cut Metal Shapes", "input": "", "output": "Cut metal shapes are used in double-patterning designs to reduce the line-end minimum spacing. A cut metal layer and the dimensions of the cut metal shapes inserted on that layer are defined in a Layer section in the technology file. The width of the cut metal shapes is defined by the cutMetalWidth attribute. The height of the cut metal shapes is defined by either the cutMetalHeight or cutMetalExtension attribute. A cut metal layer corresponds to the metal layer with the same mask number. For example, cutMetal1 corresponds to metal1. For information about the technology file, see the Synopsys Technology File and Routing Rules Reference Manual After the routing is finalized, you add cut metal shapes by using the create_cut_metals command. This command inserts a cut metal shape between metal shapes when all of the following conditions are met: The spacing between the metal shapes in the preferred direction is cutMetalWidth There is no existing cut metal shape in the location. The metal shapes are on a metal layer that corresponds to a cut metal layer defined in the technology file. The command inserts cut metal shapes between net shapes, a net shape and a PG shape, a PG shape and an obstruction, and metal shapes within a child cell. After inserting 579 Inserting and Removing Cut Metal Shapes Feedback the cut metal shapes, the command propagates the color of the metal shapes to the cut metal shapes. When you write a DEF file for a block with cut metal shapes, you must use the -version 5.8 option with the write_def command. When you write a GDSII or OASIS file for a block with cut metal shapes, you must use the -connect_below_cut_metal option with the write_gds or write_oasis command. If the routing changes after inserting cut metal shapes, you must remove the existing cut metal shapes and reinsert them. To remove all cut metal shapes from a block, use the remove_cut_metals command. 580 Feedback"}
{"instruction": "How do I Using the DRC Query Commands", "input": "", "output": "You can get information about DRC violations by using the get_drc_errors command to create a collection of DRC violations and then using the get_attribute command to query the attributes of the errors. Some attributes that provide information about DRC errors are type_name bbox objects, and shape. Note that the availability of attribute values depends on the error type and the verification method used. For a list of all attributes associated with DRC errors, use the list_attributes -application -class drc_error command. Before you run the get_drc_errors command, you must load the error data files that you want to query. To determine the error data files attached to the current block, use the get_drc_error_data command. You must use the -all option to include both the opened and unopened error data files in the result. fc_shell> get_drc_error_data -all 577 Saving Route Information Feedback To load an error data file, use the open_drc_error_data command. fc_shell> open_drc_error_data zroute.err To determine the error data types included in the error data file, use the get_drc_error_types command. fc_shell> get_drc_error_types -error_data zroute.err By default, the get_drc_errors command creates a collection that contains all DRC violations contained in the specified error data file. Use the -filter option to restrict the returned errors. For example, to return only \"Diff net spacing\" errors, use the following command: fc_shell> get_drc_errors -error_data zroute.err \\ -filter {type_name == \"Diff net spacing\"} To get the nets associated with an error, use the get_attribute command. For example, fc_shell> get_attribute [get_drc_errors -error_data zroute.err 859] \\ objects {u0_1/n237}"}
{"instruction": "How do I Fixing Buffers", "input": "", "output": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design. The command can perform the following changes: Minimize the number of dual-rail buffers or inverters Fix isolation violations in buffer trees Fix buffers and inverters that have illegal settings, as follows: Process, voltage, and temperature settings Library cell purpose or subset settings Target library subset settings Bias voltages Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: Swap buffer library cells to fix illegal settings Swap single-rail buffers for dual-rail buffers Swap dual-rail buffers for single-rail buffers Change the backup supplies of dual-rail buffers and inverters Change the input or output supplies of level shifters Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters. In addition, 1007 Fixing Multivoltage Violations Feedback the command only uses supplies that are available in the voltage area or voltage area region. The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations. Netlist changes caused by the command do not introduce new isolation or voltage violations. To specify a buffer tree, use the -from option with the name of a net or driver pin. If you specify a net name, its driver pin is used. In both cases, the driver pin defines a full or partial buffer tree. Wildcards are supported. The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells. By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations. However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area. If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order: A cell from the same library as the original library cell A cell from a library with a name similar to the original library A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells. Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells. However, the command does not change level-shifter library cells. To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}
{"instruction": "How do I Setting Up Multivoltage Designs", "input": "", "output": "The following topics describe the tasks you need to perform when setting up multivoltage designs: Applying the Multivoltage Power Intent Preparing the Power Network 113 Setting Up Multivoltage Designs Feedback Defining Voltage Areas Inserting Multivoltage Cells Controlling the Placement of Multivoltage Cells Enabling Improved Buffering for Multivoltage Nets Analyzing Multivoltage Information"}
{"instruction": "How do I Enabling Advanced PG Net Checks", "input": "", "output": "For advanced technology nodes, such as 12 nanometer, 7 nanometer, or smaller technology nodes, you can enable advanced physical DRC checks between cells and prerouted PG nets by setting the place.legalize.enable_advanced_prerouted_net_check application option to true When you enable this feature, you can further control the accessibility checks performed for standard cell pins by using the place.legalize.advanced_layer_access_check and place.legalize.advanced_libpin_access_check application options. However, the default behavior of this feature is suitable for most designs. 163 Specifying Legalization Settings Feedback"}
{"instruction": "How do I Setting Self-Gating Options", "input": "", "output": "To specify self-gating settings, use the set_self_gating_options command with the following options: -min_bitwidth bitwidth Controls the minimum size for self-gating banks. The default is 4. -max_bitwidth bitwidth Controls the maximum size for self-gating banks. The default is 8. -interaction_with_clock_gating interaction_type Registers gated by user-instantiated clock-gating cells are candidates for self-gating. Valid arguments are none (skip registers gated by tool-inserted clock gates), insert (the default; insert self-gates on gated registers), and collapse (collapse tool-inserted clock gates if they are in the same hierarchy). -objects object_list Specifies that the options should be applied to the listed objects. Supported objects are hierarchical instances, power domains, and designs. By default, the settings apply to the entire design. -tree_type combinational_logic_type Uses the specified logic type to build the gated enable tree. Valid arguments are xor nand or, and auto (the default). 332 Self-Gating Optimization Feedback To report self-gating options, use the report_self_gating_options command."}
{"instruction": "How do I Viewing the Violations in an ICV Heat Map", "input": "", "output": "An ICV heat map displays the density of signoff DRC violations in a block. You can use the heat map to locate problematic areas in your design. 673 Performing Signoff Design Rule Checking Feedback Note: This feature requires version P-2019.06 or later of the IC Validator tool and an IC Validator NXT license. To view the ICV heat map, 1. Enable the ICV heat map by setting the signoff.check_drc.enable_icv_explorer_mode application option to true fc_shell> set_app_options -name signoff.check_drc.enable_icv_explorer_mode \\ -value true 2. Perform signoff design rule checking as described in Running the signoff_check_drc Command 3. In the GUI, choose View > Map > ICV Heatmap. Figure 135 shows an ICV heat map. 674 Performing Signoff Design Rule Checking Feedback Figure 135 ICV Heat Map 675 Performing Signoff Design Rule Checking Feedback"}
{"instruction": "How do I Configuring Distributed Processing", "input": "", "output": "Distributed processing performs tasks in parallel by using multiple machines; each process uses its own process memory image. When using distributed processing, each parallel task is called a process. For the best performance during distributed processing, you should limit the number of processes to the number of available cores, which is the sum of the number CPUs times the number of cores per CPU for each host machine. The following commands support distributed processing configured by the set_host_options command: analyze_rail create_placement -floorplan signoff_check_drc signoff_fix_drc signoff_create_metal_fill signoff_fix_isolated_via When you configure distributed processing, you can specify one or more of the following settings: The job submission command (the -submit_command option) If you do not specify this option, the tool uses the rsh command to submit the parallel processes. The list of host machines (the host_names argument) The maximum number of processes (the -num_processes option) By default, the tool assigns a name to each configuration you define with the set_host_options command. To specify the configuration name, use the -name option. You use the configuration name to select the configuration to use for specific commands and to remove a configuration. For example, to specify a distributed processing configuration that uses the qsub command to submit the parallel processes, use the following command: fc_shell> set_host_options -name dp_config \\ -submit_command [list qsub -P bnormal -cwd]"}
{"instruction": "How do I Generating Via Ladder Rules for Performance Via Ladders", "input": "", "output": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the setup_performance_via_ladder command to generate the via ladder rules and associations. By default, this command Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the -max_layer attribute. 451 Inserting Via Ladders Feedback The command uses information from the technology file to generate the via ladder rules. The command derives the following information from the technology file: The cut layers that connect the specified metal layers The cut names The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block. The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules. For details about these files, see Via Ladder Rule Files You can also generate these files by using the generate_via_rules_for_performance command. Associates via ladder rules with the pins of all library cells that do not have a dont_use attribute To include the pins of library cells that have a dont_use attribute, use the -dont_use option. To associate via ladder rules only with specific pins, use the -lib_pins option. The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations. For details about this file, see Via Ladder Association File You can also generate this file by using the associate_performance_via_ladder command. Runs the generated script files See Also Defining Via Ladder Rules Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization 452 Inserting Via Ladders Feedback"}
{"instruction": "How do I Controlling the Tiling Within Relative Placement Groups", "input": "", "output": "To control the tiling of objects within a relative placement group, use the set_rp_group_options -tiling_type command with the settings shown in the following table. Table 58 Controlling Placement With the set_rp_group_options -tiling_type Command To do this Use this setting Tile objects in a bit-slice pattern and preserve both the row and column alignment. The height of a row is determined by the tallest object in the row The width of a column is determined by the widest object in the column bit_slice (Default) Horizontally compress the objects in each row and maintain row alignment. horizontal_compression Vertically compress the objects in each column and preserve the column alignment vertical_compression 800 Specifying Options for Relative Placement Groups Feedback Figure 180 Bit-Slice Placement Versus Horizontal or Vertical Compression Bit-slice placement Vertical compression Horizontal compression The setting of the -tiling_type option is not propagated from a parent group to child groups."}
{"instruction": "How do I Inserting Tap Cells", "input": "", "output": "tap cell is a special nonlogic cell with a well tie, substrate tie, or both. These cells are typically used when most or all of the standard cells in the library contain no substrate or well taps. Generally, the design rules specify the maximum distance allowed between every transistor in a standard cell and a well or substrate tap. Before global placement (during the floorplanning stage), you can insert tap cells in the block to form a two-dimensional array structure to ensure that all standard cells placed subsequently comply with the maximum diffusion-to-tap distance limit. After you insert the tap cells, visually check to ensure that all standard-cell placeable areas are properly protected by tap cells. 581 Inserting Tap Cells Feedback The Fusion Compiler tool provides two methods to insert a tap cell array: Insert the tap cell array based on the site rows and the maximum distance between tap cells To use this method, use the create_tap_cells command, as described in Using the create_tap_cells Command Insert the tap cell array using a specified offset and pitch, and optionally insert additional tap cells near the boundary To use this method, use the create_cell_array command, as described in Using the create_cell_array Command Advanced nodes often require the insertion of additional tap cells to manage the substrate and well noise. You can use the following capabilities to insert additional tap cells after standard tap cell insertion: Insertion of tap walls tap wall is a row or column of tap cells placed linearly without any gaps between cells. You can insert a tap wall outside or inside of the boundary of a block, macro, or hard placement blockage. A tap wall that is outside a boundary is called an exterior tap wall. A tap wall that is inside a boundary is called an interior tap wall To insert an exterior tap wall, use the create_exterior_tap_walls command, as described in Inserting Exterior Tap Walls To insert an interior tap wall, use the create_interior_tap_walls command, as described in Inserting Interior Tap Walls Insertion of tap meshes tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window. To insert a tap mesh, use the create_tap_meshes command, as described in Inserting Tap Meshes Insertion of dense tap arrays dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the create_tap_cells command. To insert a dense tap array, use the create_dense_tap_cells command, as described in Inserting Dense Tap Arrays"}
{"instruction": "How do I Reporting Clock-Gating Results", "input": "", "output": "After compiling your design, you can check the results using the report_clock_gating command. An example is shown in Figure 64 Figure 64 Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics. The term \"pre-existing clock gates\" refers to user-instantiated clock gates. The preexisting category also includes registers that are gated by a tool-inserted clock gate. This includes registers that are gated by both preexisting and tool-inserted clock-gating cells. By default, the tool reports multilevel statistics. This includes the maximum level of clock- gating cells in the design. Clock-gate levels are counted from the clock source toward the register. If multibit flip-flops are found in the design, multibit composition is automatically reported. 321 Reporting Clock-Gating Results Feedback Figure 65 Example of a Multibit Composition Report To report the details on ungated registers, use the -ungated option for report_clock_gating. For details on the gated registers, use the -gated option. 322 Reporting Clock-Gate Enable Signals Feedback"}
{"instruction": "How do I Selecting and Multiplexing Logic", "input": "", "output": "The Fusion Compiler tool infers SELECT_OP cells for logic that selects data signals based on control signals. SELECT_OP cells are mapped to combinational logic. The following topics describe SELECT_OP inferences: Inferring SELECT_OPs Inferring SELECT_OPs HDL Compiler uses SELECT_OP components to implement conditional operations implied by if and case statements. An example of a SELECT_OP cell implementation for an 8-bit data signal is shown in Figure 31 227 Controlling Mapping and Optimization Feedback Figure 31 SELECT_OP Implementation for an 8-bit Data Signal Figure 32 Verilog Output\u2014SELECT_OP and Selection Logic 228 Controlling Mapping and Optimization Feedback Depending on the design constraints, Fusion Compiler implements the SELECT_OP with either combinational logic or multiplexer cells from the logic library. For more information on SELECT_OP inference, see the HDL Compiler documentation."}
{"instruction": "How do I Transferring to Back End", "input": "", "output": "To transfer the clock latencies and balance points from the front-end tool to the back-end tool, use the write_ascii_files command. The command writes the design.MCMM directory, which contains timing contexts in Tcl files for. For example, The design.MCMM/scenario_ scenario.tcl file contains the following clock latency settings: set_clock_latency -clock [get_clocks {CLK}] -0.3 [get_pins {d_reg[4]/CP}] set_clock_latency -clock [get_clocks {CLK}] 0.1 [get_pins {d_reg[7]/CP}] The design.MCMM/mode_ mode.tcl file contains the following balance points: set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[4]/CP}] \\ -consider_for_balancing true \\ -rise -delay 0.3 -corners [get_corners {default}] set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[7]/CP}] \\ -consider_for_balancing true -rise -delay -0.1 -corners [get_corners {default}]"}
{"instruction": "How do I Removing Routing Guides", "input": "", "output": "To remove routing guides from the current block, use the remove_routing_guides command. To remove specific routing guides, specify the routing rules, either as a list or collection, such as that returned by the get_routing_guides command. To remove all routing guides, specify the -all option. For example, to remove the new_width_rule routing rule, use the following command: fc_shell> remove_routing_rules new_width_rule"}
{"instruction": "How do I Controlling Pin Connections", "input": "", "output": "By default, Zroute connects a signal route to a pin by using wires or vias anywhere on the pin. To restrict the allowed types of pin connections on a per-layer basis, use the following 513 Routing Constraints Feedback syntax to set the route.common.connect_within_pins_by_layer_name application option: set_app_options -name route.common.connect_within_pins_by_layer_name -value { { layer mode }... } Valid values for the mode argument are off (the default) There are no restrictions on pin connections. via_standard_cell_pins Only the connections to standard cell pins by using a via are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. There are no restrictions on signal routes connected to macro cell and pad cell pins by using a via or to any pins by using wires. via_wire_standard_cell_pins The connections to standard cell pins by using a via or a wire are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. When using a wire, the wire must be contained within the pin shape. via_all_pins The connections to any pins (standard cell, macro cell, or pad cell) by using a via are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. There are no restrictions on signal routes connected to any pins by using wires. via_wire_all_pins The connections to any pins by using a via or a wire are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. When using a wire, the wire must be contained within the pin shape. For example, if you use the following command (or use the default settings), all of the connections shown in Figure 113 are valid and no DRC violations are reported: fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 off}} 514 Routing Constraints Feedback Figure 113 Unrestricted Pin Connections If you set the mode for M1 to via_all_pins, as shown in the following example, the via enclosures must be inside the pin shape. The connections shown on the left side of Figure 114 are valid; however, the connections on the right side of the figure cause DRC violations. fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_all_pins}} Figure 114 Restricted Via-to-Pin Connections No DRC Violations DRC Violations If you set the mode for M1 to via_wire_standard_cell_pins, as shown in the following example, both the via enclosures and wires must be inside the pin shape. The connections 515 Routing Constraints Feedback shown on the left side of Figure 115 are valid; however the connections on the right side of the figure cause DRC violations. fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_wire_standard_cell_pins}} Figure 115 Restricted Via-to-Pin and Wire-to-Pin Connections DRC Violations No DRC Violations"}
{"instruction": "How do I Inserting Interior Tap Walls", "input": "", "output": "An interior tap wall is a row or column of tap cells that is placed inside the boundary of the standard cell placement area of a block, a macro, hard placement blockage, or nondefault voltage area. Note: You can insert interior tap walls only for designs with a single site definition. To insert an interior tap wall, use the create_interior_tap_walls command. You must specify the following information: The tap cell used in the tap wall (the -lib_cell option) The specified tap cell must be a single-height cell that matches the row height and site width. By default, the command inserts the tap cells with the row orientation. To place the cells with a different orientation, use the -orientation option. By default, the tool uses the following naming convention for inserted tap cells: tapfiller__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number The side along which to insert the tap wall (the -side option) You can specify only a single side, top bottom right, or left. To insert a tap wall on more than one side, run the command multiple times. 589 Inserting Tap Cells Feedback By default, the tap cells are placed along all edges on the specified side of the standard cell placement area with no gaps between the tap cells. To specify the tap insertion region, use the -bbox option to specify the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} When you use this option, the command inserts a tap wall along the longest edge on the specified side of the placeable area encompassed by the bounding box. The alignment of the tap wall depends on the number of corners of the edge segment encompassed by the bounding box. If the edge segment does not contain a corner, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall. If the edge segment contains one corner, the tap wall starts at that corner. If the edge segment contains two corners along the specified side, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall. For a horizontal tap wall with two corners, the spacing between the last two cells might be shortened to align with the right corner. If there is not enough space, the last cell might not abut the right corner. For horizontal tap walls, you can specify a gap distance between tap cells by using the -x_spacing option. If you specify a value smaller than the tap cell width, the command uses a spacing of zero. If you specify a value that is not a multiple of the site width, the command rounds it down to a multiple of the site width. When inserting the tap wall, the command honors the standard cell rows and sites; if the rows and sites are not defined, the command does not insert tap cells. Obstructions such as placement blockages, fixed cells, and macros can prevent the insertion of the tap cells and result in an incomplete or missing tap wall. After insertion, the command fixes the placement of the inserted tap cells. 590 Inserting Tap Cells Feedback"}
{"instruction": "How do I Specifying Settings for Clock Latency Adjustments", "input": "", "output": "I/O ports are usually constrained using real or virtual clocks. After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate. When you run clock tree synthesis with the clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports. You can control these latency adjustments by using the set_latency_adjustment_options command. The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell> set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the synthesize_clock_trees command, the tool does not automatically update the clock latencies. To do so, use the compute_clock_latency command after clock tree synthesis. This command honors the settings you specify with the set_latency_adjustment_options command. 369 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}
{"instruction": "How do I Bus Routing Options", "input": "", "output": "The Custom Router bus routing application options allow you to specify: Corner Type Intra-shield Placement Pin-Trunk Offset Trunk Splitting Tapoffs"}
{"instruction": "How do I Inserting Shields on the Nets", "input": "", "output": "To add shielding on the selected nets to reduce crosstalk or parasitic effects, run the create_net_shielding command. You need to specify the following information: The name of the constraint group If you do not specify a name, the command names the constraint group shielding_ where is a unique integer. By default, the command returns an error if the assigned name already exists. To delete the existing constraint group, use the -force option. The nets, bundles, and topology edges to which the constraint group applies Use the -for option. The constraints for shielding styles and layer-specific requirements To define the net shielding constraints that are applied per layer to the trunk and override any settings on the individual bits, use the options listed in Table 55 753 Defining Routing Constraints Feedback Table 55 Net Shielding Constraints Option Description -shield_net Specifies the net you want to use as the shield. When routing a single signal net, the tool uses this net for the left and bottom shields. -shield_net_2 Specifies the secondary net you want to use as the shield. When routing a single signal net, the tool uses this net for the right and top shields. -via_defs Specifies the vias that can be used to connect to the shield. By default, all via definitions can be used. -gap Specifies the global minimum spacing between route objects and shield objects. The default is 0. -max_gap Specifies the global maximum spacing between route objects and shield objects. The default is 0. -width Specifies the global shield width. The default is 0. -layer_gaps Specifies the layer-specific minimum spacing between route objects and shield objects. The default is 0. -layer_max_gaps Specifies the layer-specific maximum spacing between route objects and shield objects. The default is 0. -layer_widths Specifies the layer-specific shield width. The default is 0. -min_segment Specifies the minimum length of wiring to shield. The default is 0. -sharing Specifies whether the shielding can be shared among the nets in the constraint group. Valid values are unset, true and false -group_shield Uses a single set of shield shapes to shield all nets in the constraint group. This option is mutually exclusive with the -enclose_pins option. -enclose_pins Specifies whether pins are enclosed by the shield. This option is mutually exclusive with the -group_shield option. Valid values are unset, true, and false -enclose_vias Specifies whether vias are enclosed by the shield.Valid values are unset, true, and false -disabled_layers Specifies the layers that cannot be used for shielding. 754 Defining Routing Constraints Feedback The following example creates a constraint group and specifies constraints for adding shields on the nets whose names start with pr. The minimum spacing is 3 microns for the M2 layer and 5 microns for the M3 layer. All constituent objects can share the shield; the M5 and M6 layers cannot be used for shielding. fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*] \\ -disabled_layers {M5 M6} -sharing true -layer_gaps {M2 3 M3 5} {shielding_4}"}
{"instruction": "How do I Self-Gating Flow", "input": "", "output": "Figure 68 illustrates the Fusion Compiler flow for inserting self-gates by using the compile_fusion command. 330 Self-Gating Optimization Feedback Figure 68 General Self-Gating Flow Fusion Compiler read_saif in.saif or set_switching_activity compile_fusion SAIF RTL/netlist Libraries Reports set_app_options -name compile.clockgate.self_gating -value true"}
{"instruction": "How do I Setting Up Libraries", "input": "", "output": "block is a container for physical and functional design data. A design library is a collection of related blocks, together with technology data that applies to the block collection. A chip design consists of one or more blocks, often stored in different design libraries. A design library uses instances of blocks defined in lower-level libraries, called reference libraries. A design library can serve as a reference library for another design library. To learn about setting up libraries, see the following topics: Working With Design Libraries Setting Up Reference Libraries Library Configuration Restricting Library Cell Usage Restricting the Target Libraries Used Specifying Library Subset Restrictions 73 Setting Up Libraries Feedback"}
{"instruction": "How do I Concurrent Soft-Rule-Based Redundant Via Insertion", "input": "", "output": "Soft-rule-based redundant via insertion can improve the redundant via rate by reserving space for the redundant vias during routing. You can use concurrent soft-rule-based redundant via insertion during both initial routing and ECO routing. The actual via insertion is not done during routing; you must still perform postroute redundant via insertion by using the add_redundant_vias command. Note: Reserving space during routing increases the routing runtime. You should use this method only when needed to improve the redundant via rate beyond that provided by postroute redundant via insertion and the postroute approach resulted in a redundant via rate of at least 80 percent. 627 Inserting Redundant Vias Feedback To perform concurrent soft-rule-based redundant via insertion, 1. (Optional) Define the via mapping table as described in Defining a Customized Via Mapping Table 2. Enable concurrent soft-rule-based redundant via insertion. By default, concurrent redundant via insertion is disabled. To enable concurrent soft-rule-based redundant via insertion during initial routing, set the route.common.concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during initial routing, set the route.common.concurrent_redundant_via_effort_level application option. By default, Zroute uses low effort. The higher effort levels result in a better redundant via conversion rate at the expense of runtime. The low and medium efforts affect only global routing and track assignment, while high effort also affects detail routing, which can impact design rule convergence. Note: If you enable the route.common.concurrent_redundant_via_mode option before running the place_opt command, the redundant vias are considered during congestion estimation. To enable concurrent soft-rule-based redundant via insertion during ECO routing, set the route.common.eco_route_concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.eco_route_concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during ECO routing, set the route.common.eco_route_concurrent_redundant_via_effort_level application option. Note: Using concurrent soft-rule-based redundant via insertion during ECO routing can impact timing and design rule convergence. In general, you should use this method only when you used near 100 percent redundant via insertion during initial routing. 628 Inserting Redundant Vias Feedback 3. Route the block. During routing, Zroute reserves space for the redundant vias and fixes hard design rule violations. 4. Perform postroute redundant via insertion. During postroute redundant via insertion, Zroute inserts the redundant vias in the reserved locations."}
{"instruction": "How do I Mapping of Synchronous Reset or Preset Registers", "input": "", "output": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default. To infer registers with synchronous reset or preset pins, use the sync_set_reset Synopsys compiler directive in the RTL. HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible. To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: The sync_set_reset directive Specify the //synopsys sync_set_reset directive in the RTL. The hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to true. The default is false 233 Controlling Mapping and Optimization Feedback During compile, the tool performs the following mapping based on the registers in your library: The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin. The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin. The tool also attempts to map the logic as close as possible to the data pin. This figure shows examples of mapping to registers with and without a synchronous reset pin. ___ RST Using a reset pin ___ RST Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible. To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to true Note: Synchronous reset and preset signals are not inferred for level-sensitive latches. A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins. Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must Describe the registers correctly in the RTL Ensure the library contain the corresponding cells Ensure the hdlin.elaborate.ff_infer_async_set_reset application option is set to true (the default) 234 Controlling Mapping and Optimization Feedback If the library does not contain this type of registers, the tool leaves the cells unmapped."}
{"instruction": "How do I Setting Options for Power Grid Augmentation", "input": "", "output": "Before you run the signoff_create_pg_augmentation command, configure the run by setting the application options shown in Table 48. To set the application options, use the set_app_options command. To see the current settings, use the report_app_options command. Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff. create_pg_augmentation. ground_net_name (required) (none) Specifies the name of the ground net. signoff. create_pg_augmentation.po wer_net_name (required) (none) Specifies the name of the power net. signoff. create_pg_augmentation. run_dir signoff_create_pg_ augmentation_run Specifies the run directory, which contains the files generated by the signoff_create_pg_augmentation command. You can specify either a relative path, in which case the directory is created under the current working directory, or an absolute path. 702 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff. create_pg_augmentation. user_defined_options (none) Specifies additional options for the IC Validator command line. The string that you specify in this option is added to the command line used to invoke the IC Validator tool. The Fusion Compiler tool does not perform any checking on the specified string."}
{"instruction": "How do I Constructing Faster Clock Tree to Specific Endpoints", "input": "", "output": "The Fusion Compiler tool enables you to construct a faster clock tree to specified endpoints without any additional detouring or delay balancing. This improves clock latency to the specified endpoints. To achieve a faster clock tree to specific endpoints, you must create a user skew group for the required endpoints. To create a skew group for a specific endpoint, use the following command before running the synthesize_clock_tree or the build_clock stage of the clock_opt command: fc_shell> create_clock_skew_group -objects <endpoints> Note: If there is a balancing requirement between the fast endpoints, you must put them in the same skew group. If there is no balancing requirement between the endpoints, you must create separate skew groups for each endpoint. The upstream clock logic of the required skew group endpoints is shared with the endpoints of the default group or other user skew groups. This leads to detouring for balancing among the endpoints of the default group or other user skew group. 366 Specifying the Clock Tree Synthesis Settings Feedback Figure 79 Faster Clock Tree to Specific Endpoints If a gate drives both skew group and non-skew group endpoints, the skew group endpoints might be delayed due to the balancing requirements of the non-skew group endpoints. In such cases, in addition to creating skew groups, you must also completely isolate the skew group endpoints from the rest of the clock tree by cloning the gates along the path to these endpoints. To create a separate clock path from the clock source to the required endpoints, use the -to option with the split_clock_cells command before clock tree synthesis, that is, before using the synthesize_clock_trees or the build_clock stage of the clock_opt command. fc_shell> split_clock_cells -to $endpoints The Fusion Compiler tool enables you to construct a faster clock tree by identifying the optimal cloning solution to achieve the best latency for the group of specified sinks. To achieve a fast clock tree to certain endpoints, use the split_clock_cells -to < $sinks> -latency_driven command. The endpoints must also be created as part of the user skew group using the create_clock_skew_group command. 367 Specifying the Clock Tree Synthesis Settings Feedback"}
{"instruction": "How do I Modifying Metal Fill", "input": "", "output": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes. To change the boundary of a metal fill shape, use the set_attribute command to modify its bbox attribute. To add a metal fill shape in the top-level fill cell, use the create_shape -shape_use area_fill command. To add a metal fill shape in a specific fill cell, use the create_shape -fill_cell command. To remove a metal fill shape, use the remove_shapes command. You can also modify metal fill shapes in the GUI. To select or modify fill shapes in the GUI, 1. Select \"Multiple Levels Active\" ( ) in the View Settings panel. 2. In the \"Hierarchy Settings\" panel, set \"View level\" to a minimum of 2 and select \"Fill Cell\" in \"Expanding cell types.\""}
{"instruction": "How do I Overriding the Alignment When Adding Objects", "input": "", "output": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option. However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option. The following example creates a relative placement group named rp1 that is right aligned. It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement. 799 Specifying Options for Relative Placement Groups Feedback Figure 179 Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}
{"instruction": "How do I Associating Checkpoints and Checkpoint Behaviors", "input": "", "output": "After defining checkpoints with the eval_checkpoint command and checkpoint behaviors with the create_checkpoint_* command, you must associate the two so that the tool executes the behaviors when it encounters the checkpoints in a run, as described in the following topics: Associating Checkpoints With Checkpoint Reports Associating Checkpoints With Checkpoint Actions See Also Defining Checkpoints Defining Checkpoint Behaviors Associating Checkpoints With Checkpoint Reports To associate a checkpoint report with one or more checkpoints, use the associate_checkpoint_report command in your checkpoint.config.tcl file. 56 Adding Changes to a Script With Checkpoints Feedback Specify the checkpoint report name with the -enable option. To enable the report to run before one or more checkpoints, specify the checkpoint names with the -before option. To enable the report to run after one or more checkpoints, specify the checkpoint names with the -after option. When associating a report with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character. Assume you have defined three checkpoints in your script named remove_buffers, place_opt_to_initial_opto, and place_opt_to_final_opto using the eval_checkpoint command, and two checkpoint reports named timing and app_options using the create_checkpoint_report command. To enable your timing report to run after the place_opt_to_initial_opto and place_opt_to_final_opto checkpoints, use the following command: associate_checkpoint_report -enable timing \\ -after { place_opt_to_initial_opto place_opt_to_final_opto } To enable your app_options report to run before all the checkpoints in your script, use the following command: associate_checkpoint_report -enable app_options -before * You can also add the command like this, which enables the report to run before the remove_buffers checkpoint and any checkpoints beginning with the phrase place_opt: associate_checkpoint_report -enable app_options -before remove_buffers place_opt* The following is a portion of your checkpointed script showing what happens when the script runs. Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in the run. The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the app_options report, configured to run before each checkpoint The code identifies the timing report, configured to run after the place_opt_to_final_opto checkpoint 57 Adding Changes to a Script With Checkpoints Feedback Associating Checkpoints With Checkpoint Actions To associate a checkpoint action with one or more checkpoints, use the associate_checkpoint_action command in your checkpoint.config.tcl file. Specify the checkpoint action name with the -enable option. To enable the action to run before one or more checkpoints, specify the checkpoint names with the -before option. To enable the action to run after one or more checkpoints, specify the checkpoint names with the -after option. To enable the action to run instead of the code block enwrapped by the checkpoint, specify the checkpoint names with the -replace option. When associating an action with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character. Assume you have defined two checkpoints in your script named place_opt_to_initial_drc and incr_placement with the eval_checkpoint command, and two checkpoint actions named gropto and placer_high_effort_cong with the create_checkpoint_action command. To enable your gropto action to run before the place_opt_to_initial_drc checkpoint, use the following command: associate_checkpoint_action -enable gropto \\ -before place_opt_to_initial_drc 58 Adding Changes to a Script With Checkpoints Feedback To enable your placer_high_effort_cong action to run instead of the code block enwrapped by the incr_placement checkpoint, use the following command: associate_checkpoint_action -enable placer_high_effort_cong \\ -replace incr_placement The following is a portion of your checkpointed script showing what happens when the script runs. Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in a run. The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the gropto action, configured to run before the place_opt_to_initial_drc checkpoint The code identifies the placer_high_effort_cong action, configured to run in place of the code block enwrapped by the incr_placement checkpoint 59 Adding Changes to a Script With Checkpoints Feedback Associating a Checkpoint With Multiple Behaviors When you associate a checkpoint with multiple behaviors, the tool executes those behaviors in the following order: Any reports configured to run before the checkpoint Any actions configured to run before the checkpoint The checkpointed code block, or any actions configured to replace it Any actions configured to run after the checkpoint Any reports configured to run after the checkpoint If multiple reports or multiple actions are configured to run at the same position ( -before -after, or -replace ) in the same checkpoint, the tool executes them in the order in which they were associated with the checkpoint with the associate_checkpoint_* commands. For example, suppose you define a timing report before an area report. If you associate the area report to run after a checkpoint before you associate the timing report to run after the same checkpoint, the tool runs the area report first when it encounters the checkpoint. See Also Defining Checkpoints Defining Checkpoint Behaviors Querying Checkpoints and Checkpoint Behaviors"}
{"instruction": "How do I Enabling Wire Length Aware Power-Driven Relocation", "input": "", "output": "The Fusion Compiler tool supports improved activity driven clock gate relocation by controlling the amount of wire length degradation and considering the power impact before performing the clock gate relocation. To enable activity driven clock gate relocation, set the cts.compile.power_opt_mode application option to all or gate_relocation The clock gates are not relocated or moved if: Relocating an integrated clock gate (ICG) has a minor power benefit or degrades power while degrading wire length. Moving the clock gate has a significant wire length impact for a less power benefit."}
{"instruction": "How do I Fixing DRC Violations Caused by Pin Access Issues", "input": "", "output": "In advanced process nodes, the distance between pins decreases, which can result in DRC violations caused by pin access issues. These types of DRC violations can be fixed by using keepout margins to increase the spacing between cells. 552 Performing Postroute Optimization Feedback If your postroute design has DRC violations, analyze the violations to determine if they are caused by pin access issues. If so, run the optimize_routability command to increase the spacing between cells where the DRC violations occur. The optimize_routability command performs the following tasks: Analyzes the cells with DRC violations to find violations where cells abut By default, the command considers all DRC violations. To consider only specific DRC violations, use the -drc_rules option. To consider only violations on specific layers, use the -layer_rules option. To preview the number of DRC violations and affected cells, use the -check_drc_rules option. When you use this option, the command generates a report but does not move any cells. Sets keepout margins on these cells on the side of the cell where the error occurs By default, the command uses the site width as the keepout width. To specify a keepout width in microns, use the -keepout_width option. Note: These keepout margins are in addition to any existing keepout margins on the cells; the command does not modify the existing keepout margins. To try to fix the DRC violations by flipping the cells instead of adding keepout margins, use the -flip option. Legalizes the affected cells You must use one of the following methods to complete the routes for the cells moved by the optimization: Run ECO routing by using the route_eco command. Run ECO routing by using the -route option with the optimize_routability command. To fix the DRC in the areas that have changes, set the route.common.eco_fix_drc_in_changed_area_only application option to on When you use this option, the command runs the route_eco and check_routes commands after completing the optimization. After moving the cells and performing ECO routing, remove the keepout margins from the cells by using the optimize_routability -remove_keepouts command. 553 Analyzing and Fixing Signal Electromigration Violations Feedback"}
{"instruction": "How do I Controlling Sequential Mapping", "input": "", "output": "The sequential mapping phase consists of two steps: register inferencing and technology mapping. The term register refers to both edge-triggered registers and level-sensitive latches. Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN. SEQGENs are created during elaboration and are usually mapped to flip-flops during compile. Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library. Both of these steps are performed by the compile_fusion command. 230 Controlling Mapping and Optimization Feedback Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable QN SEQGEN This table lists the pins of a SEQGEN cell. Only a subset of these pins is used depending on the type of cell that is inferred. Unused pins are tied to zero. Direction Name Description Cell type Input clear Asynchronous reset Flip-flop or latch preset Asynchronous preset Flip-flop or latch next_state Synchronous data Flip-flop clocked_on Clock Flip-flop data_in Asynchronous data Latch enable Clock or asynchronous enable Latch synch_clear Synchronous reset Flip-flop synch_preset Synchronous preset Flip-flop synch_toggle Synchronous toggle Flip-flop synch_enable Synchronous enable Flip-flop Output Non-inverting output Flip-flop or latch 231 Controlling Mapping and Optimization Feedback Direction Name Description Cell type QN Inverting output Flip-flop or latch During technology mapping, the tool uses the SEQGEN as the starting point for mapping. The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register. Topics in this section Mapping Sequential Elements Exactly as Described in RTL Mapping of Scan Cells Mapping of Synchronous Reset or Preset Registers Specifying Synchronous Input Types for Library Cell Pins Controlling Sequential Output Inversion Preventing Connections to Register QN Pins Mapping of Synchronous Enable Logic to a MUX Identification of Shift Registers"}
{"instruction": "How do I Controlling the Adjustment of I/O Clock Latencies", "input": "", "output": "By default, the tool adjusts the latencies of the I/O clocks, which are the clocks that constrain the boundary ports, when it performs concurrent clock and data optimization during the clock_opt command. The tool also uses concurrent clock and data optimization techniques to adjust the I/O clock latencies when you subsequently run the compute_clock_latency command. The tool does not update the I/O clock latencies For the entire block when you disable this feature by setting the ccd.adjust_io_clock_latency to false or when you disable concurrent clock and data optimization for boundary paths by setting the ccd.optimize_boundary_timing application option to false For specific I/O paths when you exclude the corresponding path groups from concurrent clock and data optimization by using the ccd.skip_path_groups application option For specific I/O clocks when you disable latency adjustment those I/O clocks by using the set_latency_adjustment_options -exclude_clocks command 379 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}
{"instruction": "How do I Validating DEF Files", "input": "", "output": "To analyze the input DEF files before annotating the floorplan information on the block, enable check-only mode by using the -syntax_only option. The check-only mode provides diagnostic information about the correctness and integrity of the DEF file. The check-only mode does not annotate any floorplan information onto the block. fc_shell> read_def -syntax_only block.def fc_shell> check_duplicates -remove The check_duplicates -remove command ensures that no duplicate shapes and vias are present in the block due to the execution of the read_def command."}
{"instruction": "How do I Inserting Multivoltage Cells", "input": "", "output": "A multivoltage design requires special multivoltage cells, such as level shifters and isolation cells, at the interface between power domains. Level shifters are required between power domains that operate at different voltage levels, while isolation cells are required between power domains that are in different states (powered-down versus always-on or powered-up)."}
{"instruction": "How do I Creating Abstracts for Minimum Pulse Width Analysis", "input": "", "output": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations. The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation. You can use the following application options to: Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to true The data paths to these registers are not retained. By default, this application is set to false Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack. This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}
{"instruction": "How do I Improving the Banking Ratio", "input": "", "output": "During the initial_mapping stage, the tool can prioritize the use of sequential library cells that have functionally equivalent multibit library cells. After you run the compile_fusion command, if the report_multibit -ignored_cells command indicates that many cells were not banked due to a lack of multibit cells in the library, you can enable this feature by setting the compile.seqmap.prefer_registers_with_multibit_equivalent application option to true and rerunning the compile_fusion command. However, enabling this feature might degrade the design QoR."}
{"instruction": "How do I Deriving the Clock Trees", "input": "", "output": "The Fusion Compiler tool derives the clock trees by tracing through the transitive fanout from the clock roots to the clock endpoints. In general, the tracing terminates when it finds a clock pin of a sequential cell or macro; however, the tool traces through sequential cells if they are integrated clock-gating (ICG) cells or their fanout drives a generated clock. If the clock-gating logic uses a non-unate cell, such as an XOR or XNOR gate, the tool uses both the positive-unate timing arc and the negative-unate timing arc when tracing the clock path. If this does not correspond to the functional mode of the block, use the set_case_analysis command to hold all nonclock inputs of the cell at a constant value, which forces the cell into the required functional mode for clock tree synthesis. For example, suppose a block has the gating logic shown in Figure 71 Figure 71 Non-Unate Gated Clock To force the XOR gate (U0) into functional mode for timing analysis, use the following command: fc_shell> set_case_analysis 0 U0/B"}
{"instruction": "How do I Using Incomplete UPF Information", "input": "", "output": "The Early Data Check Manager allows you to check designs for power and multivoltage issues early in the design cycle. You can configure different error conditions in different ways. The tool provides comprehensive reports about the data checks. The general flow is as follows: 1. Use the set_early_data_check_policy command to define the global violation handling policy for data checks. 2. Proceed with your tool flow. The tool detects and responds to violations throughout the flow. 3. Use the report_early_data_checks command to obtain a report about all violations or specific data checks. 4. Use the get_early_data_check_records command to get a Tcl collection of violations that can be used in other commands. 5. Use the write_early_data_check_config command to save the settings in a file for future use. 6. Use the remove_early_data_check_records command to clear the data in preparation for another iteration. For more information about the Early Data Check Manager, see the Fusion Compiler Data Model User Guide For a list of power and multivoltage data checks, see the Fusion Compiler Multivoltage User Guide 115 Setting Up Multivoltage Designs Feedback"}
{"instruction": "How do I Command", "input": "", "output": "The following topics describe how you can control the multibit optimization performed during the clock_opt command: Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Enabling Post-Clock-Tree-Synthesis Multibit Debanking Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Some logic libraries have mixed-drive-strength multibit cells where some bits have a higher drive strength than others. For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit. To enable this feature for the clock_opt command, set the clock_opt.flow.enable_multibit_rewiring application option to true Enabling Post-Clock-Tree-Synthesis Multibit Debanking To improve the timing QoR, the clock_opt command can debank multibit registers during the final_opt stage, if doing so does not introduce hold timing violations. To enable this feature, set the clock_opt.flow.enable_multibit_debanking application option to true before you run the final_opt stage of the clock_opt command."}
{"instruction": "How do I Implementing MSCTS Multiple H-Tree", "input": "", "output": "To improve clock QoR, latency, and skew, you can build multiple global trees in different sections of the floorplan by using the -htree_sections option with the set_regular_multisource_clock_tree_options command. The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh. The global clock structure consists only of an H-tree, which directly drives the tap drivers. 403 Implementing Multisource Clock Trees Feedback Figure 86 MSCTS Multiple H-Tree You can define the different sections in the floorplan by using a symmetric configuration of tap drivers or only tap locations by coordinates, as shown in the following example: set_regular_multisource_clock_tree_options - htree_sections [ list \\ [list -section_name \"sectionA_name\" -tap_boundary {{315.8800 1275.8000} {1750.0400 2187.1000}} -prefix \"sectionA\" -tap_boxes {4 4}] \\ [list -section_name \"sectionB_name\" -tap_locations {{700472} {1350 472}} -prefix \"section\"]] Figure 87 MSCTS Multiple H-Tree"}
{"instruction": "How do I Specifying the Naming Convention for Boundary Cells", "input": "", "output": "By default, the tool uses the following naming convention for inserted boundary cells: boundarycell! library_cell_name number To change the separator character from its default of \"!,\" use the -separator option with the set_boundary_cell_rules command.. To identify the boundary cells inserted in a specific run, use the -prefix option with the set_boundary_cell_rules command to specify a prefix string. When you use this option, the tool uses the following naming convention: boundarycell! prefix library_cell_name number"}
{"instruction": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges", "input": "", "output": "To insert maximum pattern routing guides along the nonpreferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects mprg_nonpreferred option. When you specify this object type, the command creates maximum pattern routing guides parallel to each nonpreferred-direction boundary edge. The maximum edge threshold for these routing guides is zero. 486 Routing Constraints Feedback By default, The routing guides are inserted only in the top-level block To insert routing guides in all soft macros in a hierarchical block, use the -hierarchical option. The routing guides are inserted on all routing layers To insert the routing guides only on specific routing layers, use the -layers option. The routing guides have the default metal width specified for the routing layer in the technology file To specify a different width in microns, use the -width_nonpreferred option. For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual The routing guides abut the preferred-direction edges The routing guides are offset from the nonpreferred-direction edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns, use the -spacing_nonpreferred option. For information about specifying the minimum spacing for a layer, see the \"Minimum Spacing Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual Figure 104 shows the routing guides inserted for an L-shaped block on a layer whose preferred direction is horizontal. S is the spacing specified by the -spacing_nonpreferred option. W is the width specified by the -width_nonpreferred option. 487 Routing Constraints Feedback Figure 104 Routing Guide Perimeter Constraint Objects See Also Using Routing Guides to Limit Edges in the Nonpreferred Direction"}
{"instruction": "How do I Setting the Rerouting Mode", "input": "", "output": "By default, Zroute can reroute nets as needed. You can prevent rerouting or limit rerouting to minor changes by setting the physical_status attribute on the nets. To freeze the net and prevent rerouting, set the attribute to locked To limit rerouting to minor changes, set the attribute to minor_change To allow Zroute to reroute the nets as needed, set the attribute to unrestricted For example, to prevent rerouting of the net1 net, which uses the default routing rule, use the following command: fc_shell> set_attribute -objects [get_nets net1] \\ -name physical_status -value locked"}
{"instruction": "How do I Reporting Redundant Via Rates", "input": "", "output": "After redundant via insertion, whether concurrent or postroute, Zroute generates a redundant via report that provides the following information: The via conversion rate for nondefault vias The via conversion rate for nondefault vias is listed at the top of the report as the total optimized via conversion rate. 630 Inserting Redundant Vias Feedback The optimized via conversion rate for each layer The optimized via conversion rate includes both double vias and DFM-friendly bar vias, which have a single cut but a larger metal enclosure. The tool reports two values for the via conversion rate: The total optimized via conversion rate This value is computed based on the total via count, which includes both fixed vias and routed vias. Fixed vias are vias that cannot be optimized by the router, such as unrouted vias and user-defined vias. The optimized via conversion rate based on the total routed via count This value is computed based only on the routed via count, which includes only those vias that can be optimized by the router. Note: The optimized via conversion rate is not useful if you are using bar vias. The distribution of optimized vias by weight for each layer To determine the via conversion rate for conversions above a certain weight, you must add the reported conversion rates for those weights. For example, in Example 29, the via conversion rate for weight 5 and above for layer V03 is 10.75+64.50=75.25%. Note: The conversion rate for unweighted vias is reported as \"Un-optimized.\" The total double via conversion rate for the block Note: The redundant via rate reported by the report_design command differs from the redundant via rate reported by Zroute during redundant via insertion or the check_routes command. This difference occurs because the report_design command reports the double via rate for both PG vias and signal vias, while Zroute reports the double via rate only for signal vias. In addition, Zroute bases the conversion rate only on the redundant via mapping. Example 29 shows an example of the redundant via report. Example 29 Redundant Via Report Total optimized via conversion rate = 96.94% (1401030 / 1445268 vias) Layer V01 = 41.89% (490617 / 1171301 vias) Weight 10 = 9.64% (112869 vias) Weight 5 = 32.25% (377689 vias) Weight 1 = 0.01% (59 vias) Un-optimized = 58.11% (680684 vias) 631 Optimizing Wire Length and Via Count Feedback Layer V02 = 76.20% (1567822/ 2057614 vias) Weight 10 = 43.51% (895270 vias) Weight 5 = 28.62% (588805 vias) Weight 1 = 4.07% (83747 vias) Un-optimized = 23.80% (489792 vias) Layer V03 = 81.87% (687115 / 839297 vias) Weight 10 = 64.50% (541369 vias) Weight 5 = 10.75% (90224 vias) Weight 1 = 6.62% (55522 vias) Un-optimized = 18.13% (152182 vias) Layer V04 = 81.60% (226833 / 277977 vias) Weight 10 = 81.45% (226418 vias) Weight 1 = 0.15% (415 vias) Un-optimized = 18.40% (51144 vias)... Layer V09 = 85.47% (1329 / 1555 vias) Weight 10 = 85.47% (1329 vias) Un-optimized = 14.53% (226 vias) Total double via conversion rate = 46.69% (2158006 / 4622189 vias)"}
{"instruction": "How do I Clock Gating in the Compile Log File", "input": "", "output": "The compile log file contains information about clock gating, which can help you debug simple setup issues. By default, the clock-gating information is displayed after Clock-gate insertion n the initial_map stage Clock-gate restructuring in the logic_opto stage Clock-gate restructuring in the initial_opto stage Self-gating insertion in the initial_opto stage, if enabled The reported information includes the following: The number of preexisting clock gates that have a dont_touch attribute, which prevents optimization and might lead to unsatistactory results The number of clock-gating library cells that have a CTS purpose, which is required for insertion Clock-gating metrics such as the number of elements and the number of gated registers A summary of reasons for registers that could not be gated If the self-gating or fanin-based sequential clock gating features are enabled, their metrics are displayed separately. An example of the compile log for a run that includes self-gating is as follows: Number of Pre-Exsting Clock Gates with dont_touch Attribute: 0 Number of ICG library cells with CTS purpose: 12 Tool Gated Register Summary Clock Gating Type | Number of Clock Gates | Register Count | Bitwidth | | | Equivalent Regular Clock Gating | 1 | 2 | 2 Self Gating | 0 | 0 | 0 Regular Clock Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Enable is Constant One | 2 | 2 289 Introduction to Clock Gating Feedback Self Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Register is clock gated, and ineraction | | is set to none | 2 | 2 The tool as not able to find enough registers | | that are compatible to this register | | in order to be gated. | 2 | 2"}
{"instruction": "How do I Saving UPF Information", "input": "", "output": "During physical implementation, the tool updates the power intent of the design. To generate an updated UPF file, use the save_upf command. You can use this UPF file in the subsequent steps of the design flow. The save_upf command separates the UPF commands based on the input UPF file, and adds a comment indicating the input UPF file and the time it was loaded. Assume you load, commit, and save UPF information as shown in the following example script: load_upf top_1.upf load_upf top_2.upf load_upf top_3.upf commit_upf save_upf top.upf 116 Setting Up Multivoltage Designs Feedback The resulting top.upf file contains the following information: ## Start - load_upf top_1.upf on Wed Oct 26 17:03:18 2016 ## End - load_upf ## Start - load_upf top_2.upf on Wed Oct 26 17:03:49 2016 ## End - load_upf ## Start - load_upf top_3.upf on Wed Oct 26 17:04:22 2016 ## End - load_upf"}
{"instruction": "How do I Spreading Repeater Cells During Placement", "input": "", "output": "If a block has many chains of repeater cells (buffers, inverters, or pipelined registers) along the edges or corners of macro cells or blockages, the tool might clump the cells along the edges or corners, increasing congestion. You can reduce this congestion by setting the place.coarse.spread_repeater_paths application option to true before you run the create_placement compile_fusion, or clock_opt command. Then, the tool reduces congestion along the edges and corners by spreading the repeater cells in an orthogonal direction."}
{"instruction": "How do I Minimizing Large Displacements During Legalization", "input": "", "output": "To minimize large displacements of cells during legalization, enable Orientation optimization by setting the place.legalize.optimize_orientations application option to true When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization. Stream placement by setting the place.legalize.stream_place application option to true When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization. You can further control stream placement by using the place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}
{"instruction": "How do I Analyzing and Fixing Signal Electromigration Violations", "input": "", "output": "Signal electromigration problems result from an increase in current density caused by the use of smaller line widths and higher operational speeds in IC designs. Electromigration can lead to shorts or opens due to metal ion displacement caused by the flow of electrons. The more frequently a net switches, the more susceptible it is to electromigration. To analyze and fix signal electromigration violations in a detail routed block, 1. Apply the signal electromigration constraints by using the read_signal_em_constraints command. For more information, see Loading the Signal Electromigration Constraints 2. Apply switching activity by either reading in a SAIF file with the read_saif command or annotating the switching activity information on the nets with the set_switching_activity command. For more information, see Annotating the Switching Activity 3. Report the signal electromigration information by using the report_signal_em command. For more information, see Analyzing Signal Electromigration 4. Fix any signal electromigration violations by using the fix_signal_em command. For more information, see Fixing Signal Electromigration Violations The following example script shows the signal electromigration flow. # Open the block and apply the signal electromigration constraints open_block block1_routed read_signal_em_constraints em.itf # Load switching information read_saif block1.saif # Perform signal electromigration analysis report_signal_em -violated -verbose > block1.signal_em.rpt # Fix signal electromigration violations fix_signal_em 554 Analyzing and Fixing Signal Electromigration Violations Feedback"}
{"instruction": "How do I Global Routing", "input": "", "output": "Before you run global routing, Define the common routing application options For information about the common routing application options, see the route.common_options man page. Define the global routing application options For information about the global routing application options, see the route.global_options man page. To perform standalone global routing, use the route_global command. By default, global routing is not timing-driven. For information about enabling timing-driven global routing, see Timing-Driven Global Routing The global router divides a block into global routing cells. By default, the width of a global routing cell is the same as the height of a standard cell and is aligned with the standard cell rows. For each global routing cell, the routing capacity is calculated according to the blockages, pins, and routing tracks inside the cell. Although the nets are not assigned to the actual wire tracks during global routing, the number of nets assigned to each global routing cell is noted. The tool calculates the demand for wire tracks in each global routing cell and reports the overflows, which are the number of wire tracks that are still needed after the tool assigns nets to the available wire tracks in a global routing cell. For advanced node designs, via density can be a concern. To enable via density modeling, set the route.global.via_cut_modeling application option to true. The tool then calculates the number of vias in each global routing cell and reports via overflows. Global routing is done in two phases: The initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell The rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows The tool might perform several rerouting phases. At the end of each rerouting phase, the tool recalculates the overflows. You should see a reduction in the total number of global routing cells with overflow and in the total overflow numbers. The global router stops and exits from the rerouting phase when the congestion is solved or cannot be solved further or after the maximum number of phases has occurred, as defined by the -effort_level option. You can force the global router to perform the maximum number of phases based on the specified effort level by setting the route.global.force_full_effort application option to true. By default, the tool 526 Routing Signal Nets Feedback uses medium effort and performs a maximum of three rerouting phases. You can perform up to six rerouting phases by specifying ultra effort. There are five global routing effort levels: minimum low medium high, and ultra Minimum ( -effort_level minimum The minimum effort level uses two times larger global routing cells relative to the other effort levels. It also has a much lower congestion cost and runs only one rerouting phase. It should only be used for prototype routing or for an initial congestion evaluation, not for detail routing. Low ( -effort_level low Low effort runs a maximum of two rerouting phases with very similar congestion cost. It is faster in comparison to medium effort and has reasonable QoR. If your block is not very congested, you can use the low effort level. Medium ( -effort_level medium Medium effort is the default effort level and runs a maximum of three rerouting phases. Global routing stops after the third phase or when the overflow is resolved, whichever occurs first. High ( -effort_level high High effort runs up to four rerouting phases. If your block is congested, use the high effort level. Ultra ( -effort_level ultra Ultra effort runs up to six rerouting phases. If your block is very congested, use the ultra effort level. At the end of global routing, the following information is stored in the design library: The g-links and g-vias on each routed net This information is used for the next routing steps. After Zroute performs track assignment and detail routing, it removes these g-links and g-vias from the design library. The congestion data This information is used to generate a congestion map. By default, only the hard congestion data is saved in the design library. To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing. The soft congestion data includes demand from soft nondefault spacing rules, as well as tool-generated soft rules. 527 Routing Signal Nets Feedback The global router reports block statistics and congestion data after the initial routing phase and after each rerouting phase. When global routing is complete, the global router reports a summary of the wire length and via count. Example 19 shows a global routing report. In the congestion report, the Overflow value is the total number of wires in the block that do not have a corresponding track available. The Max value corresponds to the highest number of overutilized wires in a single global routing cell. The GRCs value is the total number of overcongested global routing cells in the block. Example 19 Global Routing Report Start Global Route...... Design statistics: Design Bounding Box (0.00,0.00,3180.00,1154.00) Number of routing layers = 10 layer M1, dir Hor, min width = 0.05, min space = 0.05 pitch = 0.15 layer M2, dir Ver, min width = 0.06, min space = 0.06 pitch = 0.15... Net statistics: Total number of nets = 255165 Number of nets to route = 248716 Number of single or zero port nets = 1721 4728 nets are fully connected, of which 4728 are detail routed and 0 are global routed. 1648 nets have non-default rule clock_spacing... phase3. Routing result: phase3. Both Dirs: Overflow = 3320 Max = 3 GRCs = 4405 (0.08%) phase3. H routing: Overflow = 1759 Max = 2 (GRCs = 1) GRCs = 2756 (0.10%) phase3. V routing: Overflow = 1560 Max = 3 (GRCs = 20) GRCs = 1649 (0.06%) phase3. M1 Overflow = 1475 Max = 2 (GRCs = 1) GRCs = 2426 (0.09%) phase3. M2 Overflow = 1265 Max = 3 (GRCs = 20) GRCs = 1343 (0.05%)... Overflow over macro areas phase3. Both Dirs: Overflow = 293 Max = 2 GRCs = 300 (0.04%) phase3. H routing: Overflow = 133 Max = 1 (GRCs = 129) GRCs = 139 (0.03%) phase3. V routing: Overflow = 160 Max = 2 (GRCs = 2) GRCs = 161 (0.04%) phase3. M1 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%) phase3. M2 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%)... Density distribution: Layer 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 > 1.2 M1 86.6 10.5 0.37 1.46 0.02 0.44 0.18 0.14 0.07 0.03 0.10 0.00 0.00 0.02 M2 68.2 14.4 7.71 4.54 2.07 1.55 0.66 0.28 0.13 0.03 0.33 0.00 0.00 0.02... phase3. Total Wire Length = 21154552.81 phase3. Layer M1 wire length = 947324.93 phase3. Layer M2 wire length = 3959478.25... phase3. Total Number of Contacts = 2530044 phase3. Via VIA12SQ_C count = 1050582 phase3. Via VIA23SQ_C count = 856311... phase3. completed. 528 Routing Signal Nets Feedback Before proceeding to detail routing, display the congestion map in the GUI and check the overflow distribution. The congestion report and map help you to identify congested areas. For more information about the congestion report, see Generating a Congestion Report For more information about the congestion map, see Generating a Congestion Map"}
{"instruction": "How do I Performing Distributed RedHawk Fusion Rail Analysis", "input": "", "output": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow. By default, the analyze_rail command uses a single process to perform RedHawk rail analysis. To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run. You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session. This allows you to run multiple RedHawk analyses with only one Fusion Compiler license. Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key. To examine the generated analysis result, first run the open_rail_result command to load the result that is saved in the directory you specify. You can then investigate the problematic areas in the map and check for violations in a text file or in an error view. You can open one result context at a time. To load the rail context generated in another analysis run, first close the current rail result using the close_rail_result command, and then open the desired rail result (see Displaying Maps in the GUI ). License Requirement By default, the number of required licenses is the number of script files or configurations specified with the -multiple_script_files option during distributed processing mode. If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message. To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the analyze_rail run, set the rail.license_checkout_mode application option to wait. If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately. By default, the rail.license_checkout_mode application option is set to nowait When the analysis is finished, run the remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses. fc_shell> remove_licenses SNPS_INDESIGN_RH_RAIL 915 Performing Distributed RedHawk Fusion Rail Analysis Feedback In Figure 210, the rail.license_checkout_mode application option is set to wait. There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses. In this case, the tool first checks out two licenses and waits for other licenses to become available. When a script finishes the job, the tool reuses its license immediately to submit other scripts. Figure 210 Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6 Set rail.license_checkout_mode to wait The tool first submits two scripts to the farm machines, because there are only two licenses available.... The tool checks for available licenses during the analyze_rail run. When a license becomes available, the tool reuses it. Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1. Define the distributed processing configuration by using the set_host_options command. You can specify one or more of the following options: Option Description -submit_protocol Specifies the protocol to submit jobs, such as LSF, GRD, or SGE.Note: Before job submission, run the rsh command to check if the target farm machine supports the rsh protocol to accept distributed processing from on a remote machine. -target Specifies to submit jobs for RedHawk only. -timeout Specifies the job submission timeout value. 916 Performing Distributed RedHawk Fusion Rail Analysis Feedback Option Description -submit_command Specifies the full path name of the LSF, GRD, SGE, or custom job submission program along with other options as needed, such as qsub or bsub. -max_cores Controls the number of cores each distributed worker job can use. The default is 1. 2. Run the analyze_rail command with the following options: Option Description -submit_to_other_machines Enables RedHawk job submission to the target farm machines. -multiple_script_files\\ directory_name script_name Specifies the RedHawk scripts and the directories for saving analysis results. Example 51 %> rsh myMachine ls test1 CSHRC DESKTOP > set_host_options \"myMachine\" -target RedHawk \\ -max_cores 2 -timeout 100 > analyze_rail -submit_to_other_machines \\ -voltage_drop static -nets {VDD VDDG VDDX VDDY VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only. Timeout value is 100 and the number of cores to use is 2. Example 52 > set_host_options -submit_protocol sge \\ -submit_command { qsub -P normal } > analyze_rail -submit_to_other_machines -voltage_drop \\ static -nets {VDD VSS} The above example enables job submission to a machine on the SGE farm machine. Example 53 > set_host_options -submit_protocol lsf \\ -submit_command {bsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{result1 RH1.tcl} {result2 RH2.tcl}} > open_rail_result result1 917 Voltage Driven Power Switch Cell Sizing Feedback > close_rail_result > open_rail_result result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2. Example 54 > set_app_options -name rail.license_checkout_mode \\ -value wait > set_host_options -submit_protocol sge \\ -submit_command {qsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{ result1 RH1.tcl} {result2 RH2.tcl} \\ {result3 RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the analyze_rail run."}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "By default, the tool can select any library cell from the target library during optimization. In some cases, you might want to restrict the library cells used for clock tree synthesis and optimization. For example, you might want to exclude specific double-height cells from the target library for some design blocks during optimization. To restrict the library cells used for clock tree synthesis and optimization, 1. Specify the library subset by using the set_target_library_subset command. By default, the library subset restriction applies to 78 Setting Up Libraries Feedback The top block and all its subblocks To set it for a specific subblock, use the -objects option. Both clock and data paths. To set it for only the clock or data paths, use the -clock or -data option. You can further restrict the target library subset setting as follows: Specify a list of cells from the libraries that should not be used by using the -dont_use option. Specify that these libraries cannot be used for any other objects, other than the specified objects, by using the -only_here option. 2. Enable the use of the target library subset by setting the opt.common.enable_target_library_subset_opt application option to 1. When you set target library subsets, remember the following points: The subset restriction applies to hierarchical cells but not to leaf cells. The command enforces the subset restriction on the specified blocks and their subdesigns in the hierarchy, except those subdesigns where a different subset restriction is set. A subset specified at a lower level supersedes any subset specified at a higher level. Figure 7 Logic Hierarchy of Design 79 Setting Up Libraries Feedback For example, assume your design has a logic hierarchy as shown in Figure 7 and you want to implement the following library restrictions during optimization and clock tree synthesis: Use only the cells from the library named LVT_lib for the Sub1 block and its subblocks, SubA and SubB. Do not use the cells from this library anywhere else in the design. To do so, use the following settings: fc_shell> set_target_library_subset -objects {top/Sub1} \\ -only_here [get_lib_cells LVT_lib/*] [get_libs LVT_lib] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 In addition to these settings, assume you specify the following setting: fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} Then, when adding buffers on the clock network during clock tree synthesis, the tool uses The buf1 and buf2 cells from the LVT_lib library for the block named Sub1 and its subblocks The buf1 and buf2 cells from the HVT_lib library for the rest of the design Reporting Target Library Subsets To find out which target library subsets have been defined for a top block or hierarchical cell, use the report_target_library_subset command. Reports that are generated by reporting commands, such as report_cells and report_timing, show the td attribute attached to the cells that are specified by the -dont_use or -only_here option. Removing Target Library Subsets To remove a target library subset restriction from a top block or hierarchical cell, use the remove_target_library_subset command."}
{"instruction": "How do I Handling Tap Columns and Relative Placement Group Overlaps", "input": "", "output": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option. The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns. This application option helps the relative placement engine know about the distance between the tap columns. 806 Changing the Structures of Relative Placement Groups Feedback This helps in better placement and structures of relative placement groups in the design. You must use this application option for n5 and older technical nodes. For n3 and beyond designs, the distance between tap columns is calculated automatically. place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}
{"instruction": "How do I Performing Layout-Versus-Schematic Checking", "input": "", "output": "To perform layout-versus-schematic (LVS) checking, which checks for inconsistencies in the physical layout, use the check_lvs command. By default, the check_lvs command performs the following checks for all signal, clock, and PG nets: Shorted nets A shorted net occurs when a net shapes from different nets touch or intersect. By default, the command Checks for shorts between net shapes in the top-level design, including shapes in top-level blockages To disable checking for shapes in top-level blockages, use the -check_top_level_blockages false option. Does not check for shorts between net shapes in the top-level design and net- shapes in child cells To enable this checking, use the -check_child_cells true option. To exclude certain types of child cells from checking, use the -exclude_child_cell_types 573 Analyzing the Routing Results Feedback option to specify one or more of the following cell types: abstract analog black_box corner cover diode end_cap fill filler flip_chip_driver flip_chip_pad lib_cell macro module pad pad_spacer physical_only and well_tap Does not check for shorts with zero-spacing blockages To enable this checking, use the -check_zero_spacing_blockages true option. Note: The check_lvs command supports only default routing blockages that apply to all net types and have a blockage group ID of 0. If the blockage applies only to specific net types or has a nonzero blockage group ID, the command ignores the blockage. In addition, the command ignores corridor routing blockages (which are created when you use the -reserve_for_top_level_routing option with the create_routing_blockage command) and boundary routing blockages (which are created when you use the -boundary_internal or -boundary_external options with the create_routing_blockage command). Open nets An open net occurs when the pins of a net are not connected by its net shapes. By default, the command Treats power and ground terminals as unconnected voltage sources To treat power and ground terminals as connected, use the -treat_terminal_as_voltage_source true option. For example, assume your block contains the layout shown in Figure 120. By default, the check_lvs command reports two opens for this layout. If you use the -treat_terminal_as_voltage_source true option, no opens are reported. 574 Analyzing the Routing Results Feedback Figure 120 Layout With Power and Ground Terminals Reports open nets as the bounding box of the open net and does not report floating pins To report detailed open locations, use the -open_reporting detailed option. Note that using this option might increase the runtime. To report the floating pins, use the -report_floating_pins true option. Floating net shapes A floating net shape occurs when a net shape is not physically connecting to a pin of its net. To perform a subset of these checks, use the -checks option to specify one or more of the following checks: short (shorted nets), open (open nets), and floating_routes (floating net shapes). To check only specific nets, use the -nets option to specify the nets of interest. By default, the check_lvs command reports a maximum of 20 violations for each type of error. To change this limit, use the -max_errors option. To report all violations, specify the maximum number of violations as zero ( -max_errors 0 ). You can view the violations reported by the check_lvs command in the GUI by using the error browser. For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide To reduce the runtime required by the check_lvs command, enable multithreading by using the set_host_options command, as described in Enabling Multicore Processing 575 Analyzing the Routing Results Feedback"}
{"instruction": "How do I Scan Registers", "input": "", "output": "When a design switches between the functional and scan modes, glitches might occur on asynchronous set and reset lines of scan registers, which can reset the state of these registers. The tool can prevent this by adding gating logic to the asynchronous set and reset lines. To enable this feature, you must specify a top-level port to control the gating logic by using the set_register_async_gating_pin -port command. This control port must be a predefined port in the RTL that is not connected to any other net. To get information about such gated scan registers, run the report_async_gated_registers command after physical synthesis. The added gating logic can be an AND or OR gate, depending on the polarity of the asynchronous pins on the scan registers. When gating logic is added, the Formality tool requires additional information to verify the design and the Fusion Compiler tool generates an appropriate.svf file that disables the gating logic in the functional mode. Note: This feature is supported only for the in-compile DFT flow. 260 Specifying Settings for Performance, Power, and Area Improvement Feedback"}
{"instruction": "How do I Specifying Via Ladder Candidates for Library Pins", "input": "", "output": "To specify the valid via ladders that can be used for a given library pin during preroute optimization, use the set_via_ladder_candidate command. You can specify only one via ladder each time you use the set_via_ladder_candidate command. To specify multiple via ladder candidates for a library pin, use the command multiple times, as shown in the following example: fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP4\" 181 Specifying Settings for Preroute Optimization Feedback fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP2\" The order in which you specify multiple via ladders for the same library pin indicates the priority to use when selecting a via ladder to insert for that pin. Specify the via ladder candidates starting with the highest priority. In the previous example, the tool gives the VP4 via ladder priority over the VP2 via ladder. Note: If both the pattern_must_join attribute and a via ladder candidate apply to a pin, the via ladder has a higher priority than the pattern-based must-join connection when both methods have the same estimated delay. To specify that a library pin requires an electromigration via ladder, set the is_em_via_ladder_required pin attribute to true, as shown in the following example: fc_shell> set_attribute [get_lib_pins lib1/INV4/A] \\ is_em_via_ladder_required true If you set the is_em_via_ladder_required pin attribute to true for a specific library pin, you must specify an electromigration via ladder as a candidate with the set_via_ladder_candidate command. A via ladder can be identified as an electromigration via ladder by using one of the following methods: By using the forElectromigration=1 construct when defining the via rule in the technology file, as shown in the following example: ViaRule \"EMVP1\" {......... forElectromigration=1 By setting the for_electro_migration attribute to true, as shown in the following example: fc_shell> set_attribute [get_via_rules EMVP1] \\ for_electro_migration true See Also Defining Via Ladder Rules 182 Specifying Settings for Preroute Optimization Feedback"}
{"instruction": "How do I Performing On Route Placement of Repeaters", "input": "", "output": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command. place_group_repeaters \\ -cells cell_list | -repeater_groups group_id_list [-lib_cell_input pin_name ] \\ [-lib_cell_output pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}
{"instruction": "How do I Early Data Checks, Policies, and Strategies", "input": "", "output": "The tool can identify issues and violations in data during the early stages of design. You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data. Table 64 describes the predefined checks for top-level closure. Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view Checks whether the frame view is missing for a hierarchical block Re-create frame views from the bound view error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location Checks whether the location of a physical hierarchy boundary pin is missing Assign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary Checks whether the location of a physical hierarchy boundary pin is outside the physical hierarchy boundary Reassign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT 847 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort Checks whether a port is missing in the physical hierarchy reference Create missing ports in the reference block and update its location error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame Checks whether a physical hierarchy instance is bound to a frame view error, tolerate TOP hier.block.inst ance_with_desig n_type_macro Checks whether a physical hierarchy instance is bound to a macro error, tolerate TOP hier.top.estima ted_corner Checks whether the estimated corner is at top level error, tolerate TOP hier.block.miss ing_leaf_cell_l ocation Checks whether the location of a leaf cell of a physical hierarchy is missing Assign an approximate location inside the block boundary for the leaf cell (legality not considered) error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary Checks whether the location of a leaf cell of a physical hierarchy is outside the physical hierarchy boundary Reassign the leaf cell location to the nearest location inside the block boundary (legality not considered) error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion Checks whether the location of a child physical hierarchy instance is missing in the specified physical hierarchy Assign an approximate location for the lower-level subblock based on connectivity inside the block boundary (overlap removal not considered) error, tolerate, repair MID 848 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary Checks whether the location of a child physical hierarchy instance is outside the specified physical hierarchy boundary Move the subblock to the nearest location inside the block boundary (overlap removal not considered). error, tolerate, repair MID hier.block.port _mismatch_betwe en_views Checks whether there is a mismatch of ports between the views of a physical hierarchy Bound view is treated as golden and the frame view is recreated to match the bound view error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs Checks whether the design view for an abstract is missing error, tolerate MID BOT hier.block.inst ance_unlinked Checks whether the physical hierarchy reference is not linked properly to the top-level design due to a view change from frame or ETM to abstract or design error TOP hier.block.abst ract_type_non_t iming Checks whether the abstract type is not timing error MID BOT hier.block.abst ract_target_use _non_implementa tion Checks whether the target use of an abstract is not implementation error MID BOT hier.block.miss ing_core_area Checks whether the core area for a physical hierarchy is missing error MID BOT 849 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic Checks whether unmapped logic is present in the physical hierarchy error MID BOT Where BOT signifies bottom level design. MID signifies intermediate level design, which instantiates BOT. TOP signifies the top-level design, which instantiates MID."}
{"instruction": "How do I Specifying Cut Space and Cut Distance for Repeater Groups", "input": "", "output": "Use one of the following mutually exclusive options to control cutting for repeater groups: -layer_cutting_spacing specifies the cut space of the routes to the driver pin. The cut starts from the driver side. -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}
{"instruction": "How do I Enabling Local Skew Optimization", "input": "", "output": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths. If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design. However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design. During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths. To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the synthesize_clock_trees and clock_opt commands, set the cts.compile.enable_local_skew and cts.optimize.enable_local_skew application options to true fc_shell> set_app_options -list {cts.compile.enable_local_skew true} fc_shell> set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you 360 Specifying the Clock Tree Synthesis Settings Feedback specify with the set_clock_tree_options -target_skew command. To prevent the tool from deriving skew targets, use the following application option setting: fc_shell> set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}
{"instruction": "How do I Via Ladder Rule Files", "input": "", "output": "The command generates two via ladder rule files: An XML file that provides information about the via ladder rules The XML file has the following syntax: <EmRule> <! template definition > <Template name=\" rule_name \" for_electro_migration=\"true\" for_high_performance=\"true\"> <Layer name=\" layer_name \" row_number=\" cuts_per_row... more layers </Template> \u2026 more templates </EmRule> Each Template section specifies the template for a via ladder rule. Within a template section, the via ladder structure is specified by specifying the number of cuts per row for each metal layer involved in the via ladder. By default, the generated XML file is named auto_perf_via_ladder_rule.xml. To specify a different name, use the -xml_file option. A script file that defines the via ladder rules The script file contains a create_via_rule command for each template defined in the XML file, as well as set_attribute commands to set the appropriate via rule attributes. By default, the generated script file is named auto_perf_via_ladder_rule.tcl. To specify a different file name, use the -rule_file option."}
{"instruction": "How do I Performing Signoff Design Rule Checking", "input": "", "output": "IC Validator In-Design signoff design rule checking (DRC) runs the IC Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry signoff runset. You can perform signoff design rule checking by Running the signoff_check_drc command Using the Live DRC feature in the Fusion Compiler GUI After place and route, use the signoff_check_drc command to perform signoff design rule checking on the entire block. After engineering change orders (ECO), use either method to perform incremental signoff design rule checking on the modified portions of the block. See Also Automatically Fixing Signoff DRC Violations"}
{"instruction": "How do I Shielding the Nets", "input": "", "output": "Shielding is needed around sensitive nets to reduce noise and crosstalk. When you perform custom routing by using the route_custom command, the tool automatically creates shields for the nets based on the constraints you specify by using the create_net_shielding command. To add shielding to the selected nets in a separate run, use the create_custom_shields command.The following example creates shields for net1 and net2. fc_shell> create_custom_shields -nets {net1 net2} To remove the shielding created by the create_custom_shields command, use the remove_custom_shields command. Doing this also removes the shielding created by the route_custom command. 774 Checking the Routing Results Feedback"}
{"instruction": "How do I Specifying the Orientation of Relative Placement Groups", "input": "", "output": "The Fusion Compiler tool supports the following orientations for relative placement groups: R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top. R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom. MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation. MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation. Figure 182 shows how the column and row positions in a relative placement group are placed for the four orientations. 802 Specifying Options for Relative Placement Groups Feedback Figure 182 Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length. You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command. For example, the following command sets the relative placement group orientation to MY. fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy. 803 Specifying Options for Relative Placement Groups Feedback Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}
{"instruction": "How do I Ensuring Clock Tree Exceptions are Valid", "input": "", "output": "To identify pins on the clock network, the tool checks if the is_clock_is_used_as_clock pin attribute is true during clock tree synthesis. If you use the set_clock_balance_points command to specify a clock tree exception on a pin for which the is_clock_is_used_as_clock attribute is false, the tool accepts the exception, but ignores it during clock tree synthesis. 347 Defining the Clock Trees Feedback Consider the clock network in the following figure. Figure 75 Specifying Exceptions on Pins Beyond the Clock Network CLK U2 FF3 n5 By default, the tool sets The is_clock_is_used_as_clock attribute of the U2/A, U2/Y, and FF3/D pins to false and considers the network beyond the U2/A pin as part of the data network The U2/A pin as an ignore pin and excludes the network beyond this from clock tree synthesis During clock tree synthesis, the tool adds a guide buffer and isolates the U2/A pin from the rest of the clock network. During subsequent data path optimization, the tool can fix any existing DRC violations beyond the guide buffer. Assume you want clock tree synthesis to fix DRC violations up to the FF3/D pin using clock tree constraints. To do so, you must 1. Specify the FF3/D pin as an explicit ignore pin as follows: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins FF3/D] 348 Defining the Clock Trees Feedback 2. Force clock tree synthesis to consider the FF3/D pin as a pin on the clock network by using the set_sense -clock_leaf command as follows: fc_shell> set_sense -clock_leaf [get_pins FF3/D] The set_sense -clock_leaf command sets The is_clock_used_as_clock attribute to true for all the pins of the clock branches that fanin to the pin specified as the clock leaf The is_clock_used_as_clock attribute to false for all the pins in the fanout from the pin specified as the clock leaf, and the tool does not propagate the clock beyond this pin To check the value of the is_clock_used_as_clock pin attribute, use the get_attribute command, as shown in the following example: fc_shell> get_attribute [get_pins FF3/D] is_clock_used_as_clock"}
{"instruction": "How do I Removing Routing Blockages", "input": "", "output": "To remove routing blockages from the current block, use the remove_routing_blockages command. To remove specific routing blockages, specify the routing blockages, either as a list or collection, such as that returned by the get_routing_blockages command. To remove all routing corridors, specify the -all option. 473 Routing Constraints Feedback"}
{"instruction": "How do I Specifying the Net Names, Buffers Types, and Their Locations", "input": "", "output": "When you use the add_buffer_on_route command, you must specify the following: The net on which to add buffers The type of buffers to add and where to add them on the net by using one of the following methods: Adding Buffers in a Specified Configuration Adding Buffers at Specified Locations Adding Buffers at a Specified Interval Adding Buffers at an Interval That is a Ratio of the Net Length Adding Buffers on a Bus in a Specified Pattern 964 Adding Buffers on Routed Nets Feedback"}
{"instruction": "How do I Replacing Clock Gates", "input": "", "output": "If you want to replace all the technology-independent clock gates in your RTL with integrated clock-gating cells from the libraries, use the replace_clock_gates command before executing the compile_fusion command. The replace_clock_gates command identifies combinational elements in the clock network acting as clock gates and replaces them. When you use the replace_clock_gates command, the tool honors the constraints specified by the set_clock_gate_style set_lib_cell_purpose, and set_target_ligrary_subset commands when it selects a library cell. When the tool identifies combinational elements, these elements must have only two input pins (the clock pin and the enable signal pin) and only one output pin. If the cell does not meet these criteria, the cell is not a candidate for replacement. The following table lists the WVGTECH instances and their replacement cells. Combinational Cell in RTL Integrated Clock Gate Replacement AND gate Rising-edge triggered latch-based clock gate OR gate Falling-edge triggered latch-based clock gate NAND gate Falling-edge triggered latch-based clock gate. Clock input pin is inverted. NOR gate Falling-edge triggered latch-based clock gate. Both input pins are inverted. The new clock-gating cell is inferred with the following name: rep_clock_gate_+<instance_name_of_combinational_cell> The tool reports replaced clock gates as tool-inserted clock gates."}
{"instruction": "How do I Controlling the Optimization of Relative Placement Cells", "input": "", "output": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed. When a relative placement cell is removed during optimization, the relative 805 Specifying Options for Relative Placement Groups Feedback placement information of the instance is also removed, disrupting the relative placement structure. To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting Allow unrestricted optimization of the relative placement cells all_opt Allow only sizing of the relative placement cells size_only Allow only in-place sizing of the relative placement cells size_in_place Prevent any optimization of the relative placement cells no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}
{"instruction": "How do I Importing the Floorplan Information", "input": "", "output": "A floorplan contains physical constraints such as the core area and shape, port locations, macro locations and orientations, and so on, which are required for performing physical synthesis and optimization. 103 Importing the Floorplan Information Feedback If you have a floorplan for your block, read in the floorplan as a DEF file, as described in Reading DEF Files If you do not have a floorplan for your block, you can perform design planning and generate a floorplan as described in the Fusion Compiler Design Planning User Guide During the early stages of design process, you can use automatically-generated floorplan information to run physical synthesis, as described in Using Automatic Floorplanning"}
{"instruction": "How do I Prerequisites for Routing", "input": "", "output": "Before you can run Zroute, you must ensure that the block and physical library meet the following requirements: Library requirements Zroute gets all of the design rule information from the technology file; therefore, you must ensure that all design rules are defined in the technology file before you start routing. For more information about the technology file and defining routing design rules, see the Synopsys Technology File and Routing Rules Reference Manual Block requirements Before you perform routing, your block must meet the following conditions: Power and ground nets have been routed after design planning and before placement. For more information, see the Fusion Compiler Design Planning User Guide Clock tree synthesis and optimization have been performed. For more information, see Clock Tree Synthesis Estimated congestion is acceptable. Estimated timing is acceptable (about 0 ns of slack). Estimated maximum capacitance and transition have no violations. To verify that your block meets the last three prerequisites, you can check the routability of its placement as explained in Checking Routability 442 Defining Vias Feedback"}
{"instruction": "How do I Applying Required Settings for High Performance Cores", "input": "", "output": "You can apply tool settings required for achieving the best QoR for high performance cores by using the set_hpc_options command. The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis. To List the supported high performance core types and implementation stages, use the -list option Specify the type of high performance core, use the -core option Specify the stage of the implementation flow, use the -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the set_technology command before you run the set_hpc_options command, as shown in the following example script: set_technology -node 7 set_hpc_options -core A72 -stage clock_opt_cts... clock_opt -from build_clock -to route_clock... 209 Applying Mega-Switch Command Settings Feedback set_hpc_options -core A72 -stage clock_opt_opto... clock_opt -from final_opto... set_hpc_options -core A72 -stage route_auto... route_auto... set_hpc_options -core A72 -stage route_opt... route_opt..."}
{"instruction": "How do I Merging Clock Gates", "input": "", "output": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage. The tool looks for clock-gating cells that share a common clock and enable signal. This feature is on by default. The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching. Note that the the tool also checks clock-gating style and multivoltage constraints. Clock-gating cells with the dont_touch or size_only constraints are not optimized. To disable this feature, use the set_clock_gate_transformations command. 313 Setting Clock Gating Transformations Feedback"}
{"instruction": "How do I Controlling IR-Drop-Aware Placement", "input": "", "output": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells. Figure 22 Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in Figure 22 The upper category consists of the top one percent of the total number of cells with the highest voltage drop values. During placement, the tool spreads these cells the most. The middle category consists of the next five percent of the cells. During placement, the tool spreads these cells less than those in the upper category. The lower category consists of the rest of the cells. The tool does not spread these cells. 160 Specifying Placement Settings Feedback You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options. The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false. They are true by default. The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa. The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ 161 Specifying Legalization Settings Feedback -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command. The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"instruction": "How do I Creating Constraints for Auto Floorplanning", "input": "", "output": "Use the commands and application options described in this topic to create constraints for auto floorplanning. Commands Use the following two commands to set and report auto floorplanning constraints. These two commands do not affect explicit floorplanning. set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile. For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8 report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command. To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands: Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin Pin placement constraints set_block_pin_constraints set_individual_pin_constraints Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning. compile.auto_floorplan.initialize (default: auto auto : Creates missing floorplan information. The tool exits with an error when inconsistent information is provided. true : Always creates the core and boundary. false : Never creates the core and boundary; uses only existing information. The tool exits with an error when encountering missing or inconsistent information. 111 Importing the Floorplan Information Feedback By default, the following objects are preserved: Existing placement of fixed macros Existing placement of pins and pads Existing shaping of voltage areas compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped all : Always places and shapes objects even if they are fixed. Unplaced and unshaped objects will always be placed and shaped. unfixed : Places and shapes objects that are not fixed. Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify. Unplaced and unshaped objects will always be placed and shaped. unplaced, unshaped : Never places or shapes objects when they are already placed. Unplaced and unshaped objects will always be placed and shaped. none : Never places or shapes objects even if they are not already placed. This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning. Application option setting Fixed objects Placed objects Unplaced objects all Placed and shaped Placed and shaped Placed and shaped unfixed Kept Placed and shaped Placed and shaped unplaced, unshaped Kept Kept Placed and shaped none Kept Kept Kept compile.auto_floorplan.keep_bounds (default: auto 112 Setting Up Multivoltage Designs Feedback auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing bounds. false : Removes existing bounds. compile.auto_floorplan.keep_placement_blockages (default: auto auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing placement blockages. false : Removes existing placement blockages. Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}
{"instruction": "How do I Setting Clock Tree Design Rule Constraints", "input": "", "output": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis: clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the set_max_capacitance command. If you do not specify this constraint, the clock tree synthesis default is 0.6 pF. clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the set_max_transition command. If you do not specify this constraint, the clock tree synthesis default is 0.5 ns. By default, these constraints apply to all corners associated with the current mode. To set the constraint for a specific mode, use the -mode option with the get_clocks command to identify the clocks. To set the constraint for specific corners associated with the specified mode, use the -corners option with the constraint command. Be careful to apply the correct constraints across all the modes and their associated corners. For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell> set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the -mode option with the get_clocks command to specify the mode and use the -corners option to specify the corner. For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell> set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell> set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell> set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]] 356 Specifying the Clock Tree Synthesis Settings Feedback"}
{"instruction": "How do I Sorting and Filtering the Data", "input": "", "output": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further. To sort and filter the data, see the following topics: Sorting the Data Filtering Metrics Filtering Runs Example Analysis See Also Exploring the Detailed Comparison Data 274 Performing Design Analysis Feedback Sorting the Data Click any column header to sort the data using that metric. The first click performs an ascending sort, while the second click performs a descending sort. For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom: 275 Performing Design Analysis Feedback Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly. For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in Figure 39 Figure 39 Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column. For example, to display only the first four runs in a table, select the runs as shown in Figure 40 Figure 40 Choose Baseline and Visible Runs Dialog Box 276 Performing Design Analysis Feedback Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further. Suppose you open the comparison report shown in Figure 41 and set the util60_aspect1%1_layerM9 run as the base run. Figure 41 Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer. This suggests that restricting the metal layers significantly impacts timing. 277 Performing Design Analysis Feedback You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs. You could restrict your analysis to your lower-utilization runs by turning off the 278 Performing Design Analysis Feedback visibility of your higher-utilization runs as shown in Figure 42, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals. Figure 42 Displaying Lower-Utilization Runs"}
{"instruction": "How do I Preparing for Top-Level Closure With Abstracts", "input": "", "output": "Before you can perform synthesis, placement, optimization, clock tree synthesis, and routing at the top level, you must perform the following tasks: Apply the top-level-timing constraints and settings. You can split the chip-level constraints in to separate top- and block-level constraints by using the split_constraints command. Review and specify the relationship between the top- and block-level modes, corners, and clocks by using the set_block_to_top_map command. If the pre-clock tree implemented blocks, which have undergone CCD optimization, are used for top-level placement and optimization, then the ideal clock latencies adjusted dynamically by different engines such as CCD and clock-gate estimation on the clock pins of registers or integrated clock gating (ICG) cells inside the blocks might not be seen at the top-level leading to timing inaccuracies at the top-level. Promote these clock latency constraints from block-level to the top-level by using the promote_clock_data -latency_offset -auto_clock connected command. Apply the top-level clock tree synthesis settings and exceptions. If the top-level exceptions do not include the balance points on the pins within lower-level blocks, promote the balance points from the lower levels by using the promote_clock_data -auto_clock connected -balance_points command. If concurrent clock and data (CCD) optimization is performed at the block level, the tool derives median clock latencies for the block-level clock ports, which accounts for the latency adjustments that were derived for the block-level registers during concurrent clock and data optimization. Promote these block-level clock latencies as clock balance point delays for the block-level clock pins by using the promote_clock_data -auto_clock connected -port_latency command. If the lower-level blocks contain clock-meshes, promote the mesh annotations (annotated transitions and delays) by using the promote_clock_data -mesh_annotations command. If you need to promote clock data for a specific top-level clock, use the promote_clock_data -clocks {top_clock} -port_latency command. The command also promotes clock-independent exceptions. If any of the given top-level clocks has no mapping to any block-level clock in any mode, the tool issues a warning. If there are any active modes, corners, or clocks at the top-level, which cannot be mapped to corresponding modes, corners, or clocks in the block-level, you can still promote the clock data for other mapped modes, corners, or clocks using the promote_clock_data -balance_points -force command. This command issues errors for the unmapped modes, or corners, or clocks. 842 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Apply the top-level UPF constraints, which you can create from the full-chip UPF constraints by using the split_constraints command. The tool promotes the required UPF constraints from the lower-level blocks to the top level."}
{"instruction": "How do I Querying Placement Blockages", "input": "", "output": "To return a collection of placement blockages in the current block that match certain criteria, use the get_placement_blockages comandcomandsget_placement_blockages get_placement_blockages command."}
{"instruction": "How do I Trunk Splitting", "input": "", "output": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split. custom.route.bus_split_ignore_width custom.route.bus_split_even_bits The custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section. The custom.route.bus_split_even_bits application option requires that you set the custom.route.bus_split_ignore_width application option. If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes). In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set. The spacing between the power and ground rails can accommodate three bits only. Figure 163 a shows the two possible results when the custom.route.bus_split_even_bits application option is turned off. Figure 163 b shows the result when the custom.route.bus_split_even_bits application option is turned on. Figure 163 Splitting Bus Trunk to Route Through Power and Ground Rails 768 Using Custom Routing Application Options Feedback"}
{"instruction": "How do I Registers", "input": "", "output": "Before you run the compile_fusion command on an RTL design, you can create a multibit bus consisting of specific unmapped single-bit registers by using the create_multibit command. Then, when you run the compile_fusion command, 247 Performing Multibit Optimization Feedback during the initial_map stage, the tool maps the single-bit cells of the bus created by the create_multibit command into a multibit register bank. The single-bit registers you specify with the create_multibit -sort command must Be unmapped Be of the same type Be in the same logical hierarchy Not be part of an existing bus In the following example, the single-bit cells are combined in alphanumeric descending order, which is reg4, reg3, reg2, and reg1: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort descending fc_shell> compile_fusion In the following example the single-bit cells are combined in alphanumeric ascending order, which is reg1, reg2, reg3, and reg4: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort ascending fc_shell> compile_fusion In the following example, the single-bit cells are combined in the specified order, which is reg2, reg4, reg1, and reg3: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort none fc_shell> compile_fusion Note: You must set the compile.flow.enable_multibit application option to true before you run the create_multibit command on unmapped single bit registers. If not, the tool issues the following error message: Error: create_multibit command failed: multibit flow is disabled. (MBIT-068)"}
