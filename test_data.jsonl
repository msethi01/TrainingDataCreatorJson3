{"instruction": "How do I Setting Routing Rules for Clock Gates", "input": "", "output": "When you set constraints for physical implementation, you can set nondefault routing rules to define stricter (wider) wire width and spacing requirements for specific nets to improve timing and reduce crosstalk. To specify nondefault routing rules, use the create_routing_rule and set_routing_rule commands. 315 Clock Gating and Multibit Registers Feedback However, the set_routing_rule command does not allow annotation on the output nets of tool-inserted clock gates, because these nets do not exist until after the execution of the compile_fusion command. To specify nondefault routing rules that are applied automatically on nets connected to the output pins of tool-inserted clock gates, use the set_clock_gate_routing_rule command. These rules are applied on clock gates after the compile_fusion command. For example, create_routing_rule cg_rule... set_clock_gate_routing_rule -rule cg_rule... compile_fusion... report_routing_rules"}
{"instruction": "How do I Setting Up Reference Libraries", "input": "", "output": "You can specify a reference library list for a design library when you create the design library by using the -ref_libs option of the create_lib command. You can also change the reference library list at any time by using the set_ref_libs command. Use the following commands to specify, rebind, and report reference libraries: create_lib -ref_libs You can specify a relationship between a new design library and its lower-level reference libraries by using the create_lib command. For example, fc_shell> create_lib lib_B \\ -ref_libs {../LIBS/lib_c../STND/stdhvt.ndm}... {lib_B} set_ref_libs -ref_libs For an existing design library, open the library and then use the set_ref_libs command to specify the reference libraries. For example, fc_shell> current_lib {lib_B} fc_shell> set_ref_libs \\ -ref_libs {../LIBS/lib_C../STND/stdhvt.ndm}../LIBS/lib_C../STND/stdhvt.ndm report_ref_libs To report the reference libraries of a design library, use the report_ref_libs command. 75 Setting Up Libraries Feedback For example, fc_shell> create_lib lib_A -ref_libs \\ {../libs/SCLL.ndm../libs/SCHH.ndm../BLOCKS/MACROS} {lib_A} fc_shell> report_ref_libs... Name Path Location *+ SCLL../libs/SCLL.ndm /remote/project/libs/SCLL.ndm *+ SCHH../libs/SCHH.ndm /remote/project/libs/SCHH.ndm * MACROS../BLOCKS/MACROS /remote/project/BLOCKS/MACROS \"*\" = Library currently open \"+\" = Library has technology information set_ref_libs -rebind When you make a change that invalidates the reference library list, such as moving a reference library to a new location, you need to rebind the reference libraries. To do so, use the -rebind option, which rebinds each reference library path specified by the search_path variable to libraries that are currently loaded in memory. For example, fc_shell> current_lib {lib_A} fc_shell> set_app_var search_path {.../REFLIBS../CLIBS}.../LIBS../BLOCKs fc_shell> set_ref_libs -rebind../REFLIBS/lib_C../REFLIBS/lib_D../CLIBS/stdhvt.ndm} Rebinding a library does not affect the bindings of blocks already existing in the design library. To rebind these blocks using an updated reference library list, use the -rebind option with the link_block command."}
{"instruction": "How do I Low-Threshold-Voltage (LVT) Cells", "input": "", "output": "The Fusion Compiler tool can perform percentage-LVT-based optimization. By limiting the percentage of LVT cells in a block, you can improve yield of your design. You can also use this feature during the early design phases to get an idea of the quality of the RTL. To set up for percentage-LVT-based optimization, 1. Specify the LVT library cell group as shown in the following example: fc_shell> remove_attributes -quiet \\ [get_lib_cells -quiet */*] threshold_voltage_group fc_shell> set_attribute [get_lib_cells -quiet *lvt*/*] \\ threshold_voltage_group LVT 192 Setting Up for Power-Related Features Feedback fc_shell> set_threshold_voltage_group_type \\ -type low_vt LVT Ensure that the LVT library cells you specify Have a valid purpose defined by using the set_lib_cell_purpose command and are included in the appropriate target-library subsets defined by using the set_target_library_subset command Do not have a dont_touch or dont_use attribute setting 2. Specify the percentage limit for LVT cells by using the set_multi_vth_constraint -low_vt_percentage command. To specify the limit as a percentage of the Cell count, use the -cost cell_count option Cell area, use the -cost area option To reset this constraint, use the reset_multi_vth_constraint command, and to report it, use the report_multi_vth_constraint command. After you set up percentage-LVT-based optimization, when you run the compile_fusion clock_opt, or route_opt command, the tool uses the specified LVT cell percentage constraint for the data path cells in the block. However, to minimize QoR disturbance, the tool limits the percentage-LVT-based optimization performed during the route_opt command. Therefore, it is important to enable this feature earlier in the design flow. Note: LVT cells have a smaller cell delay, but higher leakage power dissipation. Therefore, limiting the number of LVT cells reduces leakage-power dissipation. However, to further reduce leakage power, enable leakage power optimization for the different stages of the design flow."}
{"instruction": "How do I Timing-Driven Power Grid Augmentation", "input": "", "output": "Timing-driven power grid augmentation inserts PG augmentation shapes in the specified regions of the block, except around timing-critical nets. By default, the tool does not perform timing-driven PG augmentation. To perform timing-driven power grid augmentation, 1. Ensure that the block is fully routed with very few or no DRC violations. 2. Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis The IC Validator tool uses the results of this voltage drop analysis to drive the power grid augmentation. 3. Set up the IC Validator environment as described in Setting Up the IC Validator Environment 4. (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 5. Set the application options for performing power grid augmentation, as described in Setting Options for Power Grid Augmentation At a minimum, you must define the power and ground nets on which to perform PG augmentation. To specify the power net, set the signoff.create_pg_augmentation.power_net_name application option. To specify the ground net, set the signoff.create_pg_augmentation.ground_net_name application option. If your design contains more than one power net, you must perform PG augmentation once for each power net. 703 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback 6. Save the block to disk. When you run the signoff_create_pg_augmentation command, the IC Validator tool uses the on-disk information for the block, not the information in memory. To ensure accurate information, use the save_block command to save the current state of the block before running the signoff_create_pg_augmentation command. 7. Perform timing-driven power grid augmentation by using the signoff_create_pg_augmentation command with one or both of the following options: -nets This option explicitly specifies the critical nets. -timing_preserve_setup_slack_threshold This option enables the tool to automatically determine the critical nets based on a setup slack threshold. The unit for the slack threshold setting is the library time unit. You must also specify the technology node for which to perform the augmentation by using the -node option. If you must perform incremental PG augmentation because your design contains more than one power net, use the -mode add command on subsequent runs to append the PG augmentation shapes to the existing shapes. 8. Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis This second voltage drop analysis run measures the voltage drop after power grid augmentation. During timing-driven PG augmentation, the signoff_create_pg_augmentation command 1. Performs timing analysis, including multicorner-multimode analysis, to minimize timing impact 2. Identifies timing-critical nets based on the options you specify 3. Removes existing PG augmentation shapes By default, the command removes the PG augmentation shapes from the entire block. To keep the existing PG augmentation shapes, use the -mode add option. 4. Inserts PG augmentation shapes for the specified regions, except in the areas around the critical nets 704 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback 5. Saves the updated block to disk 6. Generates a summary report See Also Standard Power Grid Augmentation Guided Power Grid Augmentation Removing PG Augmentation Shapes"}
{"instruction": "How do I Routing Using Custom Router", "input": "", "output": "Custom Router is a shape-based router that supports gridded or gridless routing for custom digital, mixed signal, and analog routing needs. In the Fusion Compiler environment, you can use Custom Router to create interconnects (or routes) for critical signals between blocks and continue with the Fusion Compiler tool to complete the physical implementation. You can also preroute critical signals or clock nets by using a set of custom routing constraints. In the Fusion Compiler environment, Custom Router provides the following features: Prerouting in the batch mode Tcl-based routing constraint management Automatic routing with custom routing constraints Hybrid flow for prerouting Double Data Rate (DDR) net routing flow Custom Router is fully integrated with the Fusion Compiler tool, and supports advanced design rules for 20 nm and below technologies. To learn about using Custom Router in the Fusion Compiler environment, see the following topics: Using Custom Router in the Fusion Compiler Tool Before Using Custom Router Defining Routing Constraints Managing Constraint Groups Using Custom Routing Application Options Routing With the Custom Router Shielding the Nets Checking the Routing Results 746 Using Custom Router in the Fusion Compiler Tool Feedback Using a Hybrid Routing Flow Using a DDR Routing Flow These topics describe how to use Custom Router to create custom routes in the Fusion Compiler environment. For detailed information about Custom Router, see the Custom Compiler Custom Router User Guide"}
{"instruction": "How do I Setting Up Multivoltage Designs", "input": "", "output": "The following topics describe the tasks you need to perform when setting up multivoltage designs: Applying the Multivoltage Power Intent Preparing the Power Network 113 Setting Up Multivoltage Designs Feedback Defining Voltage Areas Inserting Multivoltage Cells Controlling the Placement of Multivoltage Cells Enabling Improved Buffering for Multivoltage Nets Analyzing Multivoltage Information"}
{"instruction": "How do I Updating Via Ladders", "input": "", "output": "You can use the following methods to update existing via ladders in a design: Use the refresh_via_ladders command Automatic updates during the route_group route_auto, and route_eco commands is enabled by default by setting the route.auto_via_ladder.update_during_route application option to true Both of these methods perform the following tasks: Verifies the existing via ladders based on the current via ladder constraints Removes invalid via ladders Inserts via ladders where needed based on the settings of the route.auto_via_ladder application options By default, the tool Updates all pins with via ladder constraints, whether on signal nets or clock nets By default, during the route_group command, the via ladder updates is restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted about the pin layer be fully contained within the pin shape boundary, which includes 461 Inserting Via Ladders Feedback the pin shape and its extensions. To specify this requirement, set the following application options: route.auto_via_ladder.connect_within_metal This application option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join. To prevent changes to the pin shape boundary, set this application option to true route.auto_via_ladder.connect_within_metal_for_via_ladder This application option controls the via enclosures only for performance and electromigration via ladders. By default, the tool uses the global setting specified by the route.auto_via_ladder.connect_within_metal application option. To explicitly specify the behavior for performance and electromigration via ladders, set this application option to true or false Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion. In many cases, the via ladder rule specifies the maximum number of stagger tracks. To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, the route.auto_via_ladder.auto_stagger application option is set to true by default. Reports the via ladder insertion status for each target pin To limit the number of via ladders reported for each category to 40, set the route.auto_via_ladder.report_all_via_ladders application option to false See Also Inserting Via Ladders Verifying Via Ladders Querying Via Ladders Removing Via Ladders 462 Inserting Via Ladders Feedback"}
{"instruction": "How do I Reading Mixed Gate-Level Netlists and RTL Files", "input": "", "output": "You can read a combination of Verilog netlists and RTL files. Use the read_verilog command to read the Verilog netlists. Use the analyze and elaborate commands to read the RTL files. After all the netlist files and RTL files have been read into the tool, use the set_top_module command to link the designs to create the block for synthesis. The following example shows how you can read a mix of netlist and RTL files. As shown in this example, when you elaborate the top-level module with parameters, the top- level module name also contains the parameterized module name. You can control the naming style for parameterized modules using the following application options: hdlin.naming.template_naming_style hdlin.naming.template_parameter_style and hdlin.naming.template_separator_style # Read netlist files read_verilog NETLIST/bot.v # Analyze design files analyze -format sverilog -hdl_library MID RTL/mid.sv analyze -format sverilog RTL/top.svd # Elaborate top design module elaborate -parameters \"N=8,M=3\" top # Set the top level module to resolve references set_top_module top_N8_M3"}
{"instruction": "How do I Routing Signal Nets by Using Automatic Routing", "input": "", "output": "Before you run automatic routing, Set the common routing application options For information about the common routing application options, see the route.common_options man page. Set the global routing application options For information about the detail routing application options, see the route.global_options man page. 537 Routing Signal Nets Feedback Set the track assignment application options For information about the detail routing application options, see the route.track_options man page. Set the detail routing application options For information about the detail routing application options, see the route.detail_options man page. To run automatic routing, use the route_auto command. By default, the route_auto command ignores existing global routes and sequentially invokes global routing, track assignment, and detail routing. The tool does not save the block between routing steps. Use the following options to change the default behavior: To perform incremental global routing, use the -reuse_existing_global_route true option. To stop after track assignment, use the -stop_after_track_assignment true option. To change the number of search and repair iterations during detail routing from the default of 40, use the -max_detail_route_iterations option. To save the block after each routing step, set the -save_after_global_route -save_after_track_assignment, and -save_after_detail_route options to true The tool uses auto as the default prefix for the saved block names. To specify the prefix, use the -save_cell_prefix option. By default, the route_auto command is not timing-driven or crosstalk-driven and does not fix soft DRC violations, such as bridge rule violations. To enable timing-driven mode, set the route.global.timing_driven route.track.timing_driven, and route.detail.timing_driven application options to true By default, when you enable timing-driving routing, Zroute uses medium effort to assign timing-critical nets to low-resistance metal layers. To change the extent to which timing-driven routing prefers lower-resistance metal layers when routing timing-critical nets, set the route.common.rc_driven_setup_effort_level application option. To increase the effort level to use more low-resistance metal layers for routing, set the option to high. To reduce the effort level, set the option to low. To disable resistance- based routing layer preferences, set the option to off 538 Shielding Nets Feedback To enable crosstalk-driven mode, set the route.global.crosstalk_driven route.track.crosstalk_driven, and time.si_enable_analysis application options to true To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_detail_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_detail_route_fix_soft_violations \\ -value true"}
{"instruction": "How do I Reporting Clock-Gating Results", "input": "", "output": "After compiling your design, you can check the results using the report_clock_gating command. An example is shown in Figure 64 Figure 64 Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics. The term \"pre-existing clock gates\" refers to user-instantiated clock gates. The preexisting category also includes registers that are gated by a tool-inserted clock gate. This includes registers that are gated by both preexisting and tool-inserted clock-gating cells. By default, the tool reports multilevel statistics. This includes the maximum level of clock- gating cells in the design. Clock-gate levels are counted from the clock source toward the register. If multibit flip-flops are found in the design, multibit composition is automatically reported. 321 Reporting Clock-Gating Results Feedback Figure 65 Example of a Multibit Composition Report To report the details on ungated registers, use the -ungated option for report_clock_gating. For details on the gated registers, use the -gated option. 322 Reporting Clock-Gate Enable Signals Feedback"}
{"instruction": "How do I Incremental Global Routing", "input": "", "output": "By default, the global router ignores existing global routes. To perform incremental global routing by reusing the existing global routes, use the -reuse_existing_global_route true option when you run global routing. Note that this option affects only the global router and not the net delay calculation that occurs before timing-driven or crosstalk-driven global routing."}
{"instruction": "How do I Mapping of Synchronous Reset or Preset Registers", "input": "", "output": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default. To infer registers with synchronous reset or preset pins, use the sync_set_reset Synopsys compiler directive in the RTL. HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible. To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: The sync_set_reset directive Specify the //synopsys sync_set_reset directive in the RTL. The hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to true. The default is false 233 Controlling Mapping and Optimization Feedback During compile, the tool performs the following mapping based on the registers in your library: The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin. The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin. The tool also attempts to map the logic as close as possible to the data pin. This figure shows examples of mapping to registers with and without a synchronous reset pin. ___ RST Using a reset pin ___ RST Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible. To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to true Note: Synchronous reset and preset signals are not inferred for level-sensitive latches. A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins. Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must Describe the registers correctly in the RTL Ensure the library contain the corresponding cells Ensure the hdlin.elaborate.ff_infer_async_set_reset application option is set to true (the default) 234 Controlling Mapping and Optimization Feedback If the library does not contain this type of registers, the tool leaves the cells unmapped."}
{"instruction": "How do I Preventing Connections to Register QN Pins", "input": "", "output": "During sequential mapping, the tool can map registers to library cells that have both Q and QN pins, if doing so improves the QoR. However, you can prevent the tool from using the QN pin of such registers by setting the compile.seqmap.disable_qn_usage application option to true"}
{"instruction": "How do I Removing Routing Guides", "input": "", "output": "To remove routing guides from the current block, use the remove_routing_guides command. To remove specific routing guides, specify the routing rules, either as a list or collection, such as that returned by the get_routing_guides command. To remove all routing guides, specify the -all option. For example, to remove the new_width_rule routing rule, use the following command: fc_shell> remove_routing_rules new_width_rule"}
{"instruction": "How do I Verifying Via Ladders", "input": "", "output": "To verify that the via ladders in the block match the via ladder constraints and are properly connected to pins, use the verify_via_ladders command. By default, this command checks all via ladders. To restrict the checking to specific nets, use the -nets option. Note: If you use the -shift_vias_on_transition_layers true option when you insert the via ladders, you must also use this option when you verify the via ladders; otherwise, the command reports false violations. A via ladder matches the via ladder constraints if the pattern of connected vias and wires for the via ladder structure satisfies any of the via ladder templates assigned to the connected pin. The command flags a violation in the following situations: A via ladder is connected to a pin that does not have a via ladder constraint A via ladder is connected to a pin with a via ladder constraint, but none of the templates correctly describe the current via ladder structure A pin has a via ladder constraint, but does not have a via ladder connected to it 460 Inserting Via Ladders Feedback A via ladder is properly connected to a pin if all the via enclosures at the base of the via ladder touch the same pin and that pin is logically connected to the same net as the via ladder. The command flags a violation in the following situations: An enclosure of the via ladder base touches a different pin, unless the pins are must- join pins that belong to the same must-join set An enclosure of the via ladder base does not touch any pin An enclosure of the via ladder touches a pin that is not of the same net as the via ladder By default, the verify_via_ladders command reports the via ladder insertion status for each target pin, which can result in a very large report. To limit the number of via ladders reported for each category to 40, use the -report_all_via_ladders false option with the verify_via_ladders command."}
{"instruction": "How do I Adding Relative Placement Groups", "input": "", "output": "Hierarchical relative placement allows relative placement groups to be embedded within other relative placement groups. The embedded groups then are handled similarly to leaf cells. 786 Adding Objects to a Group Feedback You can use hierarchical relative placement to simplify the expression of relative placement constraints. With hierarchical relative placement, you do not need to provide relative placement information multiple times for a recurring pattern. Using hierarchical relative placement provides these benefits: Allows you to organize your relative placement in a manner that is easier to maintain and understand. For example, you can create the relative placement group to parallel your Verilog or VHDL organization. Allows reuse of a repeating placement pattern, such as an adder. Can reduce the number of lines of relative placement information you need to write. Allows integrating blocks. Provides flexibility for the configuration you want."}
{"instruction": "How do I Using Routing Guides to Encourage River Routing", "input": "", "output": "River routing is a special routing topology that tries to minimize the space taken by the router by compressing the routes to follow a particular contour. River routing is useful if there are tight routing channels or you need to minimize the space taken by routing. You can use a routing guide to encourage river routing within the routing guide boundary. To create this type of routing guide, use the -river_routing option with the create_routing_guide command. You must also use the -layers option to specify the affected layers. 478 Routing Constraints Feedback For example, to encourage river routing on the M2 layer within the rectangle with its lower- left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell> create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -river_routing -layers {M2}"}
{"instruction": "How do I Controlling How Buffers are Added", "input": "", "output": "By default, the add_buffer_on_route command Adds buffers over all placement blockages, soft macros, and hard macros. To prevent buffers from being placed over specific macro cells, use the -dont_allow_insertion_over_cell option. Alternatively, you can prevent the buffers from being placed over all blockages and macro cells by using the -respect_blockages option. When you use this option, you can specify a list of macro cells over which buffers are allowed by using the -allow_insertion_over_cell option. Adds buffers on both global routed and detail routed nets. To add buffers only on nets that are global routed only, without assigned tracks or detail routing, use the -only_global_routed_nets option. Adds buffers at the lowest common level of hierarchy of the pins being driven by the buffers. To add the buffers on the highest possible level of hierarchy, use the -on_top_hierarchy option. Does not add buffers on a route segment if it is necessary to create new ports because of a difference in the logical and physical topology of the net. To add buffers on such route segments by creating new ports, use the -punch_port option."}
{"instruction": "How do I RedHawk and RedHawk-SC Fusion", "input": "", "output": "The RedHawk and RedHawk-SC power integrity solution is integrated with the implementation flow through the RedHawk Fusion and RedHawk-SC Fusion interface. You can use the RedHawk Fusion and RedHawk-SC Fusion feature for rail analysis at different points in the physical implementation flow after power planning and initial placement are completed. This enables you to detect potential power network issues before you perform detail routing and thus significantly reduce the turnaround time of the design cycle. When placement is complete and the PG mesh is available, use RedHawk Fusion or RedHawk-SC Fusion to perform voltage drop analysis on the power and ground network to calculate power consumption and to check for voltage drop violations. You can perform voltage drop analysis at other stages in the design flow, such as after detail routing. When chip finishing is complete, use RedHawk Fusion or RedHawk-SC to perform PG electromigration analysis to check for current density violations. This chapter describes how to use the RedHawk Fusion or RedHawk-SC Fusion feature to perform rail analysis in the environment. For a detailed description about the RedHawk or RedHawk-SC analysis flows and commands, see the RedHawk User Manual or RedHawk-SC User Manual This chapter includes the following topics: Running Rail Analysis Using RedHawk-SC Fusion An Overview for RedHawk Fusion and RedHawk-SC Fusion Setting Up the Executables Specifying RedHawk and RedHawk-SC Working Directories Preparing Design and Input Data for Rail Analysis Specifying Ideal Voltage Sources as Taps Missing Via and Unconnected Pin Checking Running Rail Analysis with Multiple Rail Scenarios Performing Voltage Drop Analysis Performing PG Electromigration Analysis 867 Running Rail Analysis Using RedHawk-SC Fusion Feedback Performing Minimum Path Resistance Analysis Performing Effective Resistance Analysis Performing Distributed RedHawk Fusion Rail Analysis Voltage Driven Power Switch Cell Sizing Working With Macro Models Performing Signoff Analysis Writing Analysis and Checking Reports Displaying Maps in the GUI Displaying ECO Shapes in the GUI Voltage Hotspot Analysis Querying Attributes"}
{"instruction": "How do I Controlling Sequential Mapping", "input": "", "output": "The sequential mapping phase consists of two steps: register inferencing and technology mapping. The term register refers to both edge-triggered registers and level-sensitive latches. Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN. SEQGENs are created during elaboration and are usually mapped to flip-flops during compile. Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library. Both of these steps are performed by the compile_fusion command. 230 Controlling Mapping and Optimization Feedback Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable QN SEQGEN This table lists the pins of a SEQGEN cell. Only a subset of these pins is used depending on the type of cell that is inferred. Unused pins are tied to zero. Direction Name Description Cell type Input clear Asynchronous reset Flip-flop or latch preset Asynchronous preset Flip-flop or latch next_state Synchronous data Flip-flop clocked_on Clock Flip-flop data_in Asynchronous data Latch enable Clock or asynchronous enable Latch synch_clear Synchronous reset Flip-flop synch_preset Synchronous preset Flip-flop synch_toggle Synchronous toggle Flip-flop synch_enable Synchronous enable Flip-flop Output Non-inverting output Flip-flop or latch 231 Controlling Mapping and Optimization Feedback Direction Name Description Cell type QN Inverting output Flip-flop or latch During technology mapping, the tool uses the SEQGEN as the starting point for mapping. The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register. Topics in this section Mapping Sequential Elements Exactly as Described in RTL Mapping of Scan Cells Mapping of Synchronous Reset or Preset Registers Specifying Synchronous Input Types for Library Cell Pins Controlling Sequential Output Inversion Preventing Connections to Register QN Pins Mapping of Synchronous Enable Logic to a MUX Identification of Shift Registers"}
{"instruction": "How do I Foundry", "input": "", "output": "To support designs that require combined foundry fill and track fill in the Fusion Compiler tool, you can use the -mode add option with the signoff_create_metal_fill command. fc_shell> signoff_create_metal_fill -mode add For a few advanced nodes, you can add foundry fill on top of track fill, which is the default methodology to create fill on some special layers. 731 Inserting Metal Fill With IC Validator In-Design Feedback You can use the all_runset_layers option with the signoff_create_metal_fill command. Set the all_runset_layers option to true to insert fill for all output fill layers defined in the runset settings. By default, this option is set to false and inserts fill only for the routing layers (metal and via layers)."}
{"instruction": "How do I Tap Attributes", "input": "", "output": "During validation checking, the tool marks each inserted tap object with the is_valid_location attribute to indicate its validity. When validation checking is enabled, the attribute value is true for the valid taps and false for the invalid taps. When the -nocheck option is used, the attribute value is unknown for all taps. The tool updates the tap attributes in subsequent voltage drop and minimum path resistance analyses. Each tap belonging to the PG nets is checked against the extracted shape. When the analysis is complete, the tool updates the tap validity status based on the rail analysis results. The following example first lists the attributes of tap objects that are added to the block in this command run, and then checks if the Tap_1437 tap passes the validation checking. fc_shell> list_attributes -application -class tap... Properties: A - Application-defined U - User-defined I - Importable from design/library (for user-defined) S - Settable B - Subscripted Attribute Name Object Type Properties Constraints 888 Specifying Ideal Voltage Sources as Taps Feedback context tap string A integrity, rail, session full_name tap string A is_valid_location tap boolean A layer_name tap string A layer_number tap int A net tap string A object_class tap string A parasitics tap string A position tap coord A static_current tap double A type tap string A absolute_coord, auto_pg, cell_coord, cell_pg, lib_cell_coord, lib_cell_pg, signal, terminal, top_pg fc_shell> get_attribute [get_taps Tap_1437] is_valid_location true"}
{"instruction": "How do I Fixing Buffers", "input": "", "output": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design. The command can perform the following changes: Minimize the number of dual-rail buffers or inverters Fix isolation violations in buffer trees Fix buffers and inverters that have illegal settings, as follows: Process, voltage, and temperature settings Library cell purpose or subset settings Target library subset settings Bias voltages Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: Swap buffer library cells to fix illegal settings Swap single-rail buffers for dual-rail buffers Swap dual-rail buffers for single-rail buffers Change the backup supplies of dual-rail buffers and inverters Change the input or output supplies of level shifters Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters. In addition, 1007 Fixing Multivoltage Violations Feedback the command only uses supplies that are available in the voltage area or voltage area region. The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations. Netlist changes caused by the command do not introduce new isolation or voltage violations. To specify a buffer tree, use the -from option with the name of a net or driver pin. If you specify a net name, its driver pin is used. In both cases, the driver pin defines a full or partial buffer tree. Wildcards are supported. The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells. By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations. However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area. If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order: A cell from the same library as the original library cell A cell from a library with a name similar to the original library A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells. Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells. However, the command does not change level-shifter library cells. To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}
{"instruction": "How do I Formal Verification", "input": "", "output": "The Formality tool uses formal techniques to prove or disprove the functional equivalence of two designs. It performs RTL-to-RTL, RTL-to-gate, and gate-to-gate verifications. Functional equivalence checking does not take into account static timing verification. The 34 Place and Route Design Flow Overview Feedback following figure shows an overview of the design flow from the Fusion Compiler tool to the Formality tool: Synthesis RTL/ netlist Ref. lib (NDM) Tech. data TLU+ files UPF files DEF/Tcl (Optional) SDC files (Optional) SVF files Design (NDM) Verilog UPF files Formality"}
{"instruction": "How do I Placement-Aware Clock Gating", "input": "", "output": "When you enable placement-aware clock gating, the tool performs the following optimizations: Replication of clock gates with timing-critical enables Adjustment of clock gates so they are placed closer to their gated registers Automatic clock network latency annotation for clock-gate cells To enable this feature, set the compile.clockgate.physically_aware application option to true. (The default is false.) The example in Figure 61 shows the difference between using and not using physically- aware clock gating. In this layout view, you can see that the integrated clock gates (shown in red) are physically closer to their gated registers. 316 Fanin-Based Sequential Clock Gating Feedback Figure 61 Placement-Aware Clock Gating Clock gate cells are shown in red Gated clock nets are shown in blue Placement-Aware Clock Gating Disabled Placement-Aware Clock Gating Enabled"}
{"instruction": "How do I Saving Relative Placement Information", "input": "", "output": "The relative placement information is automatically saved in the design library database when you save the design by using the save_lib command. You can also save the relative placement information to a file that contains Tcl commands that re-creates the relative placement groups, their objects, and their settings. To do so, use the write_rp_groups -file_name command. You must either specify which relative placement groups to write commands for or specify the -all option to write commands for all relative placement groups. By default, the write_rp_groups command writes out commands for creating the specified relative placement groups and to add leaf cells, hierarchical groups, and blockages to these groups. The commands for generating subgroups within hierarchical groups are not written. You can modify the default behavior by using the options described in Table 62 Table 62 The write_rp_groups Command Options To do this Use this option Write all the relative placement groups within the hierarchy of the relative placement groups. If you omit this option, only the top-level group is written and subgroups are not. -hierarchical Write only create_rp_group commands to the script. -create Write only add_to_rp_group -cells commands to the script. -cell Write only add_to_rp_group -rp_group commands to the script. -rp_group Write only add_to_rp_group -blockage commands to the script. -blockage"}
{"instruction": "How do I Automatically Fixing Isolated Vias", "input": "", "output": "An isolated via is a via that does not have neighboring vias close enough to meet the requirements of the technology. To check for and fix isolated vias, 1. Set up the IC Validator environment as described in Setting Up the IC Validator Environment 2. (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 3. Set the application options for fixing isolated vias. At a minimum, you must define the maximum distance within which a neighboring via must exist so that a via is not considered an isolated via. To define this information for each via layer, set the signoff.fix_isolated_via.isolated_via_max_range application option, which has the following syntax: { { via_layer distance }... { via_layer distance } } where the via_layer argument uses the mask names, such as via1, and the distance argument is in microns. For information about the options available for fixing isolated vias, see Setting Options for Fixing Isolated Vias 4. Run isolated via checking and fixing by using the signoff_fix_isolated_via command as described in Running the signoff_fix_isolated_via Command"}
{"instruction": "How do I Physical Datapath With Relative Placement", "input": "", "output": "The physical datapath with relative placement capability provides a way for you to create structures in which you specify the relative column and row positions of instances. During placement and legalization, these structures, which are placement constraints called relative placement structures, are preserved and the cells in each structure are placed as a single entity. Relative placement is also called physical datapath and structured placement. The concepts and tasks necessary for doing relative placement are described in these sections: Introduction to Physical Datapath With Relative Placement Relative Placement Flow Creating Relative Placement Groups Adding Objects to a Group Specifying Options for Relative Placement Groups Changing the Structures of Relative Placement Groups Generating Relative Placement Groups for Clock Sinks Performing Placement and Legalization of Relative Placement Groups Analyzing Relative Placement Groups Saving Relative Placement Information Summary of Relative Placement Commands"}
{"instruction": "How do I Performing Total-Power Optimization", "input": "", "output": "Total power optimization considers the combined leakage- and dynamic-power cost during optimization. To setup for total-power optimization, 1. Setup for leakage-power optimization by performing the following steps: a. Ensure that at least one scenario is enabled for leakage-power optimization by using the set_scenario_status -leakage_power true command. 2. Setup for dynamic-power optimization by performing the following steps: a. Annotate switching activity on the design, as described in Annotating the Switching Activity b. Ensure that at least one scenario is enabled for dynamic-power optimization by using the set_scenario_status -dynamic_power true command. When you use this setting, the tool performs total-power optimization during the clock_opt command."}
{"instruction": "How do I Mapping Combinational Multibit Cells", "input": "", "output": "Combinational multibit cells are library cells, where a single cell implements multiple logic functions. The Fusion Compiler tool: Banks single-bit combinational cells to multibit combinational cells. Debanks multibit combinational cells as needed to improve QoR. Figure 36 Combinational Multibit Library Cells To enable combinational multibit mapping during the initial_opto and final_opto stages, use the opt.common.enable_multibit_combinational_cells application option with the set_app_options command: fc_shell> set_app_options -name opt.common.enable_multibit_combinational_cells -value true 253 Performing Multibit Optimization Feedback Note: By default, the tool debanks the multibit combinational cells. Figure 37 Combinational Multibit Library Cell Flow To print the combinational multibit cells created for each library reference, use the -combinational option with the report_multibit command, as shown in the following example: fc_shell> report_multibit -combinational #Outputs Reference Number of instances Single-bit Equivalent 2 combo_mbit_lib_cell1 257 514 4 combo_mbit_lib_cell2 57 228 To check the compatible single-bit equivalent cell of combinational multibit library cells, use the -combinational option with the check_multibit_library command, as shown in the following example: fc_shell> check_multibit_library -combinational Combinational Compatibility Equivalent Singlebit Multibit LibCell LibCell combo_mbit_lib_cell1 Compatible combo_sbit_lib_cell1 Don't use Mismatch combo_sbit_lib_cell2 254 Running Concurrent Clock and Data Optimization Feedback combo_mbit_lib_cell2 PVT mismatch combo_sbit_lib_cell3"}
{"instruction": "How do I Inserting Tap Meshes", "input": "", "output": "tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window. A tap mesh is typically inserted outside of a place and route block, but you can insert one in any area that is either completely inside or completely outside the core area. To insert a tap mesh, use the create_tap_meshes command. You must specify the following information: The tap cell used in the tap mesh (the -lib_cell option) By default, the command inserts the tap cells with R0 orientation. To place the cells with a different orientation, use the -orientation option. By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number The tap insertion region (the -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} The mesh window (the -mesh_window option) You specify the size of the mesh window by specifying an integer value for the pitch in the x- and y-directions. -mesh_window { x_pitch y_pitch The mesh window is aligned with the lower-left corner of the tap insertion region. When inserting the tap mesh, the command does not honor the standard cell rows or sites. It places a tap cell in the lower-left corner of each mesh window. If that location is blocked, the command uses the closest available location, which is measured as the Manhattan distance to the lower-left corner of the mesh window. If there is no available location, the command issues a warning and does not place a tap cell in that mesh window. After insertion, the command fixes the placement of the inserted tap cells. 591 Inserting Tap Cells Feedback"}
{"instruction": "How do I Defining the Search Path", "input": "", "output": "The Fusion Compiler tool uses a search path to look for files that are specified with a relative path or with no path. To specify the search path, use the set_app_var command to set the search_path application variable to the list of directories, in order, in which to look for files. When the tool looks for a file, it starts searching in the leftmost directory specified in the search_path variable and uses the first matching file it finds. You can also use the Tcl lappend command to add your directories to the default search path, which is the directory from which you invoked the tool. For example, fc_shell> lappend search_path./mylibdir"}
{"instruction": "How do I Tool", "input": "", "output": "You can end the session and exit the Fusion Compiler tool at any time. To exit the tool, use the exit or quit command. Note: When you exit the tool from the command line, the tool exits without saving the open blocks."}
{"instruction": "How do I Overview of Abstract Views", "input": "", "output": "In an abstract view, the gate-level netlist for the block is modeled by a partial gate- level netlist that contains only the required interface logic of the block. All other logic is removed. Figure 191 shows a block and its abstract view, where the logic is preserved between The input port and the first register of each timing path The last register of each timing path and the output port 831 Overview of Abstract Views Feedback Logic associated with pure combinational input-port-to-output-port timing paths (A to X) is also preserved. Clock connections to the preserved registers are kept as well. The register-to-register logic is discarded. Figure 191 A Block and Its Abstract View CLK Block CLK Abstract View The interface logic of an abstract view consists of the following: All cells, pins, and nets in timing paths from input ports to registers or output ports All cells, pins, and nets in timing paths to output ports from registers or input ports Any logic in the connection from a master clock to generated clocks The clock trees that drive interface registers, including any logic in the clock tree The longest and shortest clock paths from the clock ports All pins with timing constraints that are part of the interface logic In addition to the interface logic, an abstract view contains the following information associated with the interface logic: Placement information Timing constraints Clock tree exceptions Parasitic information Transition and case values of dangling pins Power management cells and UPF constraints Nondefault routing rule association and minimum and maximum layer constraints, if any, for the nets that are retained in the abstract view 832 Creating Abstract Views Feedback"}
{"instruction": "How do I Controlling Register Merging", "input": "", "output": "By default, the tool performs register merging during optimization. To disable register merging, set the compile.seqmap.enable_register_merging application option to false. The default is true. Information about which registers are being merged is stored in the.svf file, and the output log file shows information messages about register merging. 239 Controlling Mapping and Optimization Feedback You can also control register merging based on the attribute setting by using the set_register_merging command. To enable register merging during optimization, specify a true value to set the register merging attribute on the specified object list. To disable register merging, specifies a false value for the specified object list. The objects can include leaf cells, hierarchical cells, and modules. This example specifies not to merge registers that have the u1/count_reg string in the instance names: fc_shell> set_register_merging \"u1/count_reg*\" false This example specifies not to merge all flip-flops of u1 instance name: fc_shell> set_register_merging \"u1\" false"}
{"instruction": "How do I Defining Routing Constraints", "input": "", "output": "The Fusion Compiler tool provides a set of application options to control custom routing results. The application options are applied globally. See Using Custom Routing Application Options You can also define net-specific routing constraints that override the routing application options. Routing constraints provide guidance during routing. In the Fusion Compiler environment, Custom Router honors both the Custom Router constraints and the Fusion Compiler nondefault routing rules. Note: You must apply net-specific routing constraints to physical nets. When specifying nets that will be constrained, use the get_nets -physical_context command to ensure the physical net is returned. For example: fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*]\\ -disabled_layers {M5 M6} -sharing true \\ -layer_gaps {M2 3 M3 5} {shielding_4} Table 52 lists the commands to define the Custom Router constraints by creating constraint groups. For information about the supported Fusion Compiler nondefault routing rules, see Using Nondefault Routing Rules To check or remove the created constraint groups, use the report_constraint_groups or remove_constraint_groups command. For more information about checking or removing constraint groups, see Managing Constraint Groups Table 52 Commands to Define Custom Router Routing Constraints Command Description create_bus_routing_style Specifies the routing style for group of nets that are routed as a single bus structure (or trunk). For more information, see Defining the Bus Routing Style create_differential_group Defines a differential group for routing. For more information, see Creating Differential Groups 749 Defining Routing Constraints Feedback Table 52 Commands to Define Custom Router Routing Constraints (Continued) Command Description create_wire_matching Defines matched wire length for a group of nets or pin-to-pin connections. For more information, see Defining Matching Wire Lengths create_length_limit Defines the minimum wire length for a group of nets or pin-to-pin connections. For more information, see Defining Minimum Wire Lengths create_net_shielding Defines the shielding style for a group of nets or bundles. For more information, see Inserting Shields on the Nets create_net_priority Determines the order in which the nets are routed. Nets with a higher priority are routed first. For more information, see Defining the Net Priority"}
{"instruction": "How do I DRC Toolbar", "input": "", "output": "The DRC toolbar provides buttons that you can use to configure and run interactive design rule checking with Live DRC, and to view the reported DRC violations in the layout view. Figure 147 shows the DRC toolbar. 695 Performing Signoff Design Rule Checking Feedback Figure 147 DRC Toolbar Table 46 DRC Toolbar Buttons Button Description Runs design rule checking using Live DRC. Opens the dialog box to view and sets the Live DRC application options. Opens the dialog box to configure the rules to use for design rule checking. Selects the region in which to perform design rule checking. Resets the design rule checking region to that used in the previous Live DRC run. Enables or disables the error environment overlay of GDSII or OASIS shapes from lower level cells that contribute to DRC errors. The error environment overlay is available only when the signoff.physical.merge_stream_files application option is set before doing DRC checking. Clears or highlights all DRC violations detected by Live DRC. Iterates through the DRC violations for the current rule from Live DRC. Controls zoom or pan when iterating through the DRC violations. Shows the design rule being highlighted. 696 Performing Signoff Design Rule Checking Feedback"}
{"instruction": "How do I Enabling High-Effort Area Mode", "input": "", "output": "On designs that need further reduction of area, set the compile.flow.high_effort_area application option to true Running high-effort area mode during compile might increase runtime because the tool performs multiple passes of placement and optimization to obtain optimal area results. 261 Performing Design Analysis Feedback"}
{"instruction": "How do I Benefits of Relative Placement", "input": "", "output": "Along with being technology-independent and having the ability to improve routability, relative placement provides the following benefits: Reduces the placement search space in critical areas of the design, which improves the predictability of QoR (wire length, timing, power, area) and congestion. Maintains relative placement during placement, optimization, clock tree synthesis, and routing. Provides a method for maintaining structured placement for legacy or intellectual property (IP) designs. 782 Relative Placement Flow Feedback Handles flat and hierarchical designs. Allows sizing of relative placement cells while maintaining relative placement."}
{"instruction": "How do I Enabling Improved Buffering for Multivoltage Nets", "input": "", "output": "Multivoltage nets are nets that logically or physically cross over more than one voltage area. You can enable the use of improved buffering techniques for fixing logical DRC violations on such nets during preroute optimization by setting the opt.buffering.enable_hierarchy_mapping application option to true This application option affects the compile_fusion and clock_opt commands. Enabling this feature reduces the number of buffers used to fix logical DRC violations. However, it can slightly increase the total negative slack or number of hold violations."}
{"instruction": "How do I Running Commands in Parallel on Your Local Host", "input": "", "output": "You can improve runtime by running checking and reporting commands in parallel on your local host. You can run the commands either in the background (with the redirect -bg command) or in the foreground (with the parallel_execute command). These techniques do not require the use of additional licenses beyond the licenses required for the parent run. They also do not require you to use or configure distributed processing. When you use these techniques, consider the following guidelines: To reduce runtime and memory usage, run the update_timing command before running the commands in parallel; otherwise, each command that requires updated timing runs the update_timing command independently. To pass variables from a child process to the parent process, you must write the contents of the variables to a file during the child process, and then read that file in the parent process. See Also Running Commands in the Background Running Commands in Parallel"}
{"instruction": "How do I Setting Up for Self-Gating", "input": "", "output": "To set up the block for self-gating, perform the following steps before you run the compile_fusion command: 1. Enable self-gating by setting the compile.clockgate.self_gating application option to true fc_shell> set_app_options -name compile.clockgate.self_gating \\ -value true 2. Apply switching activity by using the read_saif or set_switching_activity command. 3. (Optional) Specify self-gating settings using the set_self_gating_options command. For more information, see Setting Self-Gating Options 4. (Optional) Override the tool's default behavior of selecting self-gating objects by using the set_self_gating_objects command. For more information, see Controlling the Selection of Self-Gating Objects"}
{"instruction": "How do I Defining Antenna Rules", "input": "", "output": "Antenna rules define how to calculate the maximum antenna ratio for the nets in a block, as well as the antenna ratio for a pin. You must define a global antenna rule by using the define_antenna_rule command. You can also specify layer-specific antenna rules by using the define_antenna_layer_rule command. The tool uses the global antenna rule whenever a layer-specific antenna rule does not exist. The following topics describe how to define the antenna rules: Calculating the Maximum Antenna Ratio Calculating the Antenna Ratio for a Pin"}
{"instruction": "How do I Performing Design Rule Checking Using Zroute", "input": "", "output": "To use Zroute to check the routing design rules defined in the technology file, run the check_routes command. By default, the check_routes command checks for routing DRC violations, unconnected nets, antenna rule violations, and voltage area violations on all routed signal nets in the block, except those marked as user nets, frozen nets, and PG nets. To verify the routing only for specific nets, specify the nets by using the -nets option. To check user routes, set the -check_from_user_shapes option to true To check frozen routes, set the -check_from_frozen_shapes option to true A net is considered frozen when its physical_status attribute is set to locked 569 Analyzing the Routing Results Feedback To disable checks for routing DRC violations, set the -drc option to false. To disable checks for unconnected nets, set the -open_net option to false. To disable checks for antenna rule violations, set the -antenna option to false. To disable checks for voltage area violations, set the -voltage_area option to false To save time, you can restrict the routing verification to specific regions of the block by using the -coordinates option to specify the lower-left and upper-right coordinates for each rectangular region. When you perform area-based DRC, the check_routes command checks only for DRC violations and voltage area violations. It does not check for unconnected nets, antenna violations, or tie-to-rail violations, as these are net-based violations. Note: The -coordinates option and the -nets option are mutually exclusive; you can use only one of these options. The check_routes command reports the following DRC violations: Spacing violations Different-net wire spacing Different-net nondefault wire spacing (note that the DRC report refers to nondefault routing rules as variable rules) Different-net via-cut spacing Different-net nondefault via-cut spacing (note that the DRC report refers to nondefault routing rules as variable rules) Different-net fat extension spacing Dog bone spacing End-of-line spacing Enclosed via spacing Same-net spacing Same-net via-cut spacing Same-net fat extension spacing Special notch spacing U-shape spacing Via-cut to metal spacing Soft spacing 570 Analyzing the Routing Results Feedback Area violations Less than minimum area Less than minimum enclosed area Fat wire via keepout area Jog wire via keepout area Length and width violations Less than minimum width Less than minimum length Less than minimum edge length Protrusion length Contact violations Needs fat contact Needs poly contact Needs fat contact on extension Over maximum stack level Enclosure violations End-of-line wire via enclosure Jog wire via enclosure T-shape wire via enclosure Others Open nets, except when doing area-based DRC By default, the check_routes command reports a maximum of 200 open nets. To report all open nets, use the -report_all_open_nets true option (or select \"Report all open nets\" in the GUI). Antenna violations, except when doing area-based DRC Nets crossing the top-cell boundary Frozen layers Minimum layer 571 Analyzing the Routing Results Feedback Maximum layer Voltage area violations Note: These violations are also reported after each detail route iteration. The check_routes command saves the error data to a file named zroute.err. You cannot control the naming of the error data file generated by the check_routes command, but you can rename the error data file after running the command. To rename the error data file, use the following commands: fc_shell> write_drc_error_data -error_data zroute.err \\ -file_name export.err fc_shell> open_drc_error_data -file_name export.err fc_shell> attach_drc_error_data [get_drc_error_data export.err] \\ -name newname.err After you run the check_routes command, you can use the DRC query commands to get more information about the violations or use the error browser to examine the violations in the GUI. For information about analyzing the DRC violations, see Using the DRC Query Commands. For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide After running check_routes, you can use the following command to run incremental detail routing that uses the check_routes results as input: fc_shell> route_detail -incremental true \\ -initial_drc_from_input true Note: Incremental detail routing does not fix open nets. To fix open nets, you must run ECO routing. For information about ECO routing, see Performing ECO Routing"}
{"instruction": "How do I Verifying the Boundary Cell Placement", "input": "", "output": "After inserting the boundary cells with the compile_boundary_cells command, verify the placement by using the check_boundary_cells command. To create an error data file to view the errors in the error browser, use the -error_view option. For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide This command checks the boundary cell placement for the following issues: Missing boundary or corner cells This check verifies that there are boundary and corner cells around the entire boundary, with no gaps. Figure 124 shows a valid placement, as well as errors caused by missing cells. 599 Finding and Fixing Antenna Violations Feedback Figure 124 Check for Missing Boundary or Corner Cells Note: For established nodes, boundary cells are inserted only on the left and right sides. In this case, the command verifies only that there are no gaps on these sides. Incorrect boundary or corner cells This check verifies that the library cells used for the boundary and corner cells match the cells specified by the set_boundary_cell_rules command. Incorrect orientation of boundary cells This check verifies that the orientation of each boundary cell matches the allowed orientations specified by the set_boundary_cell_rules command. Short rows and edges This check verifies that each row of boundary cells is wider than the value specified by the set_boundary_cell_rules -min_row_width option and that the horizontal edges of each blockage are greater than the value specified by the set_boundary_cell_rules -min_horizontal_jog option."}
{"instruction": "How do I An Overview for RedHawk Fusion and RedHawk-SC Fusion", "input": "", "output": "Both RedHawk Fusion and RedHawk-SC Fusion support gate-level rail analysis capabilities, including static and dynamic rail analysis. You can use RedHawk Fusion and RedHawk-SC Fusion to perform the following types of checking and analysis in the Fusion Compiler environment: Missing via and unconnected pin shape checking To check for missing vias or unconnected pin shapes in the design, you first configure the checking-related settings by using the set_missing_via_check_options command, and then perform the check by using the analyze_rail -check_missing_via command. For more information, see Missing Via and Unconnected Pin Checking Voltage drop analysis To perform voltage drop analysis, use the analyze_3d_rail -voltage_drop -electromigration command. To perform voltage drop analysis, use the analyze_rail -voltage_drop command or choose Rail > Analyze Rail and select \"Voltage drop analysis\" in the GUI. Set the -voltage_drop option to static dynamic dynamic_vcd, or dynamic_vectorless to choose the type of analysis you want to perform. For more information, see Performing Voltage Drop Analysis PG electromigration analysis To perform PG electromigration analysis, use the analyze_rail -electromigration command. For more information, see Performing PG Electromigration Analysis 870 An Overview for RedHawk Fusion and RedHawk-SC Fusion Feedback Minimum path resistance analysis To perform minimum path resistance analysis, use the analyze_rail -min_path_resistance command. In the RedHawk-SC analysis flow, you must use the -voltage_drop option together with the -min_path_resistance option for minimum path resistance analysis. For more information, see Performing Minimum Path Resistance Analysis Depending on the type of analysis you run, the tool generates visual displays (maps) of the results that you can view in the Fusion Compiler GUI, as well as error data that you can display in the Fusion Compiler error browser. These maps and error data help you discover problem areas and determine corrective action without leaving the Fusion Compiler environment. Note: RedHawk Fusion in the Fusion Compiler tool does not support RedHawk signoff analysis features, such as hierarchical analysis or dynamic analysis with lumped or SPICE packages. For more information, see Preparing Design and Input Data for Rail Analysis By default, RedHawk Fusion analyzes only the current design scenario when analyzing a multicorner-multimode design. For more information about how to create and specify a rail scenario for rail analysis, see Running Rail Analysis with Multiple Rail Scenarios Figure 198 shows where you would use these analysis capabilities in a typical design flow. Figure 198 Using RedHawk Fusion in the Fusion Compiler Design Flow Find missing vias Design planning place_opt Initial placement Static voltage clock_opt Static voltage Filler cell insertion drop analysis drop analysis Power-switch cell insertion Dynamic voltage drop analysis route_opt PG electromigration analysis and fixing 871 An Overview for RedHawk Fusion and RedHawk-SC Fusion Feedback"}
{"instruction": "How do I Adding Objects to a Group", "input": "", "output": "After you create a relative placement group by using the create_rp_group command, you can add the following types of objects to it by using the add_to_rp_group command: Leaf cells, as described in Adding Leaf Cells Leaf cells, as described in Adding Hard Macro Cells Relative placement groups, as described in Adding Relative Placement Groups Blockages, as described in Adding Blockages When you add an object to a relative placement group, The relative placement group to which you are adding the object must exist. The object must be added to an empty location in the relative placement group. Only one object can be added in one location of relative placement group. To remove objects from a relative placement group, use the remove_from_rp_group command. You can remove leaf cells ( -cells ), relative placement groups ( -rp_group ), and blockages ( -blockage ). When you remove objects from a group, the space previously occupied by the removed objects is left unoccupied."}
{"instruction": "How do I Controlling IR-Drop-Aware Placement", "input": "", "output": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells. Figure 22 Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in Figure 22 The upper category consists of the top one percent of the total number of cells with the highest voltage drop values. During placement, the tool spreads these cells the most. The middle category consists of the next five percent of the cells. During placement, the tool spreads these cells less than those in the upper category. The lower category consists of the rest of the cells. The tool does not spread these cells. 160 Specifying Placement Settings Feedback You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options. The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false. They are true by default. The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa. The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ 161 Specifying Legalization Settings Feedback -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command. The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"instruction": "How do I Analyzing Clock Timing", "input": "", "output": "The timing characteristics of the clock network are important in any high-performance design. To obtain detailed information about the clock networks in the current block, use the report_clock_timing comandcomandsreport_clock_timing report_clock_timing command. You must use the -type option to specify the type of report to generate. The report_clock_timing command can generate the following types of reports: Single-clock local skew To generate a single-clock local skew report, use the -type skew option. Interclock skew To generate an interclock skew report, use the -type interclock_skew option. Latency To generate a latency report, use the -type latency option. 436 Analyzing the Clock Tree Results Feedback Transition To generate a transition time report, use the -type transition option."}
{"instruction": "How do I Merging Clock Gates", "input": "", "output": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage. The tool looks for clock-gating cells that share a common clock and enable signal. This feature is on by default. The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching. Note that the the tool also checks clock-gating style and multivoltage constraints. Clock-gating cells with the dont_touch or size_only constraints are not optimized. To disable this feature, use the set_clock_gate_transformations command. 313 Setting Clock Gating Transformations Feedback"}
{"instruction": "How do I Enabling Local Skew Optimization", "input": "", "output": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths. If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design. However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design. During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths. To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the synthesize_clock_trees and clock_opt commands, set the cts.compile.enable_local_skew and cts.optimize.enable_local_skew application options to true fc_shell> set_app_options -list {cts.compile.enable_local_skew true} fc_shell> set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you 360 Specifying the Clock Tree Synthesis Settings Feedback specify with the set_clock_tree_options -target_skew command. To prevent the tool from deriving skew targets, use the following application option setting: fc_shell> set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}
{"instruction": "How do I Setting Up for Power-Related Features", "input": "", "output": "The following topics describe the tasks you need to perform for setting up a design for power-related features: Annotating the Switching Activity Enabling Leakage Power Optimization for the compile_fusion Command Enabling Power Optimization for the clock_opt Command Improving Yield By Limiting the Percentage of Low-Threshold-Voltage (LVT) Cells Updating Activity for Improved Power Optimization Enabling the Power Integrity Features"}
{"instruction": "How do I Defining Blockages That Exclude Relative Placement Groups", "input": "", "output": "To define partial blockages that exclude relative placement groups, specify the boundary, type ( -type rp_group option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage. For example, to define a partial blockage that excludes relative placement groups, but allows a cell density of 100 percent for all other cells, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type rp_group -blocked_percentage 0 Note: Relative placement group blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Automatically Fixing Signoff DRC Violations", "input": "", "output": "Zroute can use the signoff DRC results generated by the signoff_check_drc command to automatically fix the detected design rule violations. To perform automatic fixing of the signoff DRC violations, 1. Set up the IC Validator environment as described in Setting Up the IC Validator Environment 2. Set up the physical signoff options as described in Setting Options for Signoff Design Rule Checking 3. (Optional) Generate a configuration file that aids in the fixing process. The configuration file defines the layer-to-DRC-rule mapping. The signoff_fix_drc command processes only those rules that are specified in the configuration file. By default, the signoff_fix_drc command automatically generates the configuration. You can manually generate a configuration file, as described in Creating an Autofix Configuration File 4. Set the application options for signoff DRC fixing. For information about the options for signoff DRC fixing, see Setting Options for Signoff Design Rule Checking 5. Save the block to disk. When you run the signoff_fix_drc command, the IC Validator tool uses the on- disk information for the block, not the information in memory. To ensure accurate information, use the save_block command to save the current state of the block before running the signoff_fix_drc command. 6. Run signoff DRC fixing by using the signoff_fix_drc command as described in Running the signoff_fix_drc Command If your block uses double-patterning technology, first perform signoff DRC fixing for all other routing design rules, and then perform signoff DRC fixing for only the double- patterning rules, as described in Automatically Fixing Double-Patterning Odd-Cycle Violations"}
{"instruction": "How do I Conventions", "input": "", "output": "The following conventions are used in Synopsys documentation. Convention Description Indicates syntax, such as write_file Indicates a user-defined value in syntax, such as write_file design_list Indicates user input\u2014text you type verbatim\u2014in examples, such as prompt> write_file top Purple Within an example, indicates information of special interest. Within a command-syntax section, indicates a default, such as include_enclosing = true | false [ ] Denotes optional arguments in syntax, such as write_file [-format fmt 29 About This User Guide Customer Support Feedback Convention Description... Indicates that arguments can be repeated as many times as needed, such as pin1 pin2... pinN Indicates a choice among alternatives, such as low | medium | high Indicates a continuation of a command line. Indicates levels of directory structure. Bold Indicates a graphical user interface (GUI) element that has an action associated with it. Edit > Copy Indicates a path to a menu command, such as opening the Edit menu and choosing Copy Ctrl+C Indicates a keyboard combination, such as holding down the Ctrl key and pressing C."}
{"instruction": "How do I Reporting Logic Levels in Batch Mode", "input": "", "output": "As an alternative to displaying logic-level histograms in the GUI, you can report logic levels by using the report_logic_levels command on the command line or in a script (batch mode). Note: You must have a mapped design to run logic-level reporting. You can use the command to report logic levels of The entire design or a selected path group All types of paths, including same-clock paths, cross-clock paths, infeasible paths, and multicycle paths in all scenarios The report contains logic distribution and timing information in the summary, logic-level distribution, and logic-level path report sections. By default, buffers and inverters are not reported. 282 Performing Design Analysis Feedback To report logic levels, 1. (Optional) Set a specific logic-level threshold other than the default by using the set_analyze_rtl_logic_level_threshold command. By default, the tool derives the logic-level threshold based on the delay values required for the paths. To set a logic-level threshold for the entire design, enter fc_shell> set_analyze_rtl_logic_level_threshold threshold_value To set a logic-level threshold for a specific path group, enter fc_shell> set_analyze_rtl_logic_level_threshold \\ -group path_group threshold_value The path group setting overrides the global threshold of the entire design. To reset all threshold values, enter fc_shell> set_analyze_rtl_logic_level_threshold -reset To reset a specific group setting, enter fc_shell> set_analyze_rtl_logic_level_threshold \\ -group path_group -reset 2. (Optional) Specify the fields in the summary section of the report by setting the shell.synthesis.logic_level_report_summary_format application option. The default contains five fields: \"group period wns num_paths max_level\". You can specify up to eight fields. For example, fc_shell> set_app_options \\ -name shell.synthesis.logic_level_report_summary_format \\ -value \"group num_paths max_level min_level avg_level\"... 3. (Optional) Specify the fields in the path group section of the report by setting the shell.synthesis.logic_level_report_group_format application option. The default contains five fields: \"slack ll llthreshold startpoint endpoint\". You can specify up to ten fields. For example, fc_shell> set_app_options \\ -name shell.synthesis.logic_level_report_group_format \\ -value \"slack ll ll_buf_inv clockcycles startclk endclk... 4. Report logic levels by using the report_logic_levels command. The following example generates a logic-level report of the clk_i path group: fc_shell> report_logic_levels -group clk_i 283 Performing Design Analysis Feedback"}
{"instruction": "How do I Timing-Driven Global Routing", "input": "", "output": "By default, the route_global command is not timing-driven. To enable timing-driven global routing, set the route.global.timing_driven application option before you run the route_global command. During timing-driven global routing, the global router considers the impact of layer resistance by minimizing the usage of pin access layers, even if this increases wire length. By default, when you enable timing-driven global routing, the tool 1. Calculates the net delays of the block If the design library contains global route information, the tool uses the global route information to calculate the net delays; otherwise, it uses virtual routing to calculate the net delays. The global routing results can vary depending on whether the initial net delays were calculated by using global route information or virtual routing. To remove existing global route information from the signal nets in the block, use the -global_route and -net_types signal options with the remove_routes command, as shown in the following example: fc_shell> remove_routes -global_route -net_types signal 2. Performs an initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell 529 Routing Signal Nets Feedback 3. Performs two rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows 4. Updates the design timing based on the first three global routing phases 5. Identifies newly critical nets based on the timing update 6. Performs three rerouting phases, in which the tool rips up and reroutes the newly critical nets To increase the number of rerouting phases after the timing update, set the global routing effort level to high or ultra by using the -effort_level option with the route_global command. To reduce runtime, at a possible cost to the timing QoR, set the route.global.advance_node_timing_driven_effort application option. When you set this application option to medium, the tool rips up and reroutes the newly critical nets only if doing so does not increase congestion. In addition, the number of rerouting phases is reduced for medium-, high-, and ultra-effort global routing. When you set this application option to low, the tool does not perform the timing update and the number of rerouting phases is reduced for medium, high-, and ultra- effort global routing. The following table summarizes the timing-driven global routing behavior based on the effort level settings. The shaded cell shows the default behavior. Table 32 Number of Rerouting Phases Based on the Effort Level Settings route.global.advance_node_timing_driven_effort setting route_global -effort_level setting low medium high (default) low medium (default) 3,4 3,5 high 3,4 3,4 ultra 3,4 3,4 To control the tradeoff between timing QoR and DRC convergence, set the route.global.timing_driven_effort_level application option. By default, this option has a setting of high, which favors timing QoR over DRC convergence. 3. Timing update performed after the second rerouting phase. 4. Newly critical nets are ripped up and rerouted only if it does not increase congestion. 5. Newly critical nets are always ripped up and rerouted. 530 Routing Signal Nets Feedback"}
{"instruction": "How do I Datapath Implementation", "input": "", "output": "All the extracted datapath elements and the synthetic operators are implemented by the DesignWare datapath generator in Fusion Compiler. The DesignWare datapath generator uses the smart generation technology to perform the following tasks: Implement datapath blocks using context-driven optimizations Revisit high-level optimization decisions for a given timing context Consider logic library characteristics Use these commands and application option for datapath implementation: set_datapath_architecture_options This command controls the strategies used to generate the datapath cells for arithmetic and shift operators. The following example specifies to use Booth-encoded architectures to generate multiplexers: fc_shell> set_datapath_architecture_options -booth_encoding true set_implementation This command specifies the implementation to use for dividers and synthetic library cell instances with a specified name. The following example specifies to use the cla3 implementation for the instantiated DesignWare cell U1. fc_shell> set_implementation cla3 U1 set_synlib_dont_use 224 Controlling Mapping and Optimization Feedback This command prevents using specific implementation. The following example specifies not to use the rpl implementation. fc_shell> set_synlib_dont_use \\ {dw_foundation/DW_div/cla standard/DW_div/rpl} compile.datapath.ungroup By default, all DesignWare cells and datapath blocks are ungrouped during timing optimization. To disable the ungrouping, set the compile.datapath.ungroup application option to false, changing from its default of true. For example, fc_shell> set_app_options \\ -name compile.datapath.ungroup -value false"}
{"instruction": "How do I Querying Attributes", "input": "", "output": "When rail analysis or missing via checking is complete, use the get_attribute attribute to query the results stored in the RedHawk working directory. You can query the attributes shown in Table 71, which are specific to the rail analysis results. Table 71 Rail Result Object Attributes Object Attributes Cell static_power 946 Querying Attributes Feedback Table 71 Rail Result Object Attributes (Continued) Object Attributes Pin static_current peak_current static_power switching_power leakage_power internal_power min_path_resistance voltage_drop average_effective_voltage_drop_in_tw max_effective_voltage_drop (=effective_voltage_drop) max_effective_voltage_drop_in_tw min_effective_voltage_drop_in_tw effective_resistance The following example retrieves the effective_voltage_drop attribute for the cellA/VDD pin. fc_shell> get_attribute [get_pins cellA/VDD] effective_voltage_drop -0.02812498807907104 The following example retrieves the static_power attribute for the cellA cell. fc_shell> get_attribute [get_cells cellA] static_power 2.014179968645724e-05 947 Feedback"}
{"instruction": "How do I Typical Critical Dimension Metal Fill Insertion", "input": "", "output": "Typical critical dimension (TCD) structures can improve yield for designs. These structures are made up of marker and fill layers, both of which are added to the block during TCD metal fill insertion. To enable TCD metal fill insertion, set the signoff.create_metal_fill.tcd_fill application option to true before running the signoff_create_metal_fill command. By default, the command inserts TCD structures on all metal and via layers for the entire block. To modify the default behavior, use the following options: -select_layers To restrict the layers on which to insert metal fill, use this option, as described in Specifying the Layers for Metal Fill Insertion -coordinates and -excluded_coordinates To restrict the regions on which to insert metal fill, use these options, as described in Specifying the Regions for Metal Fill Insertion Note: You cannot use timing-driven metal fill insertion with TCD metal fill insertion. See Also Removing Metal Fill"}
{"instruction": "How do I Mapping ECO Cells to Logically Equivalent Spare Cells", "input": "", "output": "When the tool maps an ECO cell, it looks for a spare cell with the same library cell name. If it is unable to find such a spare cell, the ECO cells remains unmapped. To identify and map such ECO cells to logically equivalent (LEQ) spare cells, use the following steps: 1. Identify the ECO cells that do not have matching spare cells by using the check_freeze_silicon command. 2. Find logically equivalent spare cells for these ECO cells by using the create_freeze_silicon_leq_change_list command. Specify The names of the unmapped ECO cells by using the -cells option A name for the output file by using the -output option This output file is a Tcl script with netlist editing commands. The commands replace each ECO cell with logically equivalent spare cells, which can be a Single spare cell with the same logical functionality, but a different library cell name Combination of up to two spare cells that give the same logical functionality 3. View the output Tcl file to ensure that the ECO mapping is satisfactory, and it if necessary. 4. Source the Tcl file in the tool to replace the ECO cells with their logical equivalents."}
{"instruction": "How do I Running the signoff_fix_isolated_via Command", "input": "", "output": "You can use the signoff_fix_isolated_via command either to check for isolated vias only, or to check for and fix the isolated vias."}
{"instruction": "How do I Defining the Layer Mapping for IC Validator In-Design Commands", "input": "", "output": "A layer mapping file maps the technology layers to the layers used in the runset file. You specify the location of the layer mapping file by setting the signoff.physical.layer_map_file application option. Each line in the layer mapping file specifies a layer in the technology file and the corresponding layer in the runset file using the following syntax: tf_layer [: tf_purpose ][: use_type ][: mask_type runset_layer [: runset_data_type Each line can contain the following items: tf_layer \u2013 Layer number in the technology file, a required item tf_purpose \u2013 Purpose number in the technology file use_type \u2013 Fusion Compiler usage of the geometries in the design 664 Performing Signoff Design Rule Checking Feedback Valid values are power ground signal clock boundary hard_placement_blockage soft_placement_blockage routing_blockage area_fill, and track mask_type \u2013 Multiple-patterning mask constraint of the geometries Valid values for metal layers are mask_one mask_two mask_three, and mask_same Via layers support the additional values MASK_FOUR through MASK_FIFTEEN runset_layer \u2013 Layer number in the runset file, a required item runset_data_type \u2013 Layer data type number in the runset file Any text in a line that comes after a semicolon character ( ) is considered a comment and has no effect on layer mapping."}
{"instruction": "How do I Accessing Libraries", "input": "", "output": "Before enabling the THO settings, you must ensure that: All the subblock libraries are opened in mode. You must open the parent library using the -ref_libs_for_edit option with the open_lib command. The design view of the blocks is editable. 862 Transparent Hierarchy Optimization Feedback"}
{"instruction": "How do I Defining Blockages That Allow Relative Placement Cells Only", "input": "", "output": "To define partial blockages that allow relative placement cells only, specify the boundary, type ( -type allow_rp_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage. For example, to defines a partial blockage that allows relative placement cells only, with a maximum allowed cell density of 80 percent (a blocked percentage of 20), and enclosed by the rectangle with corners at (10, 20) and (100,200), use the following command: create_placement_blockage -name rp_only -type allow_rp_only \\ -boundary {10 20 100 200} -blocked_percentage 20 These blockages allows the tool to place relative placement groups, which are usually large structures, without disturbing the placement of other cells. After the tool places and legalizes the relative placement groups, you can remove these blockages and allow the tool to place other cells in them. Note: Relative-placement-cells-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Checking PG Electromigration Violations", "input": "", "output": "When PG electromigration analysis is complete, you can check the generated error files in the error browser or write the generated errors to an output file. The tool does not write the generated errors to the working directory, meaning the error data is deleted if you exit the tool without saving the block. Ensure that you save the block to keep the generated error data if you want to examine the errors in another session. 905 Performing PG Electromigration Analysis Feedback You can examine the generated error files in the error browser or write the generated errors to an output ASCII file. To examine the generated errors in the error browser, 1. Choose View > Error Browser from the GUI. 2. In the Open Error Data dialog box, select the errors to examine and click Open Selected. 3. Check the details of the errors in the Error Browser (see Figure 205 ). 906 Performing PG Electromigration Analysis Feedback Figure 205 Opening Generated Errors in the Error Browser To write errors to an ASCII file, use the following script: set fileName \"errors.txt\" set fd [open $fileName w] set dm [open_drc_error_data rail_pg_em.VDD.err] set all_errs [get_drc_errors -error_data $dm *] foreach_in_collection err $all_errs { set info [ get_attribute $err error_info]; puts $fd $info } close $fd 907 Performing Minimum Path Resistance Analysis Feedback Here is an example of the output error file: M1 (414.000,546.584 414.344,546.584) em ratio 23585.9% width 0.06 blech length 0.000 um current 0.0024963 M1 (414.344,546.584 416.168,546.584) em ratio 23401.3% width 0.06 blech length 0.000 um current 0.0024768 M1 (416.168,546.584 416.776,546.584) em ratio 23241.7% width 0.06 blech length 0.000 um current 0.0024599 M1 (416.776,546.584 417.992,546.584) em ratio 23082.2% width 0.06 blech length 0.000 um current 0.0024430 M1 (417.992,546.584 419.208,546.584) em ratio 22897.7% width 0.06 blech length 0.000 um current 0.0024235 M1 (419.208,546.584 419.512,546.584) em ratio 22731.1% width 0.06 blech length 0.000 um current 0.0024059 M1 (419.512,546.584 421.184,546.584) em ratio 22564.4% width 0.06 blech length 0.000 um current 0.0023882 M1 (421.184,546.584 421.488,546.584) em ratio 22349% width 0.06 blech length 0.000 um current 0.0023654 M1 (421.488,546.584 423.160,546.584) em ratio 22133.5% width 0.06 blech length 0.000 um current 0.0023426 M1 (423.160,546.584 423.616,546.584) em ratio 21967.2% width 0.06 blech length 0.000 um current 0.0023250"}
{"instruction": "How do I Detail Routing", "input": "", "output": "based on total routed via count = 98.96% (2902130 / 2932706 vias) Layer VIA1 = 97.81% (1091973/ 1116367 vias) Weight 1 = 97.81% (1091973 vias) Un-optimized = 2.19% (24394 vias) Total number of nets = 255165 0 open nets, of which 0 are frozen Total number of excluded ports = 0 ports of 0 unplaced cells connected to 0 nets 0 ports without pins of 0 cells connected to 0 nets 0 ports of 0 cover cells connected to 0 non-pg nets Total number of DRCs = 7398 Total number of antenna violations = antenna checking not active Information: Routes in non-preferred voltage areas = 8170 (ZRT-559) Topology ECO iteration 1 ended with 0 qualifying violations."}
{"instruction": "How do I H-Tree-Only Global Clock Tree Structure", "input": "", "output": "The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh. The global clock structure consists only of an H-tree, which directly drives the tap drivers. Figure 85 Regular Multisource Clock Tree With an H-Tree-Only Global Clock Structure To implement a regular multisource clock tree structure with an H-tree-only global clock tree structure, 1. Specify your clock tree constraints and settings. 2. Perform the following steps for multivoltage designs: a. Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to true b. Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to true c. Run the check_mv_design command and fix all multivoltage issues. 3. Enable cell electromigration fixing by setting the cts.multisource.cell_em_aware application option to true 4. Specify the required settings by using the set_regular_multisource_clock_tree_options command and 402 Implementing Multisource Clock Trees Feedback perform tap insertion and global clock tree (H-tree) synthesis by using the synthesize_regular_multisource_clock_trees command, as described in Performing Automated Tap Insertion and H-Tree Synthesis 5. Specify options and settings for tap assignment, as described in Specifying Tap Assignment Options and Settings 6. Perform tap assignment by using the synthesize_multisource_clock_taps command, which Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks Assigns endpoints to the closest tap driver and splits cells along the path honoring any sink groups defined Copies the UPF and SDC constraints and the user-specified attributes onto the newly created cells across the active scenarios 7. Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell> clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers. It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable. You can also synthesize other clocks in the design that are not synthesized. For more information about the clock_opt command, see Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command 8. Analyze the clock tree results, as described in Analyzing the Clock Tree Results"}
{"instruction": "How do I Specifying Settings for Multivoltage Designs", "input": "", "output": "For multivoltage designs, to Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the add_buffer_on_route command. Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format. When you use this option, you must also use the -lib_cell option. Specify different single-rail and dual-rail library cells for different voltage areas, use the -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format. 970 Optimizing the Fanout of a Net Feedback When you use this option, you must also use the -lib_cell option. For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option. For the default voltage area, specify DEFAULT_VA as the voltage area name. Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the -allow_physical_feedthrough_buffer option. This option can only be used with the -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area. After you run the add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command. Add cells within gas stations of specified supply nets, use the -respect_gas_station option and specify the supply net. Gas stations are areas with a constant power supply. These areas used for buffering nets that go through power domains that are powered down. To specify the maximum allowed distance from the gas station to the added buffer, use the -max_distance_route_to_gas_station option."}
{"instruction": "How do I Routing Nets Within a Specific Region", "input": "", "output": "To route one or more nets within a specific region, 1. Define a routing corridor by using the create_routing_corridor command, as described in Defining Routing Corridors 2. Assign the nets and supernets to the routing corridor by using the add_to_routing_corridor command, as described in Assigning Nets to a Routing Corridor 3. Verify that the routing corridors are valid by using the check_routing_corridors command, as described in Verifying Routing Corridors If necessary, modify the routing corridors, as described in Modifying Routing Corridors 4. Route the nets by using the route_group command, as described in Routing Critical Nets 5. Remove the routing corridors, as described in Removing Routing Corridors See Also Reporting Routing Corridors 490 Routing Constraints Feedback"}
{"instruction": "How do I Defining Routing Corridors", "input": "", "output": "A routing corridor restricts Zroute global routing for specific nets to the region defined by a set of connected rectangles. In addition to specifying the region in which the routing occurs, you can also specify the minimum and maximum routing layers for each of the rectangles that comprise the routing corridor. Routing corridors are intended to be used to route critical nets before signal routing. Zroute global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations. Note: If a routing guide overlaps with a routing corridor and its attributes conflict with the routing corridor, the routing corridor takes precedence. For example, Figure 105 shows a routing corridor named corridor_1, which is made up of six rectangles. This routing corridor is associated with the nets shown in yellow. The figure on the left shows the nets before routing, while the figure on the right shows the nets routed within the routing corridor. Figure 105 Using a Routing Corridor Before routing After routing To define a routing corridor, use the create_routing_corridor command. At a minimum, you must define the boundary of the routing corridor. To create a rectangular routing corridor, use the -boundary option to specify the lower- left and upper-right corners of the rectangle using the following syntax: { { llx lly urx ury } } To create a rectilinear routing corridor, use the -boundary option to specify the coordinates of the polygon using the following syntax: { { x1 y1 } { x2 y2 }... } 491 Routing Constraints Feedback To create a path-based routing corridor, use the -path option to specify the path and the -width option to specify the width in microns. Specify the path using the following syntax: { { x1 y1 } { x2 y2 }... } By default, path-based routing corridors have flush end caps at the start and end of the path. To change the end cap style, use the -start_endcap and -end_endcap options. Valid styles are flush full_width, and half_width By default, the tool creates a routing corridor named CORRIDOR_ objId in the current block that honors the existing minimum and maximum routing layer constraints (for information about specifying routing layer constraints, see Specifying the Routing Resources ). Use the following options to change the default behavior. To specify a name for the routing corridor, use the -name option. To create the routing guide in a different physical cell, use the -cell option. When you use this option, the tool creates the routing guide in the cell's reference block using the coordinate system of the cell's top-level block. To specify the minimum and maximum routing layers for the routing corridor, use the -min_layer_name and -max_layer_name options. Specify the routing layers by using the layer names from the technology file."}
{"instruction": "How do I Overriding the Alignment When Adding Objects", "input": "", "output": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option. However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option. The following example creates a relative placement group named rp1 that is right aligned. It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement. 799 Specifying Options for Relative Placement Groups Feedback Figure 179 Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}
{"instruction": "How do I Specifying the Routing Resources", "input": "", "output": "You can specify the minimum and maximum routing layers both for the block (global layer constraints), for specific nets (net-specific layer constraints), and for unsynthesized clock nets (clock-tree layer constraints). If you specify both global layer constraints and net- specific layer constraints, the net-specific constraints override the global constraints. In addition to constraining the routing layers, you can also specify a preferred routing direction for each layer. The routing layer constraints are used by RC estimation, congestion analysis, and routing. Because these constraints affect RC estimation and congestion analysis as well as routing, you should set these constraints before performing placement on the block. The following topics describe how to specify routing layer constraints, preferred routing direction, and via ladders : Specifying the Global Layer Constraints Specifying Net-Specific Layer Constraints Specifying Clock-Tree Layer Constraints Enabling Level-Based Clock Nondefault Routing Rule Setting the Preferred Routing Direction for Layers"}
{"instruction": "How do I Using ETMs", "input": "", "output": "To minimize the number of iterations and obtain optimal results, you can perform feasibility analysis before running hierarchical synthesis, as shown in Figure 189 The hierarchical synthesis feasibility flow uses the following block-level information generated post compile_fusion Floorplanning information to generate the ETM in step 2 Power intent and test model (CTL) information for top-level synthesis in step 4 825 Performing Hierarchical Synthesis Using ETMs Feedback Figure 189 Hierarchical Synthesis Feasibility Analysis 1. Synthesize the block in the front- end tool compile_fusion RTL Block UPF (front end) Block CTL (front end) UPF SDC, floorplan SDC Design (ndm) Netlist UPF CTL SPEF Design (frame) 2. Create an ETM in the front-end tool extract_model Block_ETM (ndm) 3. Synthesize the top-level design in the front-end tool compile_fusion RTL Top-level UPF SDC, floorplan 826 Performing Hierarchical Synthesis Using ETMs Feedback"}
{"instruction": "How do I Clock-Gate Levels and Stages", "input": "", "output": "The tool uses the following definitions for clock-gate levels and stages in clock-gating commands and options: The clock-gate level is related to the fanin of a clock gate. Level 0 refers to a clock source. Level 1 refers to the first clock gate downstream from the clock source. Level 2 refers to a clock gate driven by a clock gate of level 1. Level N refers to a clock gate driven by a clock gate of level N-1. The clock-gate stage is related to the fanout of a clock gate. Stage 0 refers to a register driven by a clock gate. Stage 1 refers to a clock gate that only drives registers directly or across buffers, inverters, or hierarchical transitions. In addition, stage 1 is assigned to clock gates whose stage cannot be determined, such as unloaded clock gates. Stage N refers to a clock gate that drives at least one clock gate of stage N-1, either directly or across buffers, inverters, or hierarchical transitions. The tool keeps a separate count of levels and stages for all clock gates and for tool- inserted clock gates. Figure 47 shows a simple circuit with two preexisting clock gates (P1 and P2) and three tool-inserted clock gates (T1, T2, and T3). Table 23 lists the levels and stages for each of the clock gates. 290 Introduction to Clock Gating Feedback Figure 47 Design With Multiple Clock Gates Table 23 Clock-Gate Levels and Stages Object Type Level (all clock gates) Level (tool-inserted clock gates) Stage (all clock gates) Stage (tool-inserted clock gates) P1 Preexisting clock gate P2 Preexisting clock gate T1 Tool-inserted clock gate T2 Tool-inserted clock gate T3 Tool-inserted clock gate 291 Clock-Gating Prerequisite Conditions Feedback"}
{"instruction": "How do I Restricting Library Cell Usage", "input": "", "output": "By default, the Fusion Compiler tool can use all of the library cells available in the cell libraries when performing optimization or clock tree synthesis on the block. To restrict the cell usage, use the set_lib_cell_purpose command after the block is in memory. The command has a block scope and is persistent across tool sessions. The specified settings are restored when the block is reopened. To specify how the tool can or cannot use library cells, use the -include and -exclude options with the set_lib_cell_purpose command. Both of these options accept one or more of the following values: all cts hold optimization none The -include option sets the included_purposes attribute on the specified library cells. The -exclude option sets the excluded_purposes attribute on the specified library cells. 77 Setting Up Libraries Feedback Note: If a library cell has a dont_use attribute, it is excluded from all uses, which is the same as if you specified set_lib_cell_purpose -include none for that cell. When the tool performs optimization, which includes setup, hold, and logical DRC fixing, it can use library cells that have an included purpose of optimization hold, or both. When the tool performs clock tree synthesis, it can use library cells that have an included purpose of cts For example, to disallow the use of a set of library cells for all uses, use the following command: fc_shell> set_lib_cell_purpose -include none lib_cells To allow a set of library cells to be used only for clock tree synthesis, use the following commands: fc_shell> set_lib_cell_purpose -include none lib_cells fc_shell> set_lib_cell_purpose -include cts lib_cells To allow a set of library cells to be used for all uses except clock tree synthesis, use the following command: fc_shell> set_lib_cell_purpose -exclude cts lib_cells To use the asterisk wildcard character (*) to query a collection of cells, you must use the get_lib_cells command. However, the set_lib_cell_purpose command excludes synthetic modules by default. Therefore, you should use the set_synlib_dont_use command to exclude synthetic modules. For example, fc_shell> set_lib_cell_purpose \\ -include none [get_lib_cells */*01_*_AB] Warning: The'set_lib_cell_purpose' command cannot be used on synthetic library cell'standard:*OPMOD.DW01_ADD_AB.timing'. (NDMUI-511)"}
{"instruction": "How do I Verifying the Clock Trees", "input": "", "output": "Before you synthesize the clock trees, use the check_clock_tre comandcomandscheck_clock_tre check_clock_trees command to verify that the clock trees are properly defined. For example, to verify that the CLK clock tree is properly defined, use the following command: fc_shell> check_clock_trees -clocks [get_clocks CLK] If you do not specify the -clock option, the tool checks all clocks in the current block. The check_clock_trees command checks for the following issues: Clock (master or generated) with no sinks Loops in the clock network Multiple clocks reach the same register because of overlapping clocks, but multiple- clocks-per-register propagation is not enabled Ignored clock tree exceptions Stop pin or float pin defined on an output pin Buffers with multiple timing arcs used in clock tree references Situations that cause an empty buffer list 354 Verifying the Clock Trees Feedback Generated clock without a valid master clock source A generated clock does not have a valid master-clock source in the following situations: The master clock specified in create_generated_clock does not exist The master clock specified in create_generated_clock does not drive the source pin of the generated clock The source pin of the generated clock is driven by multiple clocks, and some of the master clocks are not specified with create_generated_clock For example, in Figure 78, the GEN_REG/Q pin is driven by both CLKA and CLKB. If only CLKA is specified as a master clock in a create_generated_clock command, GEN_CLK does not have a valid master clock source. Figure 78 Generated Clock With Invalid Master Clock Source REG1 REG2 GEN_REG CLKA CLKB GEN_CLK For multicorner-multimode designs, the check_clock_trees command checks all active scenarios for the following issues: Conflicting per-clock exception settings Conflicting balancing settings Before you implement the clock trees, you should manually fix the reported issues. Each message generated by the check_clock_trees command has a detailed man page that describes how to fix the identified issue. You can improve the clock tree and timing QoR by fixing all the issues identified by the check_clock_trees command. 355 Setting Clock Tree Design Rule Constraints Feedback"}
{"instruction": "How do I Using Application Options", "input": "", "output": "The Fusion Compiler tool uses application options to control the tool behavior. Application options use the following naming convention: category [. subcategory ]. option_name where category is the name of the engine affected by the application option. Some application option categories have subcategories to further refine the area affected by the application option. Application options have either a global scope or a block scope. Block-scoped application options apply only to the block on which they are set. They are saved in the design library and are persistent across tool sessions. Global-scoped application options apply to all blocks, but only within the current session. They are not saved in the design library; you must specify them in each fc_shell session. You might want to consider adding the global settings to your.synopsys_fc.setup file. To get a list of available application options, use the get_app_options command. By default, this command lists all application options. To restrict the reported application options, provide a pattern string as an argument to the command. For example, to list all available application options, use the following command: fc_shell> get_app_options To list all available timer application options, use the following command: fc_shell> get_app_options timer.* To generate a report of application options, use the report_app_options command. For detailed information about application options, see Application Options in the Fusion Compiler Data Model User Guide See Also Using Setup Files"}
{"instruction": "How do I Removing Global Layer Constraints", "input": "", "output": "To remove the global layer constraints, use the remove_ignored_layers command. You must specify one or more of the following options: -min_routing_layer This option removes the minimum routing layer setting. When you remove the minimum routing layer setting, it also removes the ignored layers for RC estimation and congestion analysis that are below the minimum routing layer. -max_routing_layer This option removes the maximum routing layer setting. When you remove the maximum routing layer setting, it also removes the ignored layers for RC estimation and congestion analysis that are above the maximum routing layer. -all This option removes the ignored layers for RC estimation and congestion analysis that are between the minimum and maximum routing layers. -rc_congestion_ignored_layers layer_list This option removes the specified ignored layers for RC estimation and congestion analysis. The specified layers must be between the minimum and maximum routing layers."}
{"instruction": "How do I Reporting the Boundary Cell Insertion Requirements", "input": "", "output": "To report the boundary cell insertion requirements specified by the set_boundary_cell_rules command, use the report_boundary_cell_rules command. This command reports only the user-specified settings; it does not report any default settings. 598 Performing Boundary Cell Insertion Feedback"}
{"instruction": "How do I Generating Via Ladder Rules for Electromigration Via Ladders", "input": "", "output": "Instead of explicitly defining via ladder rules for electromigration via ladders, you can use the generate_via_ladder_template command to generate via ladder rules and constraints based on a configuration file. The configuration file is an XML file that provides information about the via ladder rules, as well as the association between the via ladder rules and specific pins. You must specify the name of the configuration file by using the -config_file option. The command generates two script files: A script file that defines the via ladder rules, which is called the template script file This script file contains a create_via_rule command for each template defined in the configuration file, as well as set_attribute commands to set the appropriate via rule attributes. By default, the file is named auto_gen_via_ladder_template.tcl. To specify a different file name, use the -template_file option. A script file that defines the via ladder constraints, which is called the association script file This script file contains set_via_ladder_candidate commands for the pins specified in the configuration file, as well as set_attribute commands to set the is_em_via_ladder_required attribute for the pins to true By default, the file is named auto_gen_via_ladder_association.tcl. To specify a different file name, use the -association_file option. 449 Inserting Via Ladders Feedback The configuration file has the following syntax: <EmRule> <! template definition > <Template name=\" rule_name \"> <Layer name=\" layer_name \" row_number=\" cuts_per_row [max_stagger_tracks=\" count \"] [upper_cut_x_min_spacing=\" x_spacing \"] [upper_cut_y_min_spacing=\" y_spacing \"] />... more layers </Template> \u2026 more templates <! Pin to template association > <Pin name=\" pin_name \"> <Template name=\" rule_name \"/> </Pin>... more associations </EmRule> Each Template section specifies the template for a via ladder rule. You can specify one or more Template sections. Within a template section, you specify the via ladder structure by specifying the number of cuts per row for each metal layer involved in the via ladder. The command uses the information in the configuration file and associated information from the technology file to generate the via ladder rules. The command derives the following information from the technology file The cut layers that connect the specified metal layers The cut names The minimum required length for each metal layer Note: You must open the block before running the generate_via_ladder_template command to ensure that the command has access to the technology data for the block. Each Pin section specifies the template associated with a pin, where the pin name can include the asterisk wildcard character (*). You can specify one or more Pin sections. The template specified in the Pin section's Template attribute must be one of the templates specified in the Template sections. For example, assume you have a configuration file named vl_config that has the following contents: <EmRule> <Template name=\"template_1_3231\"> <Layer name=\"M1\" row_number=\"3\"/> <Layer name=\"M2\" row_number=\"2\"/> <Layer name=\"M3\" row_number=\"3\"/> 450 Inserting Via Ladders Feedback <Layer name=\"M4\" row_number=\"1\"/> </Template> <Pin name=\"*/BCELLD5A11*/Z\"> <Template name=\"template_1_3231\"/> </Pin> </EmRule> To generate the script files to define the via ladder rules and constraints, use the following command: fc_shell> generate_via_ladder_template -config_file vl_config Example 17 shows the template script file generated by this command. Example 18 shows the association script file generated by this command. Example 17 Template Script File create_via_rule -name template_1_3231 \\ -cut_layer_names {VIA1 VIA2 VIA3} -cut_names {V1S V2S V3S} \\ -cut_rows {2 3 1} -cuts_per_row {3 2 3} set viaRule [get_via_rules template_1_3231] set_attribute $viaRule upper_metal_min_length_table {0.3 0.2 0.4} set_attribute $viaRule for_electro_migration true Example 18 Association Script File foreach_in_collection pin [get_lib_pins -quiet */BCELLD5A11*/Z] { set_attribute -quiet $pin is_em_via_ladder_required true set_via_ladder_candidate $pin -ladder_name \"template_1_3231\" See Also Defining Via Ladder Rules Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}
{"instruction": "How do I Building the Local Clock Subtree Structures", "input": "", "output": "In a structural multisource clock tree, the local subtrees are directly driven by the clock mesh. You can synthesize these local subtrees by using the synthesize_multisource_clock_subtrees command. Before you synthesize the local subtrees, you must 1. Build the global clock distribution structure. 2. Model the clock mesh net with a realistic annotated delay and transition values using the set_annotated_delay and set_annotated_transition commands. 3. Remove dont_touch size_only fixed, and locked attributes setting on the clock cells that are not required. These settings prevent the synthesize_multisource_clock_subtrees command from merging or splitting clock cells, if necessary. 4. Specify settings for local subtree synthesis by using the set_multisource_clock_subtree_options command. You must specify The clock for synthesizing the subtrees by using the -clock option. The drivers of the subtrees to be synthesized by using the -driver_objects option. The clock specified with the -clock option should pass through each drivers specified with the -driver_objects option. Optionally you can Prevent the tool from merging specific clock tree cells by using the -dont_merge_cells option. Balance the levels of the local subtree by using the -balance_levels true option and specify a target number of levels, which applies to all sinks of the local subtree, by using the -target_level option. Optionally, you can apply a different target number of levels to specific sink pins and clock balance points by using the set_multisource_clock_subtree_constraints command with the -pins and -target_level options. Specify a maximum total wire delay from any subtree driver to any of its sinks by using the -max_total_wire_delay option and the corner it applies to by using the -corner option. 429 Implementing Multisource Clock Trees Feedback Enable the reordering of clock-gating cells by using the -enable_icg_reordering true option. When you enable this feature, the tool swaps the position of a clock-gating cell with the buffer that is driving the clock-gating cell. Then, the buffer is gated by the clock- gating cell, thereby reducing the dynamic power consumption. To perform reordering, you must Enable scenarios used for structural multisource clock tree synthesis for dynamic power optimization Annotate switching activity for the enable pins of the clock-gating cells You can prevent specific clock-gating cells from being reordered by using the set_multisource_clock_subtree_constraints command with the -cells and -ignore_for_icg_reordering options. To report the settings you specified, use the report_multisource_clock_subtree_options command. To remove the settings you specified, use the remove_multisource_clock_subtree_options command. 5. (Optional) Enable multicorner optimization by setting the cts.multisource.enable_multi_corner_support application option to true. The default is false By default, the tool uses the worst corner associated with the mode in which the subtree options are defined. When you enable this feature, the tool considers all corners associated with the mode in which the subtree options are defined. 6. (Optional) Ignore the maximum capacitance, maximum fanout, or both constraints of the clock drivers by using the cts.multisource.ignore_drc_on_subtree_driver application option. When you synthesize multisource clock subtrees, by default, the tool considers the maximum transition, capacitance, and fanout constraints of the clock drivers you specify. However, the clock drivers typically have relaxed or no maximum capacitance or maximum fanout constraint, which can affect the multisource clock tree QoR. The following example ignores both the maximum capacitance and maximum fanout constraints of the clock drivers: fc_shell> set_app_options \\ -name cts.multisource.ignore_drc_on_subtree_driver \\ -value \"max_fanout max_capacitance\" 7. (Optional) Enable fishbone routing for the subtree clock nets by using the cts.multisource.subtree_routing_mode application option. 430 Implementing Multisource Clock Trees Feedback fc_shell> set_app_options \\ -name cts.multisource.subtree_routing_mode -value fishbone 8. (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during local subtree synthesis by using the following application options: cts.multisource.subtree_merge_cell_name_prefix cts.multisource.subtree_merge_cell_name_suffix cts.multisource.subtree_split_cell_name_prefix cts.multisource.subtree_split_cell_name_suffix cts.multisource.subtree_split_net_name_prefix cts.multisource.subtree_split_net_name_suffix When you run the synthesize_multisource_clock_subtrees command the tool performs the following steps: 1. Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks. 2. Optimizes the subtree by splitting, sizing, and relocating the clock cells, and snaps the first level of clock cells to the clock straps. 3. Routes the clock nets. By default, it global routes the nets. However, if you enable fishbone routing by using the cts.multisource.subtree_routing_mode application option, the tool creates a mix of detail routed fishbone trunks and fingers, and global comb routes to connect the net loads to the fishbone fingers, as shown in Figure 97 You can control the fishbone routing by using the following application options: cts.routing.fishbone_max_tie_distance cts.routing.fishbone_max_sub_tie_distance cts.routing.fishbone_bias_threshold cts.routing.fishbone_bias_window cts.routing.fishbone_horizontal_bias_spacing cts.routing.fishbone_vertical_bias_spacing 4. Refines the clock trees by sizing and relocating cells based on the routing. 431 Analyzing the Clock Tree Results Feedback Figure 97 Detail Fishbone Routes and Global Comb Routes Global comb route Fishbone trunk Fishbone finger You can run specific steps of the synthesize_multisource_clock_subtrees command by using the -from and -to options and specifying merge optimize route_clock, or refine Structural subtrees that you build by using the synthesize_multisource_clock_subtrees command are not changed or removed when you subsequently run any clock tree synthesis command."}
{"instruction": "How do I Grouping Variant Cell", "input": "", "output": "In the same variant cell group, the library cell variants differ from the master-variant only in mask color (or small geometry), while the timing data is same for these variants. The variant cell feature supports the following track_pattern mode siteId_based mode track_pattern mode To specify the first metal layer for track alignment checking in track_pattern mode, use the set_app_options -name eco.placement.first_track_alignment_layer -value name command. Figure 221 shows the cell group with two variants. 993 Swapping Variant Cell Feedback Figure 221 Cell Group With Two Variants Based on the first track offset of library cells and the pitch value, you can define and derive the variant library cell types, which start from 0. Figure 222 shows variant type id definition. Figure 222 Variant Type id Definition 994 Swapping Variant Cell Feedback You can detect the variant type id for target cell current location. You can also check if the current reference is legal or illegal. If it is not legal, select the legal reference from cell group and swap it. Figure 223 shows the check and swap with legal reference for target cell. Figure 223 Check and Swap With Legal Reference for Target Cell. siteId_based mode The variant mapping and flipped mapping information are defined in the cell group. Following is an example of the report_cell_groups command. Figure 224 shows the cell group definition for mapping id and flipped mapping id. 995 Swapping Variant Cell Feedback Figure 224 Cell Group Definition for Mapping id and Flipped Mapping id There are two sub flows for siteId_based mode: 2-Variants and N-Variant. Figure 225 shows the 2-Variants and N-Variants sub flows in siteId_based mode 996 Swapping Variant Cell Feedback Figure 225 2-Variants and N-Variants Sub Flows in siteId_based Mode Each variant reference has both legal mapping id and flipped mapping id. Figure 226 shows the variant mapping and flipped mapping id. 997 Swapping Variant Cell Feedback Figure 226 Variant Mapping and Flipped Mapping id For variant siteId, you can get the cycle and offset from site rows first, then use the cell placed location to do the calculation. Figure 227 shows the calculation for variant siteId 998 Swapping Variant Cell Feedback Figure 227 Calculation for Variant siteId"}
{"instruction": "How do I Clock-Gate Collapsing", "input": "", "output": "The default of the compile.clockgate.max_number_of_levels application option is 0, which allows an infinite number of levels. You can set the compile.clockgate.max_number_of_levels application option without enabling clock-gate level expansion. In this case, the tool collapses clock-gate levels if the specified limit is less than the number of clock-gate levels that exist after the initial_map stage. The tool collapses clock-gate levels as follows: The tool first tries to collapse clock gates at levels higher than the specified maximum level, starting from the clock gates at the highest level (closest to the registers). If a specific clock gate cannot be collapsed, the tool tries to collapse upstream clock gates until it reaches the lowest level (closest to the source). The collapse can occur across hierarchies. The tool tries to preserve the parent (upstream) clock gate. The tool removes all remaining clock gates that do not meet the maximum number of levels."}
{"instruction": "How do I Enabling Variant-Aware Legalization", "input": "", "output": "To enable variant-aware legalization, set the place.legalize.enable_variant_aware application option to true When variant-aware legalization is enabled, the tool tries to fix legalization DRC violations by swapping the violating cell with a variant, rather than moving it. If the cell has no variants, it is moved to a legal location. For pin-track and pin-color alignment during variant-aware legalization, set the following application options to true place.legalize.enable_prerouted_net_check place.legalize.enable_pin_color_alignment_check In addition, you must specify the layers to be aligned by using the place.legalize.pin_color_alignment_layers application option."}
{"instruction": "How do I Setting Clock-Gating Options", "input": "", "output": "Use the set_clock_gating_options command to define the netlist structure of the inserted clock-gating cells. The following options are available: Option Description -minimum_bitwidth Specifies the minimum number of accumulated bits that can be gated. The default is 3. -max_fanout Specifies the maximum number of cells gated by the same clock-gating cell. The default is infinite. -objects Specifies the list of objects to which the clock-gating options are applied. The design objects can be hierarchical instances, power domains, and designs."}
{"instruction": "How do I Optimization", "input": "", "output": "To improve correlation with the postroute stage of the design flow, the tool can perform global routing, perform extraction based on the global routes, and use this parasitic information when performing optimization. If the tool detects that the technology used by the design is an advanced technology node that is less than 16 nm, the tool enables this feature by default. To enable it for any technology, set the opt.common.enable_rde application option to true When enabled, the tool performs route-driven parasitic estimation during the final_opt stage of the compile_fusion and clock_opt commands. The parasitic information is 180 Specifying Settings for Preroute Optimization Feedback stored in the design library and used during subsequent optimization steps. If you enable this feature, you should enable it for all subsequent preroute optimization steps in the design flow. During route-driven estimation, the tool honors the capacitance and resistance scaling factors specified with the -early_cap_scale -late_cap_scale -early_res_scale and -late_res_scale options of the set_extraction_options command. When route-driven estimation is enabled, the tool ignores the setting of the opt.common.use_route_aware_estimation application option, which enables global- route-layer-based (GRLB) RC estimation."}
{"instruction": "How do I Making ECO Changes Using Netlist Editing Commands", "input": "", "output": "If the ECO changes are minimal, you can update the design by using netlist editing commands given. If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true, before you run the netlist editing commands. For a list of netlist editing commands, see the Common Design Objects topic in the Fusion Compiler Data Model User Guide"}
{"instruction": "How do I Analyzing Relative Placement Groups", "input": "", "output": "The following sections explain methods for analyzing your relative placement groups: Checking Relative Placement Groups Before Placement Analyzing the Placeability of a Relative Placement Group Reporting Relative Placement Constraint Violations Querying Relative Placement Groups Analyzing Relative Placement in the GUI"}
{"instruction": "How do I Analyzing and Fixing Signal Electromigration Violations", "input": "", "output": "Signal electromigration problems result from an increase in current density caused by the use of smaller line widths and higher operational speeds in IC designs. Electromigration can lead to shorts or opens due to metal ion displacement caused by the flow of electrons. The more frequently a net switches, the more susceptible it is to electromigration. To analyze and fix signal electromigration violations in a detail routed block, 1. Apply the signal electromigration constraints by using the read_signal_em_constraints command. For more information, see Loading the Signal Electromigration Constraints 2. Apply switching activity by either reading in a SAIF file with the read_saif command or annotating the switching activity information on the nets with the set_switching_activity command. For more information, see Annotating the Switching Activity 3. Report the signal electromigration information by using the report_signal_em command. For more information, see Analyzing Signal Electromigration 4. Fix any signal electromigration violations by using the fix_signal_em command. For more information, see Fixing Signal Electromigration Violations The following example script shows the signal electromigration flow. # Open the block and apply the signal electromigration constraints open_block block1_routed read_signal_em_constraints em.itf # Load switching information read_saif block1.saif # Perform signal electromigration analysis report_signal_em -violated -verbose > block1.signal_em.rpt # Fix signal electromigration violations fix_signal_em 554 Analyzing and Fixing Signal Electromigration Violations Feedback"}
{"instruction": "How do I Copying Clock Tree Exceptions Across Modes", "input": "", "output": "You can specify that the tool copies clock tree exceptions from one mode to one or more equivalent modes by using the set_clock_tree_options command with the -copy_exceptions_across_modes -from_mode, and -to_mode options. The following example specifies that during clock tree synthesis the clock tree exceptions in the mode name M1 should be copied to the modes name M2 and M3: fc_shell> set_clock_tree_options -copy_exceptions_across_modes \\ -from_mode M1 -to_mode {M2 M3} 350 Defining the Clock Trees Feedback"}
{"instruction": "How do I Updating Activity for Improved Power Optimization", "input": "", "output": "The PrimePower In-Design flow in the Fusion Compiler tool uses input waveform information from the RTL FSDB file and performs time-based analysis to update the activity for enhanced power estimation accuracy. Figure 26 shows the PrimePower in- design flow in the Fusion Compiler tool, indicating points in the flow where you can run the PrimePower tool. For the best correlation with standalone PrimePower time-based analysis results, run the PrimePower tool after the route_opt command. 193 Setting Up for Power-Related Features Feedback Figure 26 The PrimePower In-Design Flow Use the set_indesign_primepower_options command to set PrimePower analysis options for the In-Design flow. You must specify the RTL activity file with the -fsdb option and the path to the PrimePower executable with the -pwr_shell option. Other options allow you to specify details about the FSDB file, settings for distributed or concurrent processing, settings for scenarios and libraries, and output files. Use the update_indesign_activity command to perform the analysis, which includes the following tasks: Invokes the PrimePower tool and reads the design data which includes the netlist, libraries, PVT settings, constraints, parasitics, essential name mapping data, UPF, and so on. Library details come from the design database stored in the Fusion Compiler tool memory. Reads the RTL FSDB file into the PrimePower tool and performs time-based analysis to generate a gate-level SAIF. Reads the gate-level SAIF back into the Fusion Compiler tool. Set the power scenario as the current scenario before starting analysis with the update_indesign_activity command. Activity is refreshed for the current scenario. If you specify multiple scenarios using the -scenarios option of the set_indesign_primepower_options command, the refreshed gate-level SAIF from the PrimePower tool is read back into the Fusion Compiler tool for all of the specified scenarios. 194 Setting Up for Power-Related Features Feedback The PrimePower In-Design UI allows you to pass input waveforms using the native ZeBu database (ZTDB). The -ztdb option of the set_indesign_primepower_options command sets up PrimePower In-Design to create a script using the update_indesign_activity command. This script uses the PrimePower read_ztdb command to perform time-based analysis and issues a gate-level SAIF file that is automatically back-annotated into the Fusion Compiler tool. Specifying Distributed Analysis For faster runtime, use distributed analysis, which is disabled by default in the PrimePower tool. To enable distributed analysis in the PrimePower tool, specify the following options with the set_indesign_primepower_options command: -num_processes : Use this option to specify the number of hosts to launch. The value must be greater than 1. -submit_command or -host_names : Use either of these options to specify the configuration of host machines. -max_cores : Use this option to specify the maximum number of cores. The default is 4. The tool prints the following message if valid options are specified: Information: PrimePower is being called in distributed mode"}
{"instruction": "How do I Adding Buffers on Routed Nets", "input": "", "output": "To add buffers or pairs of inverters on a fully routed net, use the add_buffer_on_route command as described in the following topics: Specifying the Net Names, Buffers Types, and Their Locations Controlling How Buffers are Added Specifying Settings for Multivoltage Designs Specifying Settings for the Freeze Silicon ECO Flow"}
{"instruction": "How do I Creating and Specifying Rail Scenarios for Rail Analysis", "input": "", "output": "You can create multiple rail scenarios and associate them with a design scenario in the current design. The created rail scenarios are saved in the design library. To run rail analysis on multiple rail scenarios: 1. Specify the following application options to enable multi-rail-scenario rail analysis: fc_shell> set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true 897 Running Rail Analysis with Multiple Rail Scenarios Feedback 2. Run the set_scenario_status -ir_drop command to enable rail analysis for the specified design scenario. fc_shell> set_scenario_status func_cbest -ir_drop true 3. Create a rail scenario and associate it with an existing design scenario. Specify rail attributes for the created rail scenario with the set_rail_scenario command. You can create multiple rail scenarios for different purposes and associate them with an existing design scenario. fc_shell> create_rail_scenario -name T_low -scenario func_cbest fc_shell> set_rail_scenario -name T_low -voltage_drop dynamic -extra_gsr_option_file extra.gsr \\ -nets {VDD VSS} fc_shell> create_rail_scenario -name T_high -scenario func_cbest fc_shell> set_rail_scenario -name T_high -voltage_drop dynamic -extra_gsr_option_file extra2.gsr \\ -nets {VDD VSS} 4. Specify the multicore processing setting with the set_host_options command. For example, to run rail analysis on a local host, use the following command: fc_shell> set_host_options -submit_command {local} To run analysis on a grid system, use the following command: fc_shell> set_host_options -submit_protocol sge \\ -submit_command {qsub -V -b y -cwd -P bnormal -l mfree=16G} 5. Run rail analysis with the analyze_rail command. fc_shell> analyze_rail -rail_scenario {T_high T_low} \\ -submit_to_other_machines Note: To use the multi-rail-scenario rail analysis capability for IR-driven placement or IR-driven concurrent clock and data optimization, you must set the following application option before the clock_opt -from final_opto or route_opt command: fc_shell> set_app_options \\ -name opt.common.power_integrity -value true For more information about power integrity analysis, see the Enabling the Power Integrity Features section. 898 Running Rail Analysis with Multiple Rail Scenarios Feedback Examples The following example runs rail analysis on multiple rail scenarios. # Specify options for multi-rail-scenario rail analysis set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y -cwd -j y \\ -P bnormal -l mfree=16G} # Custom RedHawk-SC Fusion python script to specify user-defined # toggle rate for scenario T_custom create_rail_scenario -name T_custom -scenario func_cbest set_rail_scenario -name T_custom -custom_script_file custom_sc.py # Default RedHawk-SC Fusion toggle rate for scenario T_def create_rail_scenario -name T_def -scenario func_cbest set_rail_scenario -name T_def -voltage_drop dynamic -nets {VDD VSS} # Run RedHawk-SC Fusion rail analysis on the specified rail scenario analyze_rail -rail_scenario {T_custom T_def} -submit_to_other_machines # (Optional) Open and examine the generated rail results open_rail_result {T_custom T_def} The following example runs multi-rail-scenario rail analysis in the power integrity flow. ## Specify RedHawk/RedHawk-SC based options set_app_options -name rail.enable_redhawk -value true set_app_options -name rail.enable_redhawk_sc -value false set_app_options -name rail.redhawk_path -value /test/bin set_app_options -name rail.tech_file -value design_data/tech/rh.tech set_app_options -name rail.lib_files -value { inputs/test/CCSP_test.lib set_host_options -submit_protocol sge -submit_command {qsub -V \\ -notify -b y -cwd -j y -P bnormal -l mfree=16G} ## Specify options for running optimization on multiple rail scenarios set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true ## Enable IR drop flag for a given scenario set_scenario_status [current_scenario] -ir_drop true ## Create a rail scenario and specify associated options create_rail_scenario -name T_low -scenario func_cbest set_rail_scenario -name T_low -voltage_drop dynamic \\ 899 Performing Voltage Drop Analysis Feedback -extra_gsr_option_file extra.gsr -nets {VDD VSS} create_rail_scenario -name T_high -scenario func_cbest set_rail_scenario -name T_high -voltage_drop dynamic \\ -extra_gsr_option_file extra2.gsr -nets {VDD VSS} ## Enable power integrity flow set_app_options -name opt.common.power_integrity -value true"}
