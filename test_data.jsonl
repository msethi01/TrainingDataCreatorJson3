{"instruction": "How do I Command", "input": "", "output": "After placing the ECO cells, the place_eco_cells command legalizes each ECO cell to the closest unoccupied site.\n The existing cells are untouched to minimize the impact to their placement.\n You can control the legalization of the ECO cells by using one of the following methods: To not legalize the cells after ECO placement, use the -no_legalize option.\n To perform legalization only, use the -legalize_only option.\n To specify the mode in which to legalize, use the -legalize_mode option with one of the following settings: free_site_only When you specify this setting, the default, the tool legalizes the ECO cells on free sites without moving preexisting cells.\n An ECO cells can have a large displacement, if a free site is unavailable nearby.\n allow_move_other_cells When you specify this setting, the tool legalizes the ECO cells to the nearest legal location by moving preexisting cells.\n minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells the can be legalized to a free site nearby without moving preexisting cells.\n For the ECO cells that do not have a free site nearby, the tool legalizes them by moving preexisting cells.\n To specify a displacement threshold for legalization, use the -displacement_threshold option.\n When you use the -displacement_threshold option, you can also use the -max_displacement_threshold option to specify a second displacement threshold that is larger than the value specified with the -displacement_threshold option.\n How the tool uses these displacement thresholds depends on the setting you use for the -legalize_mode option as follows: free_site_only When you specify this setting, the tool legalizes the ECO cells that have available free sites within the specified displacement threshold.\n 975 Placing ECO Cells Feedback If the displacement of an ECO cell exceeds this threshold, the tool does not legalize the cell.\n It creates a collection named epl_legalizer_rejected_cells that consists of such ECO cells that are not legalized.\n You can subsequently legalize the ECO cells in the epl_legalizer_rejected_cells collection by using the following command: fc_shell> place_eco_cells -legalize_mode allow_move_other_cells \\ -legalize_only -cells $epl_legalizer_rejected_cells This command moves existing cells to find legal locations for the ECO cells in the collection named epl_legalizer_rejected_cells.\n If you also specify the -max_displacement_threshold option with -displacement_threshold option, the tool also creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n The collection epl_max_displacement_cells is a subset of the collection epl_legalizer_rejected_cells and its cells are also not legalized.\n You can use the -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n allow_move_other_cells When you specify this setting, you cannot specify the -displacement_threshold and -max_displacement_threshold options.\n minimum_physical_impact When you specify this setting, the tool first legalizes the ECO cells that have available free sites within the specified displacement threshold.\n If the displacement of an ECO cell exceeds this threshold, the tool legalizes them by moving preexisting cells.\n If you also specify the -max_displacement_threshold option, the tool does not legalize the cells that exceed this maximum displacement threshold specified with this option and the tool creates a collection named epl_max_displacement_cells that consists of ECO cells with a displacement larger than that specified by this option.\n You can use the -max_displacement_threshold option to identify ECO cells with a very large displacement, for which you want to reject the ECO changes.\n To specify the types of filler cells that can be removed during legalization, use the -remove_filler_references option.\n 976 Placing and Mapping ECO Cells to Spare Cells Feedback When you use this option, the filler cells are removed if they do not have a fixed placement and they overlap with ECO cells.\n By default, the tool does not remove any filler cells when legalizing ECO cells.\n To enable Advanced Legalizer and remove the filler cells that have violations, set the place.legalize.enable_advanced_legalizer application option to true When you specify this setting, the filler cells that have violations are removed after legalizing ECO cells.\n Using the -remove_filler_references option with this application option set to true results in the legalizer engine removing only those fillers that are specified by this option.\n The -min_filler_distance option is ignored when you use the place.legalize.enable_advanced_legalizer application option."}
{"instruction": "How do I Updating Via Ladders", "input": "", "output": "You can use the following methods to update existing via ladders in a design: Use the refresh_via_ladders command Automatic updates during the route_group route_auto, and route_eco commands is enabled by default by setting the route.auto_via_ladder.update_during_route application option to true Both of these methods perform the following tasks: Verifies the existing via ladders based on the current via ladder constraints Removes invalid via ladders Inserts via ladders where needed based on the settings of the route.auto_via_ladder application options By default, the tool Updates all pins with via ladder constraints, whether on signal nets or clock nets By default, during the route_group command, the via ladder updates is restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true Does not require the via inserted above the pin layer to be contained within the pin shape To prevent changes to the pin shape boundary, you can require that the via inserted about the pin layer be fully contained within the pin shape boundary, which includes 461 Inserting Via Ladders Feedback the pin shape and its extensions.\n To specify this requirement, set the following application options: route.auto_via_ladder.connect_within_metal This application option controls via enclosures for all types of via ladders: performance, electromigration, and pattern-must-join.\n To prevent changes to the pin shape boundary, set this application option to true route.auto_via_ladder.connect_within_metal_for_via_ladder This application option controls the via enclosures only for performance and electromigration via ladders.\n By default, the tool uses the global setting specified by the route.auto_via_ladder.connect_within_metal application option.\n To explicitly specify the behavior for performance and electromigration via ladders, set this application option to true or false Uses staggering only when it is defined for the via ladder rule Via ladder staggering extends the row metal of a via ladder level in the preferred direction of the upper layer for the level to avoid obstructions above or near the pin, which can increase the success rate of via ladder insertion.\n In many cases, the via ladder rule specifies the maximum number of stagger tracks.\n To allow staggering if the maximum number of stagger tracks is not defined for the via ladder rule, the route.auto_via_ladder.auto_stagger application option is set to true by default.\n Reports the via ladder insertion status for each target pin To limit the number of via ladders reported for each category to 40, set the route.auto_via_ladder.report_all_via_ladders application option to false See Also Inserting Via Ladders Verifying Via Ladders Querying Via Ladders Removing Via Ladders 462 Inserting Via Ladders Feedback"}
{"instruction": "How do I Creating Skew Groups", "input": "", "output": "During clock tree synthesis, you might want to balance a group of sinks only among each other, and not the rest of the sinks.\n To do so, define a skew group by using the create_clock_skew_group command.\n When you use this command, specify the sinks you want to group, by using the -objects option.\n Optionally, you can specify the following: A clock or generated clock for which to create the skew group by using the -clock option.\n A mode for which to create the skew group by using the -mode option.\n 364 Specifying the Clock Tree Synthesis Settings Feedback By default, the tool creates the skew group for the current mode.\n A name for the skew group by using the -name option.\n The following example creates a skew group named sg1 consisting of sinks reg1/CP, reg2/ CP, and reg3/CP: fc_shell> create_clock_skew_group -name sg1 \\ -objects {reg1/CP reg2/CP reg3/CP} To report skew groups, use the report_clock_skew_groups command.\n To remove skew groups, use the remove_clock_skew_groups command."}
{"instruction": "How do I Synthesizing a Subblock", "input": "", "output": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1.\n Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2.\n Apply any block-specific constraints and settings required for synthesizing the block.\n 822 Performing Hierarchical Synthesis Using Abstracts Feedback 3.\n Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command.\n 4.\n Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5.\n Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}
{"instruction": "How do I Running RedHawk Fusion Commands in the Background", "input": "", "output": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished.\n You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished.\n To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command.\n When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database.\n By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed.\n However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results.\n 874 Setting Up the Executables Feedback Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not.\n When opening rail results, the tool does not detect if the result is generated with or without the -bg option.\n The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa.\n Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory.\n To check if the background analyze_rail process is active, use the report_background_jobs command."}
{"instruction": "How do I Signoff ECO Flow", "input": "", "output": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool.\n You can also perform power or area recovery in the PrimeTime tool.\n 950 Signoff ECO Flow Feedback If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in Figure 217 Figure 217 Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations?\n PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1.\n Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands.\n 2.\n Update the placement by using the place_eco_cells command as shown in the following example: place_eco_cells -legalize_mode minimum_physical_impact \\ -eco_changed_cells -legalize_only -displacement_threshold 10 For more information about the place_eco_cells command, see Placing ECO Cells 3.\n Add filler cells to the empty spaces in the site array, as described in Inserting Filler Cells 951 Incremental Signoff ECO Flow Feedback To reduce runtime, use the -post_eco option when you Insert metal filler cells with the create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4.\n Update the routing by using the route_eco command, as described in Performing ECO Routing, or by manually rerouting the affected nets."}
{"instruction": "How do I Performing ECO Routing", "input": "", "output": "Whenever you modify the nets in your block, you need to run engineering change order (ECO) routing to reconnect the routing.\n To run ECO routing, use the route_eco command.\n The route_eco command sequentially performs global routing, track assignment, and detail routing to reconnect the routing.\n By default, the route_eco command Considers timing and crosstalk during routing, which means that the tool performs extraction and updates the timing before performing the routing.\n The extraction and timing update can be time consuming and might not be necessary for your block.\n To prevent the extraction and timing update, use the following commands to disable the timing-driven and crosstalk-driven modes: fc_shell> set_app_options \\ -name route.global.crosstalk_driven -value false fc_shell> set_app_options \\ -name route.global.timing_driven -value false fc_shell> set_app_options \\ -name route.track.crosstalk_driven -value false fc_shell> set_app_options \\ -name route.track.timing_driven -value false fc_shell> set_app_options \\ -name route.detail.timing_driven -value false 558 Performing ECO Routing Feedback Works on all open nets in the block To perform ECO routing only on specific nets, use the -nets option to specify the nets.\n Ignores existing global routes To honor the existing global routes and perform incremental global routing, set the -reuse_existing_global_route option to true Relieves congestion by reusing dangling wires instead of rerouting detail routed wires To disable the reuse of dangling wires, set the -utilize_dangling_wires option to false Performs a maximum of 40 detail routing iterations To change the maximum number of detail routing iterations, use the -max_detail_route_iterations option.\n Fixes hard DRC violations on the entire block by rerouting any wires, whether modified or not To fix DRC violations only in the neighborhood of the open nets, set the -open_net_driven option to true Note: When you use the -nets option to perform ECO routing on specific nets, Zroute fixes DRC violations only within the bounding box of the specified nets.\n In this case, Zroute ignores the setting of the -open_net_driven option.\n To change the scope of rerouting performed by the ECO router, use the -reroute option.\n To limit rerouting to modified wires, set this option to modified_nets_only To first attempt to fix DRC violations by rerouting modified nets and then reroute other nets if necessary, set this option to modified_nets_first_then_others A common use for this option is to route the clock nets affected by an ECO in a fully routed block.\n To enable the fixing of soft DRC violations, such as bridge rule violations, after the final detail routing iteration, set the route.common.post_eco_route_fix_soft_violations application option to true Zroute generates a DRC violations summary at the end of each detail routing iteration.\n Before reporting the final DRC violations, Zroute merges redundant violations.\n For more 559 Routing Nets in the GUI Feedback information about the DRC violations reported by Zroute, see Performing Design Rule Checking Using Zroute Zroute also reports the nets changed during ECO routing.\n By default, it reports the first 100 changed nets.\n You can use the -max_reported_nets option to set a different limit on the reported nets.\n To report all changed nets, set the -max_reported_nets option to -1.\n See Also Routing Nets in the GUI"}
{"instruction": "How do I Naming Convention for Tool-Inserted Clock Gates", "input": "", "output": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs.\n The naming convention is as follows: prefix_base-name[_index] The prefix is clock_gate by default.\n To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option.\n The base name is the most frequent instance name among the registers gated by the clock gate.\n The base name does not include bus bit indexes.\n If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0.\n For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg.\n If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0.\n However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register.\n 288 Introduction to Clock Gating Feedback"}
{"instruction": "How do I Troubleshooting", "input": "", "output": "Table 73 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters.\n Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error: The repeater group (%d) is invalid.\n Check if the input group id exists by running the report_repeater_g roups command.\n 999 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning: Failed to connect to route for %d object: {%s }.\n Check the pin shape of object and route shapes.\n The object as driver or load can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-224 Error: The option -repeater_groups cannot be used when the app option eco.placement.eco_enable_ pipeline_register_placer is false.\n Check the pin shape of object and route shapes.\n The object as driver or load can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-227 Warning: Failed to place %d repeaters for %d drivers in collection (%s), and failed cells are in collection (%s).\n Check the failed drivers by running the query_objects get_ports get_pins and get_cells commands.\n The driver can be port, macro pin, and placed cell.\n place_group_repeat ers ECO-228 Warning: Some repeaters from path driver (%s) have same repeater group id.\n The cells belonging to the path are {%s}.\n Check if the group id of cells are on the same path.\n The command skips to place some repeaters.\n The group id of cells on one path should be different.\n place_group_repeat ers ECO-229 Warning: Failed to find intersection of cutline %s and route for cell {%s}.\n place_group_repeat ers ECO-231 Error: The repeater group (%d) has no cutline or invalid cutline.\n Check the right cutline for this group.\n Set right cutline for this group using the set_repeater_gr oup command.\n 1000 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error: Cutline {{%s} {%s}} is invalid.\n Check the format of the cutline.\n The valid format of cutline is {{x1 y} {x2 y}} or {{x y1} {x y2}}.\n place_group_repeat ers unplace_group_repeat ers ECO-233 Error: The cells in collection (%s) are invalid since they have no target input pin name (%s) and output pin name (%s).\n Check the input and output pin name.\n The input pin name and output pin name can be specified by using the -lib_cell_input and -lib_cell_output options if needed, or filter out invalid cells from input.\n The default value for -lib_cell_input is D.\n The default value for -lib_cell_output is Q.\n place_group_repeat ers ECO-234 Warning: There is no repeater to be placed for the path driver (%s).\n place_group_repeat ers ECO-235 Warning: There is no route on driver net (%s).\n place_group_repeat ers ECO-236 Warning: There is no target load for path driver (%s).\n place_group_repeat ers ECO-237 Warning: Some cell to be placed has no load for path driver (%s).\n place_group_repeat ers ECO-239 Info:%s.\n Check the place and connection mode.\n Show the place mode (cutline/distance) and connection mode (virtual connection/real connection) on this command.\n 1001 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error: The option -cells cannot be used when the app option eco.placement.eco_enable_ virtual_connection is true.\n Check the command for virtual connection.\n Specify the -repeater_groups command if you need to use virtual connection.\n place_group_repeat ers ECO-241 Warning: The distance based placement does not support multi-fanout path driver(%s).\n Check the cutline based placement for the multi-fanout path driver.\n place_group_repeat ers unplace_group_repeat ers ECO-242 Warning: The cell (%s) has no driver or load (number of driver: %d, number of load: %d).\n place_group_repeat ers ECO-243 Error: The cells in collection (%s) are invalid since they have no driver or load.\n Check for invalid cells.\n Ensure the cell that is placed has both driver and load.\n Else, remove such cells from input.\n place_group_repeat ers ECO-244 Warning: The %s %s has no shape.\n Check if the top port or macro pin has shape.\n place_group_repeat ers ECO-246 Warning: Skip the path driver (%s) since the driver or load for the path has no shape.\n place_group_repeat ers ECO-251 Info: Place group repeaters successfully.\n Check if all the input cells are placed successfully.\n place_group_repeat ers ECO-252 Warning: Failed to place repeaters for repeater path which driver is %s.\n place_group_repeat ers ECO-253 Warning: The cutline information %s for cell %s is not on valid route.\n 1002 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning: Failed to cut route for cell %s.\n Check if the command failed to cut route for cell.\n place_group_repeat ers ECO-255 Warning: Gap %s between driver and nearest route is larger than placing distance %s Check if the route to the nearest pin distance is larger than placing distance for driver or load.\n place_group_repeat ers ECO-256 Warning: The first distance (%s) specified by command option is shorter than the gap (%s) between pin and route for driver (%s).\n (warning) The last distance (%s) specified by command option is shorter than the gap (%s) between pin and route for load (%s).\n Check if the -first_distance or -last_distance option specified is shorter than the gap between pin and route for driver or load.\n place_group_repeat ers ECO-257 Warning: Cannot find cutline information for cell %s.\n place_group_repeat ers ECO-258 Info: The app option about virtual connection is turned on.\n Please make sure the cells in repeater group keep in order.\n Check if the eco.placement.eco _enable_virtual_c onnection option is set to true and the place_group_repea ters -repeater_groups option is specified.\n place_group_repeat ers unplace_group_repeat ers ECO-259 Warning: The number of cells from repeater group (%d) is not consistent with the number of drivers from driver group (%s).\n place_group_repeat ers unplace_group_repeat ers ECO-260 Warning: The number of cells from repeater group (%d) is not consistent with the number of loads from load group (%s).\n 1003 Swapping Variant Cell Feedback Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning: The number of path loads is less than the number of cells in group (%d), so skip these path loads.\n place_group_repeat ers unplace_group_repeat ers ECO-262 Warning: The number of path loads is not an integral multiple of the number of cells in group (%d), so use path loads in order.\n place_group_repeat ers ECO-265 Warning: The pin shape {%s} of %s (%s) is projected to route %s {%s}.\n Check if the route is far away from driver or loads.\n The tool projects the closest pin shape to the route.\n unplace_group_repeat ers ECO-266 Warning: The cells in collection %s which are not placed before cannot be unplaced by unplace_group_repeaters.\n Check if the cells are not placed.\n The cells that are not placed cannot be unplaced.\n Also, only the cells added by the add_group_repeat ers command and placed by the placed_group_repe aters command can be unplaced by the unplace_group_rep eaters command.\n unplace_group_repeat ers ECO-267 Error: Input and output routes are not merged after unplacing repeater %s since the routes are not aligned or not at the same layer.\n Check if the routes are merged after unplacing repeaters.\n This error occurs when the routes are not aligned or not at the same layer since they are not"}
{"instruction": "How do I Hierarchical Synthesis Flow When Floorplans are Available", "input": "", "output": "To partition and plan the top-level design and create the lower-level blocks for subsequent bottom-up synthesis, when the floorplans of subblock and top-level design are available, perform the following steps: Figure 188 Hierarchical Synthesis Flow When Floorplans are Available 1.\n Read in the full chip design and apply constraints as shown in the following example: fc_shell> set REF_LIBS \"stdcell.ndm macro.ndm\" fc_shell> create_lib TOP -technology techfile \\ -ref_libs $REF_LIBS fc_shell> analyze -format verilog $rtl_files fc_shell> elaborate TOP fc_shell> set_top_module TOP fc_shell> load_upf fullchip.upf fc_shell> read_sdc fullchip.sdc 2.\n For the design partitions, split the constraints as shown in the following example: fc_shell> set_budget_options -add_blocks {BLOCK1 BLOCK2} fc_shell> split_constraints 3.\n Create the subblock design libraries with design information and enable block-specific reference library setup as shown in the following example: fc_shell> copy_lib -to_lib BLOCK1.nlib -no_design fc_shell> copy_lib -to_lib BLOCK2.nlib -no_design fc_shell> set_attribute -objects BLOCK1.nlib \\ 821 Performing Hierarchical Synthesis Using Abstracts Feedback -name use_hier_ref_libs -value true fc_shell> set_attribute -objects BLOCK2.nlib \\ -name use_hier_ref_libs -value true fc_shell> save_lib -all 4.\n Create the subblock design partitions as shown in the following example: fc_shell> commit_block -library BLOCK1.nlib BLOCK1 fc_shell> commit_block -library BLOCK2.nlib BLOCK2 fc_shell> save_lib -all 5.\n Load the UPF and SDC constraints for the unmapped subblocks as well as the top- level, which are generated by the split_constraints command earlier as shown in the following example: fc_shell> set_constraint_mapping_file./split/mapfile fc_shell> load_block_constraints -all_blocks -type SDC \\ -type UPF -type CLKNET fc_shell> save_lib -all 6.\n Load the floorplan for the subblocks and top-level design.\n 7.\n Run the compile_fusion command until logic optimization for the subblocks and top- level design is complete as shown in the following example: fc_shell> compile_fusion -to logic_opto 8.\n Perform standard cell placement followed by the pin assignment, timing estimation and budgeting.\n 9.\n After completing the design planning operations, rebuild the subblock and top-level design by opening the elaborated RTL NDM, loading floorplan, feedthroughs and budgets.\n Note: For details about each of the design planning operation, see the Design Planning User Guide"}
{"instruction": "How do I Saving Route Information", "input": "", "output": "To save the route information, use the write_routes command.\n This command generates a Tcl script that reproduces the metal shapes and vias for a block, including their attribute settings.\n Note that the write_routes command reproduces routes, but not routing blockages.\n To generate a Tcl script that reproduces routing blockages, use the write_floorplan command."}
{"instruction": "How do I Fixing Buffers", "input": "", "output": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design.\n The command can perform the following changes: Minimize the number of dual-rail buffers or inverters Fix isolation violations in buffer trees Fix buffers and inverters that have illegal settings, as follows: Process, voltage, and temperature settings Library cell purpose or subset settings Target library subset settings Bias voltages Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: Swap buffer library cells to fix illegal settings Swap single-rail buffers for dual-rail buffers Swap dual-rail buffers for single-rail buffers Change the backup supplies of dual-rail buffers and inverters Change the input or output supplies of level shifters Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters.\n In addition, 1007 Fixing Multivoltage Violations Feedback the command only uses supplies that are available in the voltage area or voltage area region.\n The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations.\n Netlist changes caused by the command do not introduce new isolation or voltage violations.\n To specify a buffer tree, use the -from option with the name of a net or driver pin.\n If you specify a net name, its driver pin is used.\n In both cases, the driver pin defines a full or partial buffer tree.\n Wildcards are supported.\n The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells.\n By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations.\n However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area.\n If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order: A cell from the same library as the original library cell A cell from a library with a name similar to the original library A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells.\n Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells.\n However, the command does not change level-shifter library cells.\n To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}
{"instruction": "How do I Setting Up Multivoltage Designs", "input": "", "output": "The following topics describe the tasks you need to perform when setting up multivoltage designs: Applying the Multivoltage Power Intent Preparing the Power Network 113 Setting Up Multivoltage Designs Feedback Defining Voltage Areas Inserting Multivoltage Cells Controlling the Placement of Multivoltage Cells Enabling Improved Buffering for Multivoltage Nets Analyzing Multivoltage Information"}
{"instruction": "How do I Enabling Advanced PG Net Checks", "input": "", "output": "For advanced technology nodes, such as 12 nanometer, 7 nanometer, or smaller technology nodes, you can enable advanced physical DRC checks between cells and prerouted PG nets by setting the place.legalize.enable_advanced_prerouted_net_check application option to true When you enable this feature, you can further control the accessibility checks performed for standard cell pins by using the place.legalize.advanced_layer_access_check and place.legalize.advanced_libpin_access_check application options.\n However, the default behavior of this feature is suitable for most designs.\n 163 Specifying Legalization Settings Feedback"}
{"instruction": "How do I Setting Self-Gating Options", "input": "", "output": "To specify self-gating settings, use the set_self_gating_options command with the following options: -min_bitwidth bitwidth Controls the minimum size for self-gating banks.\n The default is 4.\n -max_bitwidth bitwidth Controls the maximum size for self-gating banks.\n The default is 8.\n -interaction_with_clock_gating interaction_type Registers gated by user-instantiated clock-gating cells are candidates for self-gating.\n Valid arguments are none (skip registers gated by tool-inserted clock gates), insert (the default; insert self-gates on gated registers), and collapse (collapse tool-inserted clock gates if they are in the same hierarchy).\n -objects object_list Specifies that the options should be applied to the listed objects.\n Supported objects are hierarchical instances, power domains, and designs.\n By default, the settings apply to the entire design.\n -tree_type combinational_logic_type Uses the specified logic type to build the gated enable tree.\n Valid arguments are xor nand or, and auto (the default).\n 332 Self-Gating Optimization Feedback To report self-gating options, use the report_self_gating_options command."}
{"instruction": "How do I Generating a Report of Early Data Check Records", "input": "", "output": "You can generate a report of check records from a design by using the get_early_data_check_records command.\n Using the -hierarchical option with this command enables to you get check records for all subblocks.\n The report generated is in the following format: check_name object For example, fc_shell> get_early_data_check_records -hierarchical {hier.block.missing_leaf_cell_location@eco_cell} You can use the -filter option to filter the results of this command by various parameters such as object class and check name.\n 853 Performing Top-Level Closure With Abstract Views Feedback For example, fc_shell> get_early_data_check_records \\ -filter \"checked_object_class==port\" {place.port_type_mismatch@clk route.missing_layer_direction@feed_in route.layer_name_mismatch@out}"}
{"instruction": "How do I Configuring Distributed Processing", "input": "", "output": "Distributed processing performs tasks in parallel by using multiple machines; each process uses its own process memory image.\n When using distributed processing, each parallel task is called a process.\n For the best performance during distributed processing, you should limit the number of processes to the number of available cores, which is the sum of the number CPUs times the number of cores per CPU for each host machine.\n The following commands support distributed processing configured by the set_host_options command: analyze_rail create_placement -floorplan signoff_check_drc signoff_fix_drc signoff_create_metal_fill signoff_fix_isolated_via When you configure distributed processing, you can specify one or more of the following settings: The job submission command (the -submit_command option) If you do not specify this option, the tool uses the rsh command to submit the parallel processes.\n The list of host machines (the host_names argument) The maximum number of processes (the -num_processes option) By default, the tool assigns a name to each configuration you define with the set_host_options command.\n To specify the configuration name, use the -name option.\n You use the configuration name to select the configuration to use for specific commands and to remove a configuration.\n For example, to specify a distributed processing configuration that uses the qsub command to submit the parallel processes, use the following command: fc_shell> set_host_options -name dp_config \\ -submit_command [list qsub -P bnormal -cwd]"}
{"instruction": "How do I Generating Via Ladder Rules for Performance Via Ladders", "input": "", "output": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the setup_performance_via_ladder command to generate the via ladder rules and associations.\n By default, this command Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the -max_layer attribute.\n 451 Inserting Via Ladders Feedback The command uses information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file: The cut layers that connect the specified metal layers The cut names The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block.\n The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules.\n For details about these files, see Via Ladder Rule Files You can also generate these files by using the generate_via_rules_for_performance command.\n Associates via ladder rules with the pins of all library cells that do not have a dont_use attribute To include the pins of library cells that have a dont_use attribute, use the -dont_use option.\n To associate via ladder rules only with specific pins, use the -lib_pins option.\n The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations.\n For details about this file, see Via Ladder Association File You can also generate this file by using the associate_performance_via_ladder command.\n Runs the generated script files See Also Defining Via Ladder Rules Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization 452 Inserting Via Ladders Feedback"}
{"instruction": "How do I Performing Metal Fill Insertion", "input": "", "output": "You can use the signoff_create_metal_fill command to perform the following tasks: Pattern-Based Metal Fill Insertion Track-Based Metal Fill Insertion Using an IC Validator Parameter File Typical Critical Dimension Metal Fill Insertion Timing-Driven Metal Fill Insertion Incremental Metal Fill Insertion Foundry Fill and Track Fill Combined for Different Flows of Foundry"}
{"instruction": "How do I Routing Secondary Power and Ground Pins", "input": "", "output": "To use Zroute to perform secondary power and ground pin routing, 1.\n Verify that the secondary power and ground pins have the appropriate attributes in the standard cell frame views.\n 2.\n Set the routing constraints for secondary power and ground pin routing.\n 3.\n Perform secondary power and ground pin routing by using the route_group command.\n The following topics describe these steps."}
{"instruction": "How do I Reporting Clock-Gating Results", "input": "", "output": "After compiling your design, you can check the results using the report_clock_gating command.\n An example is shown in Figure 64 Figure 64 Example of a report_clock_gating Report The report provides a summary of the clock-gating statistics.\n The term \"pre-existing clock gates\" refers to user-instantiated clock gates.\n The preexisting category also includes registers that are gated by a tool-inserted clock gate.\n This includes registers that are gated by both preexisting and tool-inserted clock-gating cells.\n By default, the tool reports multilevel statistics.\n This includes the maximum level of clock- gating cells in the design.\n Clock-gate levels are counted from the clock source toward the register.\n If multibit flip-flops are found in the design, multibit composition is automatically reported.\n 321 Reporting Clock-Gating Results Feedback Figure 65 Example of a Multibit Composition Report To report the details on ungated registers, use the -ungated option for report_clock_gating.\n For details on the gated registers, use the -gated option.\n 322 Reporting Clock-Gate Enable Signals Feedback"}
{"instruction": "How do I Selecting and Multiplexing Logic", "input": "", "output": "The Fusion Compiler tool infers SELECT_OP cells for logic that selects data signals based on control signals.\n SELECT_OP cells are mapped to combinational logic.\n The following topics describe SELECT_OP inferences: Inferring SELECT_OPs Inferring SELECT_OPs HDL Compiler uses SELECT_OP components to implement conditional operations implied by if and case statements.\n An example of a SELECT_OP cell implementation for an 8-bit data signal is shown in Figure 31 227 Controlling Mapping and Optimization Feedback Figure 31 SELECT_OP Implementation for an 8-bit Data Signal Figure 32 Verilog Output\u2014SELECT_OP and Selection Logic 228 Controlling Mapping and Optimization Feedback Depending on the design constraints, Fusion Compiler implements the SELECT_OP with either combinational logic or multiplexer cells from the logic library.\n For more information on SELECT_OP inference, see the HDL Compiler documentation."}
{"instruction": "How do I Transferring to Back End", "input": "", "output": "To transfer the clock latencies and balance points from the front-end tool to the back-end tool, use the write_ascii_files command.\n The command writes the design.MCMM directory, which contains timing contexts in Tcl files for.\n For example, The design.MCMM/scenario_ scenario.tcl file contains the following clock latency settings: set_clock_latency -clock [get_clocks {CLK}] -0.3 [get_pins {d_reg[4]/CP}] set_clock_latency -clock [get_clocks {CLK}] 0.1 [get_pins {d_reg[7]/CP}] The design.MCMM/mode_ mode.tcl file contains the following balance points: set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[4]/CP}] \\ -consider_for_balancing true \\ -rise -delay 0.3 -corners [get_corners {default}] set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[7]/CP}] \\ -consider_for_balancing true -rise -delay -0.1 -corners [get_corners {default}]"}
{"instruction": "How do I Deriving Routing Guides", "input": "", "output": "Routing guides provides routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic described how to derive the following types of routing guides: Deriving Pin Access Routing Guides Deriving Metal Cut Routing Guides See Also Defining Routing Guides 479 Routing Constraints Feedback"}
{"instruction": "How do I Controlling Pin Tapering", "input": "", "output": "Pin tapering is the method used to connect wires with nondefault routing rules to pins.\n Zroute supports pin tapering for both hard and soft nondefault routing rules; the tapering implementation is the same for both types of nondefault routing rules.\n Note: By default, if a net has both a nondefault routing rule defined by the create_routing_rule command and voltage-based spacing rules defined in the technology file, Zroute performs pin tapering on that net based on the nondefault routing rule.\n To disable pin tapering on these nets, set the route.detail.enable_ndr_tapering_on_voltage_rule application option to false You can specify the method used for pin tapering and control the tapering width, as described in the following topics: Specifying the Tapering Method Controlling the Tapering Width 516 Routing Constraints Feedback"}
{"instruction": "How do I Early Data Checks, Policies, and Strategies", "input": "", "output": "The tool can identify issues and violations in data during the early stages of design.\n You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data.\n Table 64 describes the predefined checks for top-level closure.\n Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view Checks whether the frame view is missing for a hierarchical block Re-create frame views from the bound view error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location Checks whether the location of a physical hierarchy boundary pin is missing Assign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary Checks whether the location of a physical hierarchy boundary pin is outside the physical hierarchy boundary Reassign a location for the block pin on the block boundary based on connectivity error, tolerate, repair MID BOT 847 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort Checks whether a port is missing in the physical hierarchy reference Create missing ports in the reference block and update its location error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame Checks whether a physical hierarchy instance is bound to a frame view error, tolerate TOP hier.block.inst ance_with_desig n_type_macro Checks whether a physical hierarchy instance is bound to a macro error, tolerate TOP hier.top.estima ted_corner Checks whether the estimated corner is at top level error, tolerate TOP hier.block.miss ing_leaf_cell_l ocation Checks whether the location of a leaf cell of a physical hierarchy is missing Assign an approximate location inside the block boundary for the leaf cell (legality not considered) error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary Checks whether the location of a leaf cell of a physical hierarchy is outside the physical hierarchy boundary Reassign the leaf cell location to the nearest location inside the block boundary (legality not considered) error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion Checks whether the location of a child physical hierarchy instance is missing in the specified physical hierarchy Assign an approximate location for the lower-level subblock based on connectivity inside the block boundary (overlap removal not considered) error, tolerate, repair MID 848 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary Checks whether the location of a child physical hierarchy instance is outside the specified physical hierarchy boundary Move the subblock to the nearest location inside the block boundary (overlap removal not considered).\n error, tolerate, repair MID hier.block.port _mismatch_betwe en_views Checks whether there is a mismatch of ports between the views of a physical hierarchy Bound view is treated as golden and the frame view is recreated to match the bound view error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs Checks whether the design view for an abstract is missing error, tolerate MID BOT hier.block.inst ance_unlinked Checks whether the physical hierarchy reference is not linked properly to the top-level design due to a view change from frame or ETM to abstract or design error TOP hier.block.abst ract_type_non_t iming Checks whether the abstract type is not timing error MID BOT hier.block.abst ract_target_use _non_implementa tion Checks whether the target use of an abstract is not implementation error MID BOT hier.block.miss ing_core_area Checks whether the core area for a physical hierarchy is missing error MID BOT 849 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic Checks whether unmapped logic is present in the physical hierarchy error MID BOT Where BOT signifies bottom level design.\n MID signifies intermediate level design, which instantiates BOT.\n TOP signifies the top-level design, which instantiates MID."}
{"instruction": "How do I Specifying Settings for Clock Latency Adjustments", "input": "", "output": "I/O ports are usually constrained using real or virtual clocks.\n After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate.\n When you run clock tree synthesis with the clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports.\n You can control these latency adjustments by using the set_latency_adjustment_options command.\n The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell> set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the synthesize_clock_trees command, the tool does not automatically update the clock latencies.\n To do so, use the compute_clock_latency command after clock tree synthesis.\n This command honors the settings you specify with the set_latency_adjustment_options command.\n 369 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}
{"instruction": "How do I Bus Routing Options", "input": "", "output": "The Custom Router bus routing application options allow you to specify: Corner Type Intra-shield Placement Pin-Trunk Offset Trunk Splitting Tapoffs"}
{"instruction": "How do I Using Hierarchical Relative Placement for Straddling", "input": "", "output": "A cell can occupy multiple column positions or multiple row positions, which is known as straddling.\n For more information about leaf cell straddling, see Adding Leaf Cells Figure 169 shows a relative placement group in which cells straddle columns (instance U2) and rows (instance U7).\n Figure 169 Hierarchical Relative Placement Group With Straddling U3 U4 U6 U1 U2 U7 788 Adding Objects to a Group Feedback Figure 170 shows the process of using hierarchical relative placement to build this structure.\n First, define relative placement groups that contain the leaf cells: rp1 contains U1 and U4, rp2 contains U2, and rp3 contains U3 and U6.\n Then define a group (rp4) that contains these groups.\n Finally, define a group (rp5) that contains the hierarchical group rp4 and the leaf cell U7.\n The resulting group includes both the column and the row straddle.\n Example 44 shows the commands used in this process.\n Figure 170 Straddling With Hierarchical Relative Placement rp3 rp2 rp1 U3 U2 U4 U7 U6 U1 rp4 U4 U1 U2 U3 U6 rp1 rp2 rp3 rp5 U4 U1 U2 U3 U6 col 0 col 1 row 0 col 0 col 1 col 0 col 1 row 0 row 0 row 2 row 1 row 0 col 0 row 2 row 1 row 0 col 0 col 1 U7 col 1 row 2 row 1 row 0 rp4 Example 44 Straddling With Hierarchical Relative Placement create_rp_group -name rp1 -columns 2 -rows 1 add_to_rp_group rp1 -cells U1 -column 0 -row 0 add_to_rp_group rp1 -cells U4 -column 1 -row 0 create_rp_group -name rp2 -columns 1 -rows 1 add_to_rp_group rp2 -cells U2 -column 0 -row 0 create_rp_group -name rp3 -columns 2 -rows 1 add_to_rp_group rp3 -cells U3 -column 0 -row 0 add_to_rp_group rp3 -cells U6 -column 1 -row 0 create_rp_group -name rp4 -columns 1 -rows 3 add_to_rp_group rp4 -rp_group rp1 -column 0 -row 0 add_to_rp_group rp4 -rp_group rp2 -column 0 -row 1 add_to_rp_group rp4 -rp_group rp3 -column 0 -row 2 create_rp_group -name rp5 -columns 2 -rows 1 789 Adding Objects to a Group Feedback add_to_rp_group rp5 -rp_group rp4 -column 0 -row 0 add_to_rp_group rp5 -cells U7 -column 1 -row 0"}
{"instruction": "How do I Self-Gating Flow", "input": "", "output": "Figure 68 illustrates the Fusion Compiler flow for inserting self-gates by using the compile_fusion command.\n 330 Self-Gating Optimization Feedback Figure 68 General Self-Gating Flow Fusion Compiler read_saif in.saif or set_switching_activity compile_fusion SAIF RTL/netlist Libraries Reports set_app_options -name compile.clockgate.self_gating -value true"}
{"instruction": "How do I Setting Up Libraries", "input": "", "output": "block is a container for physical and functional design data.\n A design library is a collection of related blocks, together with technology data that applies to the block collection.\n A chip design consists of one or more blocks, often stored in different design libraries.\n A design library uses instances of blocks defined in lower-level libraries, called reference libraries.\n A design library can serve as a reference library for another design library.\n To learn about setting up libraries, see the following topics: Working With Design Libraries Setting Up Reference Libraries Library Configuration Restricting Library Cell Usage Restricting the Target Libraries Used Specifying Library Subset Restrictions 73 Setting Up Libraries Feedback"}
{"instruction": "How do I Controlling Pin Connections", "input": "", "output": "By default, Zroute connects a signal route to a pin by using wires or vias anywhere on the pin.\n To restrict the allowed types of pin connections on a per-layer basis, use the following 513 Routing Constraints Feedback syntax to set the route.common.connect_within_pins_by_layer_name application option: set_app_options -name route.common.connect_within_pins_by_layer_name -value { { layer mode }...\n } Valid values for the mode argument are off (the default) There are no restrictions on pin connections.\n via_standard_cell_pins Only the connections to standard cell pins by using a via are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to macro cell and pad cell pins by using a via or to any pins by using wires.\n via_wire_standard_cell_pins The connections to standard cell pins by using a via or a wire are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n via_all_pins The connections to any pins (standard cell, macro cell, or pad cell) by using a via are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n There are no restrictions on signal routes connected to any pins by using wires.\n via_wire_all_pins The connections to any pins by using a via or a wire are restricted.\n When using a via connection, the via's metal enclosure must be contained within the pin shape.\n When using a wire, the wire must be contained within the pin shape.\n For example, if you use the following command (or use the default settings), all of the connections shown in Figure 113 are valid and no DRC violations are reported: fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 off}} 514 Routing Constraints Feedback Figure 113 Unrestricted Pin Connections If you set the mode for M1 to via_all_pins, as shown in the following example, the via enclosures must be inside the pin shape.\n The connections shown on the left side of Figure 114 are valid; however, the connections on the right side of the figure cause DRC violations.\n fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_all_pins}} Figure 114 Restricted Via-to-Pin Connections No DRC Violations DRC Violations If you set the mode for M1 to via_wire_standard_cell_pins, as shown in the following example, both the via enclosures and wires must be inside the pin shape.\n The connections 515 Routing Constraints Feedback shown on the left side of Figure 115 are valid; however the connections on the right side of the figure cause DRC violations.\n fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_wire_standard_cell_pins}} Figure 115 Restricted Via-to-Pin and Wire-to-Pin Connections DRC Violations No DRC Violations"}
{"instruction": "How do I Mapping of Synchronous Reset or Preset Registers", "input": "", "output": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default.\n To infer registers with synchronous reset or preset pins, use the sync_set_reset Synopsys compiler directive in the RTL.\n HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible.\n To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: The sync_set_reset directive Specify the //synopsys sync_set_reset directive in the RTL.\n The hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to true.\n The default is false 233 Controlling Mapping and Optimization Feedback During compile, the tool performs the following mapping based on the registers in your library: The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin.\n The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin.\n The tool also attempts to map the logic as close as possible to the data pin.\n This figure shows examples of mapping to registers with and without a synchronous reset pin.\n ___ RST Using a reset pin ___ RST Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible.\n To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to true Note: Synchronous reset and preset signals are not inferred for level-sensitive latches.\n A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins.\n Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must Describe the registers correctly in the RTL Ensure the library contain the corresponding cells Ensure the hdlin.elaborate.ff_infer_async_set_reset application option is set to true (the default) 234 Controlling Mapping and Optimization Feedback If the library does not contain this type of registers, the tool leaves the cells unmapped."}
{"instruction": "How do I Overriding the Alignment When Adding Objects", "input": "", "output": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option.\n However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option.\n The following example creates a relative placement group named rp1 that is right aligned.\n It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement.\n 799 Specifying Options for Relative Placement Groups Feedback Figure 179 Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}
{"instruction": "How do I Constructing Faster Clock Tree to Specific Endpoints", "input": "", "output": "The Fusion Compiler tool enables you to construct a faster clock tree to specified endpoints without any additional detouring or delay balancing.\n This improves clock latency to the specified endpoints.\n To achieve a faster clock tree to specific endpoints, you must create a user skew group for the required endpoints.\n To create a skew group for a specific endpoint, use the following command before running the synthesize_clock_tree or the build_clock stage of the clock_opt command: fc_shell> create_clock_skew_group -objects <endpoints> Note: If there is a balancing requirement between the fast endpoints, you must put them in the same skew group.\n If there is no balancing requirement between the endpoints, you must create separate skew groups for each endpoint.\n The upstream clock logic of the required skew group endpoints is shared with the endpoints of the default group or other user skew groups.\n This leads to detouring for balancing among the endpoints of the default group or other user skew group.\n 366 Specifying the Clock Tree Synthesis Settings Feedback Figure 79 Faster Clock Tree to Specific Endpoints If a gate drives both skew group and non-skew group endpoints, the skew group endpoints might be delayed due to the balancing requirements of the non-skew group endpoints.\n In such cases, in addition to creating skew groups, you must also completely isolate the skew group endpoints from the rest of the clock tree by cloning the gates along the path to these endpoints.\n To create a separate clock path from the clock source to the required endpoints, use the -to option with the split_clock_cells command before clock tree synthesis, that is, before using the synthesize_clock_trees or the build_clock stage of the clock_opt command.\n fc_shell> split_clock_cells -to $endpoints The Fusion Compiler tool enables you to construct a faster clock tree by identifying the optimal cloning solution to achieve the best latency for the group of specified sinks.\n To achieve a fast clock tree to certain endpoints, use the split_clock_cells -to < $sinks> -latency_driven command.\n The endpoints must also be created as part of the user skew group using the create_clock_skew_group command.\n 367 Specifying the Clock Tree Synthesis Settings Feedback"}
{"instruction": "How do I Modifying Metal Fill", "input": "", "output": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes.\n To change the boundary of a metal fill shape, use the set_attribute command to modify its bbox attribute.\n To add a metal fill shape in the top-level fill cell, use the create_shape -shape_use area_fill command.\n To add a metal fill shape in a specific fill cell, use the create_shape -fill_cell command.\n To remove a metal fill shape, use the remove_shapes command.\n You can also modify metal fill shapes in the GUI.\n To select or modify fill shapes in the GUI, 1.\n Select \"Multiple Levels Active\" ( ) in the View Settings panel.\n 2.\n In the \"Hierarchy Settings\" panel, set \"View level\" to a minimum of 2 and select \"Fill Cell\" in \"Expanding cell types.\""}
{"instruction": "How do I Guided Power Grid Augmentation", "input": "", "output": "Guided power grid augmentation inserts PG augmentation shapes only near cells with IR violations.\n For each candidate cell, guided PG augmentation inserts PG augmentation shapes in the region from the cell to its tap with the minimum path resistance.\n Because the shapes are added only in specific regions, guided PG augmentation inserts fewer metal shapes and uses less routing area, which decreases the coupling capacitance impacts.\n To perform guided power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop and minimum path resistance analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis and Performing Minimum Path Resistance Analysis The IC Validator tool uses the results of these analyses to drive the power grid augmentation.\n 3.\n Set up the IC Validator environment as described in Setting Up the IC Validator Environment 4.\n (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 5.\n Save the block to disk.\n When you run the fix_pg_wire command, the IC Validator tool uses the on- disk information for the block, not the information in memory.\n To ensure accurate information, use the save_block command to save the current state of the block before running the fix_pg_wire command.\n 705 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback 6.\n Perform guided power grid augmentation by using the fix_pg_wire command with one or both of the following options: -number_pins This option specifies the number of worst IR-drop violators for which to perform PG augmentation.\n -voltage_drop_threshold This option enables the tool to automatically determine the cells to process based on a voltage drop threshold.\n In addition, you must specify The power and ground nets on which to perform PG augmentation by using the -supply_nets option The technology node for which to perform the augmentation by using the -node option For information about the fix_pg_wire command, see the man page.\n 7.\n Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n See Also Standard Power Grid Augmentation Timing-Driven Power Grid Augmentation Removing PG Augmentation Shapes"}
{"instruction": "How do I Associating Checkpoints and Checkpoint Behaviors", "input": "", "output": "After defining checkpoints with the eval_checkpoint command and checkpoint behaviors with the create_checkpoint_* command, you must associate the two so that the tool executes the behaviors when it encounters the checkpoints in a run, as described in the following topics: Associating Checkpoints With Checkpoint Reports Associating Checkpoints With Checkpoint Actions See Also Defining Checkpoints Defining Checkpoint Behaviors Associating Checkpoints With Checkpoint Reports To associate a checkpoint report with one or more checkpoints, use the associate_checkpoint_report command in your checkpoint.config.tcl file.\n 56 Adding Changes to a Script With Checkpoints Feedback Specify the checkpoint report name with the -enable option.\n To enable the report to run before one or more checkpoints, specify the checkpoint names with the -before option.\n To enable the report to run after one or more checkpoints, specify the checkpoint names with the -after option.\n When associating a report with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined three checkpoints in your script named remove_buffers, place_opt_to_initial_opto, and place_opt_to_final_opto using the eval_checkpoint command, and two checkpoint reports named timing and app_options using the create_checkpoint_report command.\n To enable your timing report to run after the place_opt_to_initial_opto and place_opt_to_final_opto checkpoints, use the following command: associate_checkpoint_report -enable timing \\ -after { place_opt_to_initial_opto place_opt_to_final_opto } To enable your app_options report to run before all the checkpoints in your script, use the following command: associate_checkpoint_report -enable app_options -before * You can also add the command like this, which enables the report to run before the remove_buffers checkpoint and any checkpoints beginning with the phrase place_opt: associate_checkpoint_report -enable app_options -before remove_buffers place_opt* The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in the run.\n The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the app_options report, configured to run before each checkpoint The code identifies the timing report, configured to run after the place_opt_to_final_opto checkpoint 57 Adding Changes to a Script With Checkpoints Feedback Associating Checkpoints With Checkpoint Actions To associate a checkpoint action with one or more checkpoints, use the associate_checkpoint_action command in your checkpoint.config.tcl file.\n Specify the checkpoint action name with the -enable option.\n To enable the action to run before one or more checkpoints, specify the checkpoint names with the -before option.\n To enable the action to run after one or more checkpoints, specify the checkpoint names with the -after option.\n To enable the action to run instead of the code block enwrapped by the checkpoint, specify the checkpoint names with the -replace option.\n When associating an action with multiple checkpoints, you can list the checkpoint names or specify the asterisk wildcard character.\n Assume you have defined two checkpoints in your script named place_opt_to_initial_drc and incr_placement with the eval_checkpoint command, and two checkpoint actions named gropto and placer_high_effort_cong with the create_checkpoint_action command.\n To enable your gropto action to run before the place_opt_to_initial_drc checkpoint, use the following command: associate_checkpoint_action -enable gropto \\ -before place_opt_to_initial_drc 58 Adding Changes to a Script With Checkpoints Feedback To enable your placer_high_effort_cong action to run instead of the code block enwrapped by the incr_placement checkpoint, use the following command: associate_checkpoint_action -enable placer_high_effort_cong \\ -replace incr_placement The following is a portion of your checkpointed script showing what happens when the script runs.\n Note that the highlighted code is not actually in your script, but shows the checkpoint behaviors that are executed when the tool encounters the checkpoints in a run.\n The code that is commented out identifies the original script body The blue code identifies the checkpointed Tcl commands in your golden flow The green code identifies the gropto action, configured to run before the place_opt_to_initial_drc checkpoint The code identifies the placer_high_effort_cong action, configured to run in place of the code block enwrapped by the incr_placement checkpoint 59 Adding Changes to a Script With Checkpoints Feedback Associating a Checkpoint With Multiple Behaviors When you associate a checkpoint with multiple behaviors, the tool executes those behaviors in the following order: Any reports configured to run before the checkpoint Any actions configured to run before the checkpoint The checkpointed code block, or any actions configured to replace it Any actions configured to run after the checkpoint Any reports configured to run after the checkpoint If multiple reports or multiple actions are configured to run at the same position ( -before -after, or -replace ) in the same checkpoint, the tool executes them in the order in which they were associated with the checkpoint with the associate_checkpoint_* commands.\n For example, suppose you define a timing report before an area report.\n If you associate the area report to run after a checkpoint before you associate the timing report to run after the same checkpoint, the tool runs the area report first when it encounters the checkpoint.\n See Also Defining Checkpoints Defining Checkpoint Behaviors Querying Checkpoints and Checkpoint Behaviors"}
{"instruction": "How do I Enabling Wire Length Aware Power-Driven Relocation", "input": "", "output": "The Fusion Compiler tool supports improved activity driven clock gate relocation by controlling the amount of wire length degradation and considering the power impact before performing the clock gate relocation.\n To enable activity driven clock gate relocation, set the cts.compile.power_opt_mode application option to all or gate_relocation The clock gates are not relocated or moved if: Relocating an integrated clock gate (ICG) has a minor power benefit or degrades power while degrading wire length.\n Moving the clock gate has a significant wire length impact for a less power benefit."}
{"instruction": "How do I Analyzing and Fixing Signal Electromigration Violations", "input": "", "output": "Signal electromigration problems result from an increase in current density caused by the use of smaller line widths and higher operational speeds in IC designs.\n Electromigration can lead to shorts or opens due to metal ion displacement caused by the flow of electrons.\n The more frequently a net switches, the more susceptible it is to electromigration.\n To analyze and fix signal electromigration violations in a detail routed block, 1.\n Apply the signal electromigration constraints by using the read_signal_em_constraints command.\n For more information, see Loading the Signal Electromigration Constraints 2.\n Apply switching activity by either reading in a SAIF file with the read_saif command or annotating the switching activity information on the nets with the set_switching_activity command.\n For more information, see Annotating the Switching Activity 3.\n Report the signal electromigration information by using the report_signal_em command.\n For more information, see Analyzing Signal Electromigration 4.\n Fix any signal electromigration violations by using the fix_signal_em command.\n For more information, see Fixing Signal Electromigration Violations The following example script shows the signal electromigration flow.\n # Open the block and apply the signal electromigration constraints open_block block1_routed read_signal_em_constraints em.itf # Load switching information read_saif block1.saif # Perform signal electromigration analysis report_signal_em -violated -verbose > block1.signal_em.rpt # Fix signal electromigration violations fix_signal_em 554 Analyzing and Fixing Signal Electromigration Violations Feedback"}
{"instruction": "How do I Controlling Sequential Mapping", "input": "", "output": "The sequential mapping phase consists of two steps: register inferencing and technology mapping.\n The term register refers to both edge-triggered registers and level-sensitive latches.\n Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN.\n SEQGENs are created during elaboration and are usually mapped to flip-flops during compile.\n Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library.\n Both of these steps are performed by the compile_fusion command.\n 230 Controlling Mapping and Optimization Feedback Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable QN SEQGEN This table lists the pins of a SEQGEN cell.\n Only a subset of these pins is used depending on the type of cell that is inferred.\n Unused pins are tied to zero.\n Direction Name Description Cell type Input clear Asynchronous reset Flip-flop or latch preset Asynchronous preset Flip-flop or latch next_state Synchronous data Flip-flop clocked_on Clock Flip-flop data_in Asynchronous data Latch enable Clock or asynchronous enable Latch synch_clear Synchronous reset Flip-flop synch_preset Synchronous preset Flip-flop synch_toggle Synchronous toggle Flip-flop synch_enable Synchronous enable Flip-flop Output Non-inverting output Flip-flop or latch 231 Controlling Mapping and Optimization Feedback Direction Name Description Cell type QN Inverting output Flip-flop or latch During technology mapping, the tool uses the SEQGEN as the starting point for mapping.\n The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register.\n Topics in this section Mapping Sequential Elements Exactly as Described in RTL Mapping of Scan Cells Mapping of Synchronous Reset or Preset Registers Specifying Synchronous Input Types for Library Cell Pins Controlling Sequential Output Inversion Preventing Connections to Register QN Pins Mapping of Synchronous Enable Logic to a MUX Identification of Shift Registers"}
{"instruction": "How do I Controlling the Adjustment of I/O Clock Latencies", "input": "", "output": "By default, the tool adjusts the latencies of the I/O clocks, which are the clocks that constrain the boundary ports, when it performs concurrent clock and data optimization during the clock_opt command.\n The tool also uses concurrent clock and data optimization techniques to adjust the I/O clock latencies when you subsequently run the compute_clock_latency command.\n The tool does not update the I/O clock latencies For the entire block when you disable this feature by setting the ccd.adjust_io_clock_latency to false or when you disable concurrent clock and data optimization for boundary paths by setting the ccd.optimize_boundary_timing application option to false For specific I/O paths when you exclude the corresponding path groups from concurrent clock and data optimization by using the ccd.skip_path_groups application option For specific I/O clocks when you disable latency adjustment those I/O clocks by using the set_latency_adjustment_options -exclude_clocks command 379 Implementing Clock Trees and Performing Post-CTS Optimization Feedback"}
{"instruction": "How do I Validating DEF Files", "input": "", "output": "To analyze the input DEF files before annotating the floorplan information on the block, enable check-only mode by using the -syntax_only option.\n The check-only mode provides diagnostic information about the correctness and integrity of the DEF file.\n The check-only mode does not annotate any floorplan information onto the block.\n fc_shell> read_def -syntax_only block.def fc_shell> check_duplicates -remove The check_duplicates -remove command ensures that no duplicate shapes and vias are present in the block due to the execution of the read_def command."}
{"instruction": "How do I Inserting Multivoltage Cells", "input": "", "output": "A multivoltage design requires special multivoltage cells, such as level shifters and isolation cells, at the interface between power domains.\n Level shifters are required between power domains that operate at different voltage levels, while isolation cells are required between power domains that are in different states (powered-down versus always-on or powered-up)."}
{"instruction": "How do I Creating Abstracts for Minimum Pulse Width Analysis", "input": "", "output": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations.\n The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation.\n You can use the following application options to: Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to true The data paths to these registers are not retained.\n By default, this application is set to false Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack.\n This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}
{"instruction": "How do I Improving the Banking Ratio", "input": "", "output": "During the initial_mapping stage, the tool can prioritize the use of sequential library cells that have functionally equivalent multibit library cells.\n After you run the compile_fusion command, if the report_multibit -ignored_cells command indicates that many cells were not banked due to a lack of multibit cells in the library, you can enable this feature by setting the compile.seqmap.prefer_registers_with_multibit_equivalent application option to true and rerunning the compile_fusion command.\n However, enabling this feature might degrade the design QoR."}
{"instruction": "How do I Deriving the Clock Trees", "input": "", "output": "The Fusion Compiler tool derives the clock trees by tracing through the transitive fanout from the clock roots to the clock endpoints.\n In general, the tracing terminates when it finds a clock pin of a sequential cell or macro; however, the tool traces through sequential cells if they are integrated clock-gating (ICG) cells or their fanout drives a generated clock.\n If the clock-gating logic uses a non-unate cell, such as an XOR or XNOR gate, the tool uses both the positive-unate timing arc and the negative-unate timing arc when tracing the clock path.\n If this does not correspond to the functional mode of the block, use the set_case_analysis command to hold all nonclock inputs of the cell at a constant value, which forces the cell into the required functional mode for clock tree synthesis.\n For example, suppose a block has the gating logic shown in Figure 71 Figure 71 Non-Unate Gated Clock To force the XOR gate (U0) into functional mode for timing analysis, use the following command: fc_shell> set_case_analysis 0 U0/B"}
{"instruction": "How do I Using Incomplete UPF Information", "input": "", "output": "The Early Data Check Manager allows you to check designs for power and multivoltage issues early in the design cycle.\n You can configure different error conditions in different ways.\n The tool provides comprehensive reports about the data checks.\n The general flow is as follows: 1.\n Use the set_early_data_check_policy command to define the global violation handling policy for data checks.\n 2.\n Proceed with your tool flow.\n The tool detects and responds to violations throughout the flow.\n 3.\n Use the report_early_data_checks command to obtain a report about all violations or specific data checks.\n 4.\n Use the get_early_data_check_records command to get a Tcl collection of violations that can be used in other commands.\n 5.\n Use the write_early_data_check_config command to save the settings in a file for future use.\n 6.\n Use the remove_early_data_check_records command to clear the data in preparation for another iteration.\n For more information about the Early Data Check Manager, see the Fusion Compiler Data Model User Guide For a list of power and multivoltage data checks, see the Fusion Compiler Multivoltage User Guide 115 Setting Up Multivoltage Designs Feedback"}
{"instruction": "How do I Command", "input": "", "output": "The following topics describe how you can control the multibit optimization performed during the clock_opt command: Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Enabling Post-Clock-Tree-Synthesis Multibit Debanking Enabling the Rewiring of Mixed-Drive-Strength Multibit Cells Some logic libraries have mixed-drive-strength multibit cells where some bits have a higher drive strength than others.\n For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit.\n To enable this feature for the clock_opt command, set the clock_opt.flow.enable_multibit_rewiring application option to true Enabling Post-Clock-Tree-Synthesis Multibit Debanking To improve the timing QoR, the clock_opt command can debank multibit registers during the final_opt stage, if doing so does not introduce hold timing violations.\n To enable this feature, set the clock_opt.flow.enable_multibit_debanking application option to true before you run the final_opt stage of the clock_opt command."}
{"instruction": "How do I Implementing MSCTS Multiple H-Tree", "input": "", "output": "To improve clock QoR, latency, and skew, you can build multiple global trees in different sections of the floorplan by using the -htree_sections option with the set_regular_multisource_clock_tree_options command.\n The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n 403 Implementing Multisource Clock Trees Feedback Figure 86 MSCTS Multiple H-Tree You can define the different sections in the floorplan by using a symmetric configuration of tap drivers or only tap locations by coordinates, as shown in the following example: set_regular_multisource_clock_tree_options - htree_sections [ list \\ [list -section_name \"sectionA_name\" -tap_boundary {{315.8800 1275.8000} {1750.0400 2187.1000}} -prefix \"sectionA\" -tap_boxes {4 4}] \\ [list -section_name \"sectionB_name\" -tap_locations {{700472} {1350 472}} -prefix \"section\"]] Figure 87 MSCTS Multiple H-Tree"}
{"instruction": "How do I Handling Multiple Levels of Physical Hierarchy", "input": "", "output": "For designs with multiple levels of physical hierarchy, before you create an abstract for a block with an abstract instantiated in it, Bind the lower-level blocks that you want represented by abstracts to the specific abstracts For example, assume you have a design with multiple levels of physical hierarchy as shown in the following figure.\n Figure 192 A Design With Multiple Levels of Physical Hierarchy BOT MID TOP 835 Reporting Abstract Inclusion Reasons Feedback To create an abstract for the block named BOT, use the following commands: fc_shell> open_block BOT fc_shell> create_abstract To create an abstract for the block named MID, use the following commands: fc_shell> open_block MID fc_shell> change_abstract -view abstract -references BOT fc_shell> create_abstract By default, the create_abstract command preserves all levels of the physical hierarchy.\n To flatten the physical hierarchy and retain only the relevant logic of the lower-level blocks, use the -preserve_block_instances false option, as shown in the following example: fc_shell> open_block MID fc_shell> create_abstract -preserve_block_instances false Use flattened abstracts in top-level implementation flows where the lower-level blocks are treated as read-only.\n Using flattened abstracts reduces the netlist size at the top level.\n It also simplifies data management because you do not need to include the lower-level blocks in the reference library list of the top level."}
{"instruction": "How do I ECO-Aware Removal of Track Based Metal Fill Shapes", "input": "", "output": "To automatically remove track based metal fill shapes that are causing DRC violations after ECO, use the -remove_by_rule drc_auto option with the signoff_create_metal_fill command.\n This action removes DRC violating track based metal fill shapes or vias from design, including any floating connections created due to removal of DRC violating shape.\n For example, fc_shell> signoff_create_metal_fill -remove_by_rule drc_auto"}
{"instruction": "How do I Routing Application Options", "input": "", "output": "The Fusion Compiler tool provides application options that affect the individual routing engines (global routing, track assignment, and detail routing), as well as application options that affect all three routing engines.\n For information about the application options that affect all three routing engines, see the route.common_options man page.\n For information about the application options that affect global routing, see the route.global_options man page.\n For information about the application options that affect track assignment, see the route.track_options man page.\n For information about the application options that affect detail routing, see the route.detail_options man page.\n Zroute uses these option settings whenever you perform routing functions.\n When you run a routing command, Zroute writes the settings for any routing options that you have set (or that the tool has set for you) in the routing log.\n To display the settings for all routing options, not only those that have been set, set the route.common.verbose_level application option to 1.\n fc_shell> set_app_options \\ -name route.common.verbose_level -value 1 519 Routing Clock Nets Feedback"}
{"instruction": "How do I Setting Up the IC Validator Environment", "input": "", "output": "To run an IC Validator In-Design command, you must specify the location of the IC Validator executable by setting the ICV_HOME_DIR environment variable.\n You can set this variable in your.cshrc file.\n To specify the location of the IC Validator executable, use commands similar to those shown in the following example: setenv ICV_HOME_DIR /root_dir/icv set path = ($path $ICV_HOME_DIR/bin/LINUX.64) You must ensure that the version of the IC Validator executable that you specify is compatible with the Fusion Compiler version that you are using.\n To report the version compatibility, use the report_versions command.\n For more information about the IC Validator tool, see the IC Validator documentation, which is available on SolvNet."}
{"instruction": "How do I Clock Gating in the Compile Log File", "input": "", "output": "The compile log file contains information about clock gating, which can help you debug simple setup issues.\n By default, the clock-gating information is displayed after Clock-gate insertion n the initial_map stage Clock-gate restructuring in the logic_opto stage Clock-gate restructuring in the initial_opto stage Self-gating insertion in the initial_opto stage, if enabled The reported information includes the following: The number of preexisting clock gates that have a dont_touch attribute, which prevents optimization and might lead to unsatistactory results The number of clock-gating library cells that have a CTS purpose, which is required for insertion Clock-gating metrics such as the number of elements and the number of gated registers A summary of reasons for registers that could not be gated If the self-gating or fanin-based sequential clock gating features are enabled, their metrics are displayed separately.\n An example of the compile log for a run that includes self-gating is as follows: Number of Pre-Exsting Clock Gates with dont_touch Attribute: 0 Number of ICG library cells with CTS purpose: 12 Tool Gated Register Summary Clock Gating Type | Number of Clock Gates | Register Count | Bitwidth | | | Equivalent Regular Clock Gating | 1 | 2 | 2 Self Gating | 0 | 0 | 0 Regular Clock Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Enable is Constant One | 2 | 2 289 Introduction to Clock Gating Feedback Self Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Register is clock gated, and ineraction | | is set to none | 2 | 2 The tool as not able to find enough registers | | that are compatible to this register | | in order to be gated.\n | 2 | 2"}
{"instruction": "How do I Saving UPF Information", "input": "", "output": "During physical implementation, the tool updates the power intent of the design.\n To generate an updated UPF file, use the save_upf command.\n You can use this UPF file in the subsequent steps of the design flow.\n The save_upf command separates the UPF commands based on the input UPF file, and adds a comment indicating the input UPF file and the time it was loaded.\n Assume you load, commit, and save UPF information as shown in the following example script: load_upf top_1.upf load_upf top_2.upf load_upf top_3.upf commit_upf save_upf top.upf 116 Setting Up Multivoltage Designs Feedback The resulting top.upf file contains the following information: ## Start - load_upf top_1.upf on Wed Oct 26 17:03:18 2016 ## End - load_upf ## Start - load_upf top_2.upf on Wed Oct 26 17:03:49 2016 ## End - load_upf ## Start - load_upf top_3.upf on Wed Oct 26 17:04:22 2016 ## End - load_upf"}
{"instruction": "How do I Spreading Repeater Cells During Placement", "input": "", "output": "If a block has many chains of repeater cells (buffers, inverters, or pipelined registers) along the edges or corners of macro cells or blockages, the tool might clump the cells along the edges or corners, increasing congestion.\n You can reduce this congestion by setting the place.coarse.spread_repeater_paths application option to true before you run the create_placement compile_fusion, or clock_opt command.\n Then, the tool reduces congestion along the edges and corners by spreading the repeater cells in an orthogonal direction."}
{"instruction": "How do I Minimizing Large Displacements During Legalization", "input": "", "output": "To minimize large displacements of cells during legalization, enable Orientation optimization by setting the place.legalize.optimize_orientations application option to true When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization.\n Stream placement by setting the place.legalize.stream_place application option to true When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization.\n You can further control stream placement by using the place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}
{"instruction": "How do I Viewing Error Data", "input": "", "output": "RedHawk or RedHawk-SC Fusion saves the checking error data file, named missing_via.\n supplyNetName.err, in the working directory.\n The tool generates one error data file for each supply net.\n Before you quit the current session, be sure to save the block to keep the generated error data in the block.\n To open an error data file in the error browser, choose File > Open...\n from the Error Browser dialog box, and then select the error data file to open in the Open Error Data dialog box (see Figure 202 ).\n For more information about the error browser, see \"Using the Error Browser\" in the Fusion Compiler Graphical User Interface User Guide 894 Missing Via and Unconnected Pin Checking Feedback Figure 202 Opening Error Data from the Error Browser See Also Specifying RedHawk and RedHawk-SC Working Directories"}
{"instruction": "How do I Inserting Boundary Cells", "input": "", "output": "The Fusion Compiler tool provides several methods for inserting boundary cells, depending on where you want to insert the boundary cells.\n To insert boundary cells around the core area, hard macros, and placement blockages, use the compile_boundary_cells command.\n To insert boundary cells only around one or more voltage areas, use the compile_boundary_cells command with the -voltage_area option.\n To insert boundary cells only around specific objects, use the compile_targeted_boundary_cells command with the -target_objects option.\n You can use this command to insert boundary cells around specific macros, voltage areas, voltage area shapes, placement blockages, routing blockages, and the core area.\n The set_boundary_cell_rules command configures boundary cell insertion for both the compile_boundary_cells and compile_targeted_boundary_cells commands.\n However, some rules are honored only by the compile_boundary_cells command.\n For details, see Specifying the Boundary Cell Insertion Requirements"}
{"instruction": "How do I Performing Distributed RedHawk Fusion Rail Analysis", "input": "", "output": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow.\n By default, the analyze_rail command uses a single process to perform RedHawk rail analysis.\n To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run.\n You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session.\n This allows you to run multiple RedHawk analyses with only one Fusion Compiler license.\n Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key.\n To examine the generated analysis result, first run the open_rail_result command to load the result that is saved in the directory you specify.\n You can then investigate the problematic areas in the map and check for violations in a text file or in an error view.\n You can open one result context at a time.\n To load the rail context generated in another analysis run, first close the current rail result using the close_rail_result command, and then open the desired rail result (see Displaying Maps in the GUI ).\n License Requirement By default, the number of required licenses is the number of script files or configurations specified with the -multiple_script_files option during distributed processing mode.\n If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message.\n To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the analyze_rail run, set the rail.license_checkout_mode application option to wait.\n If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately.\n By default, the rail.license_checkout_mode application option is set to nowait When the analysis is finished, run the remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses.\n fc_shell> remove_licenses SNPS_INDESIGN_RH_RAIL 915 Performing Distributed RedHawk Fusion Rail Analysis Feedback In Figure 210, the rail.license_checkout_mode application option is set to wait.\n There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses.\n In this case, the tool first checks out two licenses and waits for other licenses to become available.\n When a script finishes the job, the tool reuses its license immediately to submit other scripts.\n Figure 210 Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6 Set rail.license_checkout_mode to wait The tool first submits two scripts to the farm machines, because there are only two licenses available.\n...\n The tool checks for available licenses during the analyze_rail run.\n When a license becomes available, the tool reuses it.\n Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1.\n Define the distributed processing configuration by using the set_host_options command.\n You can specify one or more of the following options: Option Description -submit_protocol Specifies the protocol to submit jobs, such as LSF, GRD, or SGE.Note: Before job submission, run the rsh command to check if the target farm machine supports the rsh protocol to accept distributed processing from on a remote machine.\n -target Specifies to submit jobs for RedHawk only.\n -timeout Specifies the job submission timeout value.\n 916 Performing Distributed RedHawk Fusion Rail Analysis Feedback Option Description -submit_command Specifies the full path name of the LSF, GRD, SGE, or custom job submission program along with other options as needed, such as qsub or bsub.\n -max_cores Controls the number of cores each distributed worker job can use.\n The default is 1.\n 2.\n Run the analyze_rail command with the following options: Option Description -submit_to_other_machines Enables RedHawk job submission to the target farm machines.\n -multiple_script_files\\ directory_name script_name Specifies the RedHawk scripts and the directories for saving analysis results.\n Example 51 %> rsh myMachine ls test1 CSHRC DESKTOP > set_host_options \"myMachine\" -target RedHawk \\ -max_cores 2 -timeout 100 > analyze_rail -submit_to_other_machines \\ -voltage_drop static -nets {VDD VDDG VDDX VDDY VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only.\n Timeout value is 100 and the number of cores to use is 2.\n Example 52 > set_host_options -submit_protocol sge \\ -submit_command { qsub -P normal } > analyze_rail -submit_to_other_machines -voltage_drop \\ static -nets {VDD VSS} The above example enables job submission to a machine on the SGE farm machine.\n Example 53 > set_host_options -submit_protocol lsf \\ -submit_command {bsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{result1 RH1.tcl} {result2 RH2.tcl}} > open_rail_result result1 917 Voltage Driven Power Switch Cell Sizing Feedback > close_rail_result > open_rail_result result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2.\n Example 54 > set_app_options -name rail.license_checkout_mode \\ -value wait > set_host_options -submit_protocol sge \\ -submit_command {qsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{ result1 RH1.tcl} {result2 RH2.tcl} \\ {result3 RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the analyze_rail run."}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "By default, the tool can select any library cell from the target library during optimization.\n In some cases, you might want to restrict the library cells used for clock tree synthesis and optimization.\n For example, you might want to exclude specific double-height cells from the target library for some design blocks during optimization.\n To restrict the library cells used for clock tree synthesis and optimization, 1.\n Specify the library subset by using the set_target_library_subset command.\n By default, the library subset restriction applies to 78 Setting Up Libraries Feedback The top block and all its subblocks To set it for a specific subblock, use the -objects option.\n Both clock and data paths.\n To set it for only the clock or data paths, use the -clock or -data option.\n You can further restrict the target library subset setting as follows: Specify a list of cells from the libraries that should not be used by using the -dont_use option.\n Specify that these libraries cannot be used for any other objects, other than the specified objects, by using the -only_here option.\n 2.\n Enable the use of the target library subset by setting the opt.common.enable_target_library_subset_opt application option to 1.\n When you set target library subsets, remember the following points: The subset restriction applies to hierarchical cells but not to leaf cells.\n The command enforces the subset restriction on the specified blocks and their subdesigns in the hierarchy, except those subdesigns where a different subset restriction is set.\n A subset specified at a lower level supersedes any subset specified at a higher level.\n Figure 7 Logic Hierarchy of Design 79 Setting Up Libraries Feedback For example, assume your design has a logic hierarchy as shown in Figure 7 and you want to implement the following library restrictions during optimization and clock tree synthesis: Use only the cells from the library named LVT_lib for the Sub1 block and its subblocks, SubA and SubB.\n Do not use the cells from this library anywhere else in the design.\n To do so, use the following settings: fc_shell> set_target_library_subset -objects {top/Sub1} \\ -only_here [get_lib_cells LVT_lib/*] [get_libs LVT_lib] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 In addition to these settings, assume you specify the following setting: fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} Then, when adding buffers on the clock network during clock tree synthesis, the tool uses The buf1 and buf2 cells from the LVT_lib library for the block named Sub1 and its subblocks The buf1 and buf2 cells from the HVT_lib library for the rest of the design Reporting Target Library Subsets To find out which target library subsets have been defined for a top block or hierarchical cell, use the report_target_library_subset command.\n Reports that are generated by reporting commands, such as report_cells and report_timing, show the td attribute attached to the cells that are specified by the -dont_use or -only_here option.\n Removing Target Library Subsets To remove a target library subset restriction from a top block or hierarchical cell, use the remove_target_library_subset command."}
{"instruction": "How do I Handling Tap Columns and Relative Placement Group Overlaps", "input": "", "output": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option.\n The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns.\n This application option helps the relative placement engine know about the distance between the tap columns.\n 806 Changing the Structures of Relative Placement Groups Feedback This helps in better placement and structures of relative placement groups in the design.\n You must use this application option for n5 and older technical nodes.\n For n3 and beyond designs, the distance between tap columns is calculated automatically.\n place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}
{"instruction": "How do I Reporting the Routing Results", "input": "", "output": "To report statistics about the routing results, use the report_design -routing command.\n This command reports the following information: Final wiring statistics, including the Number of signal net shapes for each metal layer Signal wire length for each metal layer Number of PG net shapes for each metal layer PG wire length for each metal layer Horizontal and vertical wire distribution for each metal layer Total number of signal net shapes for the block Total signal wire length for the block Final via statistics, including the Simple vias used in each via layer, including the number of instances of each via Double via conversion rate for each via layer Double via conversion rate for the block Custom vias used in the block, including the number of instances of each user- defined via By default, this command reports the information only for the top-level block.\n To report the information for the entire physical hierarchy, use the -hierarchical option.\n See Also Defining Vias"}
{"instruction": "How do I Scan Registers", "input": "", "output": "When a design switches between the functional and scan modes, glitches might occur on asynchronous set and reset lines of scan registers, which can reset the state of these registers.\n The tool can prevent this by adding gating logic to the asynchronous set and reset lines.\n To enable this feature, you must specify a top-level port to control the gating logic by using the set_register_async_gating_pin -port command.\n This control port must be a predefined port in the RTL that is not connected to any other net.\n To get information about such gated scan registers, run the report_async_gated_registers command after physical synthesis.\n The added gating logic can be an AND or OR gate, depending on the polarity of the asynchronous pins on the scan registers.\n When gating logic is added, the Formality tool requires additional information to verify the design and the Fusion Compiler tool generates an appropriate.svf file that disables the gating logic in the functional mode.\n Note: This feature is supported only for the in-compile DFT flow.\n 260 Specifying Settings for Performance, Power, and Area Improvement Feedback"}
{"instruction": "How do I Specifying Via Ladder Candidates for Library Pins", "input": "", "output": "To specify the valid via ladders that can be used for a given library pin during preroute optimization, use the set_via_ladder_candidate command.\n You can specify only one via ladder each time you use the set_via_ladder_candidate command.\n To specify multiple via ladder candidates for a library pin, use the command multiple times, as shown in the following example: fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP4\" 181 Specifying Settings for Preroute Optimization Feedback fc_shell> set_via_ladder_candidate [get_lib_pins lib1/AND2/A1] \\ -ladder_name \"VP2\" The order in which you specify multiple via ladders for the same library pin indicates the priority to use when selecting a via ladder to insert for that pin.\n Specify the via ladder candidates starting with the highest priority.\n In the previous example, the tool gives the VP4 via ladder priority over the VP2 via ladder.\n Note: If both the pattern_must_join attribute and a via ladder candidate apply to a pin, the via ladder has a higher priority than the pattern-based must-join connection when both methods have the same estimated delay.\n To specify that a library pin requires an electromigration via ladder, set the is_em_via_ladder_required pin attribute to true, as shown in the following example: fc_shell> set_attribute [get_lib_pins lib1/INV4/A] \\ is_em_via_ladder_required true If you set the is_em_via_ladder_required pin attribute to true for a specific library pin, you must specify an electromigration via ladder as a candidate with the set_via_ladder_candidate command.\n A via ladder can be identified as an electromigration via ladder by using one of the following methods: By using the forElectromigration=1 construct when defining the via rule in the technology file, as shown in the following example: ViaRule \"EMVP1\" {...\n...\n...\n forElectromigration=1 By setting the for_electro_migration attribute to true, as shown in the following example: fc_shell> set_attribute [get_via_rules EMVP1] \\ for_electro_migration true See Also Defining Via Ladder Rules 182 Specifying Settings for Preroute Optimization Feedback"}
{"instruction": "How do I Performing On Route Placement of Repeaters", "input": "", "output": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command.\n place_group_repeaters \\ -cells cell_list | -repeater_groups group_id_list [-lib_cell_input pin_name ] \\ [-lib_cell_output pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}
{"instruction": "How do I Timing-Driven Global Routing", "input": "", "output": "By default, the route_global command is not timing-driven.\n To enable timing-driven global routing, set the route.global.timing_driven application option before you run the route_global command.\n During timing-driven global routing, the global router considers the impact of layer resistance by minimizing the usage of pin access layers, even if this increases wire length.\n By default, when you enable timing-driven global routing, the tool 1.\n Calculates the net delays of the block If the design library contains global route information, the tool uses the global route information to calculate the net delays; otherwise, it uses virtual routing to calculate the net delays.\n The global routing results can vary depending on whether the initial net delays were calculated by using global route information or virtual routing.\n To remove existing global route information from the signal nets in the block, use the -global_route and -net_types signal options with the remove_routes command, as shown in the following example: fc_shell> remove_routes -global_route -net_types signal 2.\n Performs an initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell 529 Routing Signal Nets Feedback 3.\n Performs two rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows 4.\n Updates the design timing based on the first three global routing phases 5.\n Identifies newly critical nets based on the timing update 6.\n Performs three rerouting phases, in which the tool rips up and reroutes the newly critical nets To increase the number of rerouting phases after the timing update, set the global routing effort level to high or ultra by using the -effort_level option with the route_global command.\n To reduce runtime, at a possible cost to the timing QoR, set the route.global.advance_node_timing_driven_effort application option.\n When you set this application option to medium, the tool rips up and reroutes the newly critical nets only if doing so does not increase congestion.\n In addition, the number of rerouting phases is reduced for medium-, high-, and ultra-effort global routing.\n When you set this application option to low, the tool does not perform the timing update and the number of rerouting phases is reduced for medium, high-, and ultra- effort global routing.\n The following table summarizes the timing-driven global routing behavior based on the effort level settings.\n The shaded cell shows the default behavior.\n Table 32 Number of Rerouting Phases Based on the Effort Level Settings route.global.advance_node_timing_driven_effort setting route_global -effort_level setting low medium high (default) low medium (default) 3,4 3,5 high 3,4 3,4 ultra 3,4 3,4 To control the tradeoff between timing QoR and DRC convergence, set the route.global.timing_driven_effort_level application option.\n By default, this option has a setting of high, which favors timing QoR over DRC convergence.\n 3.\n Timing update performed after the second rerouting phase.\n 4.\n Newly critical nets are ripped up and rerouted only if it does not increase congestion.\n 5.\n Newly critical nets are always ripped up and rerouted.\n 530 Routing Signal Nets Feedback"}
{"instruction": "How do I Specifying Cut Space and Cut Distance for Repeater Groups", "input": "", "output": "Use one of the following mutually exclusive options to control cutting for repeater groups: -layer_cutting_spacing specifies the cut space of the routes to the driver pin.\n The cut starts from the driver side.\n -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}
{"instruction": "How do I Enabling Local Skew Optimization", "input": "", "output": "During clock tree synthesis, by default, the tool tries to minimize the global skew, which is the difference between the longest and shortest clock paths.\n If there is no timing path between the registers with the longest and shortest clock paths, optimizing global skew does not improve the timing QoR of the design.\n However, by optimizing the local skew, which is the worst skew between launch and capture registers of timing paths, you can improve the timing QoR of the design.\n During local skew optimization, the tool works on improving local skew of all violating setup and hold timing paths.\n To enable local skew optimization during the clock tree synthesis and clock tree optimization stages of the synthesize_clock_trees and clock_opt commands, set the cts.compile.enable_local_skew and cts.optimize.enable_local_skew application options to true fc_shell> set_app_options -list {cts.compile.enable_local_skew true} fc_shell> set_app_options -list {cts.optimize.enable_local_skew true} When you enable local skew optimization using the previous settings, by default, the tool derives skew targets that help improve the timing QoR, and ignores the target skew you 360 Specifying the Clock Tree Synthesis Settings Feedback specify with the set_clock_tree_options -target_skew command.\n To prevent the tool from deriving skew targets, use the following application option setting: fc_shell> set_app_options \\ -name cts.common.enable_auto_skew_target_for_local_skew -value false"}
{"instruction": "How do I Via Ladder Rule Files", "input": "", "output": "The command generates two via ladder rule files: An XML file that provides information about the via ladder rules The XML file has the following syntax: <EmRule> <!\n template definition > <Template name=\" rule_name \" for_electro_migration=\"true\" for_high_performance=\"true\"> <Layer name=\" layer_name \" row_number=\" cuts_per_row...\n more layers </Template> \u2026 more templates </EmRule> Each Template section specifies the template for a via ladder rule.\n Within a template section, the via ladder structure is specified by specifying the number of cuts per row for each metal layer involved in the via ladder.\n By default, the generated XML file is named auto_perf_via_ladder_rule.xml.\n To specify a different name, use the -xml_file option.\n A script file that defines the via ladder rules The script file contains a create_via_rule command for each template defined in the XML file, as well as set_attribute commands to set the appropriate via rule attributes.\n By default, the generated script file is named auto_perf_via_ladder_rule.tcl.\n To specify a different file name, use the -rule_file option."}
{"instruction": "How do I Finding Substitute Locations for Invalid Taps", "input": "", "output": "If the specified location for a tap is invalid, use the -snap_distance option of the create_taps command to find a substitute location for the tap.\n The command searches the nearby layout shapes within the specified snap distance both horizontally and vertically on the same layer as defined by the -layer option.\n The tap is reinserted at the corner of a valid shape which is within the minimum distance to the specified location.\n Note: You can search for a substitute location only for the invalid taps that are specified by the -point and -layer options.\n For example, fc_shell> create_taps -point {50,50} -layer {M1} \\ -snap_distance 100 Snap tap point from original location (50.000, 50.000) to new location (90.000, 65.910) As shown in Figure 201, the specified tap location does not touch any layout shape.\n The red rectangle is the shape closest to the specified location and its lower-right corner has 889 Missing Via and Unconnected Pin Checking Feedback the minimum distance among all the other rectangles.\n The tool reinserts the tap at the lower-right corner of the red rectangle.\n Figure 201 Finding a Substitute Location for an Invalid Tap Original {x,y} 100 100 100 100 Snapped tap"}
{"instruction": "How do I Checking for Filler Cell DRC Violations", "input": "", "output": "By default, the remove_stdcell_fillers_with_violation command checks for DRC violations between all cell instances with xofiller in their name and top-level signal routing objects and removes the violating filler cells.\n You can control the following aspects of the filler cell checking: The string used to identify the filler cells To specify a different string to identify the filler cells, use the -name option.\n The region in which to check for violations To restrict filler cell check to specific regions, use the -boundary option.\n 642 Inserting Filler Cells Feedback The checked objects To check for violations between filler cells and all neighboring objects, such as signal net shapes, other filler cells, standard cells, PG rails, and terminals, use the -check_between_fixed_objects true option.\n Restrict DRC to shorts-checking only By default, the command removes all filler cells that cause a routing DRC violation.\n To remove only those filler cells that cause a short by overlapping a routing shape, use the -shorts_only true option.\n Whether double-patterning rules are checked The command checks for double-patterning violations only when the following criteria are met: The route.common.color_based_dpt_flow application option is true The technology file defines double-patterning rules To check for DRC violations on filler cells before removing them, use the -check_only true option.\n When you use this option, this command writes a report to a file named block _fillers_with_violation.rpt in the current working directory.\n The report lists the filler cells with violations and reports the first violation for each filler cell."}
{"instruction": "How do I Specifying the Orientation of Relative Placement Groups", "input": "", "output": "The Fusion Compiler tool supports the following orientations for relative placement groups: R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top.\n R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom.\n MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation.\n MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation.\n Figure 182 shows how the column and row positions in a relative placement group are placed for the four orientations.\n 802 Specifying Options for Relative Placement Groups Feedback Figure 182 Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length.\n You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command.\n For example, the following command sets the relative placement group orientation to MY.\n fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy.\n 803 Specifying Options for Relative Placement Groups Feedback Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}
{"instruction": "How do I Ensuring Clock Tree Exceptions are Valid", "input": "", "output": "To identify pins on the clock network, the tool checks if the is_clock_is_used_as_clock pin attribute is true during clock tree synthesis.\n If you use the set_clock_balance_points command to specify a clock tree exception on a pin for which the is_clock_is_used_as_clock attribute is false, the tool accepts the exception, but ignores it during clock tree synthesis.\n 347 Defining the Clock Trees Feedback Consider the clock network in the following figure.\n Figure 75 Specifying Exceptions on Pins Beyond the Clock Network CLK U2 FF3 n5 By default, the tool sets The is_clock_is_used_as_clock attribute of the U2/A, U2/Y, and FF3/D pins to false and considers the network beyond the U2/A pin as part of the data network The U2/A pin as an ignore pin and excludes the network beyond this from clock tree synthesis During clock tree synthesis, the tool adds a guide buffer and isolates the U2/A pin from the rest of the clock network.\n During subsequent data path optimization, the tool can fix any existing DRC violations beyond the guide buffer.\n Assume you want clock tree synthesis to fix DRC violations up to the FF3/D pin using clock tree constraints.\n To do so, you must 1.\n Specify the FF3/D pin as an explicit ignore pin as follows: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins FF3/D] 348 Defining the Clock Trees Feedback 2.\n Force clock tree synthesis to consider the FF3/D pin as a pin on the clock network by using the set_sense -clock_leaf command as follows: fc_shell> set_sense -clock_leaf [get_pins FF3/D] The set_sense -clock_leaf command sets The is_clock_used_as_clock attribute to true for all the pins of the clock branches that fanin to the pin specified as the clock leaf The is_clock_used_as_clock attribute to false for all the pins in the fanout from the pin specified as the clock leaf, and the tool does not propagate the clock beyond this pin To check the value of the is_clock_used_as_clock pin attribute, use the get_attribute command, as shown in the following example: fc_shell> get_attribute [get_pins FF3/D] is_clock_used_as_clock"}
{"instruction": "How do I Removing Routing Blockages", "input": "", "output": "To remove routing blockages from the current block, use the remove_routing_blockages command.\n To remove specific routing blockages, specify the routing blockages, either as a list or collection, such as that returned by the get_routing_blockages command.\n To remove all routing corridors, specify the -all option.\n 473 Routing Constraints Feedback"}
{"instruction": "How do I Specifying the Net Names, Buffers Types, and Their Locations", "input": "", "output": "When you use the add_buffer_on_route command, you must specify the following: The net on which to add buffers The type of buffers to add and where to add them on the net by using one of the following methods: Adding Buffers in a Specified Configuration Adding Buffers at Specified Locations Adding Buffers at a Specified Interval Adding Buffers at an Interval That is a Ratio of the Net Length Adding Buffers on a Bus in a Specified Pattern 964 Adding Buffers on Routed Nets Feedback"}
{"instruction": "How do I Replacing Clock Gates", "input": "", "output": "If you want to replace all the technology-independent clock gates in your RTL with integrated clock-gating cells from the libraries, use the replace_clock_gates command before executing the compile_fusion command.\n The replace_clock_gates command identifies combinational elements in the clock network acting as clock gates and replaces them.\n When you use the replace_clock_gates command, the tool honors the constraints specified by the set_clock_gate_style set_lib_cell_purpose, and set_target_ligrary_subset commands when it selects a library cell.\n When the tool identifies combinational elements, these elements must have only two input pins (the clock pin and the enable signal pin) and only one output pin.\n If the cell does not meet these criteria, the cell is not a candidate for replacement.\n The following table lists the WVGTECH instances and their replacement cells.\n Combinational Cell in RTL Integrated Clock Gate Replacement AND gate Rising-edge triggered latch-based clock gate OR gate Falling-edge triggered latch-based clock gate NAND gate Falling-edge triggered latch-based clock gate.\n Clock input pin is inverted.\n NOR gate Falling-edge triggered latch-based clock gate.\n Both input pins are inverted.\n The new clock-gating cell is inferred with the following name: rep_clock_gate_+<instance_name_of_combinational_cell> The tool reports replaced clock gates as tool-inserted clock gates."}
{"instruction": "How do I Controlling the Optimization of Relative Placement Cells", "input": "", "output": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed.\n When a relative placement cell is removed during optimization, the relative 805 Specifying Options for Relative Placement Groups Feedback placement information of the instance is also removed, disrupting the relative placement structure.\n To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting Allow unrestricted optimization of the relative placement cells all_opt Allow only sizing of the relative placement cells size_only Allow only in-place sizing of the relative placement cells size_in_place Prevent any optimization of the relative placement cells no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}
{"instruction": "How do I Importing the Floorplan Information", "input": "", "output": "A floorplan contains physical constraints such as the core area and shape, port locations, macro locations and orientations, and so on, which are required for performing physical synthesis and optimization.\n 103 Importing the Floorplan Information Feedback If you have a floorplan for your block, read in the floorplan as a DEF file, as described in Reading DEF Files If you do not have a floorplan for your block, you can perform design planning and generate a floorplan as described in the Fusion Compiler Design Planning User Guide During the early stages of design process, you can use automatically-generated floorplan information to run physical synthesis, as described in Using Automatic Floorplanning"}
{"instruction": "How do I Prerequisites for Routing", "input": "", "output": "Before you can run Zroute, you must ensure that the block and physical library meet the following requirements: Library requirements Zroute gets all of the design rule information from the technology file; therefore, you must ensure that all design rules are defined in the technology file before you start routing.\n For more information about the technology file and defining routing design rules, see the Synopsys Technology File and Routing Rules Reference Manual Block requirements Before you perform routing, your block must meet the following conditions: Power and ground nets have been routed after design planning and before placement.\n For more information, see the Fusion Compiler Design Planning User Guide Clock tree synthesis and optimization have been performed.\n For more information, see Clock Tree Synthesis Estimated congestion is acceptable.\n Estimated timing is acceptable (about 0 ns of slack).\n Estimated maximum capacitance and transition have no violations.\n To verify that your block meets the last three prerequisites, you can check the routability of its placement as explained in Checking Routability 442 Defining Vias Feedback"}
{"instruction": "How do I Applying Required Settings for High Performance Cores", "input": "", "output": "You can apply tool settings required for achieving the best QoR for high performance cores by using the set_hpc_options command.\n The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis.\n To List the supported high performance core types and implementation stages, use the -list option Specify the type of high performance core, use the -core option Specify the stage of the implementation flow, use the -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the set_technology command before you run the set_hpc_options command, as shown in the following example script: set_technology -node 7 set_hpc_options -core A72 -stage clock_opt_cts...\n clock_opt -from build_clock -to route_clock...\n 209 Applying Mega-Switch Command Settings Feedback set_hpc_options -core A72 -stage clock_opt_opto...\n clock_opt -from final_opto...\n set_hpc_options -core A72 -stage route_auto...\n route_auto...\n set_hpc_options -core A72 -stage route_opt...\n route_opt..."}
{"instruction": "How do I Merging Clock Gates", "input": "", "output": "By merging clock gates, the tool attempts to minimize the number of clock gates while maximizing clock-gating coverage.\n The tool looks for clock-gating cells that share a common clock and enable signal.\n This feature is on by default.\n The fanout of clock-gating cells in different hierarchies can be moved to a clock-gating cell in a common ancestor if there is no restriction preventing port punching.\n Note that the the tool also checks clock-gating style and multivoltage constraints.\n Clock-gating cells with the dont_touch or size_only constraints are not optimized.\n To disable this feature, use the set_clock_gate_transformations command.\n 313 Setting Clock Gating Transformations Feedback"}
{"instruction": "How do I Controlling IR-Drop-Aware Placement", "input": "", "output": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells.\n Figure 22 Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in Figure 22 The upper category consists of the top one percent of the total number of cells with the highest voltage drop values.\n During placement, the tool spreads these cells the most.\n The middle category consists of the next five percent of the cells.\n During placement, the tool spreads these cells less than those in the upper category.\n The lower category consists of the rest of the cells.\n The tool does not spread these cells.\n 160 Specifying Placement Settings Feedback You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options.\n The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false.\n They are true by default.\n The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa.\n The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ 161 Specifying Legalization Settings Feedback -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command.\n The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"instruction": "How do I Creating Constraints for Auto Floorplanning", "input": "", "output": "Use the commands and application options described in this topic to create constraints for auto floorplanning.\n Commands Use the following two commands to set and report auto floorplanning constraints.\n These two commands do not affect explicit floorplanning.\n set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile.\n For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8 report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command.\n To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands: Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin Pin placement constraints set_block_pin_constraints set_individual_pin_constraints Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning.\n compile.auto_floorplan.initialize (default: auto auto : Creates missing floorplan information.\n The tool exits with an error when inconsistent information is provided.\n true : Always creates the core and boundary.\n false : Never creates the core and boundary; uses only existing information.\n The tool exits with an error when encountering missing or inconsistent information.\n 111 Importing the Floorplan Information Feedback By default, the following objects are preserved: Existing placement of fixed macros Existing placement of pins and pads Existing shaping of voltage areas compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped all : Always places and shapes objects even if they are fixed.\n Unplaced and unshaped objects will always be placed and shaped.\n unfixed : Places and shapes objects that are not fixed.\n Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify.\n Unplaced and unshaped objects will always be placed and shaped.\n unplaced, unshaped : Never places or shapes objects when they are already placed.\n Unplaced and unshaped objects will always be placed and shaped.\n none : Never places or shapes objects even if they are not already placed.\n This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning.\n Application option setting Fixed objects Placed objects Unplaced objects all Placed and shaped Placed and shaped Placed and shaped unfixed Kept Placed and shaped Placed and shaped unplaced, unshaped Kept Kept Placed and shaped none Kept Kept Kept compile.auto_floorplan.keep_bounds (default: auto 112 Setting Up Multivoltage Designs Feedback auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing bounds.\n false : Removes existing bounds.\n compile.auto_floorplan.keep_placement_blockages (default: auto auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas true : Keeps existing placement blockages.\n false : Removes existing placement blockages.\n Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}
{"instruction": "How do I Setting Clock Tree Design Rule Constraints", "input": "", "output": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis: clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the set_max_capacitance command.\n If you do not specify this constraint, the clock tree synthesis default is 0.6 pF.\n clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the set_max_transition command.\n If you do not specify this constraint, the clock tree synthesis default is 0.5 ns.\n By default, these constraints apply to all corners associated with the current mode.\n To set the constraint for a specific mode, use the -mode option with the get_clocks command to identify the clocks.\n To set the constraint for specific corners associated with the specified mode, use the -corners option with the constraint command.\n Be careful to apply the correct constraints across all the modes and their associated corners.\n For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell> set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the -mode option with the get_clocks command to specify the mode and use the -corners option to specify the corner.\n For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell> set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell> set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell> set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]] 356 Specifying the Clock Tree Synthesis Settings Feedback"}
{"instruction": "How do I Sorting and Filtering the Data", "input": "", "output": "You can sort and filter the run data to reveal patterns in the results and determine the parameters you want to explore further.\n To sort and filter the data, see the following topics: Sorting the Data Filtering Metrics Filtering Runs Example Analysis See Also Exploring the Detailed Comparison Data 274 Performing Design Analysis Feedback Sorting the Data Click any column header to sort the data using that metric.\n The first click performs an ascending sort, while the second click performs a descending sort.\n For example, to show the worst TNS numbers at the top of the table and the best TNS numbers at the bottom, click the TNS column header: Click the TNS column header again to show the best TNS numbers at the top and the worst at the bottom: 275 Performing Design Analysis Feedback Filtering Metrics To control which metrics are displayed in the table, click the Metrics button and select or deselect the metrics from the Metrics dialog box accordingly.\n For example, to show only the setup timing, netlist area, and cell counts, select the metrics as shown in Figure 39 Figure 39 Metrics Dialog Box Filtering Runs To control which runs are displayed in the table, click the Runs button and select or deselect the exploration runs accordingly from the Visible Runs (Summary) column.\n For example, to display only the first four runs in a table, select the runs as shown in Figure 40 Figure 40 Choose Baseline and Visible Runs Dialog Box 276 Performing Design Analysis Feedback Example Analysis The following example demonstrates how you might sort and filter your data to narrow down the runs you would like to explore further.\n Suppose you open the comparison report shown in Figure 41 and set the util60_aspect1%1_layerM9 run as the base run.\n Figure 41 Comparison Report You could look at your TNS numbers first and sort the data from best TNS to worst TNS, as shown in the following figure: Notice that the best TNS runs have the M9 top layer, and the worst have the M7 top layer.\n This suggests that restricting the metal layers significantly impacts timing.\n 277 Performing Design Analysis Feedback You could then restrict your analysis to your M9 runs by turning off the visibility of your M7 runs, as shown in the following figure: Now that you have your best TNS runs, you could compare their congestion by sorting the GRCOverflow column to show the worst overflow at the top, as shown in the following figure: Notice that your higher-utilization runs have more congestion than your lower-utilization runs.\n You could restrict your analysis to your lower-utilization runs by turning off the 278 Performing Design Analysis Feedback visibility of your higher-utilization runs as shown in Figure 42, leaving you with a manageable subset of exploration runs that better meet your timing and congestion goals.\n Figure 42 Displaying Lower-Utilization Runs"}
{"instruction": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges", "input": "", "output": "To insert maximum pattern routing guides along the nonpreferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects mprg_nonpreferred option.\n When you specify this object type, the command creates maximum pattern routing guides parallel to each nonpreferred-direction boundary edge.\n The maximum edge threshold for these routing guides is zero.\n 486 Routing Constraints Feedback By default, The routing guides are inserted only in the top-level block To insert routing guides in all soft macros in a hierarchical block, use the -hierarchical option.\n The routing guides are inserted on all routing layers To insert the routing guides only on specific routing layers, use the -layers option.\n The routing guides have the default metal width specified for the routing layer in the technology file To specify a different width in microns, use the -width_nonpreferred option.\n For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual The routing guides abut the preferred-direction edges The routing guides are offset from the nonpreferred-direction edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns, use the -spacing_nonpreferred option.\n For information about specifying the minimum spacing for a layer, see the \"Minimum Spacing Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual Figure 104 shows the routing guides inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n S is the spacing specified by the -spacing_nonpreferred option.\n W is the width specified by the -width_nonpreferred option.\n 487 Routing Constraints Feedback Figure 104 Routing Guide Perimeter Constraint Objects See Also Using Routing Guides to Limit Edges in the Nonpreferred Direction"}
{"instruction": "How do I Querying Placement Blockages", "input": "", "output": "To return a collection of placement blockages in the current block that match certain criteria, use the get_placement_blockages comandcomandsget_placement_blockages get_placement_blockages command."}
{"instruction": "How do I Trunk Splitting", "input": "", "output": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split.\n custom.route.bus_split_ignore_width custom.route.bus_split_even_bits The custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section.\n The custom.route.bus_split_even_bits application option requires that you set the custom.route.bus_split_ignore_width application option.\n If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes).\n In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set.\n The spacing between the power and ground rails can accommodate three bits only.\n Figure 163 a shows the two possible results when the custom.route.bus_split_even_bits application option is turned off.\n Figure 163 b shows the result when the custom.route.bus_split_even_bits application option is turned on.\n Figure 163 Splitting Bus Trunk to Route Through Power and Ground Rails 768 Using Custom Routing Application Options Feedback"}
{"instruction": "How do I Registers", "input": "", "output": "Before you run the compile_fusion command on an RTL design, you can create a multibit bus consisting of specific unmapped single-bit registers by using the create_multibit command.\n Then, when you run the compile_fusion command, 247 Performing Multibit Optimization Feedback during the initial_map stage, the tool maps the single-bit cells of the bus created by the create_multibit command into a multibit register bank.\n The single-bit registers you specify with the create_multibit -sort command must Be unmapped Be of the same type Be in the same logical hierarchy Not be part of an existing bus In the following example, the single-bit cells are combined in alphanumeric descending order, which is reg4, reg3, reg2, and reg1: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort descending fc_shell> compile_fusion In the following example the single-bit cells are combined in alphanumeric ascending order, which is reg1, reg2, reg3, and reg4: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort ascending fc_shell> compile_fusion In the following example, the single-bit cells are combined in the specified order, which is reg2, reg4, reg1, and reg3: fc_shell> set_app_option -name compile.flow.enable_multibit -value true fc_shell> create_multibit {reg2 reg4 reg1 reg3} -sort none fc_shell> compile_fusion Note: You must set the compile.flow.enable_multibit application option to true before you run the create_multibit command on unmapped single bit registers.\n If not, the tool issues the following error message: Error: create_multibit command failed: multibit flow is disabled.\n (MBIT-068)"}
