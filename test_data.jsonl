{"instruction": "How do I Mapping ECO Cells to Logically Equivalent Spare Cells", "input": "", "output": "To map an ECO cell to a specific spare cell, use the map_freeze_silicon command.\n Specify the ECO cell name and the corresponding spare cell name by using the -eco_cell and -spare_cell options.\n The following example maps the ECO cell named ECO1 to the spare cell named spare_1: fc_shell> map_freeze_silicon -eco_cell ECO1 -spare_cell spare_1 You can specify the ECO cell to spare cell mapping by using a map file and specifying this map file name by using the -map_file option with the map_freeze_silicon command.\n The map file has the following format: ECO_cell_1 spare_cell_1 ECO_cell_2 spare_cell_2...\n..."}
{"instruction": "How do I Updating Via Ladders", "input": "", "output": "To verify that the via ladders in the block match the via ladder constraints and are properly connected to pins, use the verify_via_ladders command.\n By default, this command checks all via ladders.\n To restrict the checking to specific nets, use the -nets option.\n Note: If you use the -shift_vias_on_transition_layers true option when you insert the via ladders, you must also use this option when you verify the via ladders; otherwise, the command reports false violations.\n A via ladder matches the via ladder constraints if the pattern of connected vias and wires for the via ladder structure satisfies any of the via ladder templates assigned to the connected pin.\n The command flags a violation in the following situations:  A via ladder is connected to a pin that does not have a via ladder constraint  A via ladder is connected to a pin with a via ladder constraint, but none of the templates correctly describe the current via ladder structure  A pin has a via ladder constraint, but does not have a via ladder connected to it       A via ladder is properly connected to a pin if all the via enclosures at the base of the via ladder touch the same pin and that pin is logically connected to the same net as the via ladder.\n The command flags a violation in the following situations:  An enclosure of the via ladder base touches a different pin, unless the pins are must- join pins that belong to the same must-join set  An enclosure of the via ladder base does not touch any pin  An enclosure of the via ladder touches a pin that is not of the same net as the via ladder By default, the verify_via_ladders command reports the via ladder insertion status for each target pin, which can result in a very large report.\n To limit the number of via ladders reported for each category to 40, use the -report_all_via_ladders false option with the verify_via_ladders command."}
{"instruction": "How do I Creating Skew Groups", "input": "", "output": "To define clock cell spacing rules, use the set_clock_cell_spacing command.\n At a minimum, you must specify the minimum spacing in the x-direction or the y-direction; typically you would specify the minimum spacing in both directions.\n To specify the minimum spacing in microns in the  X-direction, set the -x_spacing option to a nonzero value This value is usually dependent on the library cell's drive strength and clock frequency.\n        Y-direction, set the -y_spacing option to a nonzero value This value is usually less than half a row height.\n Note: Using a large spacing value increases the skew because the cells are spaced further away from the intended clusters of sinks.\n By default, the specified cell spacing requirements apply to all clock cells.\n To restrict the clock cell spacing rules to specific  Library cells, use the -lib_cells option  Clocks, use the -clocks option If adjoining clock cells both have cell spacing rules for a given direction, the sum of the spacing values applies.\n For example, if two adjoining clock cells both have a minimum cell spacing of 5 microns in the x-direction, they are placed at least 10 microns apart in the x-direction.\n You can relax the adjoining cell spacing rule by setting the cts.placement.cell_spacing_rule_style application option to maximum, in which case the tool uses the larger of the spacing settings between two adjoining cells instead of the sum of the spacing settings.\n For example, the clock cells in the previous example are placed at least 5 microns apart in the x-direction, instead of 10 microns.\n The clock cell spacing rules defined by the set_clock_cell_spacing command are honored by the synthesize_clock_trees balance_clock_groups, and clock_opt commands.\n To report clock cell spacing rules, use the report_clock_cell_spacings command.\n To remove clock cell spacing rules, use the remove_clock_cell_spacings command.\n By default, this command removes all clock cell spacing rules.\n To remove specific clock cell spacing rules, use the -lib_cells option."}
{"instruction": "How do I Synthesizing the Top-Level", "input": "", "output": "To synthesize a subblock and generate the block-level information required for top-level synthesis, perform the following steps: 1.\n Read in a subblock design library generated after the rebuild step as described in Partitioning and Planning the Full Chip Design 2.\n Apply any block-specific constraints and settings required for synthesizing the block.\n       3.\n Apply DFT settings by using commands such as set_dft_signal set_scan_configuration, and so on, and create a test protocol by using the create_test_protocol command.\n 4.\n Insert DFT logic and synthesize the block by using the following commands: fc_shell> compile_fusion -to logic_opto fc_shell> insert_dft fc_shell> compile_fusion -from initial_place 5.\n Create a read-only abstract view, frame view, and a test protocol, and save the block by using the following commands: fc_shell> create_abstract -read_only fc_shell> create_frame fc_shell> write_test_model BLOCK1.ctl fc_shell> save_block -as BLOCK1/PostSynthesis"}
{"instruction": "How do I Setting Up the Executables", "input": "", "output": "By default, when you execute the analyze_rail command to perform rail analysis, the RedHawk or RedHawk-SC tool is invoked to perform the specified analysis types with the input data and then load the analysis results back to the rail database when rail analysis is finished.\n You cannot run any Fusion Compiler commands unless the RedHawk Fusion or RedHawk-SC Fusion process is finished.\n To perform layout editing tasks while the tool is running in the background, run the analyze_rail -bg command.\n When analysis is completed, run the open_rail_result -back_annotate command to upload the analysis results to the rail database.\n By default, RedHawk or RedHawk-SC loads the analysis results back to the rail database when analysis is completed.\n However, when you specify the -bg option with the analyze_rail command, you need to run the open_rail_result -back_annotate command to reconstruct rail database and create the new RAIL_DATABASE file from the latest analysis results.\n       Note: When back-annotating the analysis results from the previous run after moving nets in the design, the instance-based map reflects the updated instance location change, but the parasitic map does not.\n When opening rail results, the tool does not detect if the result is generated with or without the -bg option.\n The command might not work correctly if you run the open_rail_result -back_annotate command to open the rail result that is generated without the -bg option, or vice versa.\n Reporting and Checking the Status of the Background Process When the RedHawk or RedHawk-SC Fusion process is finished, the tool issues the following message: Info: Running REDHAWK_BINARY in background with log file: LOG_FILE The LOG_FILE file is saved in the PWD directory.\n To check if the background analyze_rail process is active, use the report_background_jobs command."}
{"instruction": "How do I Incremental Signoff ECO Flow", "input": "", "output": "After you perform place and route in the Fusion Compiler tool, if your design has timing or design rule violations, you can fix these violations in the PrimeTime tool.\n You can also perform power or area recovery in the PrimeTime tool.\n       If you make changes to your design in the PrimeTime tool, you can generate an ECO change list file and incorporate those changes into the design by using the Fusion Compiler ECO capabilities, as shown in  Signoff ECO Flow Fusion Compiler ECO Yes No StarRC parasitic extraction ECO change list file PrimeTime timing ECO Violations?\n PrimeTime timing and signal integrity analysis PrimeTime area and power recovery ECO change list file Fusion Compiler ECO To incorporate the PrimeTime ECO changes, use the following steps: 1.\n Update the design by sourcing the PrimeTime ECO change list file, which is a Tcl file containing netlist editing commands.\n 2.\n Update the placement by using the place_eco_cells command as shown in the following example: place_eco_cells -legalize_mode minimum_physical_impact \\ -eco_changed_cells -legalize_only -displacement_threshold 10 For more information about the place_eco_cells command, see Placing ECO Cells 3.\n Add filler cells to the empty spaces in the site array, as described in Inserting Filler Cells       To reduce runtime, use the -post_eco option when you  Insert metal filler cells with the create_stdcell_fillers command, and the tool marks the inserted filler cells as post ECO cells  Remove filler cells with DRC violations with the remove_stdcell_fillers_with_violation command, and the tool performs DRC checking only for the post ECO cells 4.\n Update the routing by using the route_eco command, as described in Performing ECO Routing, or by manually rerouting the affected nets."}
{"instruction": "How do I Fixing Signal Electromigration Violations", "input": "", "output": "The comandsreport_signal_emreport_signal_em comand report_signal_em command performs signal electromigration analysis for each net by calculating the current on every edge and comparing this data with the constraints set by the read_signal_em_constraints command.\n For example, fc_shell> report_signal_em -violated -verbose       The report_signal_em command performs a timing update, if needed, and analyzes all nets for electromigration.\n The -verbose option causes the report to show detailed electromigration analysis information, which usually produces a very large report when used by itself.\n To get a report with a reasonable size, use the -violated option as well, which limits the report to only the nets with electromigration violations.\n To limit the analysis to specific nets, use the -nets option.\n set_em_options comandcomandset_em_options You can specify settings for electromigration analysis by setting the application options shown in the following table.\n Table 34 Application Options for Signal Electromigration Analysis Application option Default Description em.net_delta_temperature    em.net_duration_condition_for_peak    em.net_global_rms_relaxation_factor    em.net_metal_line_number      em.net_min_duty_ratio    em.net_use_waveform_duration false false true   em.net_violation_rule_types   When you perform signal electromigration analysis, the tool computes three current values:  Average  Root mean square  Peak The default report generated by the report_signal_em command lists the number of nets with electromigration violations and the types of constraints violated (mean, absolute       average, RMS, or peak).\n If you use the -verbose option, the report displays detailed information about the violations, as shown in Example 25 Example 25 Verbose Electromigration Report fc_shell> report_signal_em -violated -verbose...\n Net Name: clks/trimch_macroout_cb_group_gpaf0lts1_gpu_c_0_s_0[3] Violations: RMS PEAK  Flag Segment Layer BBox Coordinates Width/Cut Required AVERAGE RMS PEAK  v PATH_36_392230 M6D (1450.000, 995.612 -> 1452.715, 995.652) 0.040 0.085 1.514e-02 (-) 9.650e-01 (5.231e-01) 1.365e+00 (1.349e+00) VIA_S_11051278 V5D (1449.969, 995.582 -> 1450.071, 995.682) 1 - 1.465e-02 (-) 7.380e-01 (-) 1.044e+00 (-) v PATH_35_765189 M5A (1450.001, 994.973 -> 1450.039, 995.651) 0.038 0.047 1.417e-02 (-) 6.088e-01 (4.981e-01) 8.609e-01 (1.274e+00) VIA_S_11051279 V5D (1449.969, 994.942 -> 1450.071, 995.042) 1 - 1.369e-02 (-) 5.249e-01 (-) 7.423e-01 (-) PATH_36_392231 M6D (1407.370, 994.972 -> 1450.040, 995.012) 0.040 - 1.311e-02 (-) 2.047e-01 (5.231e-01) 2.894e-01 (9.443e-01) VIA_S_11051280 V5D (1407.339, 994.942 -> 1407.441, 995.042) 1 - 1.252e-02 (-) 1.926e-01 (-) 2.723e-01 (-)...\n The report shows the segment name (Segment column), layer name (Layer column), location coordinates (Bbox Coordinates column), metal width or via cut number (Width/Cut column), the constraint value (Required column), the average, RMS, and peak current in mA for the wire segment or via at that location.\n The letter \"v\" in the Flag column indicates a violation at that location.\n A hyphen in the Required column means that there is no electromigration constraint for that metal or via layer.\n In the AVERAGE, RMS, and PEAK columns, the first value is the calculated value and the value in parenthesis is the limit imposed by the electromigration constraints, where a hyphen indicates that there is no electromigration constraint."}
{"instruction": "How do I Naming Convention for Tool-Inserted Clock Gates", "input": "", "output": "Clock gating applies to synchronous load-enable registers, which are flip-flops that share the same clock and synchronous control signals.\n Synchronous control signals include synchronous load-enable, synchronous set, synchronous reset, and synchronous toggle.\n Synchronous load-enable registers are represented by a register with a feedback loop that maintains the same logic value through multiple cycles.\n Clock gating applied to synchronous load enable registers reduces the power needed when reloading the register banks.\n  shows a simple register bank implementation using a multiplexer and feedback loop.\n  Synchronous Load-Enable Register With Multiplexer Flip Flop Mux Control Logic Register Bank EN CLK DATA IN   DATA OUT When the synchronous load enable signal (EN) is at logic state 0, the register bank is disabled.\n In this state, the circuit uses the multiplexer to feed the Q output of each storage element in the register bank back to the D input.\n When the EN signal is at logic state 1, the register is enabled, allowing new values to load at the D input.\n       These feedback loops can unnecessarily use power.\n For example, if the same value is reloaded in the register throughout multiple clock cycles (EN equals 0), the register bank and its clock net consume power while values in the register bank do not change.\n The multiplexer also consumes power.\n Clock gating eliminates the feedback net and multiplexer shown in by inserting a gate in the clock net of the register.\n Note: While applying the clock-gating techniques, the tool considers generated clocks similar to defined clocks.\n The clock-gating cell selectively prevents clock edges, thus preventing the gated-clock signal from clocking the gated register.\n  shows a latch-based clock-gating cell and the waveforms of the signals are shown with respect to the clock signal, CLK.\n  Latch-Based Clock Gating Flip Flop Control Logic Register Bank    Latch CLK ENCLK ENL EN CLK DATA IN DATA OUT CLK CLK EN ENL ENCLK The clock input to the register bank, ENCLK, is gated on or off by the AND gate.\n ENL is the enabling signal that controls the gating; it derives from the EN signal on the multiplexer shown in.\n The register bank is triggered by the rising edge of the ENCLK signal.\n The latch prevents glitches on the EN signal from propagating to the register's clock pin.\n When the CLK input of the 2-input AND gate is at logic state 1, any glitching of the EN signal could, without the latch, propagate and corrupt the register clock signal.\n The latch eliminates this possibility because it blocks signal changes when the clock is at logic 1.\n       In latch-based clock gating, the AND gate blocks unnecessary clock pulses by maintaining the clock signal's value after the trailing edge.\n For example, for flip-flops inferred by HDL constructs of rising-edge clocks, the clock gate forces the gated clock to 0 after the falling edge of the clock.\n By controlling the clock signal for the register bank, you can eliminate the need for reloading the same value in the register through multiple clock cycles.\n Clock gating inserts clock-gating circuitry into the register bank's clock network, creating the control to eliminate unnecessary register activity.\n Clock gating does the following:  Reduces clock network power dissipation  Relaxes datapath timing  Reduces congestion by eliminating feedback multiplexer loops For designs that have large register banks, clock gating can save power and area by reducing the number of gates in the design.\n However, for smaller register banks, the overhead of adding logic to the clock tree might not compare favorably to the power saved by eliminating a few feedback nets and multiplexers."}
{"instruction": "How do I Fixing Multivoltage Violations", "input": "", "output": "Table 73 lists the messages of group repeater placement and insertion for the problems encountered during defining the group repeaters.\n Table 73 Group Repeater Placement and Insertion Troubleshooting Command Error Code Message Troubleshooting Tips place_group_repeat ers ECOUI-136 Error: The repeater group (%d) is invalid.\n    report_repeater_g roups        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-220 Warning: Failed to connect to route for %d object: {%s }.\n       place_group_repeat ers ECO-224 Error: The option -repeater_groups cannot be used when the app option eco.placement.eco_enable_ pipeline_register_placer is false.\n       place_group_repeat ers ECO-227 Warning: Failed to place %d repeaters for %d drivers in collection (%s), and failed cells are in collection (%s).\n   query_objects get_ports get_pins  get_cells     place_group_repeat ers ECO-228 Warning: Some repeaters from path driver (%s) have same repeater group id.\n The cells belonging to the path are {%s}.\n          place_group_repeat ers ECO-229 Warning: Failed to find intersection of cutline %s and route for cell {%s}.\n place_group_repeat ers ECO-231 Error: The repeater group (%d) has no cutline or invalid cutline.\n     set_repeater_gr oup        Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-232 Error: Cutline {{%s} {%s}} is invalid.\n      place_group_repeat ers unplace_group_repeat ers ECO-233 Error: The cells in collection (%s) are invalid since they have no target input pin name (%s) and output pin name (%s).\n       -lib_cell_input  -lib_cell_output     -lib_cell_input   -lib_cell_output  place_group_repeat ers ECO-234 Warning: There is no repeater to be placed for the path driver (%s).\n place_group_repeat ers ECO-235 Warning: There is no route on driver net (%s).\n place_group_repeat ers ECO-236 Warning: There is no target load for path driver (%s).\n place_group_repeat ers ECO-237 Warning: Some cell to be placed has no load for path driver (%s).\n place_group_repeat ers ECO-239 Info:%s.\n                Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-240 Error: The option -cells cannot be used when the app option eco.placement.eco_enable_ virtual_connection is true.\n    -repeater_groups    place_group_repeat ers ECO-241 Warning: The distance based placement does not support multi-fanout path driver(%s).\n     place_group_repeat ers unplace_group_repeat ers ECO-242 Warning: The cell (%s) has no driver or load (number of driver: %d, number of load: %d).\n place_group_repeat ers ECO-243 Error: The cells in collection (%s) are invalid since they have no driver or load.\n       place_group_repeat ers ECO-244 Warning: The %s %s has no shape.\n    place_group_repeat ers ECO-246 Warning: Skip the path driver (%s) since the driver or load for the path has no shape.\n place_group_repeat ers ECO-251 Info: Place group repeaters successfully.\n    place_group_repeat ers ECO-252 Warning: Failed to place repeaters for repeater path which driver is %s.\n place_group_repeat ers ECO-253 Warning: The cutline information %s for cell %s is not on valid route.\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-254 Warning: Failed to cut route for cell %s.\n    place_group_repeat ers ECO-255 Warning: Gap %s between driver and nearest route is larger than placing distance %s      place_group_repeat ers ECO-256 Warning: The first distance (%s) specified by command option is shorter than the gap (%s) between pin and route for driver (%s).\n (warning) The last distance (%s) specified by command option is shorter than the gap (%s) between pin and route for load (%s).\n  -first_distance -last_distance      place_group_repeat ers ECO-257 Warning: Cannot find cutline information for cell %s.\n place_group_repeat ers ECO-258 Info: The app option about virtual connection is turned on.\n Please make sure the cells in repeater group keep in order.\n  eco.placement.eco _enable_virtual_c onnection   place_group_repea ters -repeater_groups  place_group_repeat ers unplace_group_repeat ers ECO-259 Warning: The number of cells from repeater group (%d) is not consistent with the number of drivers from driver group (%s).\n place_group_repeat ers unplace_group_repeat ers ECO-260 Warning: The number of cells from repeater group (%d) is not consistent with the number of loads from load group (%s).\n       Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers unplace_group_repeat ers ECO-261 Warning: The number of path loads is less than the number of cells in group (%d), so skip these path loads.\n place_group_repeat ers unplace_group_repeat ers ECO-262 Warning: The number of path loads is not an integral multiple of the number of cells in group (%d), so use path loads in order.\n place_group_repeat ers ECO-265 Warning: The pin shape {%s} of %s (%s) is projected to route %s {%s}.\n       unplace_group_repeat ers ECO-266 Warning: The cells in collection %s which are not placed before cannot be unplaced by unplace_group_repeaters.\n       add_group_repeat ers   placed_group_repe aters  unplace_group_rep eaters  unplace_group_repeat ers ECO-267 Error: Input and output routes are not merged after unplacing repeater %s since the routes are not aligned or not at the same layer.\n               Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips place_group_repeat ers ECO-268 Error: The cells in collection (%s) are invalid since they are placed before.\n Apply the command unplace_group_repeaters to unplace them.\n    add_group_repeat ers   place_group_repea ters  add_group_repeaters place_group_repeat ers ECO-269 Error: Unable to check the current reference of cell '%s': %s.\n           add_group_repeaters place_group_repeat ers ECO-270 Error: Unable to find swappable variant reference for cell '%s': %s.\n     add_group_repeaters place_group_repeat ers ECO-271 Error: Candidate reference '%s' and reference (%s) of cell (%s) are not in the same variant cell group.\n          unplace_group_repeat ers ECO-272 Error: The mixed input cells are not supported, which includes the cells added by add_group_repeaters and the cells placed by place_group_repeaters.\n unplace_group_repeat ers ECO-273 Error: There are no placed cells to be unplaced.\n Please double check the cell status.\n          Table 73 Group Repeater Placement and Insertion Troubleshooting (Continued) Command Error Code Message Troubleshooting Tips ECO-274 Warning: You are deleting cell %s with eco_repeater_group_id %d.\n     place_group_repeat ers ECO-275 Error: Failed to traverse cutlines.\n The nets may have too many blockages.\n      -repeater_group"}
{"instruction": "How do I Inserting and Removing Cut Metal Shapes", "input": "", "output": "At advanced technology nodes, mask colors must be assigned to wires and vias to ensure correct processing of the net shapes during mask synthesis.\n The route_detail command and other routing commands in the tool usually add the necessary mask colors during routing.\n For net shapes that do not have a color assignment, use the derive_mask_constraint command to derive the color mask for the specified wires and vias from the nearest underlying tracks.\n In case of wide wires that occupy multiple tracks, the command takes the mask color opposite to the next unoccupied track.\n The following example derives the mask color for the net shapes of the net1 net.\n fc_shell> derive_mask_constraint \\ [get_shapes -of_objects [get_nets net1]]       Use options to the derive_mask_constraint command to control how the mask colors are derived.\n  Derive cut mask constraints for the specified nets or vias.\n fc_shell> derive_mask_constraint -derive_cut_mask \\ [get_vias -within {{600 600} {700 700}}]  Derive mask constraints from overlapping or touching pins or ports.\n fc_shell> derive_mask_constraint -follow_pin_mask \\ [get_shapes -of_objects [get_nets net1]]  Derive the mask constraint from the wider overlapping or touching object rather than the wire track.\n fc_shell> derive_mask_constraint -follow_wider_object_mask \\ [get_shapes -of_objects [get_nets net1]] See Also  Multiple-Patterning Concepts"}
{"instruction": "How do I Using the DRC Query Commands", "input": "", "output": "To report the total wire length at any stage of the routing flow, use the consolidated report_wirelength command.\n This command supports all net types, except power ground nets, by default such as signal nets, clock nets.\n It also supports non-stripe power ground nets by option control.\n This command generates a report, which includes the following information in the form of two tables, as shown in the figure:  Total wire length per layer with separate global and detailed routing lengths  Total wire length by both horizontal and vertical direction       In the generated report,  Virtual value means the estimated routing wire length for each net.\n For each net, the engine provides a virtual routing length before real routing.\n It remains even after route_auto  BestAvailable means the sum of wire length of all nets irrespective of the stage they are in the current design.\n This command also supports slanting wires and counts the real length of an angle wire in total and counts the projection length of the x-axis and y-axis."}
{"instruction": "How do I Fixing Diodes", "input": "", "output": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design.\n The command can perform the following changes:  Minimize the number of dual-rail buffers or inverters  Fix isolation violations in buffer trees  Fix buffers and inverters that have illegal settings, as follows:  Process, voltage, and temperature settings  Library cell purpose or subset settings  Target library subset settings  Bias voltages  Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows:  Swap buffer library cells to fix illegal settings  Swap single-rail buffers for dual-rail buffers  Swap dual-rail buffers for single-rail buffers  Change the backup supplies of dual-rail buffers and inverters  Change the input or output supplies of level shifters  Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough  Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters.\n In addition,       the command only uses supplies that are available in the voltage area or voltage area region.\n The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations.\n Netlist changes caused by the command do not introduce new isolation or voltage violations.\n To specify a buffer tree, use the -from option with the name of a net or driver pin.\n If you specify a net name, its driver pin is used.\n In both cases, the driver pin defines a full or partial buffer tree.\n Wildcards are supported.\n The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells.\n By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations.\n However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area.\n If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order:  A cell from the same library as the original library cell  A cell from a library with a name similar to the original library  A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells.\n Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells.\n However, the command does not change level-shifter library cells.\n To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}
{"instruction": "How do I Setting Up Multivoltage Designs", "input": "", "output": "Use the commands and application options described in this topic to create constraints for auto floorplanning.\n Commands Use the following two commands to set and report auto floorplanning constraints.\n These two commands do not affect explicit floorplanning.\n  set_auto_floorplan_constraints The command sets constraints, such as utilization of the floorplan to be created during compile.\n For example, fc_shell> set_auto_floorplan_constraints -core_utilization 0.8  report_auto_floorplan_constraints The command reports the constraints set by the set_auto_floorplan_constraints command.\n To specify macro placement, pin placement, and voltage area shaping constraints, use the following commands:  Macro placement constraints set_macro_constraints create_macro_array create_keepout_margin  Pin placement constraints set_block_pin_constraints set_individual_pin_constraints  Voltage area shaping constraints set_shaping_options Application Options Use these application options to set up auto floorplanning.\n  compile.auto_floorplan.initialize (default: auto  auto : Creates missing floorplan information.\n The tool exits with an error when inconsistent information is provided.\n  true : Always creates the core and boundary.\n  false : Never creates the core and boundary; uses only existing information.\n The tool exits with an error when encountering missing or inconsistent information.\n       By default, the following objects are preserved:  Existing placement of fixed macros  Existing placement of pins and pads  Existing shaping of voltage areas  compile.auto_floorplan.place_pins (default: unplaced compile.auto_floorplan.place_ios (default: unplaced compile.auto_floorplan.place_hard_macros (default: unplaced compile.auto_floorplan.shape_voltage_areas (default: unshaped  all : Always places and shapes objects even if they are fixed.\n Unplaced and unshaped objects will always be placed and shaped.\n  unfixed : Places and shapes objects that are not fixed.\n Use the fixed information from DEF files or a Tcl floorplan, and use the set_fixed_objects command to modify.\n Unplaced and unshaped objects will always be placed and shaped.\n  unplaced, unshaped : Never places or shapes objects when they are already placed.\n Unplaced and unshaped objects will always be placed and shaped.\n  none : Never places or shapes objects even if they are not already placed.\n This table summarizes how the tool handles fixed, placed, and unplaced objects for each setting of these four application options during auto floorplanning.\n Application option setting Fixed objects Placed objects Unplaced objects all    unfixed    unplaced, unshaped    none     compile.auto_floorplan.keep_bounds (default: auto        auto : Removes existing bounds if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas  true : Keeps existing bounds.\n  false : Removes existing bounds.\n  compile.auto_floorplan.keep_placement_blockages (default: auto  auto : Removes existing placement blockages if either of the following two application options is set to all compile.auto_floorplan.place_hard_macros compile.auto_floorplan.shape_voltage_areas  true : Keeps existing placement blockages.\n  false : Removes existing placement blockages.\n Automatic Floorplanning Example The following example specifies constraints for automatic floorplanning: # Application options with default settings # set_app_options -name compile.auto_floorplan.initialize -value auto # set_app_options -name compile.auto_floorplan.place_pins -value unplaced # set_app_options -name compile.auto_floorplan.place_ios -value unplaced # set_app_options -name compile.auto_floorplan.place_hard_macros \\ # -value unplaced # set_app_options -name compile.auto_floorplan.shape_voltage_areas \\ # -value unshaped  # Constraint settings for automatic floorplanning set_auto_floorplan_constraints -core_utilization 0.75 -side_ratio {1 2} set_macro_constraints -preferred_location {0 0} RAM0 set_block_pin_constraints -self -sides {1 3} set_individual_pin_constraints -ports [get_ports reset] -side 1 set_shaping_options -guard_band_size 2"}
{"instruction": "How do I Enabling Advanced PG Net Checks", "input": "", "output": "For advanced technology nodes, to improve the routability of areas with high pin densities by redistributing the cells, enable pin optimization during legalization by setting the place.legalize.optimize_pin_access_using_cell_spacing application option to true"}
{"instruction": "How do I Setting Self-Gating Options", "input": "", "output": "To set up the block for self-gating, perform the following steps before you run the compile_fusion command: 1.\n Enable self-gating by setting the compile.clockgate.self_gating application option to true fc_shell> set_app_options -name compile.clockgate.self_gating \\ -value true 2.\n Apply switching activity by using the read_saif or set_switching_activity command.\n 3.\n (Optional) Specify self-gating settings using the set_self_gating_options command.\n For more information, see Setting Self-Gating Options 4.\n (Optional) Override the tool's default behavior of selecting self-gating objects by using the set_self_gating_objects command.\n For more information, see Controlling the Selection of Self-Gating Objects"}
{"instruction": "How do I Configuring an ICV Heat Map", "input": "", "output": "An ICV heat map displays the density of signoff DRC violations in a block.\n You can use the heat map to locate problematic areas in your design.\n       Note: This feature requires version P-2019.06 or later of the IC Validator tool and an IC Validator NXT license.\n To view the ICV heat map, 1.\n Enable the ICV heat map by setting the signoff.check_drc.enable_icv_explorer_mode application option to true fc_shell> set_app_options -name signoff.check_drc.enable_icv_explorer_mode \\ -value true 2.\n Perform signoff design rule checking as described in Running the signoff_check_drc Command 3.\n In the GUI, choose View > Map > ICV Heatmap.\n  shows an ICV heat map.\n        ICV Heat Map"}
{"instruction": "How do I Configuring Distributed Processing", "input": "", "output": "Multithreading performs tasks in parallel by using multiple cores on the same machine, using a single process memory image.\n When using multithreading, each parallel task is called a thread.\n For the best performance during multithreading, you should limit the number of threads to the number of available cores, which is the number of CPUs in the machine times the number of cores per CPU.\n The following commands support multithreading configured by the set_host_options command:  place_opt  clock_opt        check_legality, when advanced legalization is enabled by setting the place.legalize.enable_advanced_legalizer application option to true  insert_via_ladders  route_auto route_global route_track route_detail, and route_eco Note: When you run routing with a single thread, the result is deterministic; if you start with the same block, you always get the same result.\n However, if you use multiple threads, the routing results are not deterministic; the final routing is slightly different between runs due to the varying division of tasks between threads.\n Global routing supports a deterministic mode for multicore routing.\n To enable this mode, set the route.global.deterministic application option to on  route_opt  signoff_check_drc  signoff_fix_drc  signoff_create_metal_fill  signoff_fix_isolated_via  write_def By default, all commands use a single thread.\n To enable multithreading for those commands that support it, set the -max_cores option of the set_host_options command to a value greater than one and less than or equal to the number of cores available on your machine, which is the number of CPUs in the machine times the number of cores per CPU.\n The number of cores specified by the -max_cores option applies to all commands that support multithreading.\n When you enable multithreading, multithreaded commands create and use the specified number of threads, even if the number is more than the number of available cores.\n You must set an appropriate number of threads, so that the command does not try to use more resources than it has.\n Overthreading can reduce performance because the extra threads compete for resources.\n For best performance, do not run more than one thread per available core.\n For example, if your machine has two CPUs and each CPU has three cores, specify six as the maximum number of threads: fc_shell> set_host_options -max_cores 6"}
{"instruction": "How do I Generating Via Ladder Rules for Performance Via Ladders", "input": "", "output": "Instead of explicitly defining via ladder rules for electromigration via ladders, you can use the generate_via_ladder_template command to generate via ladder rules and constraints based on a configuration file.\n The configuration file is an XML file that provides information about the via ladder rules, as well as the association between the via ladder rules and specific pins.\n You must specify the name of the configuration file by using the -config_file option.\n The command generates two script files:  A script file that defines the via ladder rules, which is called the template script file This script file contains a create_via_rule command for each template defined in the configuration file, as well as set_attribute commands to set the appropriate via rule attributes.\n By default, the file is named auto_gen_via_ladder_template.tcl.\n To specify a different file name, use the -template_file option.\n  A script file that defines the via ladder constraints, which is called the association script file This script file contains set_via_ladder_candidate commands for the pins specified in the configuration file, as well as set_attribute commands to set the is_em_via_ladder_required attribute for the pins to true By default, the file is named auto_gen_via_ladder_association.tcl.\n To specify a different file name, use the -association_file option.\n       The configuration file has the following syntax: <EmRule> <!\n template definition > <Template name=\" rule_name \"> <Layer name=\" layer_name \" row_number=\" cuts_per_row [max_stagger_tracks=\" count \"] [upper_cut_x_min_spacing=\" x_spacing \"] [upper_cut_y_min_spacing=\" y_spacing \"] />...\n more layers </Template> \u2026 more templates  <!\n Pin to template association > <Pin name=\" pin_name \"> <Template name=\" rule_name \"/> </Pin>...\n more associations </EmRule> Each Template section specifies the template for a via ladder rule.\n You can specify one or more Template sections.\n Within a template section, you specify the via ladder structure by specifying the number of cuts per row for each metal layer involved in the via ladder.\n The command uses the information in the configuration file and associated information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file  The cut layers that connect the specified metal layers  The cut names  The minimum required length for each metal layer Note: You must open the block before running the generate_via_ladder_template command to ensure that the command has access to the technology data for the block.\n Each Pin section specifies the template associated with a pin, where the pin name can include the asterisk wildcard character (*).\n You can specify one or more Pin sections.\n The template specified in the Pin section's Template attribute must be one of the templates specified in the Template sections.\n For example, assume you have a configuration file named vl_config that has the following contents: <EmRule> <Template name=\"template_1_3231\"> <Layer name=\"M1\" row_number=\"3\"/> <Layer name=\"M2\" row_number=\"2\"/> <Layer name=\"M3\" row_number=\"3\"/>       <Layer name=\"M4\" row_number=\"1\"/> </Template> <Pin name=\"*/BCELLD5A11*/Z\"> <Template name=\"template_1_3231\"/> </Pin> </EmRule> To generate the script files to define the via ladder rules and constraints, use the following command: fc_shell> generate_via_ladder_template -config_file vl_config Example 17 shows the template script file generated by this command.\n Example 18 shows the association script file generated by this command.\n Example 17 Template Script File create_via_rule -name template_1_3231 \\ -cut_layer_names {VIA1 VIA2 VIA3} -cut_names {V1S V2S V3S} \\ -cut_rows {2 3 1} -cuts_per_row {3 2 3} set viaRule [get_via_rules template_1_3231] set_attribute $viaRule upper_metal_min_length_table {0.3 0.2 0.4} set_attribute $viaRule for_electro_migration true Example 18 Association Script File foreach_in_collection pin [get_lib_pins -quiet */BCELLD5A11*/Z] { set_attribute -quiet $pin is_em_via_ladder_required true set_via_ladder_candidate $pin -ladder_name \"template_1_3231\"  See Also  Defining Via Ladder Rules  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}
{"instruction": "How do I Applying Compression to Groups With Straddling Leaf Cells", "input": "", "output": "To control the tiling of objects within a relative placement group, use the set_rp_group_options -tiling_type command with the settings shown in the following table.\n Table 58 Controlling Placement With the set_rp_group_options -tiling_type Command To do this Use this setting       bit_slice    horizontal_compression   vertical_compression        Bit-Slice Placement Versus Horizontal or Vertical Compression           Bit-slice placement                     Vertical compression Horizontal compression The setting of the -tiling_type option is not propagated from a parent group to child groups."}
{"instruction": "How do I Inserting Tap Cells", "input": "", "output": "The Fusion Compiler tool provides chip finishing and design for manufacturing and yield capabilities that you can apply throughout the various stages of the design flow to address process design issues encountered during chip manufacturing.\n For information about the chip finishing and design for manufacturing features, see the following topics:  Inserting Tap Cells  Performing Boundary Cell Insertion  Finding and Fixing Antenna Violations  Inserting Redundant Vias  Optimizing Wire Length and Via Count  Reducing Critical Areas  Inserting Metal-Insulator-Metal Capacitors  Inserting Filler Cells  Inserting Metal Fill"}
{"instruction": "How do I Reporting Clock-Gating Results", "input": "", "output": "If sequential clock gating is enabled, the report_clock_gating command automatically displays a summary table, similar to the following: Sequential Clock Gating Summary  | | Bitwidth |  |No of sequential clock gates | 2 | | | | | | |No of fanin-based sequential clock gates | 2 (100.0%) | | | | | | |No of sequentially-gated registers | 7 (21.2%) | 7 (21.2%) | | | | | |No of fanin-based sequentially-gated regs | 7 (21.2%) | 7 (21.2%) | | | | | |No of registers not sequentially gated | 26 (78.8%) | 26 (78.8%) | | | | | |Total number of registers | 33 | 33 |  Use the report_clock_gating -ungated command to report the reasons why sequential clock gating is not implemented.\n The report is similar to the following: fc_shell> report_clock_gating -ungated   Not fanin-based sequentially gated registers  Register | Reason for not gating | What's next?\n  q2_reg[0] | Register contains object different than edge-triggered flip-flops in its transitive fanin | Check the register transitive fanin q2_reg[4] | Register contains object different than edge-triggered flip-flops in its transitive fanin | Check the register transitive fanin u/reg1_reg[2] | Register enable function is not a cover of the transitive fanin enable function | Check the register enable condition  Total 7"}
{"instruction": "How do I Selecting and Multiplexing Logic", "input": "", "output": "The Fusion Compiler tool can map combinational logic representing multiplexers in the HDL code directly to a single multiplexer (MUX) or a tree of multiplexer cells from the target logic library.\n Multiplexers are commonly modeled with if and case statements.\n To implement the mutliplexer logic, the HDL Compiler uses SELECT_OP cells, which the Fusion Compiler tool map to combinational logic or multiplexers in the logic library.\n       User-specified Tool evaluated Implemented using MUX gates Implemented using MUX or non MUX gates based on area costing analyze elaborate Infers Select_OP cells compile_fusion"}
{"instruction": "How do I Transferring to Back End", "input": "", "output": "When performing concurrent clock and data optimization using the compile_fusion command, you can give a higher priority to the WNS optimization of  Certain path groups by specifying them by using the ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2} If a path group you specify with this application option is also specified as a path group to skip with the ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization.\n        Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell> set_app_options \\ -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified path groups.\n  The worst 300 timing paths by setting the ccd.enable_top_wns_optimization application option to true"}
{"instruction": "How do I Removing Routing Guides", "input": "", "output": "To find routing guides, use the get_routing_guides command.\n For example, to get all the routing guides in your block, use the following command: fc_shell> get_routing_guides * To find the routing guides in a specific location, use the get_objects_by_location -classes routing_guide command."}
{"instruction": "How do I Controlling Pin Connections", "input": "", "output": "When a pin is defined as a must-join pin, the router connects all terminals of the pin as a single net.\n The terminals of a must-join pin are specified with the must_join_port library pin attribute.\n By default, Zroute connects must-join pins using a random structure, as shown in the following figure:  Default Must-Join Pin Connection To achieve better electromagnetic results, Zroute can use the via ladder insertion capabilities to connect the must-join pins with a simplified structure, which is referred to as a pattern-based must-join connection.\n       The following figure shows the simplified structure:  Single-Level Pattern-Based Must-Join Pin Connection The single-level structure shown in is the default structure used for a pattern- based must-join connection.\n To use a multi-level structure, which is shown in set the route.auto_via_ladder.pattern_must_join_over_pin_layer application option to 2.\n  Multi-Level Pattern-Based Must-Join Pin Connection Zroute automatically uses a pattern-based must-join pin connection when a library cell pin has a pattern_must_join attribute and you use one of the following commands to perform the routing: route_auto route_group, or route_eco To query cells with the pattern_must_join attribute, use the following command: fc_shell> get_attribute \\ [get_lib_pins -all -of_objects */*/frame ] pattern_must_join To get a list of pins that are marked with the pattern_must_join attribute, use the following command: fc_shell> get_lib_pins -all \\ -of_objects */*/frame -filter \"pattern_must_join==true\" By default, a via ladder is not inserted if there are fixed shapes on higher layers that block the insertion.\n To increase the insertion rate, you can allow staggering of the vias on each level of the via ladder to avoid the fixed shapes.\n To specify the maximum number of tracks allowed for staggering on each level, set the route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks application option.\n You can specify a value between 0 and 9 for each level; the default is 0, which disables staggering.\n       For example, to allow staggering of up to three tracks on the first level, use the following command: fc_shell> set_app_options -name \\ route.auto_via_ladder.pattern_must_join_max_number_stagger_tracks \\ -value {3 0}  shows the possible solutions to avoid a blockage on the M3 layer when you allow staggering of up to three tracks.\n  Pattern-Based Must-Join Pin Connection With Staggering By default, the pattern-based must-join connections are updated each time you run the route_auto route_group, or route_eco command.\n  During the route_group command, the updates are restricted to only those nets specified in the route_group command by setting the route.auto_via_ladder.update_on_route_group_nets_only application option to true  To disable all updates during each of these routing commands, set the route.auto_via_ladder.update_pattern_must_join_during_route application option to false If Zroute cannot create a pattern-based must-join connection, it reports a \"Needs pattern must join pin connection\" DRC violation.\n See Also  Inserting Via Ladders"}
{"instruction": "How do I Inserting Interior Tap Walls", "input": "", "output": "An exterior tap wall is a row or column of tap cells that is placed outside the boundary of a block, macro, or hard placement blockage.\n The tap cells in the tap wall are placed linearly without any gaps between cells.\n To insert an exterior tap wall, use the create_exterior_tap_walls command.\n You must specify the following information:  The tap cell used in the tap wall (the -lib_cell option) By default, the command inserts the tap cells with R0 orientation.\n To place the cells with a different orientation, use the -orientation option.\n If the design has a FinFET grid, follow these guidelines when selecting the tap cell to ensure proper insertion of the tap wall:  For horizontal tap walls, ensure that the cell's width in the specified orientation is an integer multiple of the x-pitch of the FinFET grid  For vertical tap walls, ensure that the cell's height in the specified orientation is an integer multiple of the y-pitch of the FinFET grid By default, the tool uses the following naming convention for inserted tap cells: extTapWall__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number  The side along which to insert the tap wall (the -side option) You can specify only a single side, top bottom right, or left.\n To insert a tap wall on more than one side, run the command multiple times.\n  The tap insertion region (the -bbox option) You specify the tap insertion region by specifying the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} The bounding box must span a portion of the object's edge on the specified side along which to insert the tap wall.\n If the bounding box spans multiple edges along the specified side, the command inserts the tap wall along the longest edge.\n If the bounding box does not span any edges of the specified side, the command issues an error message.\n       By default, a horizontal tap wall starts at the left edge of the specified bounding box and abuts the top or bottom boundary edge; a vertical tap wall starts at the bottom edge of the specified bounding box and abuts the left or right boundary edge.\n To specify margins for the tap wall insertion, use the -x_margin and -y_margin options.\n If the specified region, including the margins, is too small to fit a tap wall, the command does not insert tap cells.\n You should ensure that the insertion region does not contain any placement blockages, fixed cells, or macros.\n These obstructions can prevent the insertion of the tap cells and result in an incomplete or missing tap wall.\n When inserting the tap wall, the command does not honor the standard cell rows or sites and does not cross the object boundary.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"instruction": "How do I Specifying Settings for Clock Latency Adjustments", "input": "", "output": "The timing of a design can be improved by reducing signal integrity issues on clock nets.\n To do so, the tool can derive nondefault routing rules with larger spacing requirements and assign them to the clock nets in regions without routing congestion.\n       To enable this feature, use the following application option setting: fc_shell> set_app_options \\ -name cts.optimize.enable_congestion_aware_ndr_promotion -value true When the tool derives a new nondefault routing rule for a clock net, the new spacing requirement is dependent on the spacing requirement of the existing routing rule of that net.\n If the existing routing rule is  A nondefault routing rule with a spacing requirement of less than or equal to two times the default spacing, the spacing requirement is doubled The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n  A nondefault routing rule with a spacing requirement of more than two times the default spacing, the spacing requirement is increased by one default spacing The name of this new nondefault rule is the original name with an _ext_spacing postfix.\n  The default routing rule, the spacing requirement is doubled The name of this new nondefault rule is default_rule_equivalent_ndr_double_spacing."}
{"instruction": "How do I Corner Type", "input": "", "output": "The Custom Router bus routing application options allow you to specify:  Corner Type  Intra-shield Placement  Pin-Trunk Offset  Trunk Splitting  Tapoffs"}
{"instruction": "How do I Defining the Net Priority", "input": "", "output": "To add shielding on the selected nets to reduce crosstalk or parasitic effects, run the create_net_shielding command.\n You need to specify the following information:  The name of the constraint group If you do not specify a name, the command names the constraint group shielding_ where is a unique integer.\n By default, the command returns an error if the assigned name already exists.\n To delete the existing constraint group, use the -force option.\n  The nets, bundles, and topology edges to which the constraint group applies Use the -for option.\n  The constraints for shielding styles and layer-specific requirements To define the net shielding constraints that are applied per layer to the trunk and override any settings on the individual bits, use the options listed in Table 55       Table 55 Net Shielding Constraints Option Description -shield_net    -shield_net_2    -via_defs   -gap   -max_gap   -width  -layer_gaps   -layer_max_gaps   -layer_widths  -min_segment  -sharing  unset, true and false -group_shield   -enclose_pins  -enclose_pins  -group_shield  unset, true, and false -enclose_vias  unset, true, and false -disabled_layers        The following example creates a constraint group and specifies constraints for adding shields on the nets whose names start with pr.\n The minimum spacing is 3 microns for the M2 layer and 5 microns for the M3 layer.\n All constituent objects can share the shield; the M5 and M6 layers cannot be used for shielding.\n fc_shell> create_net_shielding \\ -for [get_nets -physical_context pr*] \\ -disabled_layers {M5 M6} -sharing true -layer_gaps {M2 3 M3 5} {shielding_4}"}
{"instruction": "How do I Self-Gating Flow", "input": "", "output": "The tool supports self-gating optimization, which occurs at the compile_fusion command.\n This feature reduces dynamic power consumption by turning off the clock signal of certain registers during clock cycles when the data remains unchanged.\n        Example of a Self-Gating Cell CLK   Registers with an enable condition that cannot be inferred from the existing logic can only be gated using the self-gating technique.\n They cannot be gated using traditional clock gating.\n By default, the tool supports self-gating only on registers that are not gated.\n You can use the set_self_gating_options command to allow self-gating on these registers.\n However, the time duration that the clock signal is turned off might increase for these registers,.\n To ensure QoR improvements, the self-gating algorithm takes timing and power into consideration.\n A self-gating cell is inserted for the registers if  There is enough timing slack available in the register's data pin.\n For designs with multiple scenarios, the algorithm considers the timing of the worst case among active scenarios enabled for setup.\n  Internal dynamic power of the circuit is reduced.\n For designs with mutiple scenarios, the algorithm uses the average internal dynamic power among active scenarios enabled for dynamic power.\n To minimize the area and power overhead, a self-gating cell can be shared across a few registers by creating a combined enable condition with a tree of comparator cells.\n If the self-gated registers are driven by synchronous set or synchronous clear signals, these signals are also included in the construction of the enable signal so that the circuit remains functionally unchanged.\n is an example of a self-gating cell that is shared across two registers (4 bits).\n Note that one of the self-gated registers is a multibit register and the other register is a single-bit register.\n The tool can also self-gate a group of multibit registers or a group of single-bit registers.\n        Self-Gating Tree CLK D0 Q0 D2 Q2 D1 Q1   EN The tool does not support the following types of sequential cells for self-gate insertion:  Level-sensitive sequential cells  Level-sensitive scan design registers  Master-slave flip-flops  Retention registers  Single-bit and multibit registers that belong to shift registers  Multibit registers with multiple clock paths For more information, see the following topics:  Self-Gating Flow  Library Requirements for Self-Gating  Setting Up for Self-Gating  Reporting and Querying Self-Gating Cells"}
{"instruction": "How do I Setting Up Libraries", "input": "", "output": "The Fusion Compiler tool uses a search path to look for files that are specified with a relative path or with no path.\n To specify the search path, use the set_app_var command to set the search_path application variable to the list of directories, in order, in which to look for files.\n When the tool looks for a file, it starts searching in the leftmost directory specified in the search_path variable and uses the first matching file it finds.\n You can also use the Tcl lappend command to add your directories to the default search path, which is the directory from which you invoked the tool.\n For example, fc_shell> lappend search_path./mylibdir"}
{"instruction": "How do I Near 100 Percent Redundant Via Insertion", "input": "", "output": "Soft-rule-based redundant via insertion can improve the redundant via rate by reserving space for the redundant vias during routing.\n You can use concurrent soft-rule-based redundant via insertion during both initial routing and ECO routing.\n The actual via insertion is not done during routing; you must still perform postroute redundant via insertion by using the add_redundant_vias command.\n Note: Reserving space during routing increases the routing runtime.\n You should use this method only when needed to improve the redundant via rate beyond that provided by postroute redundant via insertion and the postroute approach resulted in a redundant via rate of at least 80 percent.\n       To perform concurrent soft-rule-based redundant via insertion, 1.\n (Optional) Define the via mapping table as described in Defining a Customized Via Mapping Table 2.\n Enable concurrent soft-rule-based redundant via insertion.\n By default, concurrent redundant via insertion is disabled.\n  To enable concurrent soft-rule-based redundant via insertion during initial routing, set the route.common.concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during initial routing, set the route.common.concurrent_redundant_via_effort_level application option.\n By default, Zroute uses low effort.\n The higher effort levels result in a better redundant via conversion rate at the expense of runtime.\n The low and medium efforts affect only global routing and track assignment, while high effort also affects detail routing, which can impact design rule convergence.\n Note: If you enable the route.common.concurrent_redundant_via_mode option before running the place_opt command, the redundant vias are considered during congestion estimation.\n  To enable concurrent soft-rule-based redundant via insertion during ECO routing, set the route.common.eco_route_concurrent_redundant_via_mode application option to reserve_space fc_shell> set_app_options \\ -name route.common.eco_route_concurrent_redundant_via_mode \\ -value reserve_space To control the effort used to reserve space for the redundant vias during ECO routing, set the route.common.eco_route_concurrent_redundant_via_effort_level application option.\n Note: Using concurrent soft-rule-based redundant via insertion during ECO routing can impact timing and design rule convergence.\n In general, you should use this method only when you used near 100 percent redundant via insertion during initial routing.\n       3.\n Route the block.\n During routing, Zroute reserves space for the redundant vias and fixes hard design rule violations.\n 4.\n Perform postroute redundant via insertion.\n During postroute redundant via insertion, Zroute inserts the redundant vias in the reserved locations."}
{"instruction": "How do I Mapping of Synchronous Reset or Preset Registers", "input": "", "output": "During test-ready compile, the tool replaces regular flip-flops with flip-flops that contain logic for testability.\n The following figure shows an example of how a D flip-flop is replaced with a scan register during test-ready compile.\n This type of architecture, a multiplexed flip- flop, incorporates a 2-input MUX at the input of the D flip-flop.\n The select line of the MUX enables two modes\u2014functional mode (normal data input) and test mode (scanned data input).\n In this example, the scan-in pin is si, the scan-enable pin is se, and the scan-out pin, so, is shared with the functional output pin, Q.\n        si  Clk se   Q/so When you run the compile_fusion command,  The tool maps all sequential cells directly to scan registers in your library  The scan pins, such as scan enable and scan out, are unconnected  The scan output pin of a scan register is used for scan connections Use the seqmap.bind_scan_pins application option to hold the scan enable pin inactive If the library contains no scan registers, the tool uses nonscan cells for mapping and issues a warning.\n Set the dont_use attribute on all scan registers in the library to map to nonscan cells"}
{"instruction": "How do I Timing-Driven Power Grid Augmentation", "input": "", "output": "Before you run the signoff_create_pg_augmentation command, configure the run by setting the application options shown in Table 48.\n To set the application options, use the set_app_options command.\n To see the current settings, use the report_app_options command.\n Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff.\n create_pg_augmentation.\n ground_net_name     signoff.\n create_pg_augmentation.po wer_net_name    signoff.\n create_pg_augmentation.\n run_dir     signoff_create_pg_augmentation            Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff.\n create_pg_augmentation.\n user_defined_options"}
{"instruction": "How do I Constructing Faster Clock Tree to Specific Endpoints", "input": "", "output": "By default, the Fusion Compiler tool uses the default routing rule and any available routing layers to route the clock trees.\n You can specify the minimum and maximum routing layers for clock nets as described in Specifying the Routing Resources.\n These routing layer constraints are used during RC estimation, congestion analysis, and routing.\n       To reduce the wire delays in the clock trees, you can use wide wires and higher metal layers instead.\n routing rulenondefault, defined Wide wires are represented by nondefault routing rules.\n To use nondefault routing rules on the clock nets, you must first define the routing rules and assign them to the clock nets as described in Using Nondefault Routing Rules"}
{"instruction": "How do I Performing Real Metal Fill Extraction", "input": "", "output": "In some cases, you might find that you can manually fix a DRC violation by changing the boundary of metal fill shapes, adding metal fill shapes, or removing metal fill shapes.\n  To change the boundary of a metal fill shape, use the set_attribute command to modify its bbox attribute.\n  To add a metal fill shape in the top-level fill cell, use the create_shape -shape_use area_fill command.\n  To add a metal fill shape in a specific fill cell, use the create_shape -fill_cell command.\n  To remove a metal fill shape, use the remove_shapes command.\n You can also modify metal fill shapes in the GUI.\n To select or modify fill shapes in the GUI, 1.\n Select \"Multiple Levels Active\" ( ) in the View Settings panel.\n 2.\n In the \"Hierarchy Settings\" panel, set \"View level\" to a minimum of 2 and select \"Fill Cell\" in \"Expanding cell types.\""}
{"instruction": "How do I Controlling the Tiling Within Relative Placement Groups", "input": "", "output": "When you add an object to a relative placement group by using the add_to_rp_group command, you can override its alignment and specify a different alignment for the object you are adding by using the -override_alignment option.\n However, if the relative placement group is pin aligned, you cannot override the alignment with the -override_alignment option.\n The following example creates a relative placement group named rp1 that is right aligned.\n It then adds a cell named U0, which overrides the alignment of the group and cells named U1, U2, and U3, which honor the alignment of the relative placement group: fc_shell> create_rp_group rp1 -name rp1 -columns 1 -rows 4 fc_shell> set_rp_group_options rp1 -alignment right fc_shell> add_to_rp_group rp1 -cells U0 -column 0 -row 0 \\ -override_alignment left fc_shell> add_to_rp_group rp1 -cells U1 -column 0 -row 1 fc_shell> add_to_rp_group rp1 -cells U2 -column 0 -row 2 fc_shell> add_to_rp_group rp1 -cells U3 -column 0 -row 3 The following figure shows the relative placement group after placement.\n        Right-Aligned Relative Placement Group With One Cell That is Left Aligned U3 U2 U1 U0 row 3 row 2 row 1 row 0 col 0"}
{"instruction": "How do I Associating Checkpoints and Checkpoint Behaviors", "input": "", "output": "You can define two types of checkpoint behaviors: reports and actions.\n Define a checkpoint report to generate one or more reports supported by the tool or custom reports you create yourself.\n Define a checkpoint action to execute any kind of flow change before,       after, or in place of the code block enwrapped by a checkpoint.\n For example, you might set an application option to a specific value before a particular checkpoint.\n Define these behaviors in your checkpoint.config.tcl file, which is automatically sourced by the checkpoint system.\n Defining Checkpoint Reports To define a checkpoint report, use the create_checkpoint_report command in your checkpoint.config.tcl file.\n Specify a unique name for the report and define the Tcl commands to generate the report.\n The following example defines a checkpoint report named timing, which writes the output of the report_qor and report_timing commands to disk: create_checkpoint_report timing { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position]  report_qor -nosplit >./checkpoint/$name.$pos.qor.rpt report_qor -summary -nosplit >>./checkpoint/$name.$pos.qor.rpt  report_timing -nosplit -max_paths 10 \\ >./checkpoint/$name.$pos.path.rpt  Notice the use of the get_current_checkpoint command with the -name and -position options to give the generated reports a meaningful name.\n When these reports are generated, their names reflect the checkpoint that triggered them get_current_checkpoint -name ), as well as whether they were generated before or after the checkpoint ( get_current_checkpoint -position ).\n For example, if this checkpoint report is executed after a checkpoint named checkpoint_A, the generated reports are saved to the checkpoint directory, and the name of the QoR report is checkpoint_A.after.qor.rpt.\n The next example defines a checkpoint report named app_options, which writes all your non-default application options to disk: create_checkpoint_report app_options { set name [get_current_checkpoint -name] set pos [get_current_checkpoint -position]  report_app_options -non_default \\ >./checkpoint/$name.$pos.app_options.rpt  Defining Checkpoint Actions To define a checkpoint action, use the create_checkpoint_action command in your checkpoint.config.tcl file.\n Specify a unique name for the action and define the Tcl commands that constitute the action.\n       The following example defines a checkpoint action named gropto, which enables global- route based buffering: create_checkpoint_action gropto { set_app_options -name place_opt.initial_drc.global_route_based \\ -value true  The next example defines a checkpoint action named placer_high_effort_cong, which runs high-effort congestion reduction: create_checkpoint_action placer_high_effort_cong { set placer_command [get_current_checkpoint -script] set cong_option \"-congestion_effort high\" eval $placer_command $cong_option  Notice the use of the get_current_checkpoint -script command and option, which retrieves the command originally enwrapped by the checkpoint and sets its congestion effort to high ( -congestion_effort high ).\n The -script option is typically used to define actions that replace the contents of a command.\n In this example, the action modifies the -congestion_effort option of the command that is enwrapped by the checkpoint associated with this action."}
{"instruction": "How do I Enabling Wire Length Aware Power-Driven Relocation", "input": "", "output": "You can enable clock tree power reduction techniques by using the cts.compile.power_opt_mode application option as shown in the following table.\n Table 26 Settings for the cts.compile.power_opt_mode Application Option To do this Use this setting   gate_relocation  low_power_targets       Table 26 Settings for the cts.compile.power_opt_mode Application Option (Continued) To do this Use this setting   all"}
{"instruction": "How do I Fixing DRC Violations Caused by Pin Access Issues", "input": "", "output": "The recommended flow for performing postroute logic optimization consists of multiple iterations of the route_opt command with different settings.\n However, you can reduce       the number of postroute optimization iterations by using a single iteration of the hyper_route_opt command.\n The postroute optimization flow using the hyper_route_opt command consists of the following steps: 1.\n Enable different settings for postroute optimization using the same settings as for the route_opt command.\n For example, you can  Specify the path-based analysis (PBA) mode by using the time.pba_optimization_mode application option  Enable concurrent clock and data optimization by using the route_opt.flow.enable_ccd application option  Enable power optimization by using the route_opt.flow.enable_power application option 2.\n (Optional) Specify settings for metal fill insertion, PG augmentation, and so on that should to be performed during the different stages of optimization and ECO routing within the hyper_route_opt command by using the snps_hyper_route_opt_post_eco Tcl-callback procedure.\n 3.\n (Optional) To improve the timing QoR, the hyper_route_opt command can debank sequential multibit registers.\n To enable this feature, set the route_opt.flow.enable_multibit_debanking application option to true.\n By default, the route_opt.flow.enable_multibit_debanking application option is set to false 4.\n Run postroute optimization using the hyper_route_opt command.\n 5.\n (Optional) Specify endpoints to target by using the set_route_opt_target_endpoints command and optimize these endpoints by using the route_opt command if there are any violating endpoints remaining after the hyper_route_opt command.\n 6.\n (Optional) Fix any remaining route DRC violations by using the route_detail -incremental command."}
{"instruction": "How do I Controlling Sequential Mapping", "input": "", "output": "You need to have multiplexer cells in the logic library and also require to use multiplexing logic from the cell library.\n The following section describes library requirements to implement multiplexer cells for multiplexer optimization or to implement multiplexing logic from the cell library to control MUX mapping:  Understanding Library Cell Requirements for Multiplexer Optimization  Implementing Multiplexing Logic From Cell Library Understanding Library Cell Requirements for Multiplexer Optimization The multiplexer optimization requires the presence of at least a 2:1 multiplexer cell in the logic library.\n The inputs or outputs of this cell can be inverted.\n If a 2:1 multiplexer primitive cell does not exist in the library, you see the following warning message: Warning: Target library does not contain any 2-1 multiplexer.\n (OPT-853) An implementation of the MUX_OP cell from the target library is created, but it might not be the best implementation possible.\n All multiplexer cells in the target library can be used to construct the implementation of the MUX_OP cell except  Enabled multiplexer cells  Bused output multiplexer  Multiplexers larger than 32 : 1 For Fusion Compiler to make the best use of the multiplexer cells available in your logic library, recompile the library or obtain a library compiled with version V3.4a or later from your ASIC vendor.\n Implementing Multiplexing Logic From Cell Library During logic synthesis, the tool implements multiplexing logic from the cell library using one of the following methods:  AND, OR, and INV gates  MUX gates The tool evaluates the area effect of both methods and selects the solution with the smallest area.\n       You can specify that the tool uses MUX gates to implement specific multiplexing logic by applying the map_to_mux attribute on the corresponding SELECT_OP WVGTECH cells in the block, as shown in Example 16 Example 16 Using map_to_mux attribute to implement specific multiplexing logic # Apply the map_to_mux attribute on the SELECT_OP cell named C10 set_attribute -objects [get_cells C10] -name map_to_mux -value true  # Query if the attribute is set as required on C10 get_attribute -objects [get_cells C10] -name map_to_mux  #Run the compile step compile_fusion  #Identify the cell created using the map_to_mux attribute get_cells -hier -filter \"map_to_mux==true &&!infer_mux_override\""}
{"instruction": "How do I Controlling the Adjustment of I/O Clock Latencies", "input": "", "output": "By default, the tool focuses on fixing setup violations during concurrent clock and data optimization.\n However, if your design has hold violations that are difficult to fix, you can increase the effort for hold fixing by setting the ccd.hold_control_effort application option to medium high, or ultra.\n The default is low Increasing the priority of hold violations reduces the number of setup violations that are fixed.\n Therefore, the hold priority should be increased only if the hold timing is critical.\n This setting affects concurrent clock and data optimization performed during the final_opt stage of the clock_opt command and the route_opt command."}
{"instruction": "How do I Validating DEF Files", "input": "", "output": "If the site names used in the DEF file do not match the site names defined in the technology file, use the -convert_sites option to specify the site name mapping.\n For example, if the DEF file uses a site named CORE, but the technology file defines only a site named unit, use the following command to convert the site names when reading the DEF file: fc_shell> read_def -convert_sites { {CORE unit} } block.def"}
{"instruction": "How do I Inserting Multivoltage Cells", "input": "", "output": "To remove voltage areas from a block, use the remove_placement_blockage comandcomandsremove_placement_blockage remove_voltage_areas command.\n To remove all voltage areas from a block, use the -all option.\n To remove specific voltage areas from a block, specify the voltage area names."}
{"instruction": "How do I Reporting Abstract Inclusion Reasons", "input": "", "output": "In the top-level timing abstracts, the Fusion Compiler tool enables you to check minimum pulse width (MPW) violations.\n The tool retains the clock sinks with MPW violations including their fan-in cells and nets at the time of abstract creation.\n You can use the following application options to:  Check and retain registers with MPW violations including their full clock path, set the abstract.keep_min_pulse_width_violation_pins application option to true The data paths to these registers are not retained.\n By default, this application is set to false  Limit the MPW violations within a given slack limit, set the abstract.min_pulse_width_violation_slack_limit application option to the required slack.\n This helps to preserve MPW pins that might not be violating but have a slightly positive slack."}
{"instruction": "How do I Improving the Banking Ratio", "input": "", "output": "To report a summary of the multibit banking ratio, a list of reasons for not banking or debanking cells, and the number of cells for each reason, use the report_multibit command, as shown in the following example: fc_shell> report_multibit **************************************** Report : report_multibit...\n...\n  ****************************************  Total number of sequential cells: 4020 Number of single-bit flip-flops: 3149 Number of single-bit latches: 29 Number of multi-bit flip-flops: 842 Number of multi-bit latches: 0        Total number of single-bit equivalent cells: 853 (A) Single-bit flip-flops: 3149 (B) Single-bit latches: 29 (C) Multi-bit flip-flops: 5352 (D) Multi-bit latches: 0  Sequential cells banking ratio ((C+D)/(A+B+C+D)): 62.74% Flip-flop cells banking ratio ((C)/(A+C)): 62.96% BitsPerflop: 2.13  Reasons for sequential cells not mapping to multibit during RTL Banking:  Explanations: r12: Cell is single bit because its parent multibit cell was debanked due to improve timing (Number of cells: 91) r31: Cell cannot be banked to multibit because it is assigned to use single-bit lib cell (Number of cells: 63)   Reasons for multibit sequential cells not debanking to single bit cells during RTL Debanking:  Explanations:: r45: Multibit cell cannot be debanked because it is not critical enough (Number of cells: 478) To report all the cells that are ignored during banking and debanking, use the -ignored_cells option with the report_multibit command.\n To report the compatible multibit and single-bit library cells that can be used for banking and debanking, use the check_multibit_library command.\n The following example generates a compatible library cell report for RTL banking and debanking: fc_shell> check_multibit_library -stage RTL \\ -banking -debanking **************************************** Report : check_multibit_library Flow : RTL BANKING ****************************************  Single bit Lib cell Compatibility Multi bit Lib cell  SB_reg1 PIN ORDER MISMATCH MB_reg1 SB_reg2 COMPATIBLE MB_reg2  Singlebit with NO Multibit Equivalents  SB_reg3        **************************************** Report : check_multibit_library Flow : RTL DEBANKING ****************************************  Multi bit Lib cell Compatibility Single bit Lib cell  MB_reg2 COMPATIBLE SB_reg2 MB_reg1 PIN ORDER MISMATCH SB_reg1  Multibit with NO Singlebit Equivalents  MB_reg3"}
{"instruction": "How do I Deriving the Clock Trees", "input": "", "output": "This section details the information required to analyze and define each clock tree before running clock tree synthesis.\n Before you run clock tree synthesis, analyze each clock tree in the block and determine  What the clock root is  What the required clock sinks and clock tree exceptions are  Whether the clock tree contains preexisting cells, such as clock-gating cells  Whether the clock tree converges, either with itself (a convergent clock path, definedclockconvergent convergent clock path) or with another clock tree (an overlaping clock path, definedclockoverlaping overlapping clock path)  Whether the clock tree has timing relationships with other clock trees in the block, such as interclock skew requirements Use this information to define the clock trees and validate that the tool has the correct clock tree definitions.\n The Fusion Compiler tool derives the clock trees based on the clocks defined in the block.\n If the derived clock trees do not meet your requirements, you can define clock trees as described in the following topics:  Deriving the Clock Trees  Defining Clock Tree Exceptions  Restricting Optimization on the Clock Network  Copying Clock Tree Exceptions Across Modes        Deriving Clock Tree Exceptions From Ideal Clock Latencies  Handling Endpoints With Balancing Conflicts"}
{"instruction": "How do I Using Incomplete UPF Information", "input": "", "output": "To load the power intent and apply it to a multivoltage design, 1.\n Read the UPF file by using the load_upf command.\n fc_shell> load_upf block.upf 2.\n If you are using the golden UPF flow and have a name-mapping file, read the file by using the read_name_map command.\n fc_shell> read_name_map block.nmf 3.\n (Optional) Verify the UPF consistency and identify any PG conflicts among the netlist, floorplan, and power intent.\n To verify the UPF consistency and identify PG conflicts, use the resolve_pg_nets -check_only command.\n This command identifies any issues and reports the changes that are made to resolve these issues when you commit the power intent.\n If you prefer to resolve the issues differently, you can use manual editing commands to resolve the issues before running the commit_upf command.\n 4.\n Commit the power intent by using the commit_upf command.\n fc_shell> commit_upf The commit_upf command performs global checks for UPF consistency; resolves PG conflicts among the netlist, floorplan, and UPF specification; and associates power strategies with existing multivoltage cells.\n For more information about associating       power strategies with existing multivoltage cells, see Associating Power Strategies With Existing Multivoltage Cells 5.\n Report the associations made for the multivoltage cells by using the report_mv_path command.\n If the tool failed to associate any multivoltage cells, the command reports the causes for these failures.\n You must successfully commit the power intent before you continue with the design flow.\n Note: After successfully running the commit_upf command, the tool issues an error message if you try to use additional UPF commands, except for the set_related_supply_net connect_supply_net set_design_attributes set_port_attributes find_objects, and set_scope commands.\n To modify the power intent after running the commit_upf command, you must remove the existing UPF specification by using the reset_upf command and then reload the power intent."}
{"instruction": "How do I Controlling Multibit Optimization Performed During the clock_opt", "input": "", "output": "Applying useful skew techniques during datapath optimization to improve the timing QoR by taking advantage of the positive slack and adjusting the clock arrival times of registers is referred to as concurrent clock and data (CCD) optimization.\n By default, the tool performs concurrent clock and data optimization during the clock_opt command.\n To disable concurrent clock and data optimization for the clock_opt command, set the clock_opt.flow.enable_ccd application option to false You can change the default behavior of concurrent clock and data optimization during the clock_opt command by performing any of the following optional steps: 1.\n (Optional) Limit the latency adjustment values for concurrent clock and data optimization as described in Limiting the Latency Adjustment Values 2.\n (Optional) Control the latency adjustment of boundary registers for concurrent clock and data optimization as described in Excluding Boundary Paths 3.\n (Optional) Ignore specific path groups during concurrent clock and data optimization as described in Excluding Specific Path Groups       4.\n (Optional) Ignore specific scenarios during concurrent clock and data optimization as described in Excluding Specific Scenarios 5.\n (Optional) Ignore specific sinks during concurrent clock and data optimization as described in Excluding Specific Sinks 6.\n (Optional) Control the effort of timing optimization performed during concurrent clock and data optimization as described in Controlling Timing Optimization Effort 7.\n (Optional) Control the effort of hold timing optimization performed during concurrent clock and data optimization as described in Controlling Hold Time Optimization Effort 8.\n (Optional) Control the adjustment of I/O clock latencies performed during concurrent clock and data optimization as described in Controlling the Adjustment of I/O Clock Latencies 9.\n (Optional) Analyze the effects of concurrent clock and data optimization as described in Reporting Concurrent Clock and Data Timing"}
{"instruction": "How do I Implementing MSCTS Multiple H-Tree", "input": "", "output": "The following figure shows a regular multisource clock where the global clock structure does not have a clock mesh.\n The global clock structure consists only of an H-tree, which directly drives the tap drivers.\n  Regular Multisource Clock Tree With an H-Tree-Only Global Clock Structure To implement a regular multisource clock tree structure with an H-tree-only global clock tree structure, 1.\n Specify your clock tree constraints and settings.\n 2.\n Perform the following steps for multivoltage designs: a.\n Enable multivoltage support by setting the cts.multisource.enable_full_mv_support application option to true b.\n Enable the addition of physical feedthrough cells, which belong to a voltage area physically but not logically, by setting the opt.common.allow_physical_feedthrough application option to true c.\n Run the check_mv_design command and fix all multivoltage issues.\n 3.\n Enable cell electromigration fixing by setting the cts.multisource.cell_em_aware application option to true 4.\n Specify the required settings by using the set_regular_multisource_clock_tree_options command and       perform tap insertion and global clock tree (H-tree) synthesis by using the synthesize_regular_multisource_clock_trees command, as described in Performing Automated Tap Insertion and H-Tree Synthesis 5.\n Specify options and settings for tap assignment, as described in Specifying Tap Assignment Options and Settings 6.\n Perform tap assignment by using the synthesize_multisource_clock_taps command, which  Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks  Assigns endpoints to the closest tap driver and splits cells along the path honoring any sink groups defined  Copies the UPF and SDC constraints and the user-specified attributes onto the newly created cells across the active scenarios 7.\n Synthesize the entire clock tree, from the clock root, by using the following command: fc_shell> clock_opt -from build_clock -to route_clock During this step, the tool builds the local subtrees that are driven by the tap drivers.\n It also fixes DRC violations beyond ignore exceptions of the multisource clock tree, if applicable.\n You can also synthesize other clocks in the design that are not synthesized.\n For more information about the clock_opt command, see Synthesizing, Optimizing, and Routing Clock Trees With the clock_opt Command 8.\n Analyze the clock tree results, as described in Analyzing the Clock Tree Results"}
{"instruction": "How do I Specifying the Naming Convention for Boundary Cells", "input": "", "output": "By default,  When you run the compile_boundary_cells command, the tool places the boundary cells in their default orientation around the core area, hard macros, and hard placement blockages.\n  When you run the compile_targeted_boundary_cells command, the tool places the boundary cells in their default orientation around the specified objects.\n To flip the boundary cell orientations, use one or more of the following options with the set_boundary_cell_rules command: -mirror_left_boundary_cell -mirror_right_boundary_cell -mirror_left_outside_corner_cell -mirror_right_outside_corner_cell -mirror_left_inside_corner_cell -mirror_right_inside_corner_cell -mirror_left_inside_horizontal_abutment_cell, and -mirror_right_inside_horizontal_abutment_cell.\n You cannot flip the orientation of the top and bottom boundary cells.\n In addition, when you use the compile_boundary_cells command, you can modify the following aspects of the default placement behavior:  Swapping of the top and bottom inside corner cells on flipped rows Use the -do_not_swap_top_and_bottom_inside_corner_cell option with the set_boundary_cell_rules command to prevent the command from using the bottom inside corner cell on the top inside corner of flipped rows and the top inside corner cell on the bottom inside corner of flipped rows.\n  Consideration of voltage areas Use the -at_va_boundary option with the set_boundary_cell_rules command to insert horizontal boundary cells on both sides of the voltage area boundaries.\n  Existence of one-unit-tile gaps Use the -no_1x option with the set_boundary_cell_rules command to prevent boundary cell insertion from creating one-unit-tile gaps.\n When you use this option, the command does not insert boundary cells on a row when the row length equals two times the corner cell width plus one unit tile width.\n Note that if the row length equals two times the corner cell width, the command does insert boundary cells.\n  Distance between tap cells Use the -tap_distance option with the set_boundary_cell_rules command to specify the distance in microns between the tap cells inserted on the top and bottom boundary rows.\n        Insertion of boundary cells on short rows Use the -min_row_width option with the set_boundary_cell_rules command to prevent insertion of boundary cells on short rows.\n This option defines the width threshold for inserting boundary cells on a row.\n If the row width is less than the specified value, the command does not insert boundary cells on the row.\n  Insertion of boundary cells in child blocks Use the -insert_into_blocks option with the set_boundary_cell_rules command to recursively insert boundary cells in the child blocks.\n By default, the tool does not insert boundary cells in the child blocks."}
{"instruction": "How do I Inserting Routing Guides Along the Nonpreferred-Direction Edges", "input": "", "output": "To insert rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this object type, the command creates one or more rectangular metal shapes parallel to each preferred-direction boundary edge.\n The metal shapes are floating; they are not connected to any logical nets.\n  If your technology does not specify a maximum area for these floating shapes, you can insert continuous metal shapes along the preferred-direction boundary edges, as described in Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges  If your technology specifies a maximum area for these floating shapes or you need more flexibility in placing the metal shapes, insert multiple metal shapes, called metal stubs, along the preferred-direction boundary edges, as described in Inserting Metal Stubs Parallel to Preferred-Direction Edges In addition to inserting metal shapes along the preferred-direction edges, you can insert short metal shapes perpendicular to the nonpreferred-direction edges, as described in Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges       Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges To insert continuous rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this option, the command creates a single rectangular metal shape parallel to each preferred-direction boundary edge.\n By default,  The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n  The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n  The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  The metal shapes abut the nonpreferred-direction edges To specify an offset from the nonpreferred-direction edges, use the -spacing_from_boundary option.\n Use the following format to specify the offset for each layer: {{ layer_name offset_value }...} The offset value must be a positive value.\n  The metal shapes are placed on the closest wire track to the preferred-direction edge  shows the metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed on the closest track to the edge.\n W is the default width for the layer and S is the spacing specified for the layer by the -spacing_from_boundary option.\n        Continuous Metal Shape Perimeter Constraint Objects          Inserting Metal Stubs Parallel to Preferred-Direction Edges To insert metal stubs along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred and -stub options.\n When you specify both of these options, the command creates rectangular metal shapes parallel to each preferred-direction boundary edge based on the parameters you specify with the -stub option.\n Use the following format to specify the shape parameters in microns: offset_value start_value length_value spacing_value By default,  The metal shapes are offset from the preferred-direction edge by the value specified in the offset_value argument The offset value is measured from the block edge to the center of the metal shape.\n It can be a positive value, zero, or a negative value.\n The absolute value of a negative value must be greater than the stub width.\n A positive value must be less than half of the smaller of the width or height of the block boundary.\n  The first metal shape is offset from the nonpreferred-direction edge by the value specified in the start_value argument The start value must be greater than or equal to 0 and less than the smaller of the width or height of the block boundary.\n For horizontal shapes, the metal shapes start at the left edge.\n For vertical shapes, the metal shapes start at the bottom edge.\n Note: When you use the -stub option, the command uses the specified start_value and ignores the -spacing_from_boundary option.\n        The metal shapes have the length specified by the length_value argument The length value must be greater than 0 and less than or equal to the smaller of the width or height of the block boundary.\n  The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  The metal shapes are separated the space specified by the spacing_value argument The spacing value must be greater than or equal to 0.\n  The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n  The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n  shows the metal stubs inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed at the specified offset, O, from the horizontal (preferred-direction) edge, where O is measured from the boundary to the center of the shape.\n The first metal stub is placed at the specified offset, S, from the vertical (nonpreferred-direction) edge.\n Each metal shape has a width of W, the default width for the layer and the specified length, L.\n The spacing between metal stubs is the specified spacing, SP.\n  Metal Stub Perimeter Constraint Objects      SP SP SP  SP SP SP SP SP           Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges To insert additional short metal shapes in the preferred direction perpendicular to the nonpreferred-direction boundary edges,  Specify the length of the metal shapes by using the -short_metal_length option  Specify the distance between the metal shapes by using the -metal_spacing option For both of these options, you use the following format to specify the value for each layer: {{ layer_name value }...}  shows the short metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape has a width of W, which is the default width for the layer, and a length of L, which is the length specified for the layer by the -short_metal_length option.\n The offset from the nonpreferred-direction edge is S, which is the spacing specified for the layer by the -spacing_from_boundary option.\n The distance between short metal shapes is SS, which is specified for the layer by the -metal_spacing option.\n  Metal Shape Perimeter Constraint Objects With Additional Short Shapes        SS"}
{"instruction": "How do I Setting the Rerouting Mode", "input": "", "output": "If a pin has a via ladder, by default, Zroute connects to the topmost layer of a via ladder and not directly to the existing pin geometry.\n To modify the connection constraints, set the following application options:  route.detail.via_ladder_upper_layer_via_connection_mode To allow vias to connect to the top level of a via ladder from below, set this application option to any  route.detail.allow_default_rule_nets_via_ladder_lower_layer_connection To allow nets with default routing rules to connect directly to the pin or to any layer of the via ladder, set this application option to true"}
{"instruction": "How do I Optimizing Wire Length and Via Count", "input": "", "output": "After redundant via insertion, whether concurrent or postroute, Zroute generates a redundant via report that provides the following information:  The via conversion rate for nondefault vias The via conversion rate for nondefault vias is listed at the top of the report as the total optimized via conversion rate.\n        The optimized via conversion rate for each layer The optimized via conversion rate includes both double vias and DFM-friendly bar vias, which have a single cut but a larger metal enclosure.\n The tool reports two values for the via conversion rate:  The total optimized via conversion rate This value is computed based on the total via count, which includes both fixed vias and routed vias.\n Fixed vias are vias that cannot be optimized by the router, such as unrouted vias and user-defined vias.\n  The optimized via conversion rate based on the total routed via count This value is computed based only on the routed via count, which includes only those vias that can be optimized by the router.\n Note: The optimized via conversion rate is not useful if you are using bar vias.\n  The distribution of optimized vias by weight for each layer To determine the via conversion rate for conversions above a certain weight, you must add the reported conversion rates for those weights.\n For example, in Example 29, the via conversion rate for weight 5 and above for layer V03 is 10.75+64.50=75.25%.\n Note: The conversion rate for unweighted vias is reported as \"Un-optimized.\"  The total double via conversion rate for the block Note: The redundant via rate reported by the report_design command differs from the redundant via rate reported by Zroute during redundant via insertion or the check_routes command.\n This difference occurs because the report_design command reports the double via rate for both PG vias and signal vias, while Zroute reports the double via rate only for signal vias.\n In addition, Zroute bases the conversion rate only on the redundant via mapping.\n Example 29 shows an example of the redundant via report.\n Example 29 Redundant Via Report Total optimized via conversion rate = 96.94% (1401030 / 1445268 vias) Layer V01 = 41.89% (490617 / 1171301 vias) Weight 10 = 9.64% (112869 vias) Weight 5 = 32.25% (377689 vias) Weight 1 = 0.01% (59 vias) Un-optimized = 58.11% (680684 vias)       Layer V02 = 76.20% (1567822/ 2057614 vias) Weight 10 = 43.51% (895270 vias) Weight 5 = 28.62% (588805 vias) Weight 1 = 4.07% (83747 vias) Un-optimized = 23.80% (489792 vias) Layer V03 = 81.87% (687115 / 839297 vias) Weight 10 = 64.50% (541369 vias) Weight 5 = 10.75% (90224 vias) Weight 1 = 6.62% (55522 vias) Un-optimized = 18.13% (152182 vias) Layer V04 = 81.60% (226833 / 277977 vias) Weight 10 = 81.45% (226418 vias) Weight 1 = 0.15% (415 vias) Un-optimized = 18.40% (51144 vias)...\n Layer V09 = 85.47% (1329 / 1555 vias) Weight 10 = 85.47% (1329 vias) Un-optimized = 14.53% (226 vias)  Total double via conversion rate = 46.69% (2158006 / 4622189 vias)"}
{"instruction": "How do I Clock Gating in the Compile Log File", "input": "", "output": "Clock gates inserted by the Fusion Compiler tool use a naming convention that is consistent between runs.\n The naming convention is as follows: prefix_base-name[_index]  The prefix is clock_gate by default.\n To change the prefix, set the compile.clockgate.clock_gate_name_prefix application option.\n  The base name is the most frequent instance name among the registers gated by the clock gate.\n The base name does not include bus bit indexes.\n  If necessary to resolve a naming conflict between clock gates, the tool adds an underscore separator character and an integer index number beginning with 0.\n For example, if the tool inserts a clock gate that gates a register named out_reg, the clock gate is named clock_gate_out_reg.\n If the tool inserts a second clock gate for a register named out_reg (perhaps on a different bit in the same bus), the clock gate is named clock_gate_out_reg_0.\n However, if the tool inserts a clock gate for a register named out_reg_1, the inserted clock gate is named clock_gate_out_reg_1_0 to avoid conflicts with the names of clock gates related to the out_reg register."}
{"instruction": "How do I Saving UPF Information", "input": "", "output": "The UPF constraints for physical-only cells can cause issues when the UPF file is read into other tools that do not support physical-only cells, such as verification tools.\n Therefore, surround the UPF constraints for physical-only cells with the syntax shown in the following example: if {[info exists snps_handle_physical_only] && \\ $snps_handle_physical_only} {  /* Supply net connections for filler cells */ connect_supply_net VDDS -ports [get_pins FILLER*/VDD]   By default, the snps_handle_physical_only variable is set to true in the Fusion Compiler tool.\n Therefore, when you load and commit the UPF file, the constraints are applied to the physical-only cells.\n When you save a UPF file with the save_upf command, the tool uses the same syntax for the user-specified and tool-derived UPF constraints for physical-only cells.\n Therefore, these UPF constraints are ignored by any tool that does not have the snps_handle_physical_only variable set to true To create a UPF file that contains commands only for specific types of cells, use the -include or -exclude option with the save_upf command.\n These options accept arguments such as diode_cells pad_cells, and physical_only_cells.\n See the save_upf command man page for the complete list of arguments.\n Command filtering for specified cell types applies to the connect_supply_net set_related_supply_net create_power_domain, and set_isolation commands.\n You can apply command filtering to both block-level and full-chip UPF files."}
{"instruction": "How do I Spreading Repeater Cells During Placement", "input": "", "output": "When you enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true, the tool creates three categories of cells based on the total number of cells.\n  Default Cell Categories for IR-Drop-Aware Placement By default, the tool selects cells for the three categories by using the criteria shown in   The upper category consists of the top one percent of the total number of cells with the highest voltage drop values.\n During placement, the tool spreads these cells the most.\n  The middle category consists of the next five percent of the cells.\n During placement, the tool spreads these cells less than those in the upper category.\n  The lower category consists of the rest of the cells.\n The tool does not spread these cells.\n       You can change the percentage of cells in the upper and middle categories by using the place.coarse.ir_drop_default_target_high_percentage and place.coarse.ir_drop_default_target_low_percentage application options.\n The following example puts the top 2 percent of cells in the upper category and the next 6 percent of cells in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 6.0 Instead of using a percentage of the total number of cells to define the cell categories, you can use the cell voltage drop as a percentage of supply voltage by setting the place.coarse.ir_drop_default_target_high_population and place.coarse.ir_drop_default_target_low_population application options to false.\n They are true by default.\n The following example puts cells with a voltage drop larger than 8 percent of the supply voltage into the upper category and cells with a voltage drop between 4 to 8 percent of the supply voltage into the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\ -value 8.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can specify a percentage of the total number of cells to define the upper category and cell voltage drop as a percentage of supply voltage to define the middle category, or vice versa.\n The following example puts the top 2 percent of the total cells in the upper category, and the next cells that have a voltage drop larger than 4 percent of supply voltage in the middle category: fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_population \\ -value true fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_high_percentage \\       -value 2.0 fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_population \\ -value false fc_shell> set_app_options \\ -name place.coarse.ir_drop_default_target_low_percentage \\ -value 4.0 You can set constraints for specific voltage areas by using the set_placement_ir_drop_target command.\n The following example puts the top 1.5 percent of the cells in the VA1 voltage area into the upper category and the next 4.5 percent of the cells into the middle category: fc_shell> set_placement_ir_drop_target VA1 high 1.5 fc_shell> set_placement_ir_drop_target VA1 low 4.5 The following example puts the cells with a voltage drop larger than 10 percent of the supply voltage in the VA2 voltage area into the upper category and the cells with a voltage drop between 5 and 10 percent of the supply voltage into the middle category: fc_shell> set_placement_ir_drop_target VA2 high 10 -irdrop fc_shell> set_placement_ir_drop_target VA2 low 5 -irdrop To get, report, and reset the voltage-area-based constraints, use the get_placement_ir_drop_target report_placement_ir_drop_target, and reset_placement_ir_drop_target commands."}
{"instruction": "How do I Minimizing Large Displacements During Legalization", "input": "", "output": "The tool performs legalization at various points during the design flow.\n The following topics describe settings for controlling legalization:  Minimizing Large Displacements During Legalization  Optimizing Pin Access During Legalization  Enabling Advanced PG Net Checks        Enabling Advanced Legalization Algorithms  Setting Up for Variant-Aware Legalization  Checking if Library Cells Are Legally Placeable"}
{"instruction": "How do I Analyzing and Fixing Signal Electromigration Violations", "input": "", "output": "In advanced process nodes, the distance between pins decreases, which can result in DRC violations caused by pin access issues.\n These types of DRC violations can be fixed by using keepout margins to increase the spacing between cells.\n       If your postroute design has DRC violations, analyze the violations to determine if they are caused by pin access issues.\n If so, run the optimize_routability command to increase the spacing between cells where the DRC violations occur.\n The optimize_routability command performs the following tasks:  Analyzes the cells with DRC violations to find violations where cells abut By default, the command considers all DRC violations.\n To consider only specific DRC violations, use the -drc_rules option.\n To consider only violations on specific layers, use the -layer_rules option.\n To preview the number of DRC violations and affected cells, use the -check_drc_rules option.\n When you use this option, the command generates a report but does not move any cells.\n  Sets keepout margins on these cells on the side of the cell where the error occurs By default, the command uses the site width as the keepout width.\n To specify a keepout width in microns, use the -keepout_width option.\n Note: These keepout margins are in addition to any existing keepout margins on the cells; the command does not modify the existing keepout margins.\n To try to fix the DRC violations by flipping the cells instead of adding keepout margins, use the -flip option.\n  Legalizes the affected cells You must use one of the following methods to complete the routes for the cells moved by the optimization:  Run ECO routing by using the route_eco command.\n  Run ECO routing by using the -route option with the optimize_routability command.\n To fix the DRC in the areas that have changes, set the route.common.eco_fix_drc_in_changed_area_only application option to on When you use this option, the command runs the route_eco and check_routes commands after completing the optimization.\n After moving the cells and performing ECO routing, remove the keepout margins from the cells by using the optimize_routability -remove_keepouts command."}
{"instruction": "How do I Global Routing", "input": "", "output": "Before you route the signal nets, all clock nets must be routed without violations.\n You can route the signal nets by using one of the following methods:  Use the task-specific commands to perform the standalone routing tasks.\n  To perform global routing, use the route_global command.\n For details see, Global Routing  To perform track assignment, use the route_track command.\n For details see, Track Assignment  To perform detail routing, use the route_detail command.\n For details see, Detail Routing When you run a standalone routing command, such as route_global or route_detail, Zroute reads in the block at the beginning of each routing command and updates the block at the end of each command.\n The router does not check the input data.\n For example, if the track assignment step is skipped and you run detail routing directly, Zroute might generate bad routing results.\n If you need to customize your routing flow or you need to run a large block step-by- step, you might want to use the standalone routing commands instead of automatic routing.\n  Use automatic routing (the route_auto command).\n The route_auto basic command performs global routing, track assignment, and detail routing.\n For details, see Routing Signal Nets by Using Automatic Routing When you run route_auto, Zroute reads the block before starting routing and updates the block when all routing steps are done.\n If you stop automatic routing before it performs detail routing, Zroute checks the input data when you restart routing with this command.\n Use the route_auto command when you run routing to verify convergence, congestion, and design rule quality-of-results (QoR).\n You also might want to use route_auto if congestion QoR is your main goal, rather than timing QoR.\n Zroute can insert redundant vias during signal routing.\n For information about this capability, see Inserting Redundant Vias on Signal Nets"}
{"instruction": "How do I Voltage Driven Power Switch Cell Sizing", "input": "", "output": "Note: The distributed rail analysis feature is supported only in the RedHawk Fusion analysis flow.\n By default, the analyze_rail command uses a single process to perform RedHawk rail analysis.\n To reduce memory usage and total runtime, use the distributed processing method to run RedHawk Fusion on a machine other than the one on which the Fusion Compiler tool is run.\n You can submit multiple RedHawk jobs to the target farm machines and run the jobs in parallel in the same Fusion Compiler session.\n This allows you to run multiple RedHawk analyses with only one Fusion Compiler license.\n Each of the RedHawk jobs requires one SNPS_INDESIGN_RH_RAIL license key.\n To examine the generated analysis result, first run the open_rail_result command to load the result that is saved in the directory you specify.\n You can then investigate the problematic areas in the map and check for violations in a text file or in an error view.\n You can open one result context at a time.\n To load the rail context generated in another analysis run, first close the current rail result using the close_rail_result command, and then open the desired rail result (see Displaying Maps in the GUI ).\n License Requirement By default, the number of required licenses is the number of script files or configurations specified with the -multiple_script_files option during distributed processing mode.\n If the number of available licenses is less than the number of script files at the time when the analyze_rail command is run, the command stops with an error message.\n To check for available SNPS_INDESIGN_RH_RAIL licenses continuously during the analyze_rail run, set the rail.license_checkout_mode application option to wait.\n If the tool detects that a license becomes available, the tool reuses or checks out the license and submits a script to a farm machine immediately.\n By default, the rail.license_checkout_mode application option is set to nowait When the analysis is finished, run the remove_licenses command to release the SNPS_INDESIGN_RH_RAIL licenses.\n fc_shell> remove_licenses SNPS_INDESIGN_RH_RAIL       In, the rail.license_checkout_mode application option is set to wait.\n There are six scripts to submit to the farm machines with only two available SNPS_INDESIGN_RH_RAIL licenses.\n In this case, the tool first checks out two licenses and waits for other licenses to become available.\n When a script finishes the job, the tool reuses its license immediately to submit other scripts.\n  Waiting for Available Licenses During Distributed RedHawk Fusion Run Invoke analyze_rail Check the number of available licenses Script 1 Script 2 license 1 license 2 Script 3 Script 4 Script 5 Script 6       Set rail.license_checkout_mode to wait The tool first submits two scripts to the farm machines, because there are only two licenses available.\n  ...\n The tool checks for available licenses during the analyze_rail run.\n When a license becomes available, the tool reuses it.\n  Steps to Enable Distributed Processing To enable distributed processing for RedHawk Fusion, 1.\n Define the distributed processing configuration by using the set_host_options command.\n You can specify one or more of the following options: Option Description -submit_protocol  rsh    -target  -timeout        Option Description -submit_command    -max_cores   2.\n Run the analyze_rail command with the following options: Option Description -submit_to_other_machines  -multiple_script_files\\ directory_name script_name   Example 51 %> rsh myMachine ls test1 CSHRC DESKTOP > set_host_options \"myMachine\" -target RedHawk \\ -max_cores 2 -timeout 100 > analyze_rail -submit_to_other_machines \\ -voltage_drop static -nets {VDD VDDG VDDX VDDY VSS} The above example first checks if the machine myMachine supports the rsh protocol, and then enables job submission to the myMachine machine for RedHawk Fusion only.\n Timeout value is 100 and the number of cores to use is 2.\n Example 52 > set_host_options -submit_protocol sge \\ -submit_command { qsub -P normal } > analyze_rail -submit_to_other_machines -voltage_drop \\ static -nets {VDD VSS} The above example enables job submission to a machine on the SGE farm machine.\n Example 53 > set_host_options -submit_protocol lsf \\ -submit_command {bsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{result1 RH1.tcl} {result2 RH2.tcl}}  > open_rail_result result1       > close_rail_result > open_rail_result result2 The above example submits two RedHawk jobs with two RedHawk scripts to the LSF farm machines and specifies the directories for saving the analysis results as result1 and result2.\n Example 54 > set_app_options -name rail.license_checkout_mode \\ -value wait > set_host_options -submit_protocol sge \\ -submit_command {qsub} > analyze_rail -submit_to_other_machines \\ -multiple_script_files {{ result1 RH1.tcl} {result2 RH2.tcl} \\ {result3 RH3.tcl}} The above example submits three RedHawk scripts to the SGE farm machines and waits for an available license during the analyze_rail run."}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "By default, the Fusion Compiler tool can use all of the library cells available in the cell libraries when performing optimization or clock tree synthesis on the block.\n To restrict the cell usage, use the set_lib_cell_purpose command after the block is in memory.\n The command has a block scope and is persistent across tool sessions.\n The specified settings are restored when the block is reopened.\n To specify how the tool can or cannot use library cells, use the -include and -exclude options with the set_lib_cell_purpose command.\n Both of these options accept one or more of the following values: all cts hold optimization none  The -include option sets the included_purposes attribute on the specified library cells.\n  The -exclude option sets the excluded_purposes attribute on the specified library cells.\n       Note: If a library cell has a dont_use attribute, it is excluded from all uses, which is the same as if you specified set_lib_cell_purpose -include none for that cell.\n When the tool performs optimization, which includes setup, hold, and logical DRC fixing, it can use library cells that have an included purpose of optimization hold, or both.\n When the tool performs clock tree synthesis, it can use library cells that have an included purpose of cts For example, to disallow the use of a set of library cells for all uses, use the following command: fc_shell> set_lib_cell_purpose -include none lib_cells To allow a set of library cells to be used only for clock tree synthesis, use the following commands: fc_shell> set_lib_cell_purpose -include none lib_cells fc_shell> set_lib_cell_purpose -include cts lib_cells To allow a set of library cells to be used for all uses except clock tree synthesis, use the following command: fc_shell> set_lib_cell_purpose -exclude cts lib_cells To use the asterisk wildcard character (*) to query a collection of cells, you must use the get_lib_cells command.\n However, the set_lib_cell_purpose command excludes synthetic modules by default.\n Therefore, you should use the set_synlib_dont_use command to exclude synthetic modules.\n For example, fc_shell> set_lib_cell_purpose \\ -include none [get_lib_cells */*01_*_AB] Warning: The'set_lib_cell_purpose' command cannot be used on synthetic library cell'standard:*OPMOD.DW01_ADD_AB.timing'.\n (NDMUI-511)"}
{"instruction": "How do I Changing the Structures of Relative Placement Groups", "input": "", "output": "During coarse placement, to avoid the overlap of relative placement groups with the tap cell columns, use the place.coarse.no_split_rp_width_threshold application option.\n The overlap can be removed for only those relative placement groups whose width is less than the distance between tap columns.\n This application option helps the relative placement engine know about the distance between the tap columns.\n       This helps in better placement and structures of relative placement groups in the design.\n You must use this application option for n5 and older technical nodes.\n For n3 and beyond designs, the distance between tap columns is calculated automatically.\n place.coarse.no_split_rp_width_threshold <value> For example, place.coarse.no_split_rp_width_threshold 46"}
{"instruction": "How do I Performing Layout-Versus-Schematic Checking", "input": "", "output": "Calibre interface You can perform design rule checking with the Calibre tool, convert the Calibre DRC error file to an Fusion Compiler error data file, and then report or view the errors in the Fusion Compiler tool.\n To convert the Calibre DRC error file to an Fusion Compiler error data file, use the read_drc_eror_file comandcomandsread_drc_eror_file read_drc_error_file command.\n For example, fc_shell> read_drc_error_file -file Calibre_error_file By default, the command generates an error data file named cell_name.err, where cell_name is derived from the Calibre error report.\n You can specify a name for the error data file by using the -error_data option.\n Note: The read_drc_error_file command supports only flat Calibre DRC error files; it does not support Calibre hierarchy DRC error files.\n You can load the error data file created by the read_drc_error_file command into the error browser to report or display the DRC violations.\n For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide"}
{"instruction": "How do I Minimizing Glitches on Asynchronous Set and Reset Lines of", "input": "", "output": "Specifying synthesis constraints specific to DFT insertion for certain registers must be mapped to non-scan versions and the core wrapper reuse threshold.\n To specify the DFT configurations: 1.\n Execute compile_fusion -from initial_map -to logic_opto 2.\n Specify the DFT configurations such as DFT signals, chain counts, test modes, and so on.\n 3.\n Complete the DFT insertion.\n For more information about DFT insertion, see the TestMAX DFT User Guide.\n 4.\n Execute compile_fusion -from initial_place Note: You must create scan test and scan in and scan out ports before importing floorplan information.\n In addition, the floorplan must contain the physical locations of the test and scan ports.\n Scan-Only Script Example # Set up the library...\n # Read the design...\n # Specify any registers that should not be mapped to scan equivalent, and also to be excluded from any scan chains set_scan_element false <registers that should not be mapped to scan equivalent> # Run compile_fusion to logic_opto step compile_fusion -to logic_opto # DFT Specifications: # Scan chain setup set_scan_configuration -chain_count sc # DFT signals # Clocks and asynchronous resets       set_dft_signal -view existing -type ScanClock \\ -port clk -timing [list 45 55] set_dft_signal -view existing -type Reset \\ -port reset_n -active_state0 # Scan in, scan out, scan enable set_dft_signal -view spec -type ScanDataIn -port SI set_dft_signal -view spec -type ScanDataOut -port SO set_dft_signal -view spec -type ScanEnable -port SE # Scan Synthesis steps create_test_protocol dft_drc preview_dft insert_dft # Continue from initial_place step compile_fusion -from initial_place -to initial_opto # Perform post dft_drc dft_drc -test_mode Internal_scan # Generate post dft_drc verbose report report_dft_drc_violations -test_mode Internal_scan -rule all # Write out Scandef write_scan_def design.scan.def # Write out test model write_test_model -output design.ctl # Save output for TetraMAX write_test_protocol -output design.scan.spf  -test_mode Internal_scan write_verilog -hierarchy all design.v"}
{"instruction": "How do I Specifying Via Ladder Candidates for Library Pins", "input": "", "output": "A via ladder is a stacked via that starts from the pin layer and extends into the upper routing layers.\n Using via ladders during optimization improves the performance and electromigration robustness of a design.\n The tool can automatically insert via ladders for cell pins on timing-critical paths during the compile_fusion and clock_opt commands.\n To perform via ladder insertion during preroute optimization, 1.\n Ensure that the via ladder rules are defined as described in Defining Via Ladder Rules 2.\n Specify the via ladders that can be used for specific library pins by using the set_via_ladder_candidate command, as described in Specifying Via Ladder Candidates for Library Pins 3.\n (Optional) Enable high-performance and electromigration via ladder insertion for critical paths by setting the opt.common.enable_via_ladder_insertion application option to true 4.\n (Optional) Enable the insertion of global-route-based via ladders on pins with via ladder constraints by setting the route.global.insert_gr_via_ladders application option to true 5.\n Perform optimization using the compile_fusion or clock_opt command."}
{"instruction": "How do I Placing Group Repeaters For Multibit Registers", "input": "", "output": "To perform on route placement of interconnect repeaters, use the place_group_repeaters command.\n place_group_repeaters \\ -cells cell_list | -repeater_groups group_id_list [-lib_cell_input pin_name ] \\ [-lib_cell_output pin_name ] \\ [-max_distance_for_incomplete_route distance] \\ [-first_distance distance] \\ [-last_distance distance] \\ [-blockage_aware] \\ [-horizontal_repeater_spacing spacing] \\ [-vertical_repeater_spacing spacing] \\ [-layer_cutting_distance layer_scale_list] [-verbose]"}
{"instruction": "How do I Setting the Policy for Early Data Checks", "input": "", "output": "The tool can identify issues and violations in data during the early stages of design.\n You can set policies and strategy configurations for the predefined checks to allow, tolerate, or repair data.\n Table 64 describes the predefined checks for top-level closure.\n Table 64 Top-Level Closure Checks, Policies, and Strategies Check Description Strategy Supported Policies Supported References hier.block.miss ing_frame_view        error, tolerate, repair MID BOT hier.block.refe rence_missing_p ort_location           error, tolerate, repair MID BOT hier.block.refe rence_port_outs ide_boundary              error, tolerate, repair MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.refe rence_missing_p ort           error, tolerate, repair MID BOT hier.block.inst ance_bound_to_f rame     error, tolerate TOP hier.block.inst ance_with_desig n_type_macro     error, tolerate TOP hier.top.estima ted_corner     error, tolerate TOP hier.block.miss ing_leaf_cell_l ocation             error, tolerate, repair MID BOT hier.block.leaf _cell_outside_b oundary              error, tolerate, repair MID BOT hier.block.miss ing_child_block _instance_locat ion                  error, tolerate, repair MID       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.chil d_block_instanc e_outside_bound ary               error, tolerate, repair MID hier.block.port _mismatch_betwe en_views             error, tolerate, repair MID BOT hier.block.miss ing_design_view _for_abs     error, tolerate MID BOT hier.block.inst ance_unlinked           error TOP hier.block.abst ract_type_non_t iming    error MID BOT hier.block.abst ract_target_use _non_implementa tion     error MID BOT hier.block.miss ing_core_area     error MID BOT       Table 64 Top-Level Closure Checks, Policies, and Strategies (Continued) Check Description Strategy Supported Policies Supported References hier.block.unma pped_logic     error MID BOT Where  BOT signifies bottom level design.\n  MID signifies intermediate level design, which instantiates BOT.\n  TOP signifies the top-level design, which instantiates MID."}
{"instruction": "How do I Specifying Horizontal and Vertical Spacing for Repeater Groups", "input": "", "output": "Use one of the following mutually exclusive options to control cutting for repeater groups:  -layer_cutting_spacing specifies the cut space of the routes to the driver pin.\n The cut starts from the driver side.\n  -layer_cutting_distance specifies the cut distance from the repeater center to the input and output routes."}
{"instruction": "How do I Enabling Local Skew Optimization", "input": "", "output": "By default, clock tree synthesis tries to achieve the best skew and latency for all clocks.\n However, this can lead to area, power, and runtime overhead for low frequency clocks, which have relaxed skew and latency targets.\n  To specify a skew target, use the -target_skew option with the set_clock_tree_options command.\n  To specify a latency target, use the -target_latency option with the set_clock_tree_options command.\n By default, when you define skew and latency targets, they apply to all clocks in all corners.\n To define targets for specific clocks, use the -clocks option.\n To define targets for specific corners, use the -corners option.\n To report the user-defined skew and latency targets, use the report_clock_tree_options command.\n To remove user-defined skew or latency targets, use the remove_clock_tree_options command.\n To remove all skew and latency targets, use the -all option; otherwise, use the appropriate -target_skew -target_latency -clocks, and -corners options to remove the specific targets."}
{"instruction": "How do I Via Ladder Rule Files", "input": "", "output": "Instead of explicitly defining via ladder rules for performance via ladders, you can use the setup_performance_via_ladder command to generate the via ladder rules and associations.\n By default, this command  Generates via ladder rules for all layers up to the M5 layer To specify a different maximum layer, use the -max_layer attribute.\n       The command uses information from the technology file to generate the via ladder rules.\n The command derives the following information from the technology file:  The cut layers that connect the specified metal layers  The cut names  The minimum required length for each metal layer Note: You must open the block before running the setup_performance_via_ladder command to ensure that the command has access to the technology data for the block.\n The command outputs an XML file that provides information about the via ladder rules and a script file that defines the via ladder rules.\n For details about these files, see Via Ladder Rule Files You can also generate these files by using the generate_via_rules_for_performance command.\n  Associates via ladder rules with the pins of all library cells that do not have a dont_use attribute To include the pins of library cells that have a dont_use attribute, use the -dont_use option.\n To associate via ladder rules only with specific pins, use the -lib_pins option.\n The command analyzes the information about each library cell pin and its shapes to determine the via ladder rules to associate with that pin and then outputs a script file that defines the associations.\n For details about this file, see Via Ladder Association File You can also generate this file by using the associate_performance_via_ladder command.\n  Runs the generated script files See Also  Defining Via Ladder Rules  Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization"}
{"instruction": "How do I Running the signoff_check_drc Command", "input": "", "output": "IC Validator In-Design signoff design rule checking (DRC) runs the IC Validator tool within the Fusion Compiler tool to check the routing design rules defined in the foundry signoff runset.\n You can perform signoff design rule checking by  Running the signoff_check_drc command  Using the Live DRC feature in the Fusion Compiler GUI After place and route, use the signoff_check_drc command to perform signoff design rule checking on the entire block.\n After engineering change orders (ECO), use either method to perform incremental signoff design rule checking on the modified portions of the block.\n See Also  Automatically Fixing Signoff DRC Violations"}
{"instruction": "How do I Checking the Routing Results", "input": "", "output": "Shielding is needed around sensitive nets to reduce noise and crosstalk.\n When you perform custom routing by using the route_custom command, the tool automatically creates shields for the nets based on the constraints you specify by using the create_net_shielding command.\n To add shielding to the selected nets in a separate run, use the create_custom_shields command.The following example creates shields for net1 and net2.\n fc_shell> create_custom_shields -nets {net1 net2} To remove the shielding created by the create_custom_shields command, use the remove_custom_shields command.\n Doing this also removes the shielding created by the route_custom command."}
{"instruction": "How do I Specifying a Keepout Margin", "input": "", "output": "The Fusion Compiler tool supports the following orientations for relative placement groups:  R0 The column position of the relative placement group is from left to right, and the row position is from bottom to top.\n  R180 The column position of the relative placement group is from right to left, and the row position is from top to bottom.\n  MY The column position of the relative placement group is from right to left, and the row position is from bottom to top; that is, the orientation of the group is flipped with respect to the R0 orientation.\n  MX The column position of the relative placement group is from left to right, and the row position is from top to bottom; that is, the group is flipped with respect to the R180 orientation.\n  shows how the column and row positions in a relative placement group are placed for the four orientations.\n        Orientation of Relative Placement Groups Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R0 MY U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U8 U9 U4 U5 U6 U24 U22 U23 U21 Row 2 Row 2 Row 1 Row 1 Row 0 Row 0 Col 0 Col 1 Col 2 Col 2 Col 1 Col 0 R180 MX U3 U1 U23 U24 U21 U22 U1 U3 U4 U5 U6 U7 U8 U9 U7 U9 U4 U6 U24 U22 U23 U21 U5 U8 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 The orientation of relative placement groups is automatically set by the tool to minimize wire length.\n You can also choose to set the orientation of relative placement groups by using the set_rp_group_options command.\n For example, the following command sets the relative placement group orientation to MY.\n fc_shell> set_rp_group_options [get_rp_groups design::rp] \\ -group_orientation MY For designs with hierarchical relative placement groups, the orientation settings are propagated down to the lowest level in hierarchy.\n       Note: When the orientation of a relative placement group is changed, the constraints on the relative placement group, such as alignment and utilization, are preserved according to the specifications that you provide."}
{"instruction": "How do I Ensuring Clock Tree Exceptions are Valid", "input": "", "output": "To define one or more pins as ignore pins, use the following syntax: set_clock_balance_points [-clock clock -consider_for_balancing false -balance_points pins The -clock option is not required.\n If you do not use it, all user-defined ignore pins apply to all clocks.\n       For the CLK clock tree shown in, assume that you want to ignore all branches of the clock tree beyond the U2 cell.\n To do so, you would use the following command: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing false -balance_points [get_pins U2/A]  User-Defined Ignore Pin CLK   U2 To report the user-defined ignore pins, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins report_clock_balance_points command.\n This command reports both the user-defined sink pins and the user-defined ignore pins.\n During clock tree synthesis, the tool adds guide buffers and isolates ignore pins from the rest of the clock network.\n During subsequent data path optimization, the tool fixes any existing DRC violations beyond the guide buffers.\n To remove the ignore pin definition from a pin, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins remove_clock_balance_points command.\n For example, to remove the ignore pin definition from pin U2/CLK for the CLK clock, use the following command: fc_shell> remove_clock_balance_points -clock [get_clocks CLK] \\ -balance_points [get_pins U2/CLK]"}
{"instruction": "How do I Removing Routing Blockages", "input": "", "output": "To find routing blockages, use the get_routing_blockages command.\n For example, to get all the routing blockages in a block, use the following command: fc_shell> get_routing_blockages * To find the routing blockages for specific nets, use the -of_objects option to specify the nets of interest.\n For example, to find the routing blockages for the n1 net, use the following command: fc_shell> get_routing_blockages -of_objects [get_nets n1] To find the routing blockages in a specific location, use the get_objects_by_location -classes routing_blockage command."}
{"instruction": "How do I Adding Buffers in a Specified Configuration", "input": "", "output": "When you use the add_buffer_on_route command, you must specify the following:  The net on which to add buffers  The type of buffers to add and where to add them on the net by using one of the following methods:  Adding Buffers in a Specified Configuration  Adding Buffers at Specified Locations  Adding Buffers at a Specified Interval  Adding Buffers at an Interval That is a Ratio of the Net Length  Adding Buffers on a Bus in a Specified Pattern"}
{"instruction": "How do I Replacing Clock Gates", "input": "", "output": "To insert clock gating logic in an RTL design and to synthesize the design with the clock- gating logic, follow these steps: 1.\n Read the RTL design.\n 2.\n (Optional) Use the insert_dft command to insert test cells into the design.\n 3.\n Use the compile_fusion command to compile the design.\n During the compile process, the tool inserts clock gates on the registers qualified for clock-gating.\n By default, during clock-gate insertion, the compile_fusion command uses the clock gating default settings and also honors the setup, hold, and other constraints specified in the logic libraries.\n To override the setup and hold values specified in the library, use the set_clock_gating_check command before compiling the design.\n The default settings are suitable for most designs.\n The compile_fusion command automatically connects the scan enable and test ports or pins of the integrated clock-gating cells, as needed.\n 4.\n Use the report_clock_gating command to report the registers and the clock-gating cells in the design.\n Use the report_power command to get information about the dynamic power used by the design after clock-gate insertion.\n The following example illustrates a typical command sequence for clock using default settings: fc_shell> read_verilog design.v fc_shell> create_clock -period 10 -name CLK fc_shell> compile_fusion fc_shell> insert_dft       fc_shell> report_clock_gating fc_shell> report_power"}
{"instruction": "How do I Controlling Movement When Legalizing Relative Placement", "input": "", "output": "When a relative placement cell is modified or moved, the relative placement structure can be disturbed.\n When a relative placement cell is removed during optimization, the relative       placement information of the instance is also removed, disrupting the relative placement structure.\n To preserve the relative placement structures during various postplacement optimization processes, use the -optimization_restriction option with the set_rp_group_options command and specify the appropriate setting as shown in Table 60 Table 60 Settings for the -optimization_restriction Option To do this Use this setting  all_opt  size_only  size_in_place  no_opt For a hierarchical relative placement group, the -optimization_restriction option setting applied to the top level is propagated to the lower-level groups and any settings applied to the lower-level groups are ignored."}
{"instruction": "How do I Importing the Floorplan Information", "input": "", "output": "During early design development, frequent design updates can cause incomplete or inconsistent data, such as pin mismatches between a block-level design and the reference to it from a top-level design.\n To enable the tool to successfully link a block even if it has certain types of design mismatch, set a mismatch configuration for the block.\n By default, the tool cannot link any block with inconsistent or mismatching data.\n When you set mismatch configurations, the tool either ignores or fixes several different types of mismatching data and continues the linking process.\n Blocks linked with mismatching data can be used only for feasibility analysis.\n To learn how to mitigate design mismatches, see the Fusion Compiler Data Model User Guide"}
{"instruction": "How do I Prerequisites for Routing", "input": "", "output": "shows the basic Zroute flow, which includes clock routing, signal routing, DFM optimizations, and route verification.\n  Basic Zroute Flow"}
{"instruction": "How do I Applying Required Settings for High Performance Cores", "input": "", "output": "To apply placement, legalization, routing, and extraction setting specific to 12 or 7 nanometer technology nodes, use the set_technology command with the -node 12 or -node 7 option.\n       When using this command, perform the following steps before placement, optimization, and routing: 1.\n Load and link the design.\n 2.\n Apply the settings required for the technology nodes by using the set_technology -node command, as shown in the following example: fc_shell> set_technology -node 7 3.\n (Optional) Report the technology-node settings by using the set_technology -report_only command.\n 4.\n Apply your design-specific application option or command settings to override the generic setting of the set_technology command.\n When you save the design library with the save_lib command, the technology-node setting is saved.\n Note: After you specify a technology node with the set_technology command, you cannot change it.\n For more information about which ASIC technologies are supported by this command, contact Synopsys Support."}
{"instruction": "How do I Merging Clock Gates", "input": "", "output": "If you load a SAIF file, the Fusion Compiler tool analyzes the switching activity to evaluate whether to expand a tool-inserted clock gate.\n This analysis prevents the insertion of unnecessary clock gates.\n For example, in, clock gates A1 and A2 are each common to two paths and are therefore candidates for multilevel expansion.\n  Before Clock-Gate Level Expansion       However, if clock gate A2 is always enabled, it has a toggle rate of 0 and a static probability of 1.\n Adding another clock-gate level does not provide any benefit in this case.\n The final configuration is shown in  After Clock-Gate Level Expansion If clock-gate level expansion is enabled, the Fusion Compiler tool performs activity- driven analysis by default.\n If a SAIF file is not available, disable this feature by setting the compile.clockgate.enable_activity_drivel_level_expansion application option to false (the default is true ).\n If clock-gate level expansion is disabled, the tool ignores the compile.clockgate.enable_activity_driven_level_expansion application option."}
{"instruction": "How do I Controlling IR-Drop-Aware Placement", "input": "", "output": "During placement, the tool can use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values, which reduces the power density of such areas.\n To perform IR-drop-aware placement, use the following steps: 1.\n Place and legalize the block.\n 2.\n Set up for RedHawk Fusion and perform static or dynamic voltage drop analysis by using the analyze_rail -voltage_drop command as shown in the following example: fc_shell> source redhawk_setup.tcl fc_shell> analyze_rail -voltage_drop static -nets {VDD VSS} For more information, see Performing Voltage Drop Analysis 3.\n Enable IR-drop-aware placement by setting the place.coarse.ir_drop_aware application option to true       4.\n (Optional) Specify additional settings for IR-drop-aware placement, as described in Controlling IR-Drop-Aware Placement 5.\n Rerun placement.\n Note: To perform IR-drop-aware placement, you must have Digital-AF and SNPS_INDESIGN_RH_RAIL license keys."}
{"instruction": "How do I Creating Constraints for Auto Floorplanning", "input": "", "output": "During early design stages, a design often undergoes many iterations due to changes such as adding features and macros; as a result, the floorplan contains limited or no physical information.\n Automatic floorplanning can generate high-quality floorplans and create missing physical information early in the design cycle, which allows you to  Achieve better correlation between the results of RTL synthesis and design implementation  Identify and fix design issues early in the design cycle  Generate a better starting point for place and route, eliminating costly iterations During automatic floorplanning, the compile_fusion command performs the following tasks:  Creates the die, rows, and tracks  Shapes and places voltage areas  Places macros  Places pins and I/Os By default, the top-level floorplan is created with a core utilization of 0.7.\n For information about setting constraints for automatic floorplanning, see Creating Constraints for Auto Floorplanning"}
{"instruction": "How do I Setting Clock Tree Design Rule Constraints", "input": "", "output": "Before you synthesize the clock trees, use the check_clock_tre comandcomandscheck_clock_tre check_clock_trees command to verify that the clock trees are properly defined.\n For example, to verify that the CLK clock tree is properly defined, use the following command: fc_shell> check_clock_trees -clocks [get_clocks CLK] If you do not specify the -clock option, the tool checks all clocks in the current block.\n The check_clock_trees command checks for the following issues:  Clock (master or generated) with no sinks  Loops in the clock network  Multiple clocks reach the same register because of overlapping clocks, but multiple- clocks-per-register propagation is not enabled  Ignored clock tree exceptions  Stop pin or float pin defined on an output pin  Buffers with multiple timing arcs used in clock tree references  Situations that cause an empty buffer list        Generated clock without a valid master clock source A generated clock does not have a valid master-clock source in the following situations:  The master clock specified in create_generated_clock does not exist  The master clock specified in create_generated_clock does not drive the source pin of the generated clock  The source pin of the generated clock is driven by multiple clocks, and some of the master clocks are not specified with create_generated_clock For example, in, the GEN_REG/Q pin is driven by both CLKA and CLKB.\n If only CLKA is specified as a master clock in a create_generated_clock command, GEN_CLK does not have a valid master clock source.\n  Generated Clock With Invalid Master Clock Source     REG1 REG2     GEN_REG CLKA CLKB GEN_CLK For multicorner-multimode designs, the check_clock_trees command checks all active scenarios for the following issues:  Conflicting per-clock exception settings  Conflicting balancing settings Before you implement the clock trees, you should manually fix the reported issues.\n Each message generated by the check_clock_trees command has a detailed man page that describes how to fix the identified issue.\n You can improve the clock tree and timing QoR by fixing all the issues identified by the check_clock_trees command."}
{"instruction": "How do I Sorting and Filtering the Data", "input": "", "output": "By default, the comparison tables show the QoR values for all runs.\n For example, the NVE number for the following run is 2374: To cycle through different display styles of the data, right-click anywhere in the table.\n You can view the data  as a percentage delta against the baseline  as an absolute delta against the baseline (shown in For example, as a percentage delta, the NVE number shows 2.7% fewer failing endpoints than the baseline: As an absolute delta, the NVE number shows 65 fewer failing endpoints than the baseline: See Also  Sorting and Filtering the Data  Exploring the Detailed Comparison Data"}
{"instruction": "How do I Checking Designs With Abstracts for Top-Level-Closure Issues", "input": "", "output": "Before you can perform synthesis, placement, optimization, clock tree synthesis, and routing at the top level, you must perform the following tasks:  Apply the top-level-timing constraints and settings.\n You can split the chip-level constraints in to separate top- and block-level constraints by using the split_constraints command.\n  Review and specify the relationship between the top- and block-level modes, corners, and clocks by using the set_block_to_top_map command.\n  If the pre-clock tree implemented blocks, which have undergone CCD optimization, are used for top-level placement and optimization, then the ideal clock latencies adjusted dynamically by different engines such as CCD and clock-gate estimation on the clock pins of registers or integrated clock gating (ICG) cells inside the blocks might not be seen at the top-level leading to timing inaccuracies at the top-level.\n Promote these clock latency constraints from block-level to the top-level by using the promote_clock_data -latency_offset -auto_clock connected command.\n  Apply the top-level clock tree synthesis settings and exceptions.\n  If the top-level exceptions do not include the balance points on the pins within lower-level blocks, promote the balance points from the lower levels by using the promote_clock_data -auto_clock connected -balance_points command.\n  If concurrent clock and data (CCD) optimization is performed at the block level, the tool derives median clock latencies for the block-level clock ports, which accounts for the latency adjustments that were derived for the block-level registers during concurrent clock and data optimization.\n Promote these block-level clock latencies as clock balance point delays for the block-level clock pins by using the promote_clock_data -auto_clock connected -port_latency command.\n  If the lower-level blocks contain clock-meshes, promote the mesh annotations (annotated transitions and delays) by using the promote_clock_data -mesh_annotations command.\n  If you need to promote clock data for a specific top-level clock, use the promote_clock_data -clocks {top_clock} -port_latency command.\n The command also promotes clock-independent exceptions.\n If any of the given top-level clocks has no mapping to any block-level clock in any mode, the tool issues a warning.\n  If there are any active modes, corners, or clocks at the top-level, which cannot be mapped to corresponding modes, corners, or clocks in the block-level, you can still promote the clock data for other mapped modes, corners, or clocks using the promote_clock_data -balance_points -force command.\n This command issues errors for the unmapped modes, or corners, or clocks.\n        Apply the top-level UPF constraints, which you can create from the full-chip UPF constraints by using the split_constraints command.\n The tool promotes the required UPF constraints from the lower-level blocks to the top level."}
{"instruction": "How do I Querying Placement Blockages", "input": "", "output": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type allow_buffer_only -blocked_percentage 70       Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Tapoffs", "input": "", "output": "The following Custom Router application options determine whether bus trunks will be split when routing through obstacles and how the bits will be split.\n  custom.route.bus_split_ignore_width  custom.route.bus_split_even_bits The custom.route.bus_split_ignore_width application option specifies the wire width threshold of any obstructing power grid or route that triggers the bus trunk to be split into more than one section.\n The custom.route.bus_split_even_bits application option requires that you set the custom.route.bus_split_ignore_width application option.\n If the custom.route.bus_split_ignore_width requirement is met, you can use the custom.route.bus_split_even_bits application option to control whether automatic bus splitting routes an even number of nets between pre-routes (power stripes).\n In the following example, the bus trunk consists of four bits and the custom.route.bus_split_ignore_width application option is set.\n The spacing between the power and ground rails can accommodate three bits only.\n a shows the two possible results when the custom.route.bus_split_even_bits application option is turned off.\n b shows the result when the custom.route.bus_split_even_bits application option is turned on.\n  Splitting Bus Trunk to Route Through Power and Ground Rails"}
{"instruction": "How do I Creating a Multibit Register Bank From Specific Single-Bit", "input": "", "output": "To perform integrated multibit register optimization during the compile_fusion command, 1.\n Enable multibit register optimization by setting the compile.flow.enable_multibit application option to true When you do so, by default, the tool performs the following multibit optimizations during different stages of the compile_fusion command:  Combines single registers or smaller register banks at the RTL level to create larger register banks during the initial_map stage To disable this feature, set the compile.flow.enable_rtl_multibit_banking application option to false  Splits multibit register banks created at the RTL level if the register bank includes registers on critical timing paths during the logic_opto stage To disable this feature, set the compile.flow.enable_rtl_multibit_debanking application option to false  Creates multibit register banks considering placement during the initial_opto stage To disable this feature, set the compile.flow.enable_physical_multibit_banking application option to false You can enable placement-based multibit banking during the final_place stage of the compile_fusion command, instead of the initial_opto stage, by setting the compile.flow.enable_second_pass_multibit_banking application option to true and the compile.flow.enable_physical_multibit_banking application option to false You should enable placement-based multibit banking either during the initial_opto stage or the final_place stage; not both.\n  Splits multibit register banks, if it improves total negative slack (TNS), during the initial_opto and final_opto stages To disable this feature, set the compile.flow.enable_multibit_debanking application option to false 2.\n (Optional).\n       3.\n Specify settings for multibit register banking by using the set_multibit_options command.\n For example, the following command excludes the reg[1] cell from multibit optimization during the RTL-banking stage: fc_shell> set_multibit_options -exclude [get_cells \"reg[1]\"] \\ -stage rtl The following command specifies that during the physical-banking stage, the tool banks only registers that are connected to the same bus: fc_shell> set_multibit_options -bus_registers_only \\ -stage physical 4.\n (Optional) Control multibit register optimization using application options as shown in the following table.\n Table 22 General Application Options for Controlling Multibit Register Optimization To do this Set this application option   multibit.banking.enable_strict_scan_check  true    multibit.banking.lcs_consider_multi_si_cells  true        multibit.banking.across_equivalent_icg true    dont_touch legalize_only size_only  mv.cells.enable_multibit_pm_cells true size_only   multibit.common.exclude_size_only_cells  false  compile_fusion  compile.flow.enable_multibit_rewiring true       To do this Set this application option   logic_opto  compile.flow.enable_toggle_aware_rtl_multibit_ reordering true      initial_opto (compile_fusion) final_place final_opto (compile_fusion/place_opt)   logic_opto compile_fusion  opt.common.enable_multibit_feature true 5.\n (Optional) Create a multibit register bank from specific single-bit registers as described in Creating a Multibit Register Bank From Specific Single-Bit Registers 6.\n (Optional) Control the naming style used for multibit banking as described in Specifying Naming Styles for Multibit Registers 7.\n Perform optimization by using the compile_fusion command.\n 8.\n (Optional) Report multibit information.\n To report the multibit register banks inferred by the tool, use the report_transformed_registers -multibit command, as described in Reporting Multibit Registers To report multibit statistics such as the total number of single-bit and multibit registers, the multibit banking ratio, and so on, use the report_multibit command.\n For more information about how to determine why multibit register banking is not performed for specific cells, see Identifying Why Multibit Banking Is Not Performed 9.\n (Optional) Analyze the multibit banking components in the GUI as described in Viewing Multibit Components in the GUI"}
