{"instruction": "How do I Displaying the PG Electromigration Map", "input": "", "output": "When PG electromigration analysis is complete, you can check for current violations by displaying a PG electromigration map or checking the generated errors in the error browser.\n  Displaying the PG Electromigration Map  Checking PG Electromigration Violations"}
{"instruction": "How do I Specifying the Clock Tree References", "input": "", "output": "The clock tree synthesis options guide the implementation of the clock trees.\n The following topics describe how to set these options:  Specifying the Clock Tree References  Setting Skew and Latency Targets  Enabling Local Skew Optimization  Specifying the Primary Corner for Clock Tree Synthesis  Preventing Specific Clocks From Being Synthesized  Preserving Preexisting Clock Trees  Enabling Clock Tree Power Reduction Techniques  Enabling Wire Length Aware Power-Driven Relocation  Reducing Electromigration  Handling Inaccurate Constraints During Clock Tree Synthesis  Defining Clock Cell Spacing Rules  Creating Skew Groups  Defining a Name Prefix for Clock Cells  Using the Global Router During Initial Clock Tree Synthesis  Specifying Constraints for Clock Nets  Constructing Faster Clock Tree to Specific Endpoints  Improving Latency-Driven Clock-Gate Splitting  Improving the Repeater Levels in Clock Tree  Reducing Signal Integrity Effects on Clock Nets  Specifying Settings for Clock Latency Adjustments  Timing Driven Sink Transition Target  Reporting the Clock Tree Settings"}
{"instruction": "How do I Using Routing Guides to Encourage River Routing", "input": "", "output": "You can use a routing guide to prioritize regions within the routing guide boundary for routing.\n The regions are called access preference areas.\n You prioritize the access preference areas by assigning strengths to them.\n Access preference areas with higher strengths are preferred for routing.\n You can define access preference areas for both wires and vias.\n When you define a via access-preference area, you are defining a preference       area for the via surrounds on the specified metal layer for vias coming from both above and below that metal layer.\n To create this type of routing guide, use the -access_preference option with the create_routing_guide command.\n Use the following syntax to specify the access preference areas and their strengths: layer [{wire_access_preference wire_rect wire_strength }] [{via_access_preference via_rect via_strength }]...} You can define multiple access preference areas.\n To define the relative preference of the access preference areas, use strength values between 0 and 1.\n If access preference areas overlap, the stronger access preference area takes precedence over the weaker access preference area.\n To require routing in a specific access preference area, use a strength value of 1.\n When you define access preference areas with a strength of 1, all access preference areas with a strength less than 1 are ignored and Zroute treats the access preference routing guide as a hard constraint.\n The following example creates an access preference routing guide whose boundary is a rectangle with its lower-left corner at (0, 0) and its upper-right corner at (300, 300).\n It contains one wire access-preference area with coordinates of (0, 0) and (2, 1) and two via access-preference areas, one with coordinates of (0, 0) and (5, 5) and one with coordinates of (40, 40) and (45, 45).\n The wire access-preference area is slightly preferred over areas outside of the access preference area because it has a strength of 0.2.\n The via access-preference area with coordinates at (40, 40) and (45, 45) is ignored, because routing is required in the via access-preference area with coordinates at (0, 0) and (5, 5), which has a strength of 1.\n fc_shell> create_routing_guide -boundary {{0 0} {300 300}} \\ -access_preference {M1 {wire_access_preference {{0 0} {2 1}} 0.2} {via_access_preference {{0 0} {5 5}} 1.0} {via_access_preference {{40 40} {45 45}} 0.5}} To report information about the access preference routing guides defined for your block, use the report_routing_guides command."}
{"instruction": "How do I Manually Enabling Dynamic Power Shaping and", "input": "", "output": "To set up for voltage-drop-aware placement, perform the following steps: 1.\n Specify the voltage-drop-analysis type by using the rail.analysis_type application option.\n The valid values are static dynamic (default), dynamic_vcd, and dynamic_vectorless 2.\n Specify settings required to perform RedHawk voltage drop analysis, as described in Performing Voltage Drop Analysis"}
{"instruction": "How do I Querying Specific Message IDs", "input": "", "output": "As an alternative to displaying logic-level histograms in the GUI, you can report logic levels by using the report_logic_levels command on the command line or in a script (batch mode).\n Note: You must have a mapped design to run logic-level reporting.\n You can use the command to report logic levels of  The entire design or a selected path group  All types of paths, including same-clock paths, cross-clock paths, infeasible paths, and multicycle paths in all scenarios The report contains logic distribution and timing information in the summary, logic-level distribution, and logic-level path report sections.\n By default, buffers and inverters are not reported.\n       To report logic levels, 1.\n (Optional) Set a specific logic-level threshold other than the default by using the set_analyze_rtl_logic_level_threshold command.\n By default, the tool derives the logic-level threshold based on the delay values required for the paths.\n  To set a logic-level threshold for the entire design, enter fc_shell> set_analyze_rtl_logic_level_threshold threshold_value  To set a logic-level threshold for a specific path group, enter fc_shell> set_analyze_rtl_logic_level_threshold \\ -group path_group threshold_value The path group setting overrides the global threshold of the entire design.\n  To reset all threshold values, enter fc_shell> set_analyze_rtl_logic_level_threshold -reset  To reset a specific group setting, enter fc_shell> set_analyze_rtl_logic_level_threshold \\ -group path_group -reset 2.\n (Optional) Specify the fields in the summary section of the report by setting the shell.synthesis.logic_level_report_summary_format application option.\n The default contains five fields: \"group period wns num_paths max_level\".\n You can specify up to eight fields.\n For example, fc_shell> set_app_options \\ -name shell.synthesis.logic_level_report_summary_format \\ -value \"group num_paths max_level min_level avg_level\"...\n 3.\n (Optional) Specify the fields in the path group section of the report by setting the shell.synthesis.logic_level_report_group_format application option.\n The default contains five fields: \"slack ll llthreshold startpoint endpoint\".\n You can specify up to ten fields.\n For example, fc_shell> set_app_options \\ -name shell.synthesis.logic_level_report_group_format \\ -value \"slack ll ll_buf_inv clockcycles startclk endclk...\n 4.\n Report logic levels by using the report_logic_levels command.\n The following example generates a logic-level report of the clk_i path group: fc_shell> report_logic_levels -group clk_i"}
{"instruction": "How do I Deriving Pin Access Routing Guides", "input": "", "output": "Routing guides provides routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic described how to derive the following types of routing guides:  Deriving Pin Access Routing Guides  Deriving Metal Cut Routing Guides See Also  Defining Routing Guides"}
{"instruction": "How do I Specifying Ideal Voltage Sources as Taps", "input": "", "output": "RedHawk-SC Fusion provides application options and commands to read in user- customized python script files.\n The tool generates all design collaterals (including DEF, LEF, SPEF, TWF and PLOC) from the design library and adds them to the user-customized python script to run voltage drop analysis in a single iteration of analyze_rail.\n The user-customized python script file is supported in rail analysis with multiple rail scenarios, as well as other IR-driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n To use a customized python script file for RedHawk-SC Fusion rail analysis, 1.\n Set the type of script file to python fc_shell> set_app_options -name rail.generate_file_type -value python 2.\n Set the rail.generate_file_variables application option to specify the variables for generating the input files (including DEF, LEF, SPEF, TWF and PLOC files) to add to the user-customized python script file.\n You do not need to set this application option if the customized python script file uses the same values as in RedHawk-SC Fusion.\n DEF File LEF File SPEF File TWF File PLOC File   DEF LEF SPEF TWF PLOC     def_files lef_files spef_files tw_files ploc For example, if you specify a test_def_file for the DEF variable to match with the DEF file specified in the customized python script file, set the following: fc_shell> set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files} 3.\n Create and specify rail scenarios for generating the necessary input files to add to the customized python script.\n Run the create_rail_scenario command to create a rail scenario and associate it with a design scenario in the current design.\n You can create multiple rail scenarios and associate them with the same scenario in the current design.\n Then run the set_rail_scenario -generate_file {LEF | TWF | DEF | SPEF | PLOC} command to specify the rail scenario and the type of input files to generate from the design library.\n       Note: When running rail analysis using multicorner-multimode technology, you must create rail scenarios using the create_rail_scenario command before the set_rail_scenario command.\n The following example creates the T_low and T_high rail scenarios and generates input files for them: fc_shell> create_rail_scenario -name T_low -scenario func_cbest fc_shell> set_rail_scenario -name T_low -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py fc_shell> create_rail_scenario -name T_high -scenario func_cbest fc_shell> set_rail_scenario -name T_high -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py You can then use the customized.py file for multi-rail-scenario rail analysis or other IR- driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n Examples The following example uses a customized python script for multi-rail-scenario rail analysis on a grid system.\n #Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true   #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python  #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files }  create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic  create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py        set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G}  analyze_rail -rail_scenario {func.ss_125c func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for multi-rail-scenario rail analysis on a local machine.\n #Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true   #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python  #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files }  create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic  create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py  set_host_options -submit_command {local}  analyze_rail -rail_scenario {func.ss_125c func.ff_125c} The following example uses a customized python script for single-scenario rail analysis on a grid system.\n Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true   #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python  #Use user-defined test_def_files for DEF variable to match #with customized python.\n       set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files }  create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py  set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G}  analyze_rail -rail_scenario {func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for IR-driven placement on a grid system.\n Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true   #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python  #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files }  create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic  create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py  set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} # Enable IR-driven placement before running clock_opt -from final_opto set_app_options -name opt.common.power"}
{"instruction": "How do I Considering Voltage Drop Information During Clock Tree", "input": "", "output": "To synthesize the clock trees, route the clock nets, and further optimize the design by using a single command, use the clock_opt command.\n The clock_opt command consist of the following stages: 1.\n The build_clock stage, during which the tool synthesizes and optimizes the clock trees for all clocks in all modes of all active scenarios.\n After clock tree synthesis, the tool sets the synthesized clocks as propagated.\n 2.\n The route_clock stage, during which the tool detail routes the synthesized clock nets.\n 3.\n The final_opto stage, during which the tool performs further optimization, timing- driven placement, and legalization.\n It then global routes the block and performs extensive global-route-based optimization, which includes incremental legalization and route patching.\n You can limit the clock_opt command to one or more contiguous stages by using the -from option to specify the stage from which you want to begin and the -to option to specify the stage after which you want to end.\n If you do not specify the -from option, the tool begins from the build_clock stage.\n Similarly, if you do not specify the -to option, the tool continues until the final_opto stage is completed.\n For example, to synthesize and optimize the clock trees and detail route the clock nets only, limit the execution to the build_clock and route_clock stages by use the following command: fc_shell> clock_opt -to route_clock Because the tool performs global routing during the final_opto stage, you should specify all router related settings, such as routing rules, route guides, application option settings required for the technology node, and so on, before you run the clock_opt command.\n You should run the final_opto only one time for each block.\n After this stage is completed, all the signal routes in the block are global routed.\n Therefore, when subsequently run any routing command, such as the route_auto route_global, or route_group command, the tool skips global routing.\n To avoid errors during subsequent track assignment and detail routing, do not change any global route shapes after you run the clock_opt command."}
{"instruction": "How do I Checking for Isolated Vias", "input": "", "output": "You can use the signoff_fix_isolated_via command either to check for isolated vias only, or to check for and fix the isolated vias."}
{"instruction": "How do I Creating Abstracts for Signal Electromigration Analysis", "input": "", "output": "To create an abstract that contains power information of the corresponding block, use the following steps at the block level: 1.\n Activate the scenarios for which you want to perform power analysis by using the -active true option of the set_scenario_status command and enable them for power analysis by using the following options:  -dynamic_power true for dynamic power analysis  -leakage_power true for leakage power analysis Power information is stored only for active scenarios that are enabled for dynamic or leakage power.\n 2.\n (Optional) Apply switching activity by either reading in a SAIF file with the read_saif command or annotating the switching activity information on the nets with the set_switching_activity command.\n For more information about applying switching activity, see Annotating the Switching Activity       3.\n Store the power information in the abstract by setting the abstract.annotate_power application option to true 4.\n Create the abstract for the block by using the create_abstract command.\n When you create an abstract with power information, the tool stores the power information only for the logic that is removed.\n When you instantiate such an abstract and perform power analysis at the top level, the tool  Recomputes the power for the interface logic in the abstract, in context, based on the switching activity and loading seen at the top level  Uses the stored power in the abstract for the logic that was removed when the abstract was created To report the power information in an abstract instantiated at the top level, use the report_power -blocks command.\n If there are multiple levels of physical hierarchy, to specify the number of level for which you want to report, use the -levels option."}
{"instruction": "How do I Defining Blockages That Allow Buffers Only", "input": "", "output": "To define partial blockages that allow relative placement cells only, specify the boundary, type ( -type allow_rp_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to defines a partial blockage that allows relative placement cells only, with a maximum allowed cell density of 80 percent (a blocked percentage of 20), and enclosed by the rectangle with corners at (10, 20) and (100,200), use the following command: create_placement_blockage -name rp_only -type allow_rp_only \\ -boundary {10 20 100 200} -blocked_percentage 20 These blockages allows the tool to place relative placement groups, which are usually large structures, without disturbing the placement of other cells.\n After the tool places and legalizes the relative placement groups, you can remove these blockages and allow the tool to place other cells in them.\n Note: Relative-placement-cells-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Marking Clock Trees as Synthesized", "input": "", "output": "The voltage level of a design is determined by the technology node (at device level) and the performance requirement.\n The Fusion Compiler tool can perform voltage optimization, which tries to achieve better performance, power, and area (PPA) at a lower voltage level.\n To perform voltage optimization, you need  Scaled library panes Voltage optimization works on the fundamental principle of scaling the voltage, Therefore, scaled library panes with different voltages are required.\n  A signoff methodology with a scaled library setup The voltage optimization flow consists of the following high-level steps: 1.\n Perform physical synthesis at the original design voltage using the compile_fusion command.\n 2.\n Perform clock tree synthesis and optimization at the original design voltage by using the clock_opt command.\n 3.\n Associate a set of related library panes to form a scaling group by using the define_scaling_lib_group command.\n 4.\n Specify voltage ranges for specific corners by using the set_vopt_range command, as shown in the following example: fc_shell> set_vopt_range -corner C1 \\ -low_voltage 0.81 -high_voltage 1.0 fc_shell> set_vopt_range -corner C2 \\ -low_voltage 0.81 -high_voltage 1.0 5.\n Specify a total negative slack (TNS) and power target and tolerance for voltage optimization by using the set_vopt_target command.\n The following example specifies a total negative slack target for voltage optimization and specifies that I/O paths should be excluded from the total negative slack costing: fc_shell> set_vopt_target -tns -1.0 -excludeIO 6.\n Perform voltage optimization by using the voltage_opt command.\n 7.\n Perform routing at the optimized voltage by using the route_auto command.\n 8.\n Perform postroute optimization at the optimized voltage by using the route_opt command."}
{"instruction": "How do I Inserting Tap Meshes", "input": "", "output": "An interior tap wall is a row or column of tap cells that is placed inside the boundary of the standard cell placement area of a block, a macro, hard placement blockage, or nondefault voltage area.\n Note: You can insert interior tap walls only for designs with a single site definition.\n To insert an interior tap wall, use the create_interior_tap_walls command.\n You must specify the following information:  The tap cell used in the tap wall (the -lib_cell option) The specified tap cell must be a single-height cell that matches the row height and site width.\n By default, the command inserts the tap cells with the row orientation.\n To place the cells with a different orientation, use the -orientation option.\n By default, the tool uses the following naming convention for inserted tap cells: tapfiller__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number  The side along which to insert the tap wall (the -side option) You can specify only a single side, top bottom right, or left.\n To insert a tap wall on more than one side, run the command multiple times.\n       By default, the tap cells are placed along all edges on the specified side of the standard cell placement area with no gaps between the tap cells.\n  To specify the tap insertion region, use the -bbox option to specify the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} When you use this option, the command inserts a tap wall along the longest edge on the specified side of the placeable area encompassed by the bounding box.\n The alignment of the tap wall depends on the number of corners of the edge segment encompassed by the bounding box.\n  If the edge segment does not contain a corner, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall.\n  If the edge segment contains one corner, the tap wall starts at that corner.\n  If the edge segment contains two corners along the specified side, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall.\n For a horizontal tap wall with two corners, the spacing between the last two cells might be shortened to align with the right corner.\n If there is not enough space, the last cell might not abut the right corner.\n  For horizontal tap walls, you can specify a gap distance between tap cells by using the -x_spacing option.\n If you specify a value smaller than the tap cell width, the command uses a spacing of zero.\n If you specify a value that is not a multiple of the site width, the command rounds it down to a multiple of the site width.\n When inserting the tap wall, the command honors the standard cell rows and sites; if the rows and sites are not defined, the command does not insert tap cells.\n Obstructions such as placement blockages, fixed cells, and macros can prevent the insertion of the tap cells and result in an incomplete or missing tap wall.\n After insertion, the command fixes the placement of the inserted tap cells."}
{"instruction": "How do I Clock-Gating Setup Condition", "input": "", "output": "The enable condition of a register or clock gate is a combinational function of nets in the design.\n The enable condition of a register represents the states for which a clock signal must be passed to the register.\n The enable condition of a clock gate corresponds to the states for which a clock is passed to the registers in the fanout of the clock gate.\n The tool uses the enable condition of the registers for clock-gate insertion.\n Enable conditions are represented by Boolean expressions for nets.\n For example: module TEST (en1, en2, en3, in, clk, dataout); input en1, en2, en3, clk; input [5:0] in; output [5.0] dataout; reg [5.0] dataout; wire enable; assign enable = (en1 | en3) & en2; always @( posedge clk ) begin if( enable ) dataout <= in; else dataout <= dataout; end endmodule In this example, the enable condition for the register bank dataout_reg* can be expressed as en1 en2 + en3 en2."}
{"instruction": "How do I Enabling the Power Integrity Features", "input": "", "output": "The PrimePower In-Design flow in the Fusion Compiler tool uses input waveform information from the RTL FSDB file and performs time-based analysis to update the activity for enhanced power estimation accuracy.\n shows the PrimePower in- design flow in the Fusion Compiler tool, indicating points in the flow where you can run the PrimePower tool.\n For the best correlation with standalone PrimePower time-based analysis results, run the PrimePower tool after the route_opt command.\n        The PrimePower In-Design Flow Use the set_indesign_primepower_options command to set PrimePower analysis options for the In-Design flow.\n You must specify the RTL activity file with the -fsdb option and the path to the PrimePower executable with the -pwr_shell option.\n Other options allow you to specify details about the FSDB file, settings for distributed or concurrent processing, settings for scenarios and libraries, and output files.\n Use the update_indesign_activity command to perform the analysis, which includes the following tasks:  Invokes the PrimePower tool and reads the design data which includes the netlist, libraries, PVT settings, constraints, parasitics, essential name mapping data, UPF, and so on.\n Library details come from the design database stored in the Fusion Compiler tool memory.\n  Reads the RTL FSDB file into the PrimePower tool and performs time-based analysis to generate a gate-level SAIF.\n  Reads the gate-level SAIF back into the Fusion Compiler tool.\n Set the power scenario as the current scenario before starting analysis with the update_indesign_activity command.\n Activity is refreshed for the current scenario.\n If you specify multiple scenarios using the -scenarios option of the set_indesign_primepower_options command, the refreshed gate-level SAIF from the PrimePower tool is read back into the Fusion Compiler tool for all of the specified scenarios.\n       The PrimePower In-Design UI allows you to pass input waveforms using the native ZeBu database (ZTDB).\n The -ztdb option of the set_indesign_primepower_options command sets up PrimePower In-Design to create a script using the update_indesign_activity command.\n This script uses the PrimePower read_ztdb command to perform time-based analysis and issues a gate-level SAIF file that is automatically back-annotated into the Fusion Compiler tool.\n Specifying Distributed Analysis For faster runtime, use distributed analysis, which is disabled by default in the PrimePower tool.\n To enable distributed analysis in the PrimePower tool, specify the following options with the set_indesign_primepower_options command:  -num_processes : Use this option to specify the number of hosts to launch.\n The value must be greater than 1.\n  -submit_command or -host_names : Use either of these options to specify the configuration of host machines.\n  -max_cores : Use this option to specify the maximum number of cores.\n The default is 4.\n The tool prints the following message if valid options are specified: Information: PrimePower is being called in distributed mode"}
{"instruction": "How do I Controlling the Optimization of Relative Placement Cells", "input": "", "output": "By default, nonrelative placement cells are  Not allowed within relative placement groups during coarse placement  Allowed within relative placement groups during optimization and legalization To reduce congestion and improve QoR, you can allow the tool to place nonrelative placement cells within the unused areas of a specific relative placement group by using the -allow_non_rp_cells option with the set_rp_group_options command.\n You can add blockages to relative placement group by using the -blockage option with the add_to_rp_group command.\n By default, no cells are allowed within these blockages during placement, optimization, and legalization.\n To allow nonrelative placement cells within relative placement blockages and unused areas of a specific relative placement group, use the -allow_non_rp_cells_on_blockages option with the set_rp_group_options command.\n The following example allows nonrelative placement cells within the unused areas of the RP1 relative placement group: fc_shell> set_rp_group_options rp1 \\ -allow_non_rp_cells The following example allows nonrelative placement cells within the blockages and unused areas of the RP2 relative placement group: fc_shell> set_rp_group_options rp2 \\ -allow_non_rp_cells_on_blockages"}
{"instruction": "How do I Using Routing Guides to Control the Routing Direction", "input": "", "output": "Routing guides provide routing directives for specific areas of a block.\n Some types of routing guides are user-defined; others are derived from the block data.\n This topic describes how to create user-defined routing guides.\n Note: User-defined routing guides are honored by Zroute; however, they are not honored by the Advanced Route tool.\n To define a routing guide, use the create_routing_guide command.\n When you define a routing guide, you must specify  Its rectangular boundary To specify the boundary, use the -boundary option to specify the lower-left and upper- right corners of the rectangle using the following syntax: {{ llx lly } { urx ury }}  Information specific to the purpose of the routing guide The following table describes the user-defined routing guides.\n Table 30 User-Defined Routing Guides Purpose Option     -preferred_direction_only     -switch_preferred_direction     -max_patterns   -horizontal_track_utilization -vertical_track_utilization       Purpose Option   -access_preference   -river_routing By default, the tool creates a routing guide named RD# in the current block, where is a unique integer.\n Use the following options to change the default behavior:  To specify a name for the routing guide, use the -name option.\n  To specify the routing layers affected by the routing guide, use the -layers option.\n Specify the routing layers by using the layer names from the technology file.\n  To create the routing guide in a different physical cell, use the -cell option.\n When you use this option, the tool creates the routing guide in the cell's reference block using the coordinate system of the cell's top-level block.\n See Also  Deriving Routing Guides  Querying Routing Guides  Removing Routing Guides"}
{"instruction": "How do I Defining Gas Stations", "input": "", "output": "Guard bands define hard keepout margins surrounding the voltage areas in which no cells, including level shifters and isolation cells, can be placed.\n The guard bands guarantee that the cells in different voltage areas are separated so that power planning does not introduce shorts.\n By default, voltage areas do not have guard bands.\n To define guard bands, use the -guard_band option with the create_voltage_area or create_voltage_area_shape command to specify the horizontal and vertical guard band width for each shape specified in the -region option.\n The horizontal guard band width applies to all vertical edges of the voltage area, while the vertical guard band width applies to all horizontal edges of the voltage area.\n Note: If you also use the -merge_regions option, you must specify the guard band widths for each disjoint shape after merging.\n You would typically use this option only when all the shapes to be merged are abutted or overlapping and therefore merge into a single shape.\n The effective boundary of a voltage area shape includes its guard band; however, the effective placeable area of the shape does not.\n       For example, shows the guard band around the PD1 voltage area that is defined by the following command: fc_shell> create_voltage_area -power_domains PD1 \\ -region {{0 0} {30 0} {30 10} {40 10} {40 30} {20 30} {20 25} {0 25}} \\ -guard_band { {3 1} }  Voltage Area Guard Band To determine the effective guard bands for abutting or overlapping shapes associated with the same voltage area, the tool merges the shapes as described in Merging Voltage Area Shapes and then applies the guard bands defined for the top shape to the merged shape.\n For example, assume that you use the following command to define guard bands for the voltage area shapes shown on the right side of fc_shell> create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } \\ -guard_band { {1 1} {3 3} {3 1} } {PD1} In this case, the effective guard band is the same as the guard band shown in which is the guard band defined for the merged shape.\n To determine the effective placement areas and guard bands for overlapping shapes associated with different voltage areas, the tool uses the effective boundaries to resolve the shapes as described in Resolving Overlapping Voltage Areas.\n The top shape retains it placement area and guard band; the effective placement area and guard bands of lower shapes does not include the overlapping region.\n Note that if abutting shapes have guard bands, they are no longer abutting, but overlapping, due to the effective boundary that includes the guard bands.\n For example, assume that you use the following commands to define guard bands for the voltage areas shown in fc_shell> create_voltage_area -power_domains PD1 \\ -region {{0 0} {30 30}} -guard_band { {2 2} } {PD1} fc_shell> create_voltage_area -power_domains PD2 \\ -region {{10 10} {20 20}} -guard_band { {2 2} } {PD2}       In this case, the effective placement area of PD1 is reduced by the effective boundary of PD2, which includes its guard band, as shown in  Effective Boundaries of Overlapping Voltage Areas"}
{"instruction": "How do I IC Validator In-Design", "input": "", "output": "After routing, you can fill the empty spaces in the block with metal wires to meet the metal density rules required by most fabrication processes.\n Before inserting metal fill, the block should be close to meeting timing and have very few or no DRC violations.\n To insert metal fill, run the signoff_create_metal_fill command, as described in Inserting Metal Fill With IC Validator In-Design Note: An IC Validator license is required to run the signoff_create_metal_fill command."}
{"instruction": "How do I Performing Design Analysis", "input": "", "output": "During the logic_opto stage of the compile_fusion command, as an initial step, the tool performs timing optimization and DesignWare reselection and ungrouping.\n After this initial step, the tool can perform an optional embedded area optimization flow before moving on to other optimization techniques performed during the logic_opto stage.\n The embedded area optimization flow consists of dedicated ungrouping, fast area- driven logic restructuring, and light timing optimization.\n To enable this feature, set the compile.flow.areaResynthesis application option to true This feature can reduce the area of blocks with many DesignWare hierarchies."}
{"instruction": "How do I Applying Required Settings for Improving Specific QoR Metrics", "input": "", "output": "You can apply tool settings required for achieving the best QoR for high performance cores by using the set_hpc_options command.\n The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis.\n To  List the supported high performance core types and implementation stages, use the -list option  Specify the type of high performance core, use the -core option  Specify the stage of the implementation flow, use the -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the set_technology command before you run the set_hpc_options command, as shown in the following example script: set_technology -node 7 set_hpc_options -core A72 -stage clock_opt_cts...\n clock_opt -from build_clock -to route_clock...\n       set_hpc_options -core A72 -stage clock_opt_opto...\n clock_opt -from final_opto...\n set_hpc_options -core A72 -stage route_auto...\n route_auto...\n set_hpc_options -core A72 -stage route_opt...\n route_opt..."}
{"instruction": "How do I Merging Voltage Area Shapes", "input": "", "output": "A voltage area is a physical placement area for the cells associated with a power domain.\n For multivoltage designs, the power domains are defined in the UPF specification.\n For single-voltage designs, the tool creates a default power domain when you read the Verilog netlist and associates it with a default voltage area, which comprises the core area of the block.\n The placer treats a voltage area the same as an exclusive move bound; it must place the cells in a voltage area within a specified region and it must place all other cells outside of the voltage area.\n Voltage areas can be rectangular or rectilinear.\n In addition, they can be disjoint, nested, or overlapping.\n For overlapping voltage areas, the effective shape of each voltage area is determined by the stacking order of the voltage area shapes.\n To define a voltage area, use the create_voltage_area command.\n When you define a voltage area, at a minimum, you must specify the power domains associated with the voltage area.\n To specify the power domains, use the -power_domains option.\n You can specify one or more power domains; however, all specified power domains must have the same primary supply net.\n If you specify a single power domain, the name of the voltage area is derived from the name of the power domain.\n If you specify multiple power domains, you must specify a name for the voltage area by using the -name option.\n A voltage area consists of one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping.\n To define the boundaries of these shapes, use the -region option with the create_voltage_area command (if you are creating a new voltage area) or the create_voltage_area_shape command (if you are adding shapes to an existing voltage area).\n Note that you can specify one or more shapes when using the create_voltage_area command, but only a single shape in each create_voltage_area_shape command.\n  To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly } { urx ury }}  To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 } { x2 y2 } { x3 y3 } { x4 y4 }...} If a voltage area consists of multiple abutting or overlapping shapes, you can merge the shapes into a minimum set of disjoint shapes based on the stacking order of the shapes.\n For information about how to merge the voltage area shapes, see Merging Voltage Area Shapes The tool also uses the stacking order to resolve overlapping shapes from different voltage areas.\n For information about resolving overlapping voltage areas, see Resolving Overlapping Voltage Areas       To ensure that no shorts occur at the boundaries of the voltage areas, you can define guard bands for the voltage areas, which act as hard keepout margins surrounding the voltage areas.\n If you define guard bands for a voltage area shape, the guard bands are included in the effective boundary of the shape; however, they are not included in the effective placement area of the voltage area.\n For information about defining guard bands, see Defining Guard Bands To modify an existing voltage area, use the set_voltage_area command, as described in Modifying Voltage Areas Multivoltage designs typically have power domains that are shut down and powered up during the operation of the chip while other power domains remain powered up.\n When dealing with shutdown domains, there can be some situations in which certain cells in the shutdown portion need to continuously stay active, such as for implementing retention registers, isolation cells, retention control paths, and isolation enable paths.\n These cells are referred to as always-on cells.\n To define a special placement area for always-on cells (an always-on well) within a voltage area, define an exclusive move bound within the boundary of the voltage area.\n For information about defining exclusive move bounds, see Defining Move Bounds After creating the voltage areas, run the check_mv_design command to verify that the design does not have any multivoltage violations."}
{"instruction": "How do I Querying Routing Blockages", "input": "", "output": "To reserve space for top-level routing, create a corridor routing blockage by using the -reserve_for_top_level_routing option when you create the routing blockage.\n During block-level implementation, a corridor routing blockage acts as a regular blockage to prevent routing in the blockage area.\n During frame view extraction, the tool removes the corridor routing blockage to allow top-level routing in this area."}
{"instruction": "How do I RedHawk/RedHawk-SC Fusion Analysis Flow", "input": "", "output": "The RedHawk/RedHawk-SC Fusion feature allows you to perform rail analysis during the implementation stage.\n With the required input files, the Fusion Compiler tool creates the RedHawk run script and the Global System Requirements (GSR) configuration file for invoking the RedHawk tool (or the RedHawk-SC Python script for invoking the RedHawk-SC tool) to run PG net extraction, power analysis, voltage drop analysis, and PG electromigration analysis.\n When analysis is complete, the Fusion Compiler tool generates analysis reports and maps using the results calculated by the RedHawk or RedHawk-SC tool.\n You can then check for hotspots graphically in the Fusion Compiler GUI.\n Error data and ASCII reports are also available to check for locations where limits are violated.\n  illustrates the data flow when using RedHawk Fusion or RedHawk-SC Fusion to perform rail analysis in the Fusion Compiler environment.\n        RedHawk Fusion and RedHawk-SC Fusion Data Flow"}
{"instruction": "How do I Enabling Leakage Power Optimization for the compile_fusion", "input": "", "output": "The leakage power of a block is scaled based on the switching probability of its supply nets, which represents the fraction of time a supply net is in the on state.\n You can specify the switching probability for one or more supply nets by using the set_supply_net_probability -static_probability command.\n By default, the switching probability is applied to the current scenario and the corresponding mode and corner.\n To specify modes, corners, or scenarios in which to apply the setting, use the -modes -corners, or -scenarios option.\n To get the switching probability of a supply net, use the get_supply_net_probability command, and to reset the value, use the reset_supply_net_probability command.\n By default, the tool propagates supply net activity through power switches and determines the static probability of the switched supply net based on the UPF power switch constraint.\n For example, consider the following UPF power switch constraint: create_power_switch my_switch \\ -output_supply_port {vout VDDS} \\ -input_supply_port {vin VDD} \\ -control_port {ms_sel ctrl1} \\ -control_port {ms_ctrl ctrl2} \\ -on_state {on vin {ms_ctrl &&!ms_sel}}       The tool derives the static probability of the supply net named VDDS, which is connected to the output of the power switch, based on the probability of the power switch being on This is derived based on the following:  The Boolean function specified with the -on_state option, which is ms_ctrl &&!\n ms_sel, and the switching activity (static probability) of the nets connected to the corresponding control ports, which are nets named ctrl1 and ctrl2.\n  The switching probability of the supply net connected to the input supply port specified with the -on_state option, which is the supply net named VDD.\n The following application options control whether dynamic and leakage power are scaled based on the supply switching activity:  The power.scale_dynamic_power_at_power_off option controls whether dynamic power is scaled.\n The default is false (no scaling).\n  The power.scale_leakage_power_at_power_off option controls whether leakage power is scaled.\n The default is true (scaling is performed)."}
{"instruction": "How do I Reporting Cell Spacing Constraints", "input": "", "output": "Cell spacing constraints control the spacing between a standard cell and another standard cell or a boundary (the chip boundary, a hard macro, a hard macro keepout margin, a hard placement blockage, or a voltage area guard band).\n You assign library cells to groups (the boundaries are in a predefined group named SNPS_BOUNDARY), and then define the required spacing between cells in these groups.\n By default, there are no spacing constraints between standard cells during legalization.\n To enhance yield, you can define the valid spacing between standard cells or between a standard cell and a boundary.\n Note: The support for spacing constraints between standard cells and power or ground nets depends on how the net is represented in the block.\n If the power or ground net is defined as a complete blockage, the legalizer and the check_legality command ignore spacing rule violations between standard cells and the power or ground net.\n If the power or ground net is defined as a partial blockage, the legalizer and the check_legality command check for spacing rule violations between standard cells and the power or ground net.\n Cell spacing constraints are implemented by attaching labels, which are similar to attributes, to the left and right sides of library cells, assuming that the cell is in its north orientation, and specifying the invalid spacings between these labels.\n To define cell spacing constraints, 1.\n Add labels to the library cells that have spacing constraints by using the set_placement_spacing_label command.\n You must specify the following information for each label:  The label name (the -name option)  The library cells to which to apply the label (the -lib_cells option)  The sides of the library cells to which to apply the label (the -side option, which can take a value of right left, or both The label definitions are additive; you can specify the same label to be used on the right side of some cells and the left side of other cells.\n For example, to assign a label named X to the right side of the cellA library cell and the left side of the cellB and cellC library cells, use the following commands: fc_shell> set_placement_spacing_label -name X \\ -lib_cells {cellA} -side right       fc_shell> set_placement_spacing_label -name X \\ -lib_cells {cellB cellC} -side left You can assign multiple labels to a side of a library cell.\n For example, to assign labels named Y and Z to the right side of the cellB library cell, use the following commands: fc_shell> set_placement_spacing_label -name Y \\ -lib_cells {cellB} -side right fc_shell> set_placement_spacing_label -name Z \\ -lib_cells {cellB} -side right 2.\n Define the spacing requirements between the labels by using the set_placement_spacing_rule command.\n You must specify the following information for each rule:  The labels being constrained (the -labels option) You must specify exactly two labels in each set_spacing_label_rule comandcomandset_spacing_label_rule set_placement_spacing_rule command.\n You can specify any of the labels defined by the set_placement_spacing_label command or the predefined SNPS_BOUNDARY label, which includes the chip boundary, hard macro boundaries, a hard macro keepout margins, hard placement blockages, and voltage area guard bands.\n The two labels can be the same or different.\n  The range of invalid spacings, in number of unit tiles For example, to specify that there must be at least one unit tile between labels X and Y (they cannot abut), use the following command: fc_shell> set_placement_spacing_rule -labels {X Y} {0 0} To specify that there must be at least one unit tile between X labels and any boundary, use the following command: fc_shell> set_placement_spacing_rule \\ -labels {X SNPS_BOUNDARY} {0 0} To specify that two X labels cannot have a spacing of two unit tiles, use the following command: fc_shell> set_placement_spacing_rule -labels {X X} {2 2} To specify that labels X and Z must have a spacing of less than two unit tiles or more than four unit tiles, use the following command: fc_shell> set_placement_spacing_rule -labels {X Z} {2 4}       Caution: The cell spacing constraints are not saved with the block; they apply only to the current session and must be redefined in each session."}
{"instruction": "How do I Inserting Routing Blockages Along the Boundary Edges", "input": "", "output": "To insert maximum pattern routing guides along the nonpreferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects mprg_nonpreferred option.\n When you specify this object type, the command creates maximum pattern routing guides parallel to each nonpreferred-direction boundary edge.\n The maximum edge threshold for these routing guides is zero.\n       By default,  The routing guides are inserted only in the top-level block To insert routing guides in all soft macros in a hierarchical block, use the -hierarchical option.\n  The routing guides are inserted on all routing layers To insert the routing guides only on specific routing layers, use the -layers option.\n  The routing guides have the default metal width specified for the routing layer in the technology file To specify a different width in microns, use the -width_nonpreferred option.\n For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  The routing guides abut the preferred-direction edges  The routing guides are offset from the nonpreferred-direction edges by the minimum spacing specified for the routing layer in the technology file To specify a different offset in microns, use the -spacing_nonpreferred option.\n For information about specifying the minimum spacing for a layer, see the \"Minimum Spacing Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual  shows the routing guides inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n S is the spacing specified by the -spacing_nonpreferred option.\n W is the width specified by the -width_nonpreferred option.\n        Routing Guide Perimeter Constraint Objects       See Also  Using Routing Guides to Limit Edges in the Nonpreferred Direction"}
{"instruction": "How do I Removing Filler Cells", "input": "", "output": "To remove the filler cell insertion rules and the threshold-voltage type annotations, use the -clear_vt_information option with the create_vtcell_fillers command."}
{"instruction": "How do I Optimizing Pin Access During Legalization", "input": "", "output": "To minimize large displacements of cells during legalization, enable  Orientation optimization by setting the place.legalize.optimize_orientations application option to true When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization.\n  Stream placement by setting the place.legalize.stream_place application option to true When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization.\n You can further control stream placement by using the place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}
{"instruction": "How do I Reading Designs Using the -autoread Option", "input": "", "output": "Use the analyze and elaborate commands followed by the set_top_module command.\n The analyze command automatically creates HDL template libraries on disk based on the name of the library provided by the -hdl_library option.\n The location of the HDL template libraries is controlled by the hdlin.hdl_library.default_dirname application option.\n When the -hdl_library option is not specified, the default library name is WORK.\n To specify a different default library name, use the hdlin.hdl_library.default_name application option.\n Note: All of the application options that control the RTL reading behavior have the hdlin prefix.\n The elaborate command builds the module specified without linking the rest of the design.\n Design linking can be performed only after the entire design is in memory, so linking is not performed by the elaborate command.\n This allows multiple elaborate commands to be run before performing the single linking of the entire design.\n The top-level module must be one of the modules that is elaborated.\n Linking of the design and setting the top-level module is done using the set_top_module command.\n The top-level module is given as an argument to the set_top_module command.\n The top-level module must be a module that was previously elaborated with the elaborate command.\n The set_top_module command sets the specified module to be       the top-level design, links the entire design, and creates a single block to be used for the remainder of the synthesis flow.\n The following script reads VHDL files using template libraries and creates a block called top.\n You do not need to specify the location of the template libraries on disk, which is automatically created by the analyze command based on the -hdl_library option.\n analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top If the top-level design is analyzed to an HDL template library other than the default library, you should provide the HDL template library name for the top-level design using the -hdl_library option.\n For example, analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl -hdl_library TOP_HDL_LIB top.vhd elaborate -hdl_library TOP_HDL_LIB top set_top_module top You can optionally specify the location of the HDL template libraries on disk by using the define_hdl_library command.\n For example, define_hdl_library BOT_HDL_LIB -path./TEMPLATES/BOT_HDL_LIB define_hdl_library MID_HDL_LIB -path./TEMPLATES/MID_HDL_LIB define_hdl_library WORK -path./TEMPLATES/WORK analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top"}
{"instruction": "How do I Performing Prechecks", "input": "", "output": "To perform unified physical synthesis, use the compile_fusion command.\n The compile_fusion command consists of the following stages: 1.\n initial_map During this stage, the tool maps the design and performs area optimization.\n 2.\n logic_opt During this stage, the tool performs logic-based delay optimization.\n 3.\n initial_place During this stage, the tool merges the clock-gating logic and performs coarse placement.\n 4.\n initial_drc During this stage, the tool removes existing buffer trees and performs high-fanout-net synthesis and electrical DRC violation fixing.\n 5.\n initial_opto During this stage, the tool performs physical optimization and incremental placement.\n 6.\n final_place During this stage, the tool performs final placement to improve timing and congestion.\n 7.\n final_opto During this stage, the tool performs final optimization and legalization to improve timing, power, and logical DRCs.\n       When you run the compile_fusion command, by default, the tool runs all stages.\n To run only some of these stages, use the -from option to specify the stage from which you want to begin and the -to option to specify the stage after which you want to end.\n If you do not specify the -from option, the tool begins from the initial_place stage.\n Similarly, if you do not specify the -to option, the tool continues until the final_opto stage is completed.\n Breaking the compile_fusion command in to stages allows you to perform different tasks between the stages, such as changing constraints or settings, generating reports for analysis, performing other implementation tasks such as design planning or DFT insertion, and so on.\n If you make manual changes to the design between stages, ensure the changes honor the expected state of the design.\n For example, the design is expected to be mapped after the initial_map stage.\n Therefore, do not introduce unmapped logic to the design after this stage.\n You can repeat a stage; however, ensure that you run all stages in the correct sequence.\n The following example runs the compile_fusion command until it completes the initial_opto stage, performs analysis, changes an application option setting, and restarts by running the initial_opto stage again.\n fc_shell> compile_fusion -to initial_opto fc_shell> report_qor fc_shell> set_app_option \\ -name opt.common.advanced_logic_restructuring_mode -value timing fc_shell> compile_fusion -from initial_opto In the following situations, the design can contain unmapped cells after the compile_fusion command:  Missing the required cells in the library  User-specified restrictions on the required library cells When a design contains unmapped cells, the compile_fusion command continues the compilation and provides an estimated area for the unmapped cells.\n Unmapped cells are marked with the is_unmapped attribute.\n To query unmapped cells in a netlist, use the following command: fc_shell> get_cells -hierarchical -filter \"is_unmapped==true\" Note the following limitations:  DesignWare operators are not mitigated.\n  Only placement information is stored in the database after mitigation; routing information is not saved."}
{"instruction": "How do I Constraint-Based Via Ladder Insertion", "input": "", "output": "The command generates a script file that defines the association between the library cell pins and the via ladder rules.\n This script file contains set_via_ladder_candidate commands for the library cell pins.\n By default, the generated script file is named auto_perf_via_ladder_association.tcl.\n To specify a different file name, use the -association_file option."}
{"instruction": "How do I Reducing Signal Integrity Effects on Clock Nets", "input": "", "output": "The tool supports clock level improvement which ensures considering level improvement as a metric while building the clock trees and also considers buffering solutions which helps to improve the repeater levels.\n With lesser buffer trees chosen the level improvement takes place locally which further helps to improve the metric for overall clock tree.\n  Improving the Repeater Levels in Clock Tree To enable clock level improvement, set the cts.buffering.reduce_clock_level_effort application option to high before the build_clock stage of the clock_opt command."}
{"instruction": "How do I Creating a Via Definition", "input": "", "output": "To read via definitions specified by via rule GENERATE statements in a LEF file, use the read_tech_lef command.\n This command supports the following LEF syntax: via_rule_name GENERATE [DEFAULT] LAYER lower_layer_name ENCLOSURE lower_overhang1 lower_overhang2 LAYER upper_layer_name ENCLOSURE upper_overhang1 upper_overhang2 LAYER cut_layer_name RECT llx lly urx ury SPACING x_spacing BY y_spacing The WIDTH and RESISTANCE statements are not supported."}
{"instruction": "How do I Mapping Sequential Elements Exactly as Described in RTL", "input": "", "output": "The sequential mapping phase consists of two steps: register inferencing and technology mapping.\n The term register refers to both edge-triggered registers and level-sensitive latches.\n Register inferencing is the process by which the RTL description of a register is translated into a technology-independent representation called a SEQGEN.\n SEQGENs are created during elaboration and are usually mapped to flip-flops during compile.\n Technology mapping is the process by which a SEQGEN is mapped to gates of a specified target logic library.\n Both of these steps are performed by the compile_fusion command.\n       Both registers and latches are represented by a SEQGEN cell, which is a technology- independent model of a sequential element as shown in the following figure: clear preset next_state clocked_on data_in enable synch_clear synch_preset synch_toggle synch_enable  QN SEQGEN This table lists the pins of a SEQGEN cell.\n Only a subset of these pins is used depending on the type of cell that is inferred.\n Unused pins are tied to zero.\n Direction Name Description Cell type                                          Direction Name Description Cell type    During technology mapping, the tool uses the SEQGEN as the starting point for mapping.\n The sequential mapper checks the connections to the pins and the information present in the library cell descriptions when it maps to a logic library register.\n Topics in this section  Mapping Sequential Elements Exactly as Described in RTL  Mapping of Scan Cells  Mapping of Synchronous Reset or Preset Registers  Specifying Synchronous Input Types for Library Cell Pins  Controlling Sequential Output Inversion  Preventing Connections to Register QN Pins  Mapping of Synchronous Enable Logic to a MUX  Identification of Shift Registers"}
{"instruction": "How do I Clock-Gate Multilevel Expansion", "input": "", "output": "The number of clock-gate levels is the count of clock gates between a clock source and a register.\n Standard clock-gate insertion provides one level of clock-gate insertion.\n However, designs often contain preexisting clock gates, in which case the design might contain multiple levels of clock gates.\n       You can modify the default clock-gate insertion operation by allowing additional levels of clock gating, by limiting the number of clock-gate levels, or both."}
{"instruction": "How do I Soft Shielding Rules During Signal Routing", "input": "", "output": "To provide the most protection for critical clock nets, perform shielding on those nets after clock tree routing but before signal net routing.\n To add shielding to the routed clock nets based on the assigned shielding rules, use the create_shields command.\n By default, the create_shields command  Performs shielding on all nets that have predefined shielding rules, except those marked as frozen To explicitly specify the nets on which to perform shielding, use the -nets option.\n  Does not perform shielding on wires that are less than four pitches long To specify the minimum wire length in microns on which to perform shielding for each layer, set the route.common.min_shield_length_by_layer_name application option.\n Use the following syntax to set this option: { { layer wire_length }...\n } Specify the routing layers by using the layer names from the technology file.\n If you do not specify a value for a layer, Zroute uses the default minimum length of four pitch lengths for that layer.\n Note: Wires that are less than the minimum length are not considered when computing the shielding ratio.\n        Ties the shielding wires to the ground net If the block contains multiple ground nets or you want to tie the shielding wires to the power net, use the -with_ground option to specify the power or ground net to which to tie the shielding wires.\n If the shielding wires can be tied to multiple power or ground nets, specify the nets by setting the route.common.shielding_nets application option before running the create_shields command.\n Note: If you specify both the create_shields -with_ground option and the route.common.shielding_nets option, the tool issues a warning message and uses the route.common.shielding_nets setting.\n  Performs same-layer shielding To perform coaxial shielding, use the -coaxial_above and -coaxial_below options.\n By default, the create_shields command leaves one routing track open between each used track.\n To change the default behavior, use one of the following methods:  Specify the number of open tracks between coaxial shielding segments by using the following options:  -coaxial_above_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding above the shielded net segment layer ( -coaxial_above true ).\n  -coaxial_below_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding below the shielded net segment layer ( -coaxial_below true ).\n For either of these options, you can specify an integer between zero and seven.\n  Specify the number of open tracks between coaxial shielding segments on a per- layer basis by using the -coaxial_skip_tracks_on_layers option To disable shielding on a specific layer, set the value to -1; otherwise, specify an integer between 0 and 7 to specify the number of tracks to skip.\n  Specify the spacing between coaxial shielding segments by using the following options:  -coaxial_above_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding above the shielded net segment layer ( -coaxial_above true ).\n        -coaxial_below_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding below the shielded net segment layer ( -coaxial_below true ).\n You cannot use this method when performing incremental shielding.\n Note: You cannot mix these methods of specifying coaxial shielding.\n If the generated coaxial shielding wires violate minimum area or minimum length rules, Zroute automatically patches the wires to satisfy these design rules.\n  Connects the shielding wires to the standard-cell power or ground pins and the standard-cell rails To prevent connections to the standard-cell power and ground pins, set the -ignore_shielding_net_pins option to true.\n To prevent connections to the standard-cell rails, set the -ignore_shielding_net_rails option to true  Creates the shielding wires such that they surround the shielded routing shape To trim the shielding wires so that they align with the shielded routing shape ends, set the -align_to_shape_end option to true.\n To force Zroute to create shielding wires only in the preferred direction, set the -preferred_direction_only option to true Note that the -preferred_direction_only option does not honor route guides to change the preferred routing direction.\n When you set either of these options to true extra effort is required to connect the shielding wires to the power and ground network and any shielding wires that are not connected to the power and ground network are deleted.\n For example, to perform coaxial shielding below the shielded net segment layer on the clock nets, prevent signal routing below the shielded net segment layer, and tie the shielding wires to VSS, use the following command: fc_shell> create_shields -nets $clock_nets \\ -coaxial_below true -coaxial_below_skip_tracks 0 \\ -with_ground VSS When you run the create_shields command, it reports both the net-based and length- based average shielding ratios, as shown in the following example: Shielded 82% side-wall of (reset) Shielded 96% side-wall of (clk) Shielded 2 nets with average ratio as follows.\n 1) 89.00% (total shield ratio/number of shielded nets) 2) 87.92% (total shield length/total shielded net length)       Note: In some cases there is a slight difference in the shielding ratios reported by the create_shields and report_shields commands.\n This is due to graph connectivity differences between the two commands.\n When the reported values differ, use the values reported by the report_shields command.\n The difference in reported values is typically less than three percent, but can be up to five percent.\n If you use the -preferred_direction_only true option when running the create_shields command, but Zroute must use some nonpreferred direction wires for shielding, the shielding ratio report specifies the percentage of nonpreferred direction wires.\n By default, the power and ground structure is not included in the shielding ratio calculation.\n To include the power and ground structure within a threshold distance in the shielding ratio calculation, set the route.common.pg_shield_distance_threshold application option, which specifies the distance threshold in microns.\n fc_shell> set_app_options \\ -name route.common.pg_shield_distance_threshold -value distance Note that this option affects only the shielding ratio calculation and does not change the routing behavior."}
{"instruction": "How do I Reporting Leakage Power", "input": "", "output": "By default, the tool performs leakage power optimization during compile.\n To produce optimal leakage power optimization, use libraries with multithreshold voltage group cells.\n To set up leakage optimization, 1.\n Enable at least one scenario for leakage power by using the set_scenario_status -leakage_power true command.\n For example, fc_shell> set_scenario_status -leakage_power true SC1 If the block has multiple scenarios enabled for leakage power, the tool uses the worst- case leakage value of all the specified scenarios.\n 2.\n Set the threshold_voltage_group attribute on the reference library cells.\n For example, fc_shell> set_attribute [get_lib_cells -quiet lib1_name/*] \\ threshold_voltage_group HVT 3.\n Set the threshold_voltage_group attribute to one of the three built-in threshold voltage group types: high, normal, or low threshold voltage.\n       If there are more than three threshold-voltage groups, you should group them into the three voltage group types as follows: fc_shell> set_threshold_voltage_group_type \\ -type high_vt {HVT HVTX} fc_shell> set_threshold_voltage_group_type \\ -type low_vt {LVT LVTX} fc_shell> set_threshold_voltage_group_type \\ -type normal_vt {RVT RVTX}"}
{"instruction": "How do I Analyzing the Clock Tree Results", "input": "", "output": "In a structural multisource clock tree, the local subtrees are directly driven by the clock mesh.\n You can synthesize these local subtrees by using the synthesize_multisource_clock_subtrees command.\n Before you synthesize the local subtrees, you must 1.\n Build the global clock distribution structure.\n 2.\n Model the clock mesh net with a realistic annotated delay and transition values using the set_annotated_delay and set_annotated_transition commands.\n 3.\n Remove dont_touch size_only fixed, and locked attributes setting on the clock cells that are not required.\n These settings prevent the synthesize_multisource_clock_subtrees command from merging or splitting clock cells, if necessary.\n 4.\n Specify settings for local subtree synthesis by using the set_multisource_clock_subtree_options command.\n You must specify  The clock for synthesizing the subtrees by using the -clock option.\n  The drivers of the subtrees to be synthesized by using the -driver_objects option.\n The clock specified with the -clock option should pass through each drivers specified with the -driver_objects option.\n Optionally you can  Prevent the tool from merging specific clock tree cells by using the -dont_merge_cells option.\n  Balance the levels of the local subtree by using the -balance_levels true option and specify a target number of levels, which applies to all sinks of the local subtree, by using the -target_level option.\n Optionally, you can apply a different target number of levels to specific sink pins and clock balance points by using the set_multisource_clock_subtree_constraints command with the -pins and -target_level options.\n  Specify a maximum total wire delay from any subtree driver to any of its sinks by using the -max_total_wire_delay option and the corner it applies to by using the -corner option.\n        Enable the reordering of clock-gating cells by using the -enable_icg_reordering true option.\n When you enable this feature, the tool swaps the position of a clock-gating cell with the buffer that is driving the clock-gating cell.\n Then, the buffer is gated by the clock- gating cell, thereby reducing the dynamic power consumption.\n To perform reordering, you must  Enable scenarios used for structural multisource clock tree synthesis for dynamic power optimization  Annotate switching activity for the enable pins of the clock-gating cells You can prevent specific clock-gating cells from being reordered by using the set_multisource_clock_subtree_constraints command with the -cells and -ignore_for_icg_reordering options.\n To report the settings you specified, use the report_multisource_clock_subtree_options command.\n To remove the settings you specified, use the remove_multisource_clock_subtree_options command.\n 5.\n (Optional) Enable multicorner optimization by setting the cts.multisource.enable_multi_corner_support application option to true.\n The default is false By default, the tool uses the worst corner associated with the mode in which the subtree options are defined.\n When you enable this feature, the tool considers all corners associated with the mode in which the subtree options are defined.\n 6.\n (Optional) Ignore the maximum capacitance, maximum fanout, or both constraints of the clock drivers by using the cts.multisource.ignore_drc_on_subtree_driver application option.\n When you synthesize multisource clock subtrees, by default, the tool considers the maximum transition, capacitance, and fanout constraints of the clock drivers you specify.\n However, the clock drivers typically have relaxed or no maximum capacitance or maximum fanout constraint, which can affect the multisource clock tree QoR.\n The following example ignores both the maximum capacitance and maximum fanout constraints of the clock drivers: fc_shell> set_app_options \\ -name cts.multisource.ignore_drc_on_subtree_driver \\ -value \"max_fanout max_capacitance\" 7.\n (Optional) Enable fishbone routing for the subtree clock nets by using the cts.multisource.subtree_routing_mode application option.\n       fc_shell> set_app_options \\ -name cts.multisource.subtree_routing_mode -value fishbone 8.\n (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during local subtree synthesis by using the following application options:  cts.multisource.subtree_merge_cell_name_prefix  cts.multisource.subtree_merge_cell_name_suffix  cts.multisource.subtree_split_cell_name_prefix  cts.multisource.subtree_split_cell_name_suffix  cts.multisource.subtree_split_net_name_prefix  cts.multisource.subtree_split_net_name_suffix When you run the synthesize_multisource_clock_subtrees command the tool performs the following steps: 1.\n Merges equivalent clock cells to remove any artificial boundaries between clusters of sinks.\n 2.\n Optimizes the subtree by splitting, sizing, and relocating the clock cells, and snaps the first level of clock cells to the clock straps.\n 3.\n Routes the clock nets.\n By default, it global routes the nets.\n However, if you enable fishbone routing by using the cts.multisource.subtree_routing_mode application option, the tool creates a mix of detail routed fishbone trunks and fingers, and global comb routes to connect the net loads to the fishbone fingers, as shown in You can control the fishbone routing by using the following application options:  cts.routing.fishbone_max_tie_distance  cts.routing.fishbone_max_sub_tie_distance  cts.routing.fishbone_bias_threshold  cts.routing.fishbone_bias_window  cts.routing.fishbone_horizontal_bias_spacing  cts.routing.fishbone_vertical_bias_spacing 4.\n Refines the clock trees by sizing and relocating cells based on the routing.\n        Detail Fishbone Routes and Global Comb Routes Global comb route Fishbone trunk Fishbone finger You can run specific steps of the synthesize_multisource_clock_subtrees command by using the -from and -to options and specifying merge optimize route_clock, or refine Structural subtrees that you build by using the synthesize_multisource_clock_subtrees command are not changed or removed when you subsequently run any clock tree synthesis command."}
{"instruction": "How do I Performing Global-Route-Based Optimization Using Machine", "input": "", "output": "Before you perform interclock delay balancing, you must generate the interclock delay balancing constraints as described in Defining the Interclock Delay Balancing Constraints interclock delay balancingruning To perform interclock delay balancing, use the balance_inter_clock_delay comandcomandsbalance_inter_clock_delay balance_clock_groups command.\n For multicorner-multimode designs, the tool performs interclock delay balancing on all active scenarios.\n fc_shell> balance_clock_groups"}
{"instruction": "How do I Specifying Settings for the Freeze Silicon ECO Flow", "input": "", "output": "For multivoltage designs, to  Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the add_buffer_on_route command.\n  Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format.\n When you use this option, you must also use the -lib_cell option.\n  Specify different single-rail and dual-rail library cells for different voltage areas, use the -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format.\n       When you use this option, you must also use the -lib_cell option.\n For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option.\n For the default voltage area, specify DEFAULT_VA as the voltage area name.\n  Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the -allow_physical_feedthrough_buffer option.\n This option can only be used with the -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area.\n After you run the add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command.\n  Add cells within gas stations of specified supply nets, use the -respect_gas_station option and specify the supply net.\n Gas stations are areas with a constant power supply.\n These areas used for buffering nets that go through power domains that are powered down.\n To specify the maximum allowed distance from the gas station to the added buffer, use the -max_distance_route_to_gas_station option."}
{"instruction": "How do I Setting Options for Power Grid Augmentation", "input": "", "output": "Standard power grid augmentation inserts as many PG augmentation shapes as possible to lower the instance voltage drop.\n To perform standard power grid augmentation, 1.\n Ensure that the block is fully routed with very few or no DRC violations.\n 2.\n Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis The IC Validator tool uses the results of this voltage drop analysis to drive the power grid augmentation.\n 3.\n Set up the IC Validator environment as described in Setting Up the IC Validator Environment 4.\n (Optional) Enable distributed processing by using the set_host_options command, as described in Enabling IC Validator Multicore Processing 5.\n Set the application options for performing power grid augmentation, as described in Setting Options for Power Grid Augmentation At a minimum, you must define the power and ground nets on which to perform PG augmentation.\n  To specify the power net, set the signoff.create_pg_augmentation.power_net_name application option.\n  To specify the ground net, set the signoff.create_pg_augmentation.ground_net_name application option.\n If your design contains more than one power net, you must perform PG augmentation once for each power net.\n 6.\n Save the block to disk.\n When you run the signoff_create_pg_augmentation command, the IC Validator tool uses the on-disk information for the block, not the information in memory.\n To ensure accurate information, use the save_block command to save the current state of the block before running the signoff_create_pg_augmentation command.\n 7.\n Perform power grid augmentation by using the signoff_create_pg_augmentation command.\n When you run this command, you must specify the technology node for which to perform the augmentation by using the -node option.\n       If you must perform incremental PG augmentation because your design contains more than one power net, use the -mode add command on subsequent runs to append the PG augmentation shapes to the existing shapes.\n 8.\n Run voltage drop analysis using RedHawk Fusion, as described in Performing Voltage Drop Analysis This second voltage drop analysis run measures the voltage drop after power grid augmentation.\n During standard PG augmentation, the signoff_create_pg_augmentation command performs the following tasks: 1.\n Inserts PG augmentation shapes for the specified regions When the IC Validator tool inserts the PG augmentation shapes, it considers the routing design rules to ensure that it does not create design rule violations.\n By default, the command performs PG augmentation for the entire block.\n To specify the regions for PG augmentation, use one or more of the following options:  -coordinates_ground This option restricts PG augmentation for the ground net to the specified regions.\n  -excluded_coordinates_ground This option prevents PG augmentation for the ground net in the specified regions.\n If you specify this option with the -coordinates_ground option, the command does not perform PG augmentation in the overlapping regions.\n  -coordinates_power This option restricts PG augmentation for the power net to the specified regions.\n  -excluded_coordinates_power This option prevents PG augmentation for the power net in the specified regions.\n If you specify this option with the -coordinates_power option, the command does not perform PG augmentation in the overlapping regions.\n The shapes added during PG augmentation have a shape_use attribute of pg_augmentation.\n You can use this attribute to query the shapes added during PG augmentation.\n For example, fc_shell> get_shapes -filter {shape_use=~pg_augmentation}       2.\n Generates a summary report that shows the following information for each PG net:  The distribution of power grid augmentation shapes added on each layer  The total number of metal shapes added, the total number of via shapes added, and the total number of all shapes added 3.\n Saves the updated block to disk See Also  Timing-Driven Power Grid Augmentation  Guided Power Grid Augmentation  Removing PG Augmentation Shapes"}
{"instruction": "How do I Specifying Cut Space and Cut Distance for Repeater Groups", "input": "", "output": "Use the -allow_insertion_over_block option to allow repeater groups to be added on top of soft or hard macros.\n Note: If the repeater cell is an inverter, you are responsible for ensuring logical correctness."}
{"instruction": "How do I Performing Wire Widening", "input": "", "output": "After you have performed detail routing and redundant via insertion, you can perform wire spreading to increase the average spacing between wires, which reduces the critical area short faults and therefore improves yield.\n To perform wire spreading, use the spread_zrt_wires comandcomandspread_zrt_wires spread_wires command.\n By default, the spread_wires command uses the following settings to spread the signal wires on the same layer: To perform wire spreading, use the spread_zrt_wires comandcomandspread_zrt_wires spread_wires command.\n By default, the spread_wires command uses the following settings to spread the signal wires on the same layer:  Spreads the wires by half a pitch in the preferred direction To modify the spread distance, use the -pitch option.\n You specify the spread distance as a multiplier for the layer pitch.\n For example, to specify a spread distance of 1.5 times the layer pitch, use the following command: fc_shell> spread_wires -pitch 1.5  Uses twice the layer pitch as the minimum jog length To modify the minimum jog length, use the -min_jog_length option.\n You specify the minimum jog length as an integer multiple of the layer pitch.\n  Uses the minimum layer spacing plus one half the layer pitch as the minimum jog length To modify the minimum jog spacing, use the -min_jog_spacing_by_layer_name option.\n You specify the minimum jog spacing in microns for each layer.\n The tool uses the default jog spacing for any unspecified layers.\n  shows how the jog length and jog spacing values are used in wire spreading.\n  Wire Spreading Results       In the following example, the minimum jog length is set to three times the layer pitch, the minimum jog spacing for the M1 layer is set to 0.07 microns, and the minimum jog spacing for the M2 layer is 0.08 microns.\n All other metal layers use the default minimum jog spacing.\n fc_shell> spread_wires -min_jog_length 3 \\ -min_jog_spacing_by_layer_name {{M1 0.07} {M2 0.08}} After spreading, the spread_wires command performs detail routing iterations to fix any DRC violations caused as a result of spreading.\n When you change the layout, it can change the timing of your block.\n Wire spreading has a timing-preservation mode that allows you to perform wire spreading without affecting the block timing.\n To enable timing-preservation mode for wire spreading, define the timing preservation constraints by using the following options with the spread_wires command:  -timing_preserve_setup_slack_threshold threshold  -timing_preserve_hold_slack_threshold threshold  -timing_preserve_nets nets The threshold values are floating-point numbers in library units.\n Wire spreading is performed only on nets with slack greater than or equal to the specified values or the nets specified in the -timing_preserve_nets option, as well as adjacent nets on the same layer within two routing pitches."}
{"instruction": "How do I Analyzing the Routing Results", "input": "", "output": "After routing is complete, you can clean up the routed nets by running the remove_redundant_shapes command.\n fc_shell> remove_redundant_shapes By default, this command reads the DRC information stored in the design view of the block and then removes dangling and floating net shapes from all nets in the block based on this information.\n To run the check_routes command to get the DRC information instead of using the information stored in the design view, use the -initial_drc_from_input false option.\n You can restrict the removal to  Specific nets by using the -nets option  Specific layers by using the -layers option  Fixed or unfixed route types by using the -route_types option When removing dangling net shapes, the tool does not change topologies or connections and does not touch terminals.\n In addition, no changes are made to open nets or nets with DRC violations.\n You can disable the removal of dangling net shapes by using the -remove_dangling_shapes false option.\n You can disable the removal of floating net shapes by using the -remove_floating_shapes false option.\n In addition to removing dangling and floating net shapes, this command can also remove loops in the specified nets.\n To remove loops, use the -remove_loop_shapes true option.\n By default, the remove_redundant_shapes does not report the changes it makes.\n To report the changes, use the -report_changed_nets true option.\n For example, to remove dangling net shapes, floating net shapes, and loops from the net named my_net, use the following command: fc_shell> remove_redundant_shapes -nets my_net \\ -remove_loop_shapes true After cleaning up the routed nets, reverify the routing, as described in Performing Design Rule Checking Using Zroute"}
{"instruction": "How do I Multiple-Patterning Concepts", "input": "", "output": "The Fusion Compiler tool supports both the traditional UPF flow and the golden UPF flow.\n The golden UPF flow is an optional method of maintaining the UPF multivoltage power intent of the design.\n It uses the original \"golden\" UPF file throughout the synthesis, physical implementation, and verification steps, along with supplemental UPF files generated by the Fusion Compiler tool.\n        compares the traditional UPF flow with the golden UPF flow.\n  UPF-Prime (Traditional) and Golden UPF Flows The golden UPF flow maintains and uses the same, original \"golden\" UPF file throughout the flow.\n The Fusion Compiler tool writes power intent changes into a separate \"supplemental\" UPF file.\n Downstream tools and verification tools use a combination of the golden UPF file and the supplemental UPF file, instead of a single UPF' or UPF'' file.\n The golden UPF flow offers the following advantages:  The golden UPF file remains unchanged throughout the flow, which keeps the form, structure, comment lines, and wildcard naming used in the UPF file as originally written.\n  You can use tool-specific conditional statements to perform different tasks in different tools.\n Such statements are lost in the traditional UPF-prime flow.\n  Changes to the power intent are easily tracked in the supplemental UPF file.\n  You can optionally use the Verilog netlist to store all PG connectivity information, making connect_supply_net commands unnecessary in the UPF files.\n This can significantly simplify and reduce the overall size of the UPF files.\n To enable the golden UPF flow, use the following application option setting before you load the UPF: fc_shell> set_app_options -as_user_default \\ -list {mv.upf.enable_golden_upf true} To load supplemental UPF files, use the -supplemental option with the load_upf command.\n For more information about using the golden UPF flow, see SolvNet article 1412864, \"Golden UPF Flow Application Note.\""}
{"instruction": "How do I Using Routing Guides to Control the Routing Density", "input": "", "output": "You can use a routing guide to limit the number of occurrences of a specific routing pattern within the routing guide boundary on specific layers.\n Zroute tries to route the nets within the routing guide to meet this constraint; however, if the number of edges in the nonpreferred direction exceeds the specified threshold, Zroute reports a violation.\n To create this type of routing guide, use the -max_patterns option with the create_routing_guide command.\n Use the following syntax to specify the routing pattern and its threshold for each affected layer: { { layer pattern limit }...\n } In addition to using the -max_patterns option, you must also use the -layers option when you create this type of routing guide.\n Specify the same layers in the -layers option as those specified in the -max_patterns option.\n       If you do not specify a pattern threshold for a layer, the routing pattern has no limit for that layer.\n Currently, the only supported pattern is non_pref_dir_edge, which represents the edges in the nonpreferred direction.\n For example, to limit the number of edges in the nonpreferred direction to two on M2 and to three on M4, with no limits on other layers, use the following command: fc_shell> create_routing_guide -boundary {{50 50} {200 200}} \\ -max_patterns {{M2 non_pref_dir_edge 2} {M4 non_pref_dir_edge 3}} \\ -layers {M2 M4}"}
{"instruction": "How do I Specifying Settings for Performance, Power, and Area", "input": "", "output": "When a design switches between the functional and scan modes, glitches might occur on asynchronous set and reset lines of scan registers, which can reset the state of these registers.\n The tool can prevent this by adding gating logic to the asynchronous set and reset lines.\n To enable this feature, you must specify a top-level port to control the gating logic by using the set_register_async_gating_pin -port command.\n This control port must be a predefined port in the RTL that is not connected to any other net.\n To get information about such gated scan registers, run the report_async_gated_registers command after physical synthesis.\n The added gating logic can be an AND or OR gate, depending on the polarity of the asynchronous pins on the scan registers.\n When gating logic is added, the Formality tool requires additional information to verify the design and the Fusion Compiler tool generates an appropriate.svf file that disables the gating logic in the functional mode.\n Note: This feature is supported only for the in-compile DFT flow."}
{"instruction": "How do I Analyzing the Placeability of a Relative Placement Group", "input": "", "output": "Before you run placement and optimization, you can check the relative placement constraints for issues that might lead to critical or noncritical failures after placement by using the check_rp_constraints command.\n The following example checks for possible relative placement constraint violation in the group named rp_volt1: fc_shell> check_rp_constraints rp_volt1  ********************************************************************** *** Report : Relative Placement Summary Total number of specified top level relative placement groups: 1 Total number of relative placement groups which may not honor its constraints: 1 ************************************************************************* RP Group: rp_volt1  Warning: The height of relative placement group 'rp_volt1' is more than the height of voltage area or exclusive move bound.\n (RPGP-018)"}
{"instruction": "How do I Creating Routing Guides During Boundary Cell Insertion", "input": "", "output": "By default, the tool uses the following naming convention for inserted boundary cells: boundarycell!\n library_cell_name number To change the separator character from its default of \"!,\" use the -separator option with the set_boundary_cell_rules command..\n To identify the boundary cells inserted in a specific run, use the -prefix option with the set_boundary_cell_rules command to specify a prefix string.\n When you use this option, the tool uses the following naming convention: boundarycell!\n prefix library_cell_name number"}
{"instruction": "How do I Adding Buffers at an Interval That is a Ratio of the Net Length", "input": "", "output": "To add buffers to one or more nets at a specified interval, specify  A list of one or more library cells to select from by using the -lib_cell option  The distance between the driver of the net and the first buffer by using the -first_distance option  The distance between the load pin of the net and the last buffer by using the -last_distance option You must use the -last_distance option with the -repeater_distance option or the -repeater_distance_length_ratio option.\n You can also use the -last_distance option with the -first_distance option.\n However, you cannot use it with the following options:  -location  -user_specified_buffers  -user_specified_bus_buffers Note: When you use the -last_distance option, the value of the eco.add_buffer_on_route.min_distance_buffer_to_load application option is ignored.\n  The interval between the buffers by using the -repeater_distance option Optionally, you can scale the distance between the buffers by  Specifying a different scaling factor for each layer using the -scaled_by_layer option  Using the ratio between the default width for the layer and the actual route width as the scaling factor by specifying the -scaled_by_width option The following example adds the BUF1 library cell on the nets n2 and n5 at an interval of 150 microns.\n The distance between the driver and the first repeater cell is 100 microns.\n fc_shell> add_buffer_on_route {n2 n5} -lib_cell BUF1 \\ -first_distance 100 -repeater_distance 150       The following example adds the BUF2 library cell on the net n1 at an interval of 100 microns.\n The distance between the driver and the first repeater cell is 50 microns and the last distance is 20 microns.\n fc_shell> add_buffer_on_route -repeater_distance 100 \\ -first_distance 50 -last_distance 20 net1 -lib_cell BUF2 By default, the tool uses eco_cell and eco_net as the name prefix of all new cells and nets.\n To specify a name prefix for the new cells and nets, use the -cell_prefix and -net_prefix options, respectively."}
{"instruction": "How do I Defining a Name Prefix for Clock Cells", "input": "", "output": "During clock tree synthesis, you might want to balance a group of sinks only among each other, and not the rest of the sinks.\n To do so, define a skew group by using the create_clock_skew_group command.\n When you use this command, specify the sinks you want to group, by using the -objects option.\n Optionally, you can specify the following:  A clock or generated clock for which to create the skew group by using the -clock option.\n  A mode for which to create the skew group by using the -mode option.\n       By default, the tool creates the skew group for the current mode.\n  A name for the skew group by using the -name option.\n The following example creates a skew group named sg1 consisting of sinks reg1/CP, reg2/ CP, and reg3/CP: fc_shell> create_clock_skew_group -name sg1 \\ -objects {reg1/CP reg2/CP reg3/CP} To report skew groups, use the report_clock_skew_groups command.\n To remove skew groups, use the remove_clock_skew_groups command."}
{"instruction": "How do I Formal Verification", "input": "", "output": "shows the basic physical synthesis design flow.\n        Fusion Compiler Physical Synthesis Flow RTL/ netlist Design (NDM) Ref.\n lib (NDM) Tech.\n data TLU+ files UPF files DEF/Tcl (Optional) SDC files (Optional) Set up the libraries Read RTL files Handle design mismatches and black boxes Apply multivoltage power intent Apply timing and physical constraints Set up clock-gating cells Set up DFT and insert DFT structures Insert multivoltage cells Compile the design Analyze and report QoR Export the design SDC files Design (NDM) Verilog UPF files DEF/ SCANDEF"}
{"instruction": "How do I Analyzing Libraries", "input": "", "output": "The pin access checker (PAC) utility helps you to identify the pin accessibility issues in the library development stage.\n This helps you to enhance the cell layout as you cannot modify the cell layout later, after the library is finalized and released to the Place and Route group.\n The routing DRCs identify the pin access issues after routing.\n When the cells are abutted or placed too close, two or multiple adjacent pins compete for common routing resources and causes routing DRCs.\n       The benefits of PAC utility are listed as follows:  Produces a place and route database with various permutations of abutted cell placement.\n  Generates a place and route database and assesses the ability to place and pin accessibility of the library created based on the reports.\n The PAC performs various checks listed as follows:  Placement of cells  Number of accessible tracks for each library cell's pins  Legalization check after placement  Design rule check after routing  All the earlier listed checks with PG routes You can use the create_pin_check_lib command to create or open a new library based on the input technology and reference libraries.\n PAC creates and stores blocks in this library.\n You must provide minimum three inputs by using the following application options with the create_pin_check_lib command:  Technology file: Use the -technology option to provide the technology file information.\n  Reference library: Use the -ref_libs option to provide the reference library information.\n  Routing direction for metal layers: Use the set_attribute [get_layers Mx] routing_direction horizontal/vertical command to define routing direction in Tcl script.\n You must specify the name of the script using the pin_check.place.preplace_option_file application option.\n To enable the pin access check utility, you can use the check_libcell_pin_access command.\n You can use this command and the pin_check.* application option to enable the following pin access checks:  Legalization  Router  Automatic derivation of cell spacing rule Use the -mode option with the check_libcell_pin_access command to perform multiple checks by specifying different modes.\n create_pin_check_lib myTest.nlib -ref_libs../lib/refLib.ndm -technology../tf/refTech.tf        set_app_options -as_user_default -name pin_check.place.preplace_option_file -value  check_libcell_pin_access -mode analyze_lib_cell  check_libcell_pin_access -mode analyze_lib_pin  check_libcell_pin_access -mode design_under_test If you have been using the earlier Tcl based version, you can translate your old scripts into new Fusion Compiler commands by using the translate_pin_check_ui command.\n translate_pin_check_ui -from old_script.tcl -to new_script.tcl"}
{"instruction": "How do I Defining Clock Cell Spacing Rules", "input": "", "output": "In the early stages of the implementation of a design, the constraints can be inaccurate or too restrictive.\n Running clock tree synthesis on such a design can lead to long runtime or poor clock tree QoR.\n You can run clock tree synthesis on such a design, but still get usable results in a reasonable runtime.\n To do so, set the following application variable before you begin clock tree synthesis: fc_shell> set_app_options \\ -name cts.common.enable_dirty_design_mode -value true When you use this application option setting, the tool  Ignores dont_touch and dont_touch_network attribute settings on clock nets.\n  Removes maximum transition and maximum capacitance constraints if they are too tight.\n  Removes the maximum net length constraint if it is less than 50 microns.\n  Ignores clock cell spacing rules if the horizontal spacing requirement is more than three times the site height and the vertical spacing requirement is more than twenty times the site height.\n  Ignores nondefault routing rules if the width plus the spacing requirement of the routing rule is more than ten times the default width plus the default spacing.\n  Reports balance point delay values that are large enough to cause an increase in clock insertion delay."}
{"instruction": "How do I Performing Total-Power Optimization", "input": "", "output": "To set up for dynamic-power optimization during the preroute optimization stage, perform the following: 1.\n Annotate switching activity on the design, as described in Annotating the Switching Activity 2.\n Ensure that at least one scenario is enabled for dynamic-power optimization by using the set_scenario_status -dynamic_power true command.\n When you use these settings, the tool performs dynamic-power optimization during the clock_opt command.\n However, it does not perform any leakage-power optimization."}
{"instruction": "How do I Activity-Based Optimization", "input": "", "output": "You can specify the maximum number of clock-gate levels that the tool should use for either all clock gates or only tool-inserted clock gates.\n If you specify a value for all clock gates, you must know how many clock-gate levels already exist in the RTL design.\n Alternatively, you can specify a value only for tool-inserted clock gates.\n For details about how the Fusion Compiler tool counts clock-gate levels, see Clock-Gate Levels and Stages       To specify the maximum number of clock-gate levels, use the set_clock_gating_tree_options command with one of the following mutually exclusive options:  The -max_total_levels option specifies the maximum number of levels for all clock gates.\n The argument is an integer greater than or equal to 1.\n  The -max_tool_inserted_levels option specifies the maximum number of levels for tool-inserted clock gates.\n The argument is an integer greater than or equal to 1.\n To restrict the clock-level control to specific clock sources, use the the -clocks option of the set_clock_gating_tree_options command, which takes a list of clocks as an argument.\n To allow clock-gate removal (also known as ungating) if some clock gates are not collapsible when the tool attempts to meet the maximum clock level constraint, use the -ungate_if_not_collapsible option."}
{"instruction": "How do I Setting Up the IC Validator Environment", "input": "", "output": "The following topics describe the tasks you must perform before you run the IC Validator In-Design commands:  Setting Up the IC Validator Environment  Enabling IC Validator Multicore Processing  Defining the Layer Mapping for IC Validator In-Design Commands"}
{"instruction": "How do I Starting the CLI", "input": "", "output": "The Fusion Compiler tool operates in the X Window environment on Linux.\n IThe tool provides a flexible working environment with both a shell command-line interface and a GUI.\n The CLI is always available during a Fusion Compiler session.\n You can start or exit a session in either the shell or the GUI, and you can open or close the GUI during a session.\n The tool uses Tcl, which is used in many applications in the EDA industry.\n Using Tcl, you can extend the fc_shell command language by writing reusable procedures and scripts (see the Using Tcl With Synopsys Tools manual).\n The following topics describe how to start and exit the tool using the command-line interface.\n  Starting the CLI  Exiting the Fusion Compiler Tool For information about using the GUI, see the Fusion Compiler Graphical User Interface User Guide The following topics describe how to use the user interfaces of the Fusion Compiler tool:  Starting the GUI  Closing the GUI"}
{"instruction": "How do I Routing Signal Nets by Using Automatic Routing", "input": "", "output": "Before you run detail routing,  Define the common routing application options For information about the common routing application options, see the route.common_options man page.\n  Define the detail routing application options For information about the detail routing application options, see the route.detail_options man page.\n  Complete global routing and track assignment The detail router uses the general pathways suggested by global routing and track assignment to route the nets, and then it divides the block into partitions and looks for DRC violations in each partition.\n When the detail router finds a violation, it rips up the wire and reroutes it to fix the violation.\n During detail routing, Zroute concurrently addresses routing design rules and antenna rules and optimizes via count and wire length.\n For more information about antenna rules, see Finding and Fixing Antenna Violations To perform standalone detail routing, run the route_detail command.\n By default, the route_detail command  Performs detail routing on the whole block You can restrict the routing to a specific area of the block by using the -coordinates option (or by specifying or selecting the bounding box in the GUI).\n  Uses one uniform partition for the first iteration and adjusts the partitioning for subsequent iterations Zroute uses the single uniform partition for the first iteration to generate all DRC violations for the chip at the same time.\n At the beginning of each subsequent iteration, the router checks the distribution of the DRC violations.\n If the DRC violations are evenly distributed, the detail router uses a uniform partition.\n If the DRC violations are located in some local areas, the detail router uses nonuniform partitions.\n In some cases, such as when a design contains standard cells with long pins, you can improve the detail routing QoR and reduce the runtime by increasing the partition size.\n To enable this feature, set the route.detail.optimize_partition_size_for_drc application option to true        Performs iterations until one of the following conditions exists:  All of the violations have been fixed  The maximum number of iterations has been reached By default, the maximum number of iterations is 40.\n You can change this limit by setting the -max_number_iterations option.\n fc_shell> route_detail -max_number_iterations 20  It cannot fix any of the remaining violations You can change the effort that the detail router uses for fixing the remaining violations before it gives up by setting the route.detail.drc_convergence_effort_level application option.\n fc_shell> set_app_options \\ -name route.detail.drc_convergence_effort_level -value high You can force the detail router to complete the maximum number of iterations, regardless of the DRC convergence status, by setting the route.detail.force_max_number_iterations application option to true fc_shell> set_app_options \\ -name route.detail.force_max_number_iterations -value true  Is not timing-driven To enable timing-driven detail routing, set the route.detail.timing_driven application option to true fc_shell> set_app_options \\ -name route.detail.timing_driven -value true By default, when you enable timing-driving detail routing, Zroute uses medium effort to assign timing-critical nets to low-resistance metal layers.\n To change the extent to which timing-driven detail routing prefers lower-resistance metal layers when routing timing- critical nets, set the route.common.rc_driven_setup_effort_level application option.\n To increase the effort level to use more low-resistance metal layers for routing, set the option to high.\n To reduce the effort level, set the option to low.\n To disable resistance-based routing layer preferences, set the option to off  Does not fix shorted nets over macro cells If default detail routing leaves shorted nets over macro cells, analyze the block to determine if the shorts are caused by the availability of only a single layer for routing over the macro cells.\n If so, use routing guides to encourage river routing over the macros with shorted nets and rerun detail routing.\n For details, see Using Routing Guides to Encourage River Routing       If shorted nets remain after using river routing, enable the fixing of shorted nets over macro cells by automatically ripping up and rerouting the shorted nets by setting the route.detail.repair_shorts_over_macros_effort_level application option to low medium, or high and running incremental detail routing.\n The higher the effort level, the more ECO routing iterations are performed, which can reduce the number of DRC violations at the expense of runtime.\n fc_shell> set_app_options \\ -name route.detail.repair_shorts_over_macros_effort_level \\ -value high  Does not fix soft DRC violations, such as bridge rule violations To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_detail_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_detail_route_fix_soft_violations \\ -value true You can run additional detail routing iterations on a routed block by running incremental detail routing (the -incremental option).\n Be sure to use the -incremental option; otherwise, Zroute restarts at iteration 0 with a fixed-size partition.\n fc_shell> route_detail -incremental true By default, incremental detail routing does not fix soft DRC violations, such as bridge rule violations.\n To enable the fixing of soft DRC violations after the final incremental detail routing iteration, set the route.common.post_incremental_detail_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_incremental_detail_route_fix_soft_violations \\ -value true Note: Incremental detail routing does not fix open nets.\n To fix open nets, you must run ECO routing.\n For information about ECO routing, see Performing ECO Routing If you want to override certain runtime-intensive application options, you can run detail routing in early mode.\n To turn on the early mode in detail routing, use the set_qor_strategy command with the -mode option set as early fc_shell> set_qor_strategy -mode early -stage pnr       Early mode detail routing automatically creates a new DRC type called skipped regions that can detect dirty regions with pin overflow.\n To identify the dirty regions, open the error browser and select Skipped region If you want to view the DRC violations before postroute optimization, you can save the block after a specified number of iterations by setting the route.detail.save_after_iterations application option.\n The saved block is called DR_itr, where n is the specified iteration.\n You can use a string other than DR as the prefix by setting the route.detail.save_cell_prefix application option.\n Zroute generates a DRC violations summary at the end of each iteration.\n After completing detail routing, Zroute outputs a final summary report.\n This report includes all violations detected by Zroute, as well as information about the redundant via conversion rates.\n If you want an additional report that excludes violations that are not of interest to you, specify the rules to exclude by setting the route.detail.report_ignore_drc application option.\n The syntax to set this option is set_app_options -name route.detail.report_ignore_drc -value list_of_drcs The values used in the list_of_drcs argument are the DRC names used in the summary report.\n If the DRC name includes a space, you must enclose the name in double quotation marks.\n For a complete list of the supported DRC names, see the man page.\n Example 21 shows a detail routing report.\n Example 21 Detail Routing Report Start DR iteration 0: uniform partition Routed 1/27405 Partitions, Violations = 0 Routed 137/27405 Partitions, Violations = 264   DR finished with 7398 violations  DRC-SUMMARY: @@@@@@@ TOTAL VIOLATIONS = 7398 Diff net spacing : 194 Same net spacing : 4 Diff net via-cut spacing : 2328 Same net via-cut spacing : 1 Less than minimum width : 5 Less than minimum area : 36 Short : 87 End of line enclosure : 4742 Less than NDR width : 1  Total Wire Length = 23928849 micron Total Number of Contacts = 2932706 Total Number of Wires = 2878293 Total Number of PtConns = 88536 Total Number of Routed Wires = 2878293 Total Routed Wire Length = 23920011 micron Total Number of Routed Contacts = 2932706 Layer M1 : 962827 micron Layer M2 : 4233755 micron        Via VIA78SQ_C : 1742 Via VIA78SQ_C(rot) : 9   Redundant via conversion report:   Total optimized via conversion rate = 98.96% (2902130 / 2932706 vias)  Layer VIA1 = 97.81% (1091973/ 1116367 vias) Weight 1 = 97.81% (1091973 vias) Un-optimized = 2.19% (24394 vias)   Total double via"}
{"instruction": "How do I Specifying Optimization Targets at the Postroute Stage", "input": "", "output": "When performing concurrent clock and data optimization using the place_opt or clock_opt command, you can give a higher priority to the WNS optimization of  Certain path groups by specifying them by using the ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2}       If a path group you specify with this application option is also specified as a path group to skip with the ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization.\n  Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified paths groups.\n  The worst 300 timing paths by setting the ccd.enable_top_wns_optimization application option to true"}
{"instruction": "How do I Defining Insertion Delay Requirements", "input": "", "output": "To define one or more pins as sink pins, use the following syntax: set_clock_balance_points -clock clock -consider_for_balancing true -balance_points pins [-corners corners The -clock option is not required.\n If you do not use it, the sink pin applies to all clocks.\n By default, the insertion delay for the user-specified sink pins is 0.\n For information about overriding the default insertion delay, see Defining Insertion Delay Requirements When you define sink pins, by default, they apply to all corners.\n To apply the definition to specific corners, use the -corners option.\n For example, to specify pin U2/A as a sink pin for the CLK clock in the current corner, use the following command: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -consider_for_balancing true -balance_points [get_pins U2/A] To report the user-defined sink pins, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins report_clock_balance_points command.\n This command reports both the user-defined sink pins and the user-defined ignore pins.\n To remove the sink pin definition from a pin, use the remove_clock_tre_exceptions comand-stop_pinscomandsremove_clock_tre_exceptions-stop_pins remove_clock_balance_points command.\n For example, to remove the sink pin definition from the U2/A pin for the CLK clock, use the following command: fc_shell> remove_clock_balance_points -clock [get_clocks CLK] \\ -balance_points [get_pins U2/A]"}
{"instruction": "How do I Using the create_tap_cells Command", "input": "", "output": "tap cell is a special nonlogic cell with a well tie, substrate tie, or both.\n These cells are typically used when most or all of the standard cells in the library contain no substrate or well taps.\n Generally, the design rules specify the maximum distance allowed between every transistor in a standard cell and a well or substrate tap.\n Before global placement (during the floorplanning stage), you can insert tap cells in the block to form a two-dimensional array structure to ensure that all standard cells placed subsequently comply with the maximum diffusion-to-tap distance limit.\n After you insert the tap cells, visually check to ensure that all standard-cell placeable areas are properly protected by tap cells.\n       The Fusion Compiler tool provides two methods to insert a tap cell array:  Insert the tap cell array based on the site rows and the maximum distance between tap cells To use this method, use the create_tap_cells command, as described in Using the create_tap_cells Command  Insert the tap cell array using a specified offset and pitch, and optionally insert additional tap cells near the boundary To use this method, use the create_cell_array command, as described in Using the create_cell_array Command Advanced nodes often require the insertion of additional tap cells to manage the substrate and well noise.\n You can use the following capabilities to insert additional tap cells after standard tap cell insertion:  Insertion of tap walls tap wall is a row or column of tap cells placed linearly without any gaps between cells.\n You can insert a tap wall outside or inside of the boundary of a block, macro, or hard placement blockage.\n A tap wall that is outside a boundary is called an exterior tap wall.\n A tap wall that is inside a boundary is called an interior tap wall  To insert an exterior tap wall, use the create_exterior_tap_walls command, as described in Inserting Exterior Tap Walls  To insert an interior tap wall, use the create_interior_tap_walls command, as described in Inserting Interior Tap Walls  Insertion of tap meshes tap mesh is a two-dimensional array of tap cells with a tap cell in each mesh window.\n To insert a tap mesh, use the create_tap_meshes command, as described in Inserting Tap Meshes  Insertion of dense tap arrays dense tap array is a tap cell array whose tap distance is smaller than the tap distance used by the create_tap_cells command.\n To insert a dense tap array, use the create_dense_tap_cells command, as described in Inserting Dense Tap Arrays"}
{"instruction": "How do I Marking Clocks as Propagated After Clock Tree Synthesis", "input": "", "output": "A via ladder is a stacked via that starts from the pin layer and extends into an upper layer where the router connects to it.\n Via ladders reduce the via resistance, which can improve performance and electromigration robustness.\n The via ladder insertion flow during clock tree synthesis, optimization, and clock routing consists of the following steps: 1.\n Ensure that the via ladder rules are defined as described in Defining Via Ladder Rules 2.\n Specify the via ladders that can be used for specific library pins by using the set_via_ladder_candidate command, as described in Specifying Via Ladder Candidates for Library Pins 3.\n Define the via ladder constraints by using the set_via_ladder_rules command, as described in Defining Via Ladder Constraints 4.\n Enable high-performance and electromigration via ladder insertion for critical paths during the clock_opt command by setting the opt.common.enable_via_ladder_insertion application option to true 5.\n Perform clock tree synthesis and optimization by using the clock_opt -to build_clock command.\n 6.\n Insert the via ladders by using the insert_via_ladders command, as described in Inserting Via Ladders 7.\n Route the clock nets by using the clock_opt -from route_clock command."}
{"instruction": "How do I Setting Up for Power-Related Features", "input": "", "output": "To improve the area, timing, and power QoR, you can enable advanced logic restructuring.\n To enable this feature for the final_opto stage of the compile_fusion and clock_opt commands, use the opt.common.advanced_logic_restructuring_mode application option, as shown in the following table.\n Table 15 Settings for the opt.common.advanced_logic_restructuring_mode Application Option To do this Use this setting  none   area  timing  power  area_timing  timing_power  area_power  area_timing_power       When restructuring, the tool does not  Restructure across logical hierarchy  Consider cells with dont_touch size_only, or fixed attributes  Accept the results if it increases the wire length However, if your design does not have congestion or routing issues, you can specify that the tool accepts the restructuring results even if it increases the wire length by setting the opt.common.advanced_logic_restructuring_wirelength_costing application option to medium or none.\n The default is high"}
{"instruction": "How do I Controlling MUX Optimization", "input": "", "output": "Th following script disables the ungrouping of the DP_OP cell with datapath gating element add_3: # Disable ungrouping of DP_OP with datapath gating set_datapath_gating_options -ungroup false [get_cells add_3] Analyzing Datapath Extraction To get the best QoR results from datapath optimization, ensure that the biggest possible datapath blocks are extracted from the RTL code during compile.\n To examine how the datapath blocks will be extracted from your RTL before compile, use the analyze_datapath_extraction command.\n The command analyzes the arithmetic contents of the design and provides feedback, so you can improve the RTL code as needed.\n The following example shows a datapath report: Cell : DP_OP_123_2304_10297_J1  Current Implementation : str(area,speed) Contained Operations : add_30(test.v:30) add_30_2(test.v:30) mult_36(test.v:36) Multiplier Arch : benc_radix4  Data Var Type Class Width Expression  PI_0 PI Unsigned 6 PI_1 PI Unsigned 1 PI_2 PI Unsigned 24 T16 IFO Unsigned 7 PI_0 + PI_1 (test.v:30) PO_0 PO Unsigned 30 PI_2 * T16 (test.v:36)       To report the resources and datapath blocks used in the design, use the report_resources command.\n To report the implementation overview, specify the -summary with the report_resources command.\n For example, fc_shell> report_resources -hierarchy Controlling Datapath Gating The following figure shows signal transitions of the inputs of a DP_OP cell that is generated during datapath gating optimization.\n To control datapath gating, use the set_datapath_gating_options command.\n The following script disables datapath gating on the datapath element add_3: # Disable datapath gating on particular operator set_datapath_gating_options -enable false [get_cells add_3]"}
{"instruction": "How do I Reporting Early Data Check Records", "input": "", "output": "To set or modify the policy for all the checks, or modify the policy settings for data checks, use the set_early_data_check_policy command.\n Use the following options to configure the policy:  -checks : Specifies a predefined list of data checks.\n It supports an asterisk wildcard character (*) as the name of a check.\n  -policy : Specifies the type of policy depending on what is supported by the check.\n This can be  error : The tool issues an error message if the check does not support error as a policy.\n  tolerate : The tool issues an error message if the check does not support tolerate as a policy.\n  repair : The tool issues an error message if the check does not support repair as a policy.\n  strict : The tool sets the first matching policy in the following order: 1.\n error 2.\n tolerate 3.\n repair For example, when a check supports the error and tolerate policies, and you select strict as the policy type, the error policy type is set.\n        lenient : The tool sets the first matching policy in the following order: 1.\n repair 2.\n tolerate 3.\n error For example, when a check supports the error and tolerate policies, and you select lenient as the policy type, the tolerate policy type is set.\n Note: If you specify both the checks and policies, the configuration supports all the policies described in this section, depending on what the application-specific check supports.\n However, if you specify only the policies, but not the checks, the configuration supports only the strict and lenient policies.\n  You can also use the if_not_exists keyword with the -policy option to set a policy on the current design only if the design does not already have a policy set.\n  -strategy : Specifies the strategy to apply for a check.\n Note: -strategy is not applicable for the hierarchical checks.\n  -references : Specifies the policy and strategy for reference subdesigns."}
{"instruction": "How do I Generating Hotspots", "input": "", "output": "When rail analysis is complete, there might be hundreds to thousands of voltage drop violations reported in the analysis report, which might make it difficult to identify the root causes for the violations.\n Use the voltage hotspot analysis capability to generate hotspots for a power or ground net by dividing the whole chip into small grid boxes, and report rail-related information for the generated grid boxes.\n In addition, you can query cell- or geometry-based rail results only for the specific analysis type by using the get_instance_result and get_geometry_result commands.\n       Hotspot analysis provides the following features:  Identify the root cause of aggressors with high voltage drop, such as large current from the aggressor itself or from the neighboring cells due to simultaneous switching by the overlapping timing windows.\n  Determine which design technique to use for fixing voltage violations based on the report, such as choosing a candidate reference cell for cell sizing replacement, moving or relocating cells to reduce voltage drops, or applying PG augmentation to solve a voltage drop issue.\n This section contains the following topics:  Generating Hotspots  Reporting Hotspots  Removing Hotspots  Voltage Hotspot Analysis Examples To write rail results only for the cell instances or geometries that reside in the hotspot area, use the get_instance_result and get_geometry_result commands.\n For more information, see Generating Instance-Based Analysis Reports and Generating Geometry- Based Analysis Reports"}
{"instruction": "How do I Overview of Abstract Views", "input": "", "output": "You must provide power intent of the subblock for the top-level design implementation when running hierarchical synthesis.\n To do so, you can provide full block-level UPF for the tool to automatically extract power intent interface.\n The following figure shows a subblock named U1, and the top-level power intent script loads the block-level power intent by using the load_upf command.\n Note: The block-level power intent specification is required only for hierarchical synthesis using ETMs.\n In the abstract flow, the UPF constraints are handled automatically by the tool.\n        U1 as an ETM in the PD_Top design  Top-Level power intent create_power_domain PD_TOP -include_scope create_supply_net VDD_AO...\n load_upf block.upf -scope U1...\n connect_supply_net VDD_AO -port U1/VDD_AO  Block-level power intent: block.upf create_power_domain PD_BLK -include_scope create_power_switch sw1 -domain PD_BLK \\ -input_supply_port {in VDD_AO} \\ -output_supply_port {out VDD_SW}...\n...\n add_port_state sw1/out -state {ON 1.08} -state {OFF off}...\n create_pst pst -supplies {VDD_SW...}"}
{"instruction": "How do I Making ECO Changes Using Netlist Editing Commands", "input": "", "output": "You can make ECO changes to a block by using the eco_netlist command.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true before you run the eco_netlist command.\n When you use the eco_netlist command, use one of the following two methods to make the ECO changes:  Specify a golden Verilog netlist that includes the ECO changes by using the -by_verilog_file option  Specify a golden block that includes the ECO changes by using the -block option When you use the -block option, by default,  The tool assumes the golden block is in the current design library.\n To specify a different design library, use the -golden_lib option.\n  The tool makes the ECO changes to the current design.\n To make the ECO changes to a different design, use the -working_block option.\n To specify the design library that contains the design specified by the -working_block option, use the -working_lib option.\n The tool compares the working design to the input Verilog netlist or the golden design and generates a change file containing netlist editing Tcl commands that implements the functional changes.\n You must specify the name of the output file by using the -write_changes option.\n By default, the tool ignores the following:  Differences in the physical-only cells To consider the differences in the physical-only cells, use the -compare_physical_only_cells option.\n  Timing ECO changes, such as cells that are resized or repeaters that are added or removed.\n To consider the timing ECO changes, in addition to the functional ECO changes, use the -extract_timing_eco_changes option.\n  Differences in power and ground objects.\n       To make the ECO changes to the working design, source the change file that the eco_netlist command generates, as shown in the following example: fc_shell> eco_netlist -by_verilog_file eco.v \\ -compare_physical_only_cells -write_changes eco_changes.tcl fc_shell> source eco_changes.tcl"}
{"instruction": "How do I Performing Conventional Leakage-Power Optimization", "input": "", "output": "The Fusion Compiler tool can optimize both dynamic and static (leakage) power.\n  Dynamic power This is the energy dissipated due to the voltage or logic transitions in the design objects, such as cells, pins, and nets.\n The dynamic power consumption is directly proportional to the number and frequency of transitions in the design.\n  Static (leakage) power This is the energy dissipated even when there are no transitions in the circuit.\n This is also known as leakage power and depends on the device characteristics.\n The main contributor to leakage power is the sub-threshold-voltage leakage in the device.\n At lower technology nodes, leakage power consumption contributes significantly to the total power consumption of the circuit.\n The following topics describe how to enable the different types of power optimization the tool performs:  Performing Conventional Leakage-Power Optimization  Performing Dynamic-Power Optimization  Performing Total-Power Optimization"}
{"instruction": "How do I Modifying Routing Corridors", "input": "", "output": "To successfully route a net within a routing corridor, the routing corridor must meet the following requirements:  It must be a contiguous region; all regions that comprise the routing corridor must be connected.\n  It must contain the pins that connect to the nets and supernets associated with the routing corridor.\n To verify that a routing corridor meets these requirements, use the check_routing_corridors command.\n fc_shell> check_routing_corridors RC_0 You can view the errors detected by the check_routing_corridors command in the message browser."}
{"instruction": "How do I Considering the Effects of Clock Gating Cells of Sequential", "input": "", "output": "To improve timing and reduce crosstalk, nondefault routing rules are used extensively for routing clock nets.\n However, these nondefault routing rules require additional space, which can increase the congestion after clock routing.\n To consider the effects of the nondefault routing rules of the clock nets during placement, set the place.coarse.ndr_area_aware application option to true"}
{"instruction": "How do I Defining Blockages That Exclude Registers", "input": "", "output": "A category blockage is a special type of partial blockage that controls the placement of a predefined category of cells within the partial blockage.\n To create a category blockage, 1.\n Create the cell category by defining a user attribute for the category by using the define_user_attribute command and applying it to the affected cell references or instances by using the set_attribute command.\n To prevent the cell from being placed in the category blockage, set the attribute to true.\n To allow the cell in the category blockage, set the attribute to false When defining and applying attributes, observe the following rules:  A blockage can only be controlled by a single attribute.\n  Multiple blockages can be controlled by the same attribute.\n  A cell can have multiple attributes, which could impact its placement in multiple category blockages.\n        The same attribute can be applied to a reference and an instance.\n  If a cell instance and its reference have different attributes, the attribute on the cell instance takes precedence.\n 2.\n Create the category blockage by using the create_placement_blockage command with the -type category -blocked_percentage, and -category options.\n The argument to the -category option is the name of the user attribute.\n The following example defines a blockage that prevents a certain category of cells from being placed within it: define_user_attribute -type boolean \\ -classes lib_cell dr_cells set_attribute [get_lib_cells mylib/dr*] dr_cells true create_placement_blockage -boundary {{4300 2400} {4500 2700}} \\ -type category -blocked_percentage 45 -category dr_cell The following example defines a blockage that allows only a certain category of cells to be placed within it: define_user_attribute -type boolean \\ -classes lib_cell non_iso set_attribute [get_lib_cells mylib/*] non_iso true set_attribute [get_lib_cells mylib/iso*] non_iso false create_placement_blockage -boundary {{4300 2400}{4500 2700}} \\ -type category -blocked_percentage 30 -category non_iso Note: Category blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Generating a Congestion Report", "input": "", "output": "You can analyze the routing results by reporting on the cell placement and routing statistics.\n The following topics describe how to perform these tasks:  Generating a Congestion Report  Generating a Congestion Map  Performing Design Rule Checking Using Zroute  Performing Signoff Design Rule Checking  Performing Design Rule Checking in an External Tool  Performing Layout-Versus-Schematic Checking  Reporting the Routing Results  Reporting the Wire Length  Using the DRC Query Commands"}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "To ensure that the tool resize preexisting gates in the clock network during clock tree synthesis and optimization, you must specify equivalent cells as clock references.\n Not specifying a complete list of equivalent cells for preexisting gates can affect clock tree QoR.\n You can automatically derive equivalent cells for all the preexisting clock tree cells and specify them as clock references by using the derive_clock_cell_references command.\n       When you run this command, the tool sets the valid_purpose attribute to true on equivalent library cells of the preexisting clock tree cells that are not buffers or inverters.\n This command does not derive equivalent library cells for preexisting buffers and inverters, Therefore, you must manually specify the buffers and inverters to use for clock tree synthesis, as shown in the following example: fc_shell> set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell> derive_clock_cell_references fc_shell> synthesize_clock_trees Instead of automatically specifying the equivalent library cells of the preexisting clock tree cells as clock tree references, you can generate a Tcl script that specifies the equivalent library cells of the preexisting clock tree cells as clock tree references.\n To do so, use the -output option.\n fc_shell> derive_clock_cell_references -output cts_leq_cells.tcl You can the output file, source it, and then run clock tree synthesis, as shown in the following example: fc_shell> set_lib_cell_purpose -include cts \\ {tech_lib/clk_buf* tech_lib/clk_inv*} fc_shell> source cts_leq_cells.tcl fc_shell> synthesize_clock_trees"}
{"instruction": "How do I Trunk Splitting", "input": "", "output": "The custom.route.bus_pin_trunk_offset application option changes the default spacing between the bus trunk and the bus bit pins."}
{"instruction": "How do I Reporting Shielding Statistics", "input": "", "output": "To query the shield shapes associated with a shielded net, use the get_shapes command with the -shield_only option, as shown in the following example: fc_shell> get_shapes -shield_only -of_objects [get_nets myclk] {PATH_19_4317 PATH_19_4318 PATH_19_4319 PATH_19_4320 PATH_19_4322       PATH_17_11590 PATH_17_11591 PATH_17_11592 PATH_17_11593 PATH_17_11594 PATH_17_11595 PATH_17_11596 PATH_17_11597 PATH_17_11599 PATH_17_11600 PATH_17_11601 PATH_17_11602 PATH_17_11604 PATH_17_11605 PATH_17_11606 PATH_17_11607 PATH_17_11608 PATH_17_11609 PATH_17_11610 PATH_17_11611 PATH_17_11612 PATH_17_11613 PATH_17_11614 PATH_17_11615 PATH_17_11616 PATH_17_11617 PATH_17_11618 PATH_17_11619 PATH_17_11620 PATH_17_11621 PATH_17_11622 PATH_17_11623 PATH_17_11624 PATH_17_11625 PATH_17_11626}"}
{"instruction": "How do I Deriving Clock Tree Exceptions From Ideal Clock Latencies", "input": "", "output": "You can specify that the tool copies clock tree exceptions from one mode to one or more equivalent modes by using the set_clock_tree_options command with the -copy_exceptions_across_modes -from_mode, and -to_mode options.\n The following example specifies that during clock tree synthesis the clock tree exceptions in the mode name M1 should be copied to the modes name M2 and M3: fc_shell> set_clock_tree_options -copy_exceptions_across_modes \\ -from_mode M1 -to_mode {M2 M3}"}
{"instruction": "How do I Building the Local Clock Subtree Structures", "input": "", "output": "Before you can perform automated tap assignment by using the synthesize_multisource_clock_taps command, you must perform the following steps: 1.\n Remove dont_touch size_only fixed, and locked attributes setting on the clock cells that are not required.\n These settings prevent the tool from merging or splitting clock cells during tap assignment, if necessary.\n 2.\n Specify settings for automated tap assignment by using the set_multisource_clock_tap_options command.\n You must specify  The clock for tap assignment by using the -clock option.\n All the sinks reachable from the given clock are considered for redistribution.\n  The tap drivers among which the sinks are redistributed by using the -driver_objects option.\n        The number of taps that the sinks are redistributed among by using the -num_taps option.\n Currently, the number of taps specified with this option must be equal to the number of drivers specified with the -driver_objects option.\n To prevent the tool from merging specific clock tree cells, specify the instance names using the -dont_merge_cells option.\n To report the settings you specify for automated tap assignment, use the report_multisource_clock_tap_options command.\n To remove the settings you specify for automated tap assignment, use the remove_multisource_clock_tap_options command.\n 3.\n (Optional) Create multisource sink groups for tap assignment by using the create_multisource_clock_sink_group command.\n Skew groups defined for the clock can be distributed among different taps.\n To retain the objects of a skew group under the same tap, create a corresponding multisource sink group.\n Use the following commands to remove, report, or manipulate multisource sink groups:  remove_multisource_clock_sink_groups  report_multisource_clock_sink_groups  get_multisource_clock_sink_groups  add_to_multisource_clock_sink_group  remove_from_multisource_clock_sink_group 4.\n (Optional) Specify name prefixes and suffixes to use when merging and splitting clock cells during tap assignment by using the following application options:  cts.multisource.subtree_merge_cell_name_prefix  cts.multisource.subtree_merge_cell_name_suffix  cts.multisource.subtree_split_cell_name_prefix  cts.multisource.subtree_split_cell_name_suffix  cts.multisource.subtree_split_net_name_prefix  cts.multisource.subtree_split_net_name_suffix"}
{"instruction": "How do I Specifying Switching Probability for Supply Nets", "input": "", "output": "If the clock frequency used in the SAIF file is different from the clock frequency used in the Fusion Compiler tool, you can scale the switching activity by performing the following steps: 1.\n Read in the SAIF file by using the read_saif command.\n 2.\n Enable scaling by setting the power.use_generated_clock_scaling_factor application option to on 3.\n Scale the switching activity by using the set_power_clock_scaling command.\n When you use this command, you must specify the following:  The clock objects associated with the switching activity you want to scale  The clock period used in the SAIF file by using the -period option or the ratio between the clock period used in the SAIF file and the clock period used in the Fusion Compiler tool by using the -ratio option In addition, you can specify the scenario for which to apply the scaling by using the -scenario option.\n       The following example reads in a SAIF file, enables scaling, scales the switching activity associated with clocks named CLK1 and CLK2 by a ratio of five, and scales the switching activity associated with clock named CLK3 by a ratio of two: fc_shell> read_saif top.saif fc_shell> set_app_options -list \\ {power.use_generated_clock_scaling_factor true} fc_shell> set_power_clock_scaling -ratio 5 {CLK1 CLK2} fc_shell> set_power_clock_scaling -ratio 2 {CLK3} If you run the set_power_clock_scaling command again for the same clock, the tool scales the already scaled switching activity.\n When you use the set_power_clock_scaling command, the tool scales only the switching activity applied with the read_saif command.\n The tool does not scale the following:  Switching activity applied with the set_switching_activity command  Switching activity within block abstracts The scaled switching activity is persistent in the design.\n You can write it out by using the write_saif command and use it in the subsequent steps of the design flow."}
{"instruction": "How do I Defining Instance-Specific Via Ladder Constraints", "input": "", "output": "To define global via ladder constraints, which are referred to as via ladder rules, use the set_via_ladder_rules command to set via ladder constraints on library cell pins.\n You must specify the mapping between library cell pins and via ladder templates, as well as the pins to which to apply the mapping.\n Use the following options to specify the mapping:  -master_pin_map or -master_pin_map_file These options specify the mappings for specific library pins using the following format: { { lib_cell pin via_ladder_list }}...}       To specify the mapping on the command line, use the -master_pin_map option.\n To specify the mapping in an external file, use the -master_pin_map_file option to specify the mapping file name.\n  -default_ladders This option specifies the via ladder templates to use for all library pins not explicitly specified in the mapping.\n Use the following options to specify the pins to which to apply the mapping:  -all_instances_of This option explicitly specifies library cell pins to which to apply the mapping.\n  -all_clock_outputs Set this option to true to apply the mapping to all clock output pins.\n  -all_clock_inputs Set this option to true to apply the mapping to all clock input pins.\n  -all_pins_driving This option applies the mapping to all pins that drive one of the specified ports.\n To report the via ladder rules, use the report_via_ladder_rules command.\n To remove via ladder rules, use the remove_via_ladder_rules command."}
{"instruction": "How do I Preparing the Design", "input": "", "output": "To improve runtime, you can run checking and reporting commands in parallel and return to the parent process after the longest running command in the parallel execution list completes.\n This is useful in batch scripts.\n To run commands in parallel, use the parallel_execute command, as shown in the following example: fc_shell> update_timing fc_shell> parallel_execute { report_cmd1 log_file1 report_cmd2 log_file2 report_cmd3 log_file3...\n        To list the supported commands, use the -list_allowed_commands option with the parallel_execute command.\n To specify the maximum number of cores to use when running the parallel_execute command, use the -max_cores option.\n If you do not use this option, the tool uses the value of the -max_cores option from the set_host_options command.\n If you do not specify the maximum number of cores with either command, the tool runs the commands sequentially instead of in parallel.\n To run commands in parallel as a background job, use the redirect -bg command to run the parallel_execute command, as shown in the following example: fc_shell> redirect -bg -max_cores 3 -file bg_log.out { parallel_execute { report_cmd1 log_file1 report_cmd2 log_file2"}
{"instruction": "How do I Inserting Via Ladders", "input": "", "output": "To define a custom via, use the following create_via_def syntax: create_via_def -shapes { { layer coordinates } [ mask_constraint ]}...\n } [-lower_mask_pattern alternating | uniform] [-upper_mask_pattern alternating | uniform] [-force] via_def_name In the -shapes option, you must specify shapes for one via layer and two metal layers, which are the enclosure layers for the via.\n You can specify multiple shapes per layer.\n For example, to create a custom via definition, use a command similar to the following: fc_shell> create_via_def design_H_shape_via \\ -shapes { {VIA12 {0.035 -0.035} {0.100 0.035}} {VIA12 {-0.100 -0.035} {-0.035 0.035}} {METAL1 {-0.130 -0.035} {0.130 0.035}} {METAL2 {-0.100 -0.065} {-0.035 0.065}} {METAL2 {0.035 -0.065} {0.100 0.065}} {METAL2 {-0.100 -0.035} {0.100 0.035}} } To overwrite an existing via definition, use the -force option; otherwise, the command fails if the specified via definition already exists.\n       If you are using double-patterning technology, you can assign mask constraints to the shapes or the enclosure layers, but not both.\n  To assign mask constraints to the shapes, use the mask_one mask_two, or mask_three keywords for the mask_constraint arguments when specifying the -shapes option.\n You would use this method if the mask constraints follow an arbitrary pattern.\n When you create a via with the create_via command, the via shapes inherit the mask constraints specified in the via definition.\n If the mask constraint you specify for an enclosure layer when you create a via differs from the mask constraint specified for the first shape in the via definition, the specified mask constraint determines the mask-shift used for all shapes on that layer.\n For example, fc_shell> create_via_def VIA12 \\ -shapes { {M1 {-0.037 -0.010} {-0.017 0.01} mask_two} {M1 {0.017 -0.010} {0.037 0.01} mask_one} {VIA1 {-0.037 -0.01} {0.037 0.01} mask_two} {M2 {-0.044 -0.010} {0.044 0.010} mask_one} } fc_shell> create_via -net n1 -via_def VIA12 \\ -origin {100.100 200.320}  To assign mask constraints to the enclosure layers, use the -lower_mask_pattern and -upper_mask_pattern options.\n You can specify either uniform or alternating as the mask pattern.\n In either case, you specify the mask constraint for the first shape when you create a via with the create_via command.\n If you specify uniform, all shapes on the layer use the specified mask constraint.\n If you specify alternating, the colors alternate from shape to shape after the first shape.\n For example, fc_shell> create_via_def VIA12 \\ -shapes { {M1 {-0.010 -0.030} {0.027 0.050}} {M1 {0.047 -0.030} {0.084 0.050}} {VIA1 {0.000 0.000} {0.074 0.020}} {M2 {-0.030 0.000} {0.104 0.020}} } \\ -lower_mask_pattern uniform fc_shell> create_via -via_def VIA12 -origin {000.100 200.320} -lower_mask_constraint mask_two To report information about the via definitions, use the report_via_defs command.\n This command reports the shapes that comprise the via definition but does not report the upper and lower mask patterns."}
{"instruction": "How do I UPF Flows", "input": "", "output": "The UPF language establishes a set of commands to specify the low-power design intent for electronic systems.\n Using UPF commands, you can specify the supply network, switches, isolation, retention, and other aspects relevant to power management of a chip design.\n The same set of low-power design specification commands is to be used throughout the design, analysis, verification, and implementation flow.\n Synopsys tools are designed to follow the official IEEE 1801 UPF standard.\n The UPF language provides a way to specify the power requirements of a design, but without specifying explicitly how those requirements are implemented.\n The language specifies how to create a power supply network for each design element, the behavior of supply nets with respect to each other, and how the logic functionality is extended to support dynamic power switching to design elements.\n It does not contain any placement or routing information.\n In the UPF language, a power domain is a group of elements in the design that share a common set of power supply needs.\n By default, all logic elements in a power domain use the same primary supply and primary ground.\n Other power supplies can be defined for a power domain as well.\n A power domain is typically implemented as a contiguous voltage area in the physical chip layout, although this is not a requirement of the language.\n Each power domain has a scope and an extent.\n The scope is the level of logic hierarchy designated as the root of the domain.\n The extent is the set of logic elements that belong to the power domain and share the same power supply needs.\n The scope is the hierarchical level at which the domain is defined and is an ancestor of the elements belonging to the power domain, whereas the extent is the actual set of elements belonging to the power domain.\n Each scope in the design has supply nets and supply ports at the defined hierarchical level of the scope.\n A supply net is a conductor that carries a supply voltage or ground throughout a given power domain.\n A supply net that spans more than one power domain is said to be \"reused\" in multiple domains.\n A supply port is a power supply connection point between two adjacent levels of the design hierarchy, between the parent and child blocks of the hierarchy.\n A supply net that crosses from one level of the design hierarchy to the next passes through a supply port.\n supply set is an abstract collection of supply nets, consisting of two supply functions, power and ground.\n A supply set is domain-independent, which means that the power and ground in the supply set are available to be used by any power domain defined within the scope where the supply set was created.\n However, each power domain can be restricted to limit its usage of supply sets within that power domain.\n You can use supply sets to define power intent at the RTL level, so you can synthesize a design even before you know the names of the actual supply nets.\n A supply set is an abstraction of the supply nets and supply ports needed to power a design.\n Before such a       design can physically implemented (placed and routed), its supply sets must be refined, or associated with actual supply nets.\n supply set handle is an abstract supply set created for a power domain.\n By default, a power domain has supply set handles for the domain's primary supply set, a default isolation supply set, and a default retention supply set.\n These supply set handles let you synthesize a design even before you create any supply sets, supply nets, and supply ports for the power domain.\n Before such a design can be physically implemented, its supply set handles must be refined, or associated with actual supply sets; and those supply sets must be refined so that they are associated with actual supply nets.\n power switch (or simply switch ) is a device that turns on and turns off power for a supply net.\n A switch has an input supply net, an output supply net that can be switched on or off, and at least one input signal to control switching.\n The switch can optionally have multiple input control signals and one or more output acknowledge signals.\n A power state table lists the allowed combinations of voltage values and states of the power switches for all power domains in the design.\n level shifter must be present where a logic signal leaves one power domain and enters another at a substantially different supply voltage.\n The level shifter converts a signal from the voltage swing of the first domain to that of the second domain.\n An isolation cell must be present where a logic signal leaves a switchable power domain and enters a different power domain.\n The level shifter generates a known logic value during shutdown of the domain.\n If the voltage levels of the two domains are substantially different, the interface cell must be able to perform both level shifting (when the domain is powered up) and isolation (when the domain is powered down).\n A cell that can perform both functions is called an enable level shifter In a power domain that has power switching, any registers that must retain data during shutdown must be implemented as retention registers.\n A retention register has a separate, always-on supply net, sometimes called the backup supply, which keeps the data stable in the retention register while the primary supply of the domain is shut down."}
{"instruction": "How do I Controlling the Tapering Width", "input": "", "output": "You specify the tapering method for a nondefault routing rule when you define the rule with the create_routing_rule command.\n By default, Zroute uses distance-based pin tapering; it uses the default routing rule within the tapering distance from the pin and uses the nondefault routing rule beyond the tapering distance.\n However, advanced process nodes are very sensitive to jogs and fat metal, and sometimes the tapering distance is not sufficient to fix the routing DRC violations on nets with nondefault routing rules.\n In these cases, you can use layer-based tapering, which targets DRC violations on nets with nondefault routing rules.\n Note: Distance-based tapering and layer-based tapering are mutually exclusive.\n If you define a routing rule that uses both a distance-based tapering option and a layer-based tapering option, the tool uses the layer-based tapering settings and ignores the distance-based tapering settings.\n When Zroute performs distance-based pin tapering, it  Determines the tapering distance, which is about 10 times the mean number of tracks for all routing layers.\n To explicitly specify the tapering distance, use the -taper_distance option when you create a nondefault routing rule with the create_routing_rule command.\n  Uses the same tapering distance for all pins.\n To specify a different tapering distance for driver pins, use the -driver_taper_distance option when you create a nondefault routing rule with the create_routing_rule command.\n To perform layer-based pin tapering, use the -taper_over_pin_layers or -taper_under_pin_layers option when you create a nondefault routing rule with the create_routing_rule command.\n To specify a different layer-based tapering distance for driver pins, use the -driver_taper_over_pin_layers or -driver_taper_under_pin_layers option.\n  For pins on the M1 or M2 layers, use the -taper_over_pin_layers option (or the -driver_taper_over_pin_layers option for driver pins) to specify the number of layers on or above the pin layer available for tapering.\n A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers above the pin layer.\n  For pins on upper layers, use the -taper_under_pin_layers option (or the -driver_taper_under_pin_layers option for driver pins)to specify the number of layers on or below the pin layer available for tapering.\n A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers below the pin layer."}
{"instruction": "How do I Defining a Soft Placement Blockage", "input": "", "output": "To define a hard macro blockage, specify the boundary, type ( -type hard_macro option), and optionally the name for the placement blockage.\n For example, to define a hard macro blockage enclosed by a rectangle with corners at (120, 75) and (230, 200), use the following command: create_placement_blockage -boundary {120 75 230 200} \\ -type hard_macro Note: Hard macro placement blockages are honored during placement, legalization, and optimization.\n This is the only type of placement blockage that is honored by hard macro placement."}
{"instruction": "How do I Assigning Nets to a Routing Corridor", "input": "", "output": "A routing corridor restricts Zroute global routing for specific nets to the region defined by a set of connected rectangles.\n In addition to specifying the region in which the routing occurs, you can also specify the minimum and maximum routing layers for each of the rectangles that comprise the routing corridor.\n Routing corridors are intended to be used to route critical nets before signal routing.\n Zroute global routing considers routing corridors as a hard constraint, while track assignment and detail routing consider routing corridors as a soft constraint and might route nets slightly outside of the routing corridor to fix DRC violations.\n Note: If a routing guide overlaps with a routing corridor and its attributes conflict with the routing corridor, the routing corridor takes precedence.\n For example, shows a routing corridor named corridor_1, which is made up of six rectangles.\n This routing corridor is associated with the nets shown in yellow.\n The figure on the left shows the nets before routing, while the figure on the right shows the nets routed within the routing corridor.\n  Using a Routing Corridor Before routing After routing To define a routing corridor, use the create_routing_corridor command.\n At a minimum, you must define the boundary of the routing corridor.\n  To create a rectangular routing corridor, use the -boundary option to specify the lower- left and upper-right corners of the rectangle using the following syntax: { { llx lly urx ury } }  To create a rectilinear routing corridor, use the -boundary option to specify the coordinates of the polygon using the following syntax: { { x1 y1 } { x2 y2 }...\n }        To create a path-based routing corridor, use the -path option to specify the path and the -width option to specify the width in microns.\n Specify the path using the following syntax: { { x1 y1 } { x2 y2 }...\n } By default, path-based routing corridors have flush end caps at the start and end of the path.\n To change the end cap style, use the -start_endcap and -end_endcap options.\n Valid styles are flush full_width, and half_width By default, the tool creates a routing corridor named CORRIDOR_ objId in the current block that honors the existing minimum and maximum routing layer constraints (for information about specifying routing layer constraints, see Specifying the Routing Resources ).\n Use the following options to change the default behavior.\n  To specify a name for the routing corridor, use the -name option.\n  To create the routing guide in a different physical cell, use the -cell option.\n When you use this option, the tool creates the routing guide in the cell's reference block using the coordinate system of the cell's top-level block.\n  To specify the minimum and maximum routing layers for the routing corridor, use the -min_layer_name and -max_layer_name options.\n Specify the routing layers by using the layer names from the technology file."}
{"instruction": "How do I Performing Signoff Design Rule Checking", "input": "", "output": "To use Zroute to check the routing design rules defined in the technology file, run the check_routes command.\n By default, the check_routes command checks for routing DRC violations, unconnected nets, antenna rule violations, and voltage area violations on all routed signal nets in the block, except those marked as user nets, frozen nets, and PG nets.\n  To verify the routing only for specific nets, specify the nets by using the -nets option.\n  To check user routes, set the -check_from_user_shapes option to true  To check frozen routes, set the -check_from_frozen_shapes option to true A net is considered frozen when its physical_status attribute is set to locked       To disable checks for routing DRC violations, set the -drc option to false.\n To disable checks for unconnected nets, set the -open_net option to false.\n To disable checks for antenna rule violations, set the -antenna option to false.\n To disable checks for voltage area violations, set the -voltage_area option to false To save time, you can restrict the routing verification to specific regions of the block by using the -coordinates option to specify the lower-left and upper-right coordinates for each rectangular region.\n When you perform area-based DRC, the check_routes command checks only for DRC violations and voltage area violations.\n It does not check for unconnected nets, antenna violations, or tie-to-rail violations, as these are net-based violations.\n Note: The -coordinates option and the -nets option are mutually exclusive; you can use only one of these options.\n The check_routes command reports the following DRC violations:  Spacing violations  Different-net wire spacing  Different-net nondefault wire spacing (note that the DRC report refers to nondefault routing rules as variable rules)  Different-net via-cut spacing  Different-net nondefault via-cut spacing (note that the DRC report refers to nondefault routing rules as variable rules)  Different-net fat extension spacing  Dog bone spacing  End-of-line spacing  Enclosed via spacing  Same-net spacing  Same-net via-cut spacing  Same-net fat extension spacing  Special notch spacing  U-shape spacing  Via-cut to metal spacing  Soft spacing        Area violations  Less than minimum area  Less than minimum enclosed area  Fat wire via keepout area  Jog wire via keepout area  Length and width violations  Less than minimum width  Less than minimum length  Less than minimum edge length  Protrusion length  Contact violations  Needs fat contact  Needs poly contact  Needs fat contact on extension  Over maximum stack level  Enclosure violations  End-of-line wire via enclosure  Jog wire via enclosure  T-shape wire via enclosure  Others  Open nets, except when doing area-based DRC By default, the check_routes command reports a maximum of 200 open nets.\n To report all open nets, use the -report_all_open_nets true option (or select \"Report all open nets\" in the GUI).\n  Antenna violations, except when doing area-based DRC  Nets crossing the top-cell boundary  Frozen layers  Minimum layer        Maximum layer  Voltage area violations Note: These violations are also reported after each detail route iteration.\n The check_routes command saves the error data to a file named zroute.err.\n You cannot control the naming of the error data file generated by the check_routes command, but you can rename the error data file after running the command.\n To rename the error data file, use the following commands: fc_shell> write_drc_error_data -error_data zroute.err \\ -file_name export.err fc_shell> open_drc_error_data -file_name export.err fc_shell> attach_drc_error_data [get_drc_error_data export.err] \\ -name newname.err After you run the check_routes command, you can use the DRC query commands to get more information about the violations or use the error browser to examine the violations in the GUI.\n For information about analyzing the DRC violations, see Using the DRC Query Commands.\n For information about using the error browser, see the Fusion Compiler Graphical User Interface User Guide After running check_routes, you can use the following command to run incremental detail routing that uses the check_routes results as input: fc_shell> route_detail -incremental true \\ -initial_drc_from_input true Note: Incremental detail routing does not fix open nets.\n To fix open nets, you must run ECO routing.\n For information about ECO routing, see Performing ECO Routing"}
{"instruction": "How do I Reducing Dynamic Voltage Drop", "input": "", "output": "To specify a maximum delayed latency for useful skew computation, set the ccd.max_postpone application option to a specific value, as shown in the following example: fc_shell> set_app_options \\ ccd.max_postpone 50       To specify a maximum advanced latency for useful skew computation, set the ccd.max_prepone application option to a specific value, as shown in the following example: fc_shell> set_app_options \\ ccd.max_prepone 100 To omit useful skew computation for specific path groups, specify one or more path groups with the ccd.skip_path_groups application option as follows: fc_shell> set_app_options ccd.skip_path_groups path_group_list To disable concurrent clock and data optimization for boundary timing paths, set the ccd.optimize_boundary_timing application to false, changing it from its default of true.\n All optimization on I/O paths and latencies for boundary registers will not be adjusted to improve register to register timing.\n fc_shell> set_app_options ccd.optimize_boundary_timing false"}
{"instruction": "How do I Synthesizing the Global Clock Trees", "input": "", "output": "To insert clock drivers from the top level of a design with multiple levels of physical hierarchy, 1.\n Enable the lower-level physical blocks for editing by using the set_editability command.\n 2.\n Enable clock driver insertion for multiple levels of physical hierarchy by setting the cts.multisource.enable_mlph_flow application option to true       3.\n Insert clock drivers by using the create_clock_drivers command.\n 4.\n Route the inserted clock drivers by using the synthesize_multisource_global_clock_trees -roots -leaves -use_zroute_for_pin_connections command.\n When inserting clock drivers to lower-level blocks, the tool reuses existing clock ports.\n If there are no existing clock ports, the tool creates new ports, if it is allowed.\n You can allow new ports to be added to a block by using use the set_freeze_ports command."}
