{"instruction": "How do I Viewing PG Electromigration Analysis Results", "input": "", "output": "When PG electromigration analysis is complete, you can check for current violations by displaying a PG electromigration map or checking the generated errors in the error browser.\n Displaying the PG Electromigration Map Checking PG Electromigration Violations"}
{"instruction": "How do I Using Variables", "input": "", "output": "In general, the Fusion Compiler tool modifies default behavior by using application options rather than application variables; however it does support user-defined Tcl variables, as well as a minimal number of application variables, such as the search_path variable.\n 48 Viewing Man Pages Feedback To list the variables and their values, use the printvar command.\n For example, to list all variables defined in the current session, use the following command: fc_shell> printvar * To print the value of the search_path variable, use the following command: fc_shell> printvar search_path See Also Defining the Search Path"}
{"instruction": "How do I Introduction to Clock Gating", "input": "", "output": "Clock gating applies to synchronous load-enable registers, which are flip-flops that share the same clock and synchronous control signals.\n Synchronous control signals include synchronous load-enable, synchronous set, synchronous reset, and synchronous toggle.\n Synchronous load-enable registers are represented by a register with a feedback loop that maintains the same logic value through multiple cycles.\n Clock gating applied to synchronous load enable registers reduces the power needed when reloading the register banks.\n Figure 45 shows a simple register bank implementation using a multiplexer and feedback loop.\n Figure 45 Synchronous Load-Enable Register With Multiplexer Flip Flop Mux Control Logic Register Bank EN CLK DATA IN DATA OUT When the synchronous load enable signal (EN) is at logic state 0, the register bank is disabled.\n In this state, the circuit uses the multiplexer to feed the Q output of each storage element in the register bank back to the D input.\n When the EN signal is at logic state 1, the register is enabled, allowing new values to load at the D input.\n 286 Introduction to Clock Gating Feedback These feedback loops can unnecessarily use power.\n For example, if the same value is reloaded in the register throughout multiple clock cycles (EN equals 0), the register bank and its clock net consume power while values in the register bank do not change.\n The multiplexer also consumes power.\n Clock gating eliminates the feedback net and multiplexer shown in Figure 45 by inserting a gate in the clock net of the register.\n Note: While applying the clock-gating techniques, the tool considers generated clocks similar to defined clocks.\n The clock-gating cell selectively prevents clock edges, thus preventing the gated-clock signal from clocking the gated register.\n Figure 46 shows a latch-based clock-gating cell and the waveforms of the signals are shown with respect to the clock signal, CLK.\n Figure 46 Latch-Based Clock Gating Flip Flop Control Logic Register Bank Latch CLK ENCLK ENL EN CLK DATA IN DATA OUT CLK CLK EN ENL ENCLK The clock input to the register bank, ENCLK, is gated on or off by the AND gate.\n ENL is the enabling signal that controls the gating; it derives from the EN signal on the multiplexer shown in Figure 45.\n The register bank is triggered by the rising edge of the ENCLK signal.\n The latch prevents glitches on the EN signal from propagating to the register's clock pin.\n When the CLK input of the 2-input AND gate is at logic state 1, any glitching of the EN signal could, without the latch, propagate and corrupt the register clock signal.\n The latch eliminates this possibility because it blocks signal changes when the clock is at logic 1.\n 287 Introduction to Clock Gating Feedback In latch-based clock gating, the AND gate blocks unnecessary clock pulses by maintaining the clock signal's value after the trailing edge.\n For example, for flip-flops inferred by HDL constructs of rising-edge clocks, the clock gate forces the gated clock to 0 after the falling edge of the clock.\n By controlling the clock signal for the register bank, you can eliminate the need for reloading the same value in the register through multiple clock cycles.\n Clock gating inserts clock-gating circuitry into the register bank's clock network, creating the control to eliminate unnecessary register activity.\n Clock gating does the following: Reduces clock network power dissipation Relaxes datapath timing Reduces congestion by eliminating feedback multiplexer loops For designs that have large register banks, clock gating can save power and area by reducing the number of gates in the design.\n However, for smaller register banks, the overhead of adding logic to the clock tree might not compare favorably to the power saved by eliminating a few feedback nets and multiplexers."}
{"instruction": "How do I Signoff DRC Results Files", "input": "", "output": "The signoff_check_drc command writes its output files to the run directory, which is specified by the signoff.check_drc.run_dir application option (or the signoff_check_drc_run directory if you do not use this option).\n The following files are written to the run directory: The error data file By default, the error data generated by the signoff_check_drc command is saved in a file named signoff_check_drc.err, which is stored in the design library.\n To specify the name for the error data file, use the -error_data option.\n The error data shows child- 672 Performing Signoff Design Rule Checking Feedback level errors on only one of the cell instances, which makes it easier to identify lower- level errors.\n You can use the error data file to report or display the DRC violations in the error browser.\n For information about using the error browser, see Using the Error Browser.\n The IC Validator results files You can use the following IC Validator results files for debugging the signoff DRC results: block.LAYOUT_ERRORS This file contains details about the errors detected during the signoff_check_drc run.\n block.RESULTS This file contains a summary of the signoff_check_drc run results.\n signoff_check_drc.log This file contains a summary of the signoff_check_drc run environment.\n icv_config_out This file contains the paths to the top-level block and the cell libraries.\n icv_sdrc.conclude This file contains an error summary report.\n layer.map This file contains the layer mapping file generated by the signoff_check_drc command.\n signoff_check_drc.rc This file contains the IC Validator runset environment variables.\n./run_details directory This directory contains all the data generated by the IC Validator tool for the signoff DRC run.\n For more information about these files, see the IC Validator documentation."}
{"instruction": "How do I Querying Specific Message IDs", "input": "", "output": "To query specific information, warning, or error message IDs that occurred during the previous command step, you can use the check_error command.\n Follow these steps to set up and query the message IDs: 1.\n Specify the message IDs to query by using the global scope application option, shell.common.check_error_list fc_shell> set_app_options -name shell.common.check_error_list \\ -value {DES-001 CMD-005} shell.common.check_error_list {DES-001 CMD-005} 2.\n Use the link command as an example for the previous command step.\n fc_shell> link Error: Current block is not defined.\n (DES-001) 3.\n Query the specified message IDs that were issued during the link command step by using the check_error command.\n fc_shell> check_error -verbose {DES-001} The result shows that the DES-001 message ID was issued during the link command step.\n If none of the specified message IDs was issued, the check_error command returns 0.\n 284 Feedback"}
{"instruction": "How do I Deriving Pin Access Routing Guides", "input": "", "output": "When you reuse hard macros, such as IP blocks, at a smaller technology node, it can cause routability issues to the macro pins.\n You can use routing guides and blockages to enable access to the hard macro pins.\n To create these routing guides, which are referred to as pin access routing guides, and the associated blockages, use the derive_pin_access_routing_guides command.\n You must specify the following information: The hard macros around which to create the routing guides and routing blockages (the -cells option) The metal layers for which to create the routing guides and routing blockages (the -layers option) The width of the routing guides and blockages in the x- and y-directions (the -x_width and -y_width options) For each specified hard macro, the command creates routing guides to enable routing to the pins on the specified layers.\n In addition, the command creates metal blockages that surround the macro on the specified layers, with cutouts to allow pin access, and via blockages that cover the macro on the via layers adjacent to the specified metal layers.\n Vertical routing guides and blockages have the specified x-width.\n Horizontal routing guides and blockages have the specified y-width.\n By default, the command creates pin cutouts only in the preferred routing direction.\n To also create pin cutouts in the nonpreferred direction, use the -nonpreferred_direction option.\n To extend the pin cutouts beyond the metal blockages, use the -pin_extension option to specify the extension distance in microns.\n To enable proper routing to pins of different sizes, the command sets the is_rectangle_only_rule_waived attribute on the macro pins to true to waive the rectangle-only rule.\n For example, the following command creates the routing guides and blockages shown in Figure 100 fc_shell> derive_pin_access_routing_guides -cells myMacro \\ -layers {M2 M3} -x_width 0.6 -y_width 0.7 In the figure, the two red pins are on M2 and the green pin is on M3.\n The figure shows the routing guides created on both the M2 and M3 layers, the metal blockages created on the M3 layer, and the via blockage created on the V2 and V3 layers.\n The tool also creates metal blockages on the M2 layer, which have cutouts for the M2 pins, and via blockages on the V1 and V2 layers.\n 480 Routing Constraints Feedback Figure 100 Pin Access Routing Guides and Blockages If a hard macro already has pin access routing guides and their associated blockages, the command removes these existing objects and creates new routing guides and blockages.\n If you move a hard macro after deriving the pin access routing guides, you must regenerate the pin access routing guides.\n You cannot manually modify pin access routing guides."}
{"instruction": "How do I Supporting RedHawk-SC Customized Python Script Files", "input": "", "output": "RedHawk-SC Fusion provides application options and commands to read in user- customized python script files.\n The tool generates all design collaterals (including DEF, LEF, SPEF, TWF and PLOC) from the design library and adds them to the user-customized python script to run voltage drop analysis in a single iteration of analyze_rail.\n The user-customized python script file is supported in rail analysis with multiple rail scenarios, as well as other IR-driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n To use a customized python script file for RedHawk-SC Fusion rail analysis, 1.\n Set the type of script file to python fc_shell> set_app_options -name rail.generate_file_type -value python 2.\n Set the rail.generate_file_variables application option to specify the variables for generating the input files (including DEF, LEF, SPEF, TWF and PLOC files) to add to the user-customized python script file.\n You do not need to set this application option if the customized python script file uses the same values as in RedHawk-SC Fusion.\n DEF File LEF File SPEF File TWF File PLOC File Default name in fc_shell DEF LEF SPEF TWF PLOC Default variable name in RedHawk-SC Fusion def_files lef_files spef_files tw_files ploc For example, if you specify a test_def_file for the DEF variable to match with the DEF file specified in the customized python script file, set the following: fc_shell> set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files} 3.\n Create and specify rail scenarios for generating the necessary input files to add to the customized python script.\n Run the create_rail_scenario command to create a rail scenario and associate it with a design scenario in the current design.\n You can create multiple rail scenarios and associate them with the same scenario in the current design.\n Then run the set_rail_scenario -generate_file {LEF | TWF | DEF | SPEF | PLOC} command to specify the rail scenario and the type of input files to generate from the design library.\n 881 Preparing Design and Input Data for Rail Analysis Feedback Note: When running rail analysis using multicorner-multimode technology, you must create rail scenarios using the create_rail_scenario command before the set_rail_scenario command.\n The following example creates the T_low and T_high rail scenarios and generates input files for them: fc_shell> create_rail_scenario -name T_low -scenario func_cbest fc_shell> set_rail_scenario -name T_low -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py fc_shell> create_rail_scenario -name T_high -scenario func_cbest fc_shell> set_rail_scenario -name T_high -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py You can then use the customized.py file for multi-rail-scenario rail analysis or other IR- driven features, such as IR-driven placement or IR-driven concurrent clock and data optimization.\n Examples The following example uses a customized python script for multi-rail-scenario rail analysis on a grid system.\n #Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py 882 Preparing Design and Input Data for Rail Analysis Feedback set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} analyze_rail -rail_scenario {func.ss_125c func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for multi-rail-scenario rail analysis on a local machine.\n #Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_command {local} analyze_rail -rail_scenario {func.ss_125c func.ff_125c} The following example uses a customized python script for single-scenario rail analysis on a grid system.\n Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python.\n 883 Preparing Design and Input Data for Rail Analysis Feedback set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} analyze_rail -rail_scenario {func.ff_125c} \\ -submit_to_other_machine The following example uses a customized python script for IR-driven placement on a grid system.\n Required.\n Specify the below options to enable multi-rail-scenario rail analysis.\n set_app_options -list { rail.enable_new_rail_scenario true rail.enable_parallel_run_rail_scenario true #Required.\n Set the type of the script file to python.\n set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python.\n set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y \\ -cwd -j y -P bnormal -l mfree=16G} # Enable IR-driven placement before running clock_opt -from final_opto set_app_options -name opt."}
{"instruction": "How do I Assigning Nondefault Routing Rules to Nets", "input": "", "output": "The Fusion Compiler tool provides two commands for assigning nondefault routing rules to nets: set_clock_routing_rules This command assigns nondefault routing rules to clock nets before clock tree synthesis.\n During clock tree synthesis and optimization, the tool propagates the nondefault routing rules to the newly created clock nets.\n set_routing_rule This command assigns nondefault routing rules to signal nets and to clock nets after clock tree synthesis.\n The following topics describe how to assign nondefault routing rules to nets: Assigning Nondefault Routing Rules to Clock Nets Assigning Nondefault Routing Rules to Signal Nets Reporting Nondefault Routing Rule Assignments Assigning Nondefault Routing Rules to Clock Nets To assign a clock routing rule to a clock net, use the -rule option with the set_clock_routing_rules command.\n The specified rule must be a rule that you previously defined with the create_routing_rule command.\n To reset a clock routing rule to the default routing rule, use the -default_rule option.\n To change a clock routing rule, first reset it to the default routing rule and then use the -rule option after resetting the assignment to the default routing rule.\n 506 Routing Constraints Feedback By default, the set_clock_routing_rules command assigns the specified clock routing rule to all clock trees in the block.\n Table 31 shows the options used to restrict the routing rule assignment.\n Table 31 Restricting Clock Routing Rule Assignments To assign a nondefault routing rule to Use this option Specific clock trees -clocks clocks Nets connected to the clock root -net_type root Nets connected to one or more clock sinks -net_type sink Internal nets in the clock tree (all nets except the root and sink nets) -net_type internal Specific clock nets -nets nets Figure 107 shows the root, internal, and sink nets of a clock tree after clock tree synthesis.\n By default, the root-net routing rule is applied to all the single-fanout clock nets starting from the clock root up to the point where the clock tree branches out to a fanout of more than one.\n Internal-net routing rules are applied to the nets from this point until the sink nets.\n Figure 107 Root, Internal, and Sink Clock Net Types Sink nets Internal nets Root nets 200 sinks 200 sinks 200 sinks The following example specifies routing rules for the root, internal, and sink nets: fc_shell> set_clock_routing_rules -rules NDR1 -net_type root fc_shell> set_clock_routing_rules -rules NDR2 -net_type internal fc_shell> set_clock_routing_rules -rules NDR3 -net_type sink 2.\n You can use this option with the -clocks option to further restrict the assignment.\n This option is not valid with the -nets option.\n 507 Routing Constraints Feedback To specify a transitive fanout limit to use when identifying root nets, use the set_clock_tree_options -root_ndr_fanout_limit command.\n For example, to specify that any clock net with a transitive fanout of more than 300 be considered as a root net, use the following command: fc_shell> set_clock_tree_options -root_ndr_fanout_limit 300 Figure 108 shows the root, internal, and sink nets of the same clock tree when a transitive fanout limit of 300 is used for identifying the clock root nets.\n Figure 108 Using a Fanout Limit for Selecting Root Nets Sink nets Internal nets Root nets 200 sinks 200 sinks 200 sinks When calculating the transitive fanout of clock nets for the purpose of identifying root nets, the tool includes only the valid clock sinks; It does not include the ignore pins.\n If a net identified as a root net is less than 10 microns, the tool uses internal-net routing rules for that net.\n Note: Specifying a smaller value with the set_clock_tree_options -root_ndr_fanout_limit command increases the number of clock nets that are assigned the root-net routing rule, which can increase routing congestion.\n During clock tree synthesis and optimization, the tool also honors nondefault routing rules set by using the set_routing_rule command.\n However, the tool does not propagate these routing rules to any new clock nets it creates.\n If a net is assigned more than one nondefault routing rule, the tool uses the following priority to determine the effective routing rule: 1.\n Nondefault routing rule set by the set_routing_rule command 2.\n Net-specific clock routing rule set by the set_clock_routing_rules -nets command 508 Routing Constraints Feedback 3.\n Clock-specific clock routing rule set by the set_clock_routing_rules -clocks command 4.\n Global clock routing rule set by the set_clock_routing_rules command Assigning Nondefault Routing Rules to Signal Nets To assign a nondefault routing rule to a net, use the -rule option with the set_routing_rule command.\n The specified rule must be a rule that you previously defined with the create_routing_rule command.\n You must specify the nets to which to assign the nondefault routing rule.\n You can assign multiple nondefault routing rules to a net.\n To change the routing rule assignment for one or more nets, Use the -default_rule option to reset the nets to the default routing rule.\n To assign different nondefault routing rules to the nets, use the -rule option after resetting the nets to the default routing rule.\n Use the -no_rule option to remove all routing rules from the nets and allow the tool to automatically assign a routing rule to them.\n Use the -clear option to remove all routing rules and net-specific layer constraints from the nets.\n For example, to assign a nondefault routing rule called WideMetal to the CLK net, use the following command: fc_shell> set_routing_rule -rule WideMetal [get_nets CLK] To reset the routing rule for the CLK net to the default routing rule, use the following command: fc_shell> set_routing_rule -default_rule [get_nets CLK] Reporting Nondefault Routing Rule Assignments The Fusion Compiler tool provides commands to report the nondefault routing rules assigned by the set_routing_rule command and the clock routing rules assigned by the set_clock_routing_rules command.\n To report the nondefault routing rules assigned by the set_routing_rule command, use the -of_objects option with the report_routing_rules command.\n fc_shell> report_routing_rules -of_objects [get_nets *] To report the clock routing rule assignments, use the report_clock_routing_rules command.\n This command reports only the routing rules assigned by the set_clock_routing_rules command.\n 509 Routing Constraints Feedback"}
{"instruction": "How do I Example Script of Hierarchical Synthesis Using ETMs", "input": "", "output": "The following script shows an example of the hierarchical synthesis flow: # Specify reference libraries set REF_LIBS ${std_cell}.ndm lappend REF_LIBS ${block_design}_etm.ndm create_lib -tech ${TECH_FILE} -ref_libs $REF_LIBS ${DESIGN_NAME} # Read the RTL design analyze -format verilog [list $rtl_list] elaborate ${DESIGN_NAME} #ETM.ndm in ref_lib is used to link cell instances set_top_module ${DESIGN_NAME} # Load UPF for ETM cell instance load_upf ${block_design}.upf -scope cell_instance # Read test model for ETM cell instance read_test_model ${block_design}.mapped.ctl...\n compile_fusion -to initial_opto # Query commands # List all macro cell instances get_cells -hierarchical -filter \"is_hard_macro == true\" # ref view name is \"timing\" for cell instances bound to ETM get_attribute ${CELL} is_etm_moded_cell"}
{"instruction": "How do I Preparing Design and Input Data for Rail Analysis", "input": "", "output": "Before analyzing voltage drop and current density violations in a design using the RedHawk/RedHawk-SC Fusion capability, use the set_app_options command to specify the location of the libraries and the required input files.\n Table 66 lists the application options for specifying design and input data for running RedHawk/RedHawk-SC rail analysis within the Fusion Compiler environment.\n Table 66 Application Options for Specifying Design and Input Data Application Option Description rail.lib_files Specifies the library files in.lib format.\n For example, fc_shell> set_app_options \\ -name rail.lib_files \\ -value {test1.lib test2.lib} rail.tech_file Specifies the Apache technology file for performing PG extraction and PG electromigration analysis.\n For example, fc_shell> set_app_options \\ -name rail.tech_file \\ -value ChipTop.tech Specifies the dies that are included in detailed analysis.\n For example, fc_shell> set_app_options \\ -name rail.3dic_enable_die\\ -value {DIE1 true DIE2 true...} 877 Preparing Design and Input Data for Rail Analysis Feedback Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description Specifies user-defined Instance Power File (IPF) for providing power to pins.\n For example, fc_shell> set_app_options \\ -name rail.instance_power_file\\ -value {E1 FILE1 DIE2 FILE2...} rail.apl_files Specifies the Apache APL files, which contain current waveforms and intrinsic parasitics for performing dynamic rail analysis.\n For example, fc_shell> set_app_options \\ -name rail.apl_files -value \\ {cell.current current \\ cell.cdev cap} rail.switch_model_files Specifies the RedHawk switch cell model files for performing dynamic rail analysis.\n For example, fc_shell> set_app_options \\ -name rail.switch_model_files \\ -value {switch.model} rail.macro_models Specifies the macro model files.\n For example, fc_shell> set_app_options \\ -name rail.macro_models \\ -value {gds_cell1 mm_dir1 \\ gds_cell2 mm_dir2} rail.lef_files (Optional) Specifies a list of LEF files.\n When not specified, the tool generates one using the data in the design library.\n rail.def_files (Optional) Specifies a list of DEF files.\n When not specified, the tool generates one using the data in the design library.\n rail.pad_files (Optional) Specifies a list of pad location files.\n When not specified, you need to specify the ideal voltage sources by running the create_taps command.\n rail.sta_file (Optional) Specifies the static timing file (STA), which contains the final slew and delay information.\n When not specified, the tool generates the static timing window information using the data in the design library.\n rail.spef_files (Optional) Specifies a list of SPEF files, which contain the detailed parasitic resistive and capacitive loading data of the signal nets.\n When not specified, the Fusion Compiler tool generates the SPEF file using the data in the design library.\n 878 Preparing Design and Input Data for Rail Analysis Feedback Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.effective_resistance_ instance_file (Optional) Specifies the instance file, which lists the cell instances for effective resistance calculation.\n rail.generate_file_type (Optional) Specifies the type of the script file to generate for RedHawk Fusion or RedHawk-SC Fusion rail analysis.\n The available file types are: tcl (default): Generates the file in Tcl format.\n The default file name is set_user_input.tcl python : Generates the file in python format.\n The default file name is input_files.py.\n The python script file is supported only in RedHawk-SC Fusion rail analysis flow.\n This application option is required when you run the RedHawk-SC rail analysis with a customized python script file.\n For more information, see Supporting RedHawk-SC Customized Python Script Files Example: fc_shell> set_app_options \\ -name rail.generate_file_type -value python rail.generate_file_variab les This application option is supported in RedHawk-SC only.\n Specifies the preferred user variables when a customized python script file is used for RedHawk-SC rail analysis.\n This application option is required when the script contains non-standard collateral python variable names.\n See Supporting RedHawk-SC Customized Python Script Files for details.\n Supported file types are: LEF DEF SPEF TWF PLOC Example: fc_shell> set_app_options \\ -name rail.generate_file_variables -value \\ {PLOC ploc LEF lef_files DEF def_files \\ SPEF spef_files TWF tw_files} rail.enable_new_rail_scena rio (Optional) Enables RedHawk Fusion or RedHawk-SC Fusion rail analysis with multiple rail scenario.\n The default is false.\n See Running Rail Analysis with Multiple Rail Scenarios for details.\n rail.enable_parallel_run_r ail_scenario (Optional) Enables distributed RedHawk Fusion or RedHawk SC Fusion analysis within the analysis flow.\n 879 Preparing Design and Input Data for Rail Analysis Feedback Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.scenario_name (Optional) Specifies the scenario for RedHawk or RedHawk-SC Fusion rail analysis.\n The tool honors the specified design scenario for the IR-driven features in power integrity flow, such as IR-driven placement, IR-driven concurrent clock and data optimization, and IR-driven optimizationSee Running Rail Analysis with Multiple Rail Scenarios for details..\n rail.dump_icc2_results_st yle -value 2.0 Specifies how to load the results with the new Ansys map style."}
{"instruction": "How do I Defining Blockages That Allow Buffers Only", "input": "", "output": "To define a partial blockage that allows buffers only, specify the boundary, type ( -type allow_buffer_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that allows only the placement of buffers and inverters, with a cell density of 30 percent, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type allow_buffer_only -blocked_percentage 70 144 Specifying Physical Constraints for Placement and Legalization Feedback Note: Buffer-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Reporting the Metal Density", "input": "", "output": "To report the metal density information, run the signoff_report_metal_density command.\n 734 Inserting Metal Fill With IC Validator In-Design Feedback To calculate the metal density information for a metal layer, the tool requires the following information: The density rule for the layer The tool determines the density rule for each layer by using the following settings, in order of priority: 1.\n The setting of the _min_density parameter in the IC Validator parameter file specified by the signoff.report_metal_density.user_defined_options application option 2.\n The setting of the signoff.report_metal_density.min_density application option 3.\n The setting of the minDensity attribute in the DensityRule section of the technology file 4.\n 10 percent The grid sizes for the layer The tool determines the grid sizes for each layer by using the following settings, in order of priority: 1.\n The setting of the _min_density_window or _density_gradient_window parameter in the IC Validator parameter file specified by the signoff.report_metal_density.user_defined_options application option 2.\n The setting of the signoff.report_metal_density.density_window or signoff.report_metal_density.gradient_window_size application option 3.\n The setting of the windowSize attribute in the DensityRule section of the technology file 4.\n 50 microns For information about defining the metal density and density gradient rules in the technology file, including the windowSize attribute, see the Synopsys Technology File and Routing Rules Reference Manual By default, the signoff_report_metal_density command Uses the fill data for the metal density calculation To use the design view if its timestamp is newer than the fill data, set the signoff.report_metal_density.fill_view_data application option to read_if_uptodate To use the design view regardless of its timestamp, set the signoff.report_metal_density.fill_view_data application option to discard 735 Inserting Metal Fill With IC Validator In-Design Feedback Creates the density and gradient windows starting from the lower-left corner of the chip boundary using a step size of half the window size To change the starting point for creating the windows, use the -starting_point option with the signoff_report_metal_density command.\n To change the step size, set the signoff.report_metal_density.density_window_step application option or the _window_step_size parameter in the IC Validator parameter file specified by the signoff.report_metal_density.user_defined_options application option.\n If you specify both, the IC Validator parameter overrides the application option.\n Computes the metal density for the entire block To compute the metal density for specific regions, use the -coordinates option with the signoff_report_metal_density command.\n When you use this option, the command combines the specified regions when reporting the metal density; it does not report the metal density individually for each specified region.\n To specify the coordinates, use the following format: {{x } {x }...\n {x }} Note that there must be a space between each set of coordinates.\n Computes the metal density for each metal layer from the minimum routing layer to the maximum routing layer To compute the metal density for specific layers, use the -select_layers option with the signoff_report_metal_density command.\n Does not generate heat maps To generate heat maps to enable viewing of the metal density information in the GUI, set the signoff.report_metal_density.create_heat_maps application option to true.\n For information about viewing the heat maps, see Viewing Density Heat Maps in the GUI Writes the report files to a directory named signoff_report_metal_density_run under the current working directory To change the name of the IC Validator working directory, set the signoff.report_metal_density.run_dir application option.\n By default, the report files are named report_metal_density.txt and gradient_density_report.txt.\n To change the file names, use the -output option with the signoff_report_metal_density command.\n When you use this option, the density report has the specified file name, while the gradient density report adds a.gradient file extension.\n For example, if you specify - output density.rpt, the density report is named density.rpt and the gradient density report is named density.rpt.gradient.\n 736 Inserting Metal Fill With IC Validator In-Design Feedback The signoff_report_metal_density command uses the options that you specify to generate the command line to invoke the IC Validator tool.\n You can specify additional options for the IC Validator command line by setting the signoff.report_metal_density.user_defined_options application option.\n The string that you specify in this option is added to the command line used to invoke metal density reporting in the IC Validator tool.\n The Fusion Compiler tool does not perform any checking on the specified string.\n See Also Using an IC Validator Parameter File"}
{"instruction": "How do I Querying Routing Blockages", "input": "", "output": "To find routing blockages, use the get_routing_blockages command.\n For example, to get all the routing blockages in a block, use the following command: fc_shell> get_routing_blockages * To find the routing blockages for specific nets, use the -of_objects option to specify the nets of interest.\n For example, to find the routing blockages for the n1 net, use the following command: fc_shell> get_routing_blockages -of_objects [get_nets n1] To find the routing blockages in a specific location, use the get_objects_by_location -classes routing_blockage command."}
{"instruction": "How do I Clock-Gating Setup Condition", "input": "", "output": "To perform clock gating, the tool requires that the enable signal of the register bank is synchronous with its clock.\n This is the setup condition.\n For latch-based or integrated clock gating, the tool can insert clock gating irrespective of the enable signal's and the clock's clock domains.\n If the enable signal and the register bank reside in different clock domains, you must ensure that the two clock domains are synchronous and that the setup and hold times for the clock-gating cell meet the timing requirements.\n An exception exists for primary input ports that use a clock specified with the set_input_delay command.\n In this case, the input port is synchronous with the clock and the setup condition is true."}
{"instruction": "How do I Considering the Effects of Cell Pins During Placement", "input": "", "output": "When you specify a technology node setting of 7+ s5, or s4 by using the set_technology -node command, you can specify that the tool uses a technology- specific pin-cost model during placement by setting the place.coarse.pin_cost_aware application option to true.\n The default is false.\n When you enable this feature, during placement, the tool tries to improve pin accessibility by using a technology-specific model to predict the routing resources required to access each pin.\n For all other technology nodes, you can control the maximum local pin density during placement by setting the place.coarse.pin_density_aware application option to true The default is false Table 11 Settings for Controlling the Effects of Pins During Placement set_technology -node place.coarse.\n pin_cost_aware place.coarse.\n pin_density_aware The tool does this 7+ s5, or s4 true true or false Performs technology-specific pin-cost-aware placement 7+ s5, or s4 false true Performs pin-density-aware placement 7+ s5, or s4 false false Does not consider the effects of cell pins during placement Any other setting true or false true Performs pin-density-aware placement 157 Specifying Placement Settings Feedback Table 11 Settings for Controlling the Effects of Pins During Placement (Continued) set_technology -node place.coarse.\n pin_cost_aware place.coarse.\n pin_density_aware The tool does this Any other setting true or false false Does not consider the effects of cell pins during placement"}
{"instruction": "How do I Comparing Libraries", "input": "", "output": "To compare libraries, perform the following steps: 1.\n Create a collection of the libraries you want to analyze, which is known as a libset, by using the create_libset command, as shown in the following example: fc_shell> create_libset -name myLibset -libs {abcd1.db abcd2.db} When you perform library analysis, you can specify the libset name, instead of specifying a list of libraries.\n In addition, the tool uses the libset name, instead of using a list of the library names, when it generates reports, plots, and so on during analysis.\n You can include a cell library in more then one libset.\n 2.\n Set up the library analysis environment by using the create_environment command.\n The create_environment command associates a predefined libset with a process label, process number, voltage, and temperature, which is then used for analyzing the libraries.\n You can specify the process label, process number, voltage, and temperature of the analysis environment by using one of the following methods: Specify the process label, process number, voltage, and temperature values by using the -ppvt option, as shown in the following example: fc_shell> create_environment -name env1 -libset myLibset \\ -ppvt {{SS1p, 1.0, 0.6, 125}} 93 Analyzing Libraries Feedback Specify a predefined operating condition from the reference library by using the -op_conds option, as shown in the following example: fc_shell> create_environment -name env2 -libset myLibset \\ -op_conds SS1p6125 Specify corners from which to infer the process label, process number, voltage, and temperature values by using the -corners option, as shown in the following example: fc_shell> create_environment -name env3 -libset myLibset \\ -corners nworst Specify that the tool infers the process label, process number, voltage, and temperature values from the scenario and UPF associated with the current design by using the -auto_infer_design option, as shown in the following example: fc_shell> create_environment -name env4 -libset myLibset \\ -auto_infer_design 3.\n (Optional) Specify a naming convention for library cells and perform lexical classification by using lexical attributes.\n A library cell naming convention can help the tool identify cell families in the subsequent steps of the flow.\n For example, assume a cell in your library is named AND2D4WSULVT.\n This name is the concatenation of the AND2, D4, WS, and ULVT strings, which represent cell characteristics that are associated to a lexical attribute as shown in the following table: Table 3 Lexical Attributes for the Naming Convention of an Example Library Column Lexical Attribute Allowed Pattern Values for Example Cell lexical_cell_prefix_name [a-zA-Z0-9]* AND2 lexical_drive1_name D[0-9]* D4 lexical_well_substrate_bias_arch itecure WS WS lexical_device_threshold_voltage ULVT | SVT | LVT | MVT ULVT 94 Analyzing Libraries Feedback You can specify the naming convention for this library by using the set_lib_cell_naming_convention command, as shown in the following example: fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 1 -pattern {[a-zA-Z0-9]*} -attribute \"lexical_cell_prefix_name\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 2 -pattern {D[0-9]*} -attribute \"lexical_drive1_name\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 3 -pattern {WS} -attribute \"lexical_well_substrate_bias_architecure\" fc_shell> set_lib_cell_naming_convention -library $lib \\ -column 4 -pattern {ULVT|SVT|LVT|MVT} -attribute \"lexical_device_threshold_voltage\" Note: For a list of all the predefined lexical attributes, see the man page for the set_lib_cell_naming_convention command.\n After you specify the naming convention, perform lexical classification, by using the classify_lib_cell_attributes command as shown in the following example: fc_shell> classify_lib_cell_attributes -libset myLibset To report the lexical classification results, use the report_lib_cell_classification_attributes command.\n To report the library cells which are not lexical classified under the given naming convention, use the report_lexical_unclassified_lib_cells command.\n If there are lexically unclassified cells, specifies addition naming conventions and rerun lexical classification.\n 4.\n (Optional) Exclude specific cells from library analysis by using the set_use_for_library_analysis command.\n By default, the tool excludes physical-only cells during library analysis.\n However, you can exclude additional cells, such as library cells with a dont_use setting, as shown in the following example: fc_shell> set exclude_cells [filter_collection [get_lib_cells $libs/*] \"dont_use == true\"] fc_shell> set_use_for_library_analysis $exclude_cells false To report the cells that are excluded, use the report_lexical_ignored_lib_cells command.\n 5.\n Identify all library cell families by using the identify_lib_cell_families command.\n 95 Analyzing Libraries Feedback To report the tool-identified library cell families, use the report_lib_cell_families -all_initial command.\n To manually define library cell families, use the define_lib_cell_family command, and to report these user-defined cell families, use the report_lib_cell_families -all_userdef command.\n 6.\n Analyze the libraries by using the run_library_analysis command, as shown in the following example: fc_shell> run_library_analysis -name myLibset_run1 -environment env1 The name of the environment you specify with the -environment option must correspond to an environment you previously created by using the create_environment command.\n 7.\n Compare libraries by using the compare_libraries command.\n When doing so, you must specify the two libraries you want to compare by using the -ref_lib and -target_lib options.\n In addition, you must specify the name of the library analysis runs, performed by using the run_library_analysis command in the previous step, for each of these libraries.\n To do so use the -ref_lib_analysis and -target_lib_analysis options, as shown in the following example: fc_shell> compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa -verbose -plot When comparing libraries, you might encounter the following situations related to name matching between the cells of the reference and target libraries: The cell names in the reference and target libraries can be an exact match, as in the case when it is two different versions of the same library.\n If so, additional lexical classification is not required.\n The reference and target libraries can have the same naming convention, except less lexical attributes in one library.\n For example, assume a cell named ND2D1SVT in the reference library matches a cell named ND2D1 in the target library.\n In this case, the target library cell names do not contain a lexical_device_threshold_voltage attribute, as shown in the following table.\n Table 4 Reference and Target Library Lexical Attribute Differences Lexical Attribute Reference Library Target Library lexical_cell_prefix_name ND2 ND2 lexical_drive1_name D1 D1 96 Analyzing Libraries Feedback Lexical Attribute Reference Library Target Library lexical_device_threshold_voltage SVT In this situation, you should ignore the lexical_device_threshold_voltage attribute when comparing the two libraries.\n To do so, use the following application option settings before you run the compare_libraries command: fc_shell> set_app_options -name libra.complib.match_full_cell_name -value false fc_shell> set_app_options -name libra.complib.match_lexical_device_threshold_voltage -value false fc_shell> compare_libraries -ref_lib $rvt_lib -ref_lib_analysis sa \\ -target_lib $lvt_lib -target_lib_analysis sa -verbose -plot Note: For a complete list of application options you can use to control name matching during library comparison, see the man page for the compare_libraries command.\n The reference and target libraries can have a similar naming convention, but the lexical attributes values might not identical.\n For example, assume a cell named ND2D1SVT in the reference library matches a cell named nand2_svth_x1 in the target library.\n In this case, the reference and"}
{"instruction": "How do I Setting Constraints of Variant Cell", "input": "", "output": "To set the constraints of variant cell: 1.\n Use the set_repeater_group_constraints -type variant_cell_swapping command to set the variant for cell swapping.\n 2.\n Use the report_repeater_group_constraints command to view the report of the repeater group constraint settings, after setting the variant for cell swapping.\n The report provides the Track pattern of the variant cell group Variant site ids Honor cell group not sharing timing First track alignment 3.\n Use the remove_repeater_group_constraints command to remove the constraints and reset the settings based on the report."}
{"instruction": "How do I Defining Gas Stations", "input": "", "output": "Gas stations are small voltage areas that are created for the purpose of minimizing the use of dual-rail buffers on physical feedthrough paths.\n Only single-rail repeaters are allowed in gas stations, and only optimization steps can add cells to gas stations.\n You create gas stations by using the create_voltage_area command during the design planning stage.\n The tool recognizes gas stations automatically and uses them by trading off the cost of a routing detour with the cost of using a dual-rail cell.\n Use the -nwell and -pwell options of the create_voltage_area command to specify n-well and p-well supply nets for a voltage area.\n Defining well supplies for gas station voltage areas provides flexibility for using gas stations for different design styles.\n If you do not use these options for a voltage area, the well bias values are assumed to be the same as the domain supply values.\n The report_voltage_areas command lists the n-well and p-well supply nets regardless of whether they are explicitly set."}
{"instruction": "How do I Adding Leaf Cells", "input": "", "output": "To add leaf cells, including physical only cells, to a relative placement group, use the -cells option with the add_to_rp_group command.\n Specify the column and row position within the relative placement group at which to add the cell by using the -column and -row options.\n In a relative placement group, a leaf cell can occupy multiple column positions or multiple row positions, which is known as leaf cell straddling.\n To specify the number of columns and rows the cells occupies, use the -num_columns and -num_rows options respectively.\n If you do not set these options, the default is 1 for both the number of columns and rows.\n For example, to add a leaf cell that occupies two columns and one row at position (0,0), use fc_shell> add_to_rp_group rp1 -cells U23 \\ -column 0 -row 0 -num_columns 2 -num_rows 1 Straddling is for leaf cells only, and not for hierarchical groups or blockages.\n 785 Adding Objects to a Group Feedback"}
{"instruction": "How do I Performing Design Analysis", "input": "", "output": "Use the reports generated by Fusion Compiler to analyze and debug your design.\n You can generate reports before and after you compile your design.\n Generate reports before compile to check that you have set attributes, constraints, and design rules properly.\n Generate reports after compile to analyze the results and debug your design.\n This section includes the following topics: Reporting Commands and Examples Measuring Quality of Results Comparing QoR Data Reporting Logic Levels in Batch Mode Querying Specific Message IDs"}
{"instruction": "How do I Applying Required Settings for Improving Specific QoR Metrics", "input": "", "output": "To apply tool settings required for improving specific QoR metrics, use the set_qor_strategy -stage synthesis command.\n To specify the QoR metrics to improve, use the -metric option.\n To optimize the block for the best Timing, use the timing setting Leakage power and timing, use the leakage_power setting Total power and timing, use the total_power setting.\n To further improve total power, at the expense of runtime, you can use the -mode extreme_power option, with the -metric total_power option.\n To specify a target mode for the design flow, use the -mode option.\n The supported values for this option are: balanced, which is the default mode that optimizes the design for the target metrics specified with the -metric option.\n early_design, which is suitable for the early stages of the design flow, when the emphasis is on short turnaround time for prototyping purposes.\n With this mode, you can reduce runtime at the expense of QoR.\n extreme_power, which is recommended for further improvement of total power at the expense of runtime.\n This mode should only be specified along with the -metric leakage_power or -metric total_power option.\n If you specify this mode with the -metric timing option, the tool ignores the specified mode setting and uses the balanced mode.\n 210 Applying Mega-Switch Command Settings Feedback When you use this command, the tool applies application option settings that affect synthesis, optimization, placement, legalization, clock tree synthesis, routing, extraction, and timing analysis.\n To review the required setting, use one of the following methods: Generate a Tcl script that contains the settings by using the -output option Report the settings by using the -report_only option Report only the settings that are not set to their required values by using the -diff_only option 211 Feedback"}
{"instruction": "How do I Merging Voltage Area Shapes", "input": "", "output": "To merge the voltage area shapes into a minimum set of disjoint shapes, use the -merge_regions option with the create_voltage_area create_voltage_area_shape or set_voltage_area command.\n When you use the create_voltage_area -merge_regions command, the merges the shapes specified with the -region option.\n When you use the create_voltage_area_shape -merge_regions command, the merges the shape specified with the -region option and the existing shapes of the specified voltage area.\n When you use the set_voltage_area -merge_regions command, the tool merges all existing shapes of the specified voltage area.\n The tool merges the voltage area shapes based on their stacking order.\n By default, the stacking order is the order in which you define the shapes, with the last shape defined on top.\n The merged shape replaces the top shape of a set of abutting or overlapping shapes; the other shapes in the set are removed and are no longer associated with the voltage area.\n 121 Setting Up Multivoltage Designs Feedback For example, assume that you use the following command to create a voltage area comprising three rectangle shapes, as shown on the left side of Figure 14 fc_shell> create_voltage_area -power_domains {PD1} \\ -region { {{0 0} {10 10}} {{10 0} {30 10}} {{15 5} {35 15}} } {PD1} fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_1 VOLTAGE_AREA_SHAPE_2 VOLTAGE_AREA_SHAPE_3} After you use the -merge_regions option to merge these shapes, the voltage area consists of a single rectilinear shape, as shown on the right side of Figure 14.\n The merged voltage area shape is named VOLTAGE_AREA_SHAPE_3, which was the last voltage area shape defined when the voltage area was created.\n fc_shell> set_voltage_area PD1 -merge_regions Information: Merging abutted and overlapping shapes in voltage_area 'PD1'.\n (NDMUI-154) fc_shell> get_voltage_area_shapes -of_objects PD1 {VOLTAGE_AREA_SHAPE_3} Figure 14 Merging Voltage Area Shapes To report the stacking order of the voltage area shapes, use the report_voltage_areas -verbose command.\n To modify the stacking order of the voltage area shapes, use the set_voltage_area_shape command, as described in Modifying the Stacking Order"}
{"instruction": "How do I Setting the Routing Constraints", "input": "", "output": "You can set routing constraints for secondary power and ground pin routing in the same way as for regular signal routing.\n For example, you can set constraints by Defining the minimum and maximum routing layers by using the set_routing_rule command For more information about using the set_routing_rule command, see Specifying Net-Specific Layer Constraints Specifying the preferred pin connections by setting the route.common.single_connection_to_pins and route.common.connect_within_pins_by_layer_name application options For example, to require a single connection to the secondary power and ground pins and require that the M1 connections use vias contained within the pin shapes, use the following command: fc_shell> set_app_options \\ -name route.common.single_connection_to_pins \\ -value standard_cell_pins fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_standard_cell_pins}} Defining the maximum number of power or ground pins in a cluster by setting the route.common.number_of_secondary_pg_pin_connections application option A cluster is a set of connected secondary power or ground pins that has one connection to a PG strap or ring.\n By default, the value of this option is 0, which means that there is no limit on the number of secondary power or ground pins in a cluster.\n For example, to connect all secondary power and ground pins directly to a PG strap or ring, use the following command: fc_shell> set_app_options \\ -name route.common.number_of_secondary_pg_pin_connections \\ -value 1 523 Routing Secondary Power and Ground Pins Feedback Defining a nondefault routing rule for secondary power and ground pin routing For example, to define a nondefault routing rule named wideSVDD for wide M1 and M2 and set the nondefault routing rule on the VDD2 net, to which the secondary power and ground pins are connected, use the following commands: fc_shell> create_routing_rule wideSVDD -widths { M1 0.3 M2 0.3 } fc_shell> set_routing_rule -rule wideSVDD {VDD2} For more information about using nondefault routing rules, see Using Nondefault Routing Rules By default, the constraints apply to both the secondary power and ground connections and the tie-off connections.\n To separate these connections so that you can set constraints only for the secondary power and ground connections, set the route.common.separate_tie_off_from_secondary_pg application option to true"}
{"instruction": "How do I Pin-Trunk Offset", "input": "", "output": "The custom.route.bus_pin_trunk_offset application option changes the default spacing between the bus trunk and the bus bit pins."}
{"instruction": "How do I Command", "input": "", "output": "By default, the tool performs leakage power optimization during compile.\n To produce optimal leakage power optimization, use libraries with multithreshold voltage group cells.\n To set up leakage optimization, 1.\n Enable at least one scenario for leakage power by using the set_scenario_status -leakage_power true command.\n For example, fc_shell> set_scenario_status -leakage_power true SC1 If the block has multiple scenarios enabled for leakage power, the tool uses the worst- case leakage value of all the specified scenarios.\n 2.\n Set the threshold_voltage_group attribute on the reference library cells.\n For example, fc_shell> set_attribute [get_lib_cells -quiet lib1_name/*] \\ threshold_voltage_group HVT 3.\n Set the threshold_voltage_group attribute to one of the three built-in threshold voltage group types: high, normal, or low threshold voltage.\n 189 Setting Up for Power-Related Features Feedback If there are more than three threshold-voltage groups, you should group them into the three voltage group types as follows: fc_shell> set_threshold_voltage_group_type \\ -type high_vt {HVT HVTX} fc_shell> set_threshold_voltage_group_type \\ -type low_vt {LVT LVTX} fc_shell> set_threshold_voltage_group_type \\ -type normal_vt {RVT RVTX}"}
{"instruction": "How do I Reporting Cell Spacing Constraints", "input": "", "output": "To report the cell spacing rules, use the report_spacing_rules comandcomandsreport_spacing_rules report_placement_spacing_rules command.\n This command reports the cell spacing labels defined in the current session, the library cells (and their sides) to which they apply, and the rules defined for them."}
{"instruction": "How do I Deriving Clock Tree Exceptions From Ideal Clock Latencies", "input": "", "output": "If you have set ideal clock latencies for specific sinks in your design, you can use the derive_clock_balance_points command to convert these ideal latency settings to clock tree exceptions.\n The derive_clock_balance_points command converts ideal latencies specified with the set_clock_latency command on clock sink pins to set_clock_balance_points commands.\n Use the derive_clock_balance_points command before clock tree synthesis, when the design has ideal clocks.\n By default, the derive_clock_balance_points command Generates balance point constraints for all ideal primary clocks of all active scenarios that are enabled for setup analysis, hold analysis, or both.\n It does not generate balance points for generated clocks.\n To generate the balance points for Specific primary clocks, use the -clocks option.\n All active scenarios of specific corners, use the -corners option.\n Calculates a reference latency for each primary ideal clock, which is the sum of the ideal source and network latency specified on the clock with the set_clock_latency command.\n To specify a different reference latency value, use the -reference_latency option.\n Applies the derived clock balance point constraints to the design.\n To generate an output file containing set_clock_balance_points commands, instead applying it to the design, use the -output option.\n Balance points that the tool derives are clock and corner specific.\n Ensure that appropriate set_clock_latency constraints are set for all clocks for all modes used for clock tree synthesis in at least the worst corner.\n The tool uses the following formula to derive the delay values for the corresponding set_clock_balance_points commands: (Clock balance point delay value at the sink) = (Reference latency of the clock) - (Total ideal clock latency at the sink) The total ideal clock latency at the sink is the sum of the source latency of the clock and the ideal network latency for the sink.\n 351 Defining the Clock Trees Feedback For example, assume you have the following timing constraint settings: fc_shell> set_clock_latency -source 0.5 [get_clocks clk] fc_shell> set_clock_latency 1.0 [get_clocks clk] fc_shell> set_clock_latency 1.5 [get_pins reg1/CK] fc_shell> set_clock_latency 0.5 [get_pins reg2/CK] If you run the derive_clock_balance_points command, the tool derives the following clock balance point constraints: fc_shell> set_clock_balance_points -delay -0.5 \\ -balance_points [get_pins reg1/CK] -clock clk -corners worst fc_shell> set_clock_balance_points -delay 0.5 \\ -balance_points [get_pins reg2/CK] -clock clk -corners worst To avoid conflicts, do not manually apply any clock balance points for a clock that you derive balance points with the derive_clock_balance_points command."}
{"instruction": "How do I Optimizing Pin Access During Legalization", "input": "", "output": "For advanced technology nodes, to improve the routability of areas with high pin densities by redistributing the cells, enable pin optimization during legalization by setting the place.legalize.optimize_pin_access_using_cell_spacing application option to true"}
{"instruction": "How do I Specifying Switching Probability for Supply Nets", "input": "", "output": "The leakage power of a block is scaled based on the switching probability of its supply nets, which represents the fraction of time a supply net is in the on state.\n You can specify the switching probability for one or more supply nets by using the set_supply_net_probability -static_probability command.\n By default, the switching probability is applied to the current scenario and the corresponding mode and corner.\n To specify modes, corners, or scenarios in which to apply the setting, use the -modes -corners, or -scenarios option.\n To get the switching probability of a supply net, use the get_supply_net_probability command, and to reset the value, use the reset_supply_net_probability command.\n By default, the tool propagates supply net activity through power switches and determines the static probability of the switched supply net based on the UPF power switch constraint.\n For example, consider the following UPF power switch constraint: create_power_switch my_switch \\ -output_supply_port {vout VDDS} \\ -input_supply_port {vin VDD} \\ -control_port {ms_sel ctrl1} \\ -control_port {ms_ctrl ctrl2} \\ -on_state {on vin {ms_ctrl &&!ms_sel}} 188 Setting Up for Power-Related Features Feedback The tool derives the static probability of the supply net named VDDS, which is connected to the output of the power switch, based on the probability of the power switch being on This is derived based on the following: The Boolean function specified with the -on_state option, which is ms_ctrl &&!\n ms_sel, and the switching activity (static probability) of the nets connected to the corresponding control ports, which are nets named ctrl1 and ctrl2.\n The switching probability of the supply net connected to the input supply port specified with the -on_state option, which is the supply net named VDD.\n The following application options control whether dynamic and leakage power are scaled based on the supply switching activity: The power.scale_dynamic_power_at_power_off option controls whether dynamic power is scaled.\n The default is false (no scaling).\n The power.scale_leakage_power_at_power_off option controls whether leakage power is scaled.\n The default is true (scaling is performed)."}
{"instruction": "How do I Reading Designs Using the -autoread Option", "input": "", "output": "To enable the tool to automatically read a list of RTL files, specify the -autoread option with the analyze command, as shown in the following example.\n When this option is specified, the RTL language used to analyze the RTL files is automatically determined by the file name extension.\n To control the file name extensions, use the following application options: hdlin.autoread.verilog_extensions hdlin.autoread.sverilog_extensions hdlin.autoread.vhdl_extensions, and hdlin.autoread.exclude_extensions set DESIGN_NAME top analyze -autoread -top ${DESIGN_NAME} ${RTL_FILE_LIST} elaborate ${DESIGN_NAME} elaborate -hdl_library TOP_HDL_LIB top set_top_module ${DESIGN_NAME} 100 Reading the Design Feedback"}
{"instruction": "How do I Performing Real Metal Fill Extraction", "input": "", "output": "To enable metal fil extractionreal real metal fill extraction, 1.\n Associate non-emulation TLUPlus files with the timing corners by using the set_parasitic_parameters command, as described in the Fusion Compiler Timing Analysis User Guide 2.\n Enable real metal fill extraction by using the following command: fc_shell> set_extraction_options \\ -real_metalfill_extraction floating For more information about performing extraction in the Fusion Compiler tool, see the Fusion Compiler Timing Analysis User Guide 741 Automatically Fixing Isolated Vias Feedback"}
{"instruction": "How do I Specifying a Cell Name Prefix for Optimization", "input": "", "output": "You can specify a name prefix for the cells added on the data nets during optimization by using the opt.common.user_instance_name_prefix application option.\n The following example specifies a name prefix of CF_ for the cells added on the data nets during the compile_fusion command CO_ for the cells added on the data nets during the clock_opt command RO_ for the cells added on the data nets during the route_opt command fc_shell> set_app_options \\ -name opt.common.user_instance_name_prefix -value \"CF_\" fc_shell> compile_fusion fc_shell> set_app_options \\ -name opt.common.user_instance_name_prefix -value \"CO_\" fc_shell> clock_opt fc_shell> set_app_options \\ -name opt.common.user_instance_name_prefix -value \"PO_\" fc_shell> route_opt To specify a name prefix for the cells added on the clock network during clock tree synthesis, use the cts.common.user_instance_name_prefix application option, as described in Defining a Name Prefix for Clock Cells"}
{"instruction": "How do I Shielding Nets", "input": "", "output": "Zroute shields routed nets net shieldingshielding nets by generating shielding wires that are based on the shielding widths and spacing defined in the shielding rules.\n In addition to shielding nets on the same layer, you also have the option to shield one layer above and one layer below.\n Shielding above or below the layer is called coaxial shielding Figure 116 shows an example of coaxial shielding.\n Coaxial shielding provides even better signal isolation than same-layer shielding, but it uses more routing resources.\n Figure 116 Coaxial Shielding You can perform shielding either before or after signal routing.\n Shielding before signal routing, which is referred to as preroute shielding, provides better shielding coverage but can result in congestion issues during signal routing.\n Preroute shielding is typically used to shield critical clock nets.\n Shielding after signal routing, which is referred to as postroute shielding, has a very minimal impact on routability, but provides less protection to the shielded nets.\n 539 Shielding Nets Feedback Figure 117 shows the Zroute shielding flow, which is described in the topics that follow.\n Figure 117 Zroute Shielding Flow"}
{"instruction": "How do I Reading DEF Files", "input": "", "output": "To read the floorplan information from a DEF file, use the read_def command.\n fc_shell> read_def block.def Note: When possible, use DEF v5.8 or later, as this version supports more types of physical objects and obstructions than previous versions.\n By default, the read_def command Annotates the floorplan information onto the current block To annotate the information onto a different block, use the -design option to specify the block name.\n Preserves the existing floorplan information In incremental mode, The placement area is imported based on the current core area and site rows in the DEF files Physical constraints that can have only one value are overwritten by the value from the latest DEF file; for example, port location and macro location are overwritten.\n Physical constraints that can have accumulated values are recomputed; that is, core area can be recomputed based on the existing value and the site row definitions in the latest DEF file.\n Placement keepouts from different DEF files are accumulated and the final keepout geometry is computed internally during synthesis.\n To remove the existing floorplan information before annotating the floorplan information from the DEF file, use the -no_incremental option.\n In this mode, the placement area is imported based on the site rows in the DEF files.\n Uses rule-based name matching for macros and ports 104 Importing the Floorplan Information Feedback Rule-based name matching automatically resolves name differences by using the tool's intelligent name matching capability.\n By default, when rule-based name matching is enabled, the following characters are considered equivalent: Hierarchical separators { / _.\n } For example, a cell named a.b_c/d_e is automatically matched with the string a/b_c.d/e in the DEF file.\n Bus notations { [ ] __ ( ) } For example, a cell named a [4] [5] is automatically matched with the string a_4__5_ in the DEF file.\n To disable rule-based name matching and require exact name matches between the DEF file and the block, set the file.def.rule_based_name_matching application option to false For more information, see \"Rule-Based Name Matching\" in the Fusion Compiler Data Model User Guide Ignores any objects in the DEF file that do not exist in the block, except for PG objects To allow new non-PG objects to be created from the DEF file, use the -add_def_only_objects option to specify the types of objects to create.\n Specify one or more of the following keywords: cells The tool creates the cells that exist only in the DEF file and connects their power and ground pins as defined in the DEF file; it does not connect the signal, clock, or tie pins even if these connections are defined in the DEF file.\n The tool also does not create new hierarchical cells; any hierarchy specified in the DEF file must already exist in the block.\n nets The tool creates the signal, clock, and tie nets that exist only in the DEF file and connects them to the ports specified in the DEF PINS section; it does not connect the nets to any other ports or pins in the netlist even if these connections 105 Importing the Floorplan Information Feedback are defined in the DEF file.\n The tool does not create new hierarchical nets; any hierarchy specified in the DEF file must already exist in the block.\n ports The tool creates the signal, clock, and tie ports that exist only in the DEF file and connects them to the nets specified in the DEF PINS section.\n all The tool creates the non-PG cells, nets, and ports that exist only in the DEF file, as if you had specified cells nets, and ports"}
{"instruction": "How do I Mapping Sequential Elements Exactly as Described in RTL", "input": "", "output": "To specify that the tool maps sequential elements exactly as described in the RTL, set the compile.seqmap.exact_map application option to true.\n When this feature is enabled, the tool disables mapping to sequential library cells with inverted outputs or unused ports."}
{"instruction": "How do I Clock-Gate Multilevel Expansion", "input": "", "output": "It is difficult to determine the optimum number of clock-gate levels manually.\n The Fusion Compiler tool can analyze all clock gates and insert additional clock gates to take advantage of shared enable signals.\n Inserting additional clock gates might improve power, area, or other metrics, depending on the design.\n If six or more clock gates share an enable signal, the tool inserts an additional level of clock gates.\n The new clock gates are then considered for further level expansion.\n As a result, the tool might insert multiple levels of clock gates during this operation.\n To allow the tool to expand the number of clock-gate levels, set the compile.clockgate.enable_level_expansion application option to true (the default is false ) and set the compile.clockgate.max_number_of_levels application option to a nonzero value (the default is 0).\n In this case, the tool adds clock gates until either of the following conditions is met: All common enable signals are identified and used for multilevel clock-gate expansion.\n The user-specified maximum number of clock-gate levels is reached.\n The tool names a newly-inserted clock gate as follows, based on the status of the set of clock gates whose enable functions are modified by the new clock gate: If at least one of the clock gates is a tool-inserted clock gate, the base name is clock_gate_ml.\n The name is appended with the register base name, similar to the naming convention for other tool-inserted clock gates.\n If all of the clock gates are preexisting clock gates, the tool uses the name of the preexisting clock gate with the largest fanout and appends _ml_pe The compile.clockgate.max_number_of_levels application option specifies the maximum number of allowed clock-gate levels.\n The default is 0, which allows an infinite number of levels.\n However, to use the clock-gate level expansion capability, you must set this application option to a nonzero value (in addition to setting the compile.clockgate.enable_level_expansion application option to true ).\n If you specify clock-gate level expansion, but the maximum number of allowed levels is low, the expansion operation cannot take full advantage of the tool's ability to analyze common enable signals.\n To enable or disable clock-gate level expansion for specific clock gates, use the set_clock_gate_transformations -expand_levels command.\n 310 Controlling the Number of Clock-Gate Levels Feedback The following usage notes apply: New clock gates inherit the constraints set by the set_clock_gate_transformations set_clock_gate_style set_dont_touch set_size_only set_lib_cell_purpose and set_boundary_optimization commands.\n Clock-gate latency estimations are updated after the insertion operation.\n When the insertion operation modifies the enable signal of a clock gate, the gate retains its original designation of being either preexisting or tool-inserted.\n Self-gating is restricted from adding another clock-gate level if the maximum number of levels is already reached.\n Integrated clock gates inside multibit cells are counted as part of the clock-gate level count.\n However, they are not candidates for clock-gate level expansion.\n New clock gates do not inherit timing exceptions."}
{"instruction": "How do I Controlling the Tiling Within Relative Placement Groups", "input": "", "output": "To control the tiling of objects within a relative placement group, use the set_rp_group_options -tiling_type command with the settings shown in the following table.\n Table 58 Controlling Placement With the set_rp_group_options -tiling_type Command To do this Use this setting Tile objects in a bit-slice pattern and preserve both the row and column alignment.\n The height of a row is determined by the tallest object in the row The width of a column is determined by the widest object in the column bit_slice (Default) Horizontally compress the objects in each row and maintain row alignment.\n horizontal_compression Vertically compress the objects in each column and preserve the column alignment vertical_compression 800 Specifying Options for Relative Placement Groups Feedback Figure 180 Bit-Slice Placement Versus Horizontal or Vertical Compression Bit-slice placement Vertical compression Horizontal compression The setting of the -tiling_type option is not propagated from a parent group to child groups."}
{"instruction": "How do I Controlling Mapping and Optimization", "input": "", "output": "The following topics describe how you can customize and control the mapping and optimization that is performed during the initial_map logic_opto, and initial_drc stages of the compile_fusion command: Ungrouping or Preserving Hierarchies During Optimization Controlling Boundary Optimization Controlling Datapath Optimization Controlling MUX Optimization Controlling Sequential Mapping Controlling Register Replication Controlling Register Merging 217 Controlling Mapping and Optimization Feedback Selectively Removing or Preserving Constant and Unloaded Registers Reporting Cross-Probing Information for Optimized Registers Controlling High-Fanout-Net Synthesis"}
{"instruction": "How do I Analyzing the Clock Tree Results", "input": "", "output": "After synthesizing the clock trees, analyze the results to verify that they meet your requirements.\n Typically the analysis process consists of the following tasks: Analyzing the clock tree QoR (as described in Generating Clock Tree QoR Reports Analyzing the clock tree timing (as described in Analyzing Clock Timing Verifying the placement of the clock instances, using the GUI (as described in Analyzing Clock Trees in the GUI"}
{"instruction": "How do I Performing Minimum Path Resistance Analysis", "input": "", "output": "Note: Minimum path resistance analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows.\n Perform minimum path resistance analysis to quickly detect power and ground network weaknesses in the design.\n The minimum path resistance value of a node is the resistance value on the smallest resistive path to the ideal voltage source locations (taps).\n The ideal voltage sources can be power or ground pins, user-defined taps, or packages.\n Because this value represents only the resistance on a single path, it is not necessarily same as the effective resistance value from the node to the supply or ground; instead, it represents an upper bound on the effective resistance of a node to the supply or ground.\n 908 Performing Minimum Path Resistance Analysis Feedback To perform minimum path resistance analysis, run the analyze_rail -min_path_resistance command.\n You must specify the power and ground nets to analyze by using the -nets option.\n Note: In RedHawk-SC rail analysis flow, you must specify both the -voltage_drop and -min_path_resistance options for minimum path resistance calculation.\n You can perform minimum path resistance analysis before or during voltage drop analysis.\n When the analysis is completed, the tool writes the minimum path resistance values and the voltage drop results into the same rail result.\n The following example performs voltage drop analysis and minimum path resistance calculation at the same time.\n fc_shell> analyze_rail -nets {VDD VSS} \\ -min_path_resistance -voltage_drop static The following example performs only minimum path resistance analysis.\n fc_shell> analyze_rail -nets {VDD VSS} -min_path_resistance"}
{"instruction": "How do I Specifying Settings for Multivoltage Designs", "input": "", "output": "For multivoltage designs, to Ensure that primary and secondary voltage areas are honored and cells are added in logical hierarchies that are physically in the corresponding voltage areas, use the -respect_voltage_areas option with the add_buffer_on_route command.\n Specify different library cells for different voltage areas, use the -voltage_area_specific_lib_cells option and specify the list of library cells using the {va1 lib_cell1 va2 lib_cell2...} format.\n When you use this option, you must also use the -lib_cell option.\n Specify different single-rail and dual-rail library cells for different voltage areas, use the -select_mv_buffers option and specify the list of library cells by using the {va1 single_rail_lib_cell1 dual_rail_lib_cell1 va2 single_rail_lib_cell2 dual_rail_lib_cell2...} format.\n 970 Optimizing the Fanout of a Net Feedback When you use this option, you must also use the -lib_cell option.\n For voltage areas that you do not specify with this option, the tool uses library cells specified with the -lib_cell option.\n For the default voltage area, specify DEFAULT_VA as the voltage area name.\n Allow buffers on physical feedthrough nets of a voltage area, specify the voltage areas with the -allow_physical_feedthrough_buffer option.\n This option can only be used with the -respect_voltage_areas or -voltage_area_specific_lib_cells option, and the voltage area you specify must be a primary voltage area.\n After you run the add_buffer_on_route command with this option, update the supply net and power domain setting for the added buffers by using the set_eco_power_intention command.\n Add cells within gas stations of specified supply nets, use the -respect_gas_station option and specify the supply net.\n Gas stations are areas with a constant power supply.\n These areas used for buffering nets that go through power domains that are powered down.\n To specify the maximum allowed distance from the gas station to the added buffer, use the -max_distance_route_to_gas_station option."}
{"instruction": "How do I Setting Options for Power Grid Augmentation", "input": "", "output": "Before you run the signoff_create_pg_augmentation command, configure the run by setting the application options shown in Table 48.\n To set the application options, use the set_app_options command.\n To see the current settings, use the report_app_options command.\n Table 48 Application Options for Power Grid Augmentation Application option Default Description signoff.\n create_pg_augmentation.\n ground_net_name (required) (none) Specifies the name of the ground net.\n signoff.\n create_pg_augmentation.po wer_net_name (required) (none) Specifies the name of the power net.\n signoff.\n create_pg_augmentation.\n run_dir signoff_create_pg_ augmentation_run Specifies the run directory, which contains the files generated by the signoff_create_pg_augmentation command.\n You can specify either a relative path, in which case the directory is created under the current working directory, or an absolute path.\n 702 Improving Instance Voltage Drop by Augmenting the Power Grid Feedback Table 48 Application Options for Power Grid Augmentation (Continued) Application option Default Description signoff.\n create_pg_augmentation.\n user_defined_options (none) Specifies additional options for the IC Validator command line.\n The string that you specify in this option is added to the command line used to invoke the IC Validator tool.\n The Fusion Compiler tool does not perform any checking on the specified string."}
{"instruction": "How do I Specifying Horizontal and Vertical Spacing for Repeater Groups", "input": "", "output": "Use one of the following mutually exclusive options to control spacing for repeater groups: -horizontal_repeater_spacing specifies the horizontal spacing between repeaters by cell site width.\n -vertical_repeater_spacing specifies the vertical spacing between repeaters by site row height."}
{"instruction": "How do I Performing Wire Widening", "input": "", "output": "After you have performed detail routing, redundant via insertion, and wire spreading, you can perform wire widening to increase the average width of the wires, which reduces the critical area open faults and therefore improves yield.\n To perform wire widening, use the widen_zrt_wires comandcomandswiden_zrt_wireswire widening widen_wires command.\n By default, the widen_wires command widens all wires in the block to 1.5 times their original width.\n For more flexibility, you can use the -widen_widths_by_layer_name option to define up to five possible wire widths to use for each layer.\n For example, to define possible wire widths of 0.07 and 0.06 microns for the M1 layer; wire widths of 0.08 and 0.07 microns for the M2 layer; and 1.5 times the existing wire width for all other layers, enter the following command: fc_shell> widen_wires \\ -widen_widths_by_layer_name {{M1 0.07 0.06} {M2 0.08 0.07}} When you perform wire widening, the spacing between neighboring wires is decreased, which can reduce the improvement in critical area shorts gained from wire spreading.\n You can control the tradeoff between wire spreading and wire widening by using the 634 Inserting Metal-Insulator-Metal Capacitors Feedback -spreading_widening_relative_weight option.\n By default, wire spreading and wire widening are given equal priority.\n To weight the priority toward wire widening and reduced critical area open faults, set this option to a value between 0.0 and 0.5.\n To weight the priority toward wire spreading and reduced critical area short faults, set this option to a value between 0.5 and 1.0.\n After widening, the widen_wires command performs detail routing iterations to fix any DRC violations caused as a result of widening.\n Note that the widened wires do not trigger fat wire spacing rules.\n When you widen the wires, it changes the timing of your block.\n Wire widening has a timing-preservation mode that allows you to perform wire widening without affecting the block timing.\n To enable timing-preservation mode for wire widening, define the timing preservation constraints by using the following options with the widen_wires command: -timing_preserve_setup_slack_threshold threshold -timing_preserve_hold_slack_threshold threshold -timing_preserve_nets nets The threshold values are floating-point numbers in library units.\n Wire widening is not performed on nets with slack less than the specified values or the nets specified in the -timing_preserve_nets option."}
{"instruction": "How do I Global Routing", "input": "", "output": "Before you run global routing, Define the common routing application options For information about the common routing application options, see the route.common_options man page.\n Define the global routing application options For information about the global routing application options, see the route.global_options man page.\n To perform standalone global routing, use the route_global command.\n By default, global routing is not timing-driven.\n For information about enabling timing-driven global routing, see Timing-Driven Global Routing The global router divides a block into global routing cells.\n By default, the width of a global routing cell is the same as the height of a standard cell and is aligned with the standard cell rows.\n For each global routing cell, the routing capacity is calculated according to the blockages, pins, and routing tracks inside the cell.\n Although the nets are not assigned to the actual wire tracks during global routing, the number of nets assigned to each global routing cell is noted.\n The tool calculates the demand for wire tracks in each global routing cell and reports the overflows, which are the number of wire tracks that are still needed after the tool assigns nets to the available wire tracks in a global routing cell.\n For advanced node designs, via density can be a concern.\n To enable via density modeling, set the route.global.via_cut_modeling application option to true.\n The tool then calculates the number of vias in each global routing cell and reports via overflows.\n Global routing is done in two phases: The initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell The rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows The tool might perform several rerouting phases.\n At the end of each rerouting phase, the tool recalculates the overflows.\n You should see a reduction in the total number of global routing cells with overflow and in the total overflow numbers.\n The global router stops and exits from the rerouting phase when the congestion is solved or cannot be solved further or after the maximum number of phases has occurred, as defined by the -effort_level option.\n You can force the global router to perform the maximum number of phases based on the specified effort level by setting the route.global.force_full_effort application option to true.\n By default, the tool 526 Routing Signal Nets Feedback uses medium effort and performs a maximum of three rerouting phases.\n You can perform up to six rerouting phases by specifying ultra effort.\n There are five global routing effort levels: minimum low medium high, and ultra Minimum ( -effort_level minimum The minimum effort level uses two times larger global routing cells relative to the other effort levels.\n It also has a much lower congestion cost and runs only one rerouting phase.\n It should only be used for prototype routing or for an initial congestion evaluation, not for detail routing.\n Low ( -effort_level low Low effort runs a maximum of two rerouting phases with very similar congestion cost.\n It is faster in comparison to medium effort and has reasonable QoR.\n If your block is not very congested, you can use the low effort level.\n Medium ( -effort_level medium Medium effort is the default effort level and runs a maximum of three rerouting phases.\n Global routing stops after the third phase or when the overflow is resolved, whichever occurs first.\n High ( -effort_level high High effort runs up to four rerouting phases.\n If your block is congested, use the high effort level.\n Ultra ( -effort_level ultra Ultra effort runs up to six rerouting phases.\n If your block is very congested, use the ultra effort level.\n At the end of global routing, the following information is stored in the design library: The g-links and g-vias on each routed net This information is used for the next routing steps.\n After Zroute performs track assignment and detail routing, it removes these g-links and g-vias from the design library.\n The congestion data This information is used to generate a congestion map.\n By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing.\n The soft congestion data includes demand from soft nondefault spacing rules, as well as tool-generated soft rules.\n 527 Routing Signal Nets Feedback The global router reports block statistics and congestion data after the initial routing phase and after each rerouting phase.\n When global routing is complete, the global router reports a summary of the wire length and via count.\n Example 19 shows a global routing report.\n In the congestion report, the Overflow value is the total number of wires in the block that do not have a corresponding track available.\n The Max value corresponds to the highest number of overutilized wires in a single global routing cell.\n The GRCs value is the total number of overcongested global routing cells in the block.\n Example 19 Global Routing Report Start Global Route...\n...\n Design statistics: Design Bounding Box (0.00,0.00,3180.00,1154.00) Number of routing layers = 10 layer M1, dir Hor, min width = 0.05, min space = 0.05 pitch = 0.15 layer M2, dir Ver, min width = 0.06, min space = 0.06 pitch = 0.15...\n Net statistics: Total number of nets = 255165 Number of nets to route = 248716 Number of single or zero port nets = 1721 4728 nets are fully connected, of which 4728 are detail routed and 0 are global routed.\n 1648 nets have non-default rule clock_spacing...\n phase3.\n Routing result: phase3.\n Both Dirs: Overflow = 3320 Max = 3 GRCs = 4405 (0.08%) phase3.\n H routing: Overflow = 1759 Max = 2 (GRCs = 1) GRCs = 2756 (0.10%) phase3.\n V routing: Overflow = 1560 Max = 3 (GRCs = 20) GRCs = 1649 (0.06%) phase3.\n M1 Overflow = 1475 Max = 2 (GRCs = 1) GRCs = 2426 (0.09%) phase3.\n M2 Overflow = 1265 Max = 3 (GRCs = 20) GRCs = 1343 (0.05%)...\n Overflow over macro areas phase3.\n Both Dirs: Overflow = 293 Max = 2 GRCs = 300 (0.04%) phase3.\n H routing: Overflow = 133 Max = 1 (GRCs = 129) GRCs = 139 (0.03%) phase3.\n V routing: Overflow = 160 Max = 2 (GRCs = 2) GRCs = 161 (0.04%) phase3.\n M1 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%) phase3.\n M2 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%)...\n Density distribution: Layer 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 > 1.2 M1 86.6 10.5 0.37 1.46 0.02 0.44 0.18 0.14 0.07 0.03 0.10 0.00 0.00 0.02 M2 68.2 14.4 7.71 4.54 2.07 1.55 0.66 0.28 0.13 0.03 0.33 0.00 0.00 0.02...\n phase3.\n Total Wire Length = 21154552.81 phase3.\n Layer M1 wire length = 947324.93 phase3.\n Layer M2 wire length = 3959478.25...\n phase3.\n Total Number of Contacts = 2530044 phase3.\n Via VIA12SQ_C count = 1050582 phase3.\n Via VIA23SQ_C count = 856311...\n phase3.\n completed.\n 528 Routing Signal Nets Feedback Before proceeding to detail routing, display the congestion map in the GUI and check the overflow distribution.\n The congestion report and map help you to identify congested areas.\n For more information about the congestion report, see Generating a Congestion Report For more information about the congestion map, see Generating a Congestion Map"}
{"instruction": "How do I Standard Filler Cell Insertion", "input": "", "output": "The standard filler cell insertion flow uses the create_stdcell_fillers command to insert filler cells in the block and the remove_stdcell_fillers_with_violation command to perform design rule checking on the filler cells and remove filler cells with violations.\n During filler cell insertion, the create_stdcell_fillers command uses the placement legalizer to ensure that the inserted filler cells honor advanced node placement rules and physical constraints such as placement blockages and keepout margins.\n When the place.legalize.enable_advanced_legalizer application option is set to true the command uses the advanced legalization algorithms for 2D rule checking and cell interaction, which can reduce filler cell insertion runtime.\n To insert filler cells in your block, 1.\n Ensure that the block is legalized by using the check_legality command.\n When verifying that a block is fillable, the check_legality command assumes that all standard cells that have a design_type attribute of filler can be used as filler cells.\n However, the create_stdcell_fillers command inserts only the cells specified in 637 Inserting Filler Cells Feedback the -lib_cells option.\n This difference might result in unfillable gaps after filler cell insertion even though the check_legality command did not report any issues.\n 2.\n (Optional) Insert required filler cells to abut specific standard cells by using the create_left_right_filler_cells command, as described in Abutting Standard Cells With Specific Filler Cells 3.\n (Optional) Enable multithreaded filler cell insertion by using the set_host_options command to specify the multicore configuration.\n fc_shell> set_host_options -max_cores The create_stdcell_fillers command uses the multicore configuration only when the technology file contains minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules.\n Note: The multicore configuration specified with the set_host_options command applies to all Fusion Compiler commands that support multicore processing.\n 4.\n Insert metal filler cells by using the create_stdcell_fillers command.\n Use the -lib_cells option to specify the metal filler library cells to insert.\n The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n To determine the filler cells available in a cell library, use the following command: fc_shell> get_lib_cells ref_lib /* -filter \"design_type==filler\" To sort the filler cells by decreasing size, use the sort_collection command, as shown in the following example: fc_shell> set FILLER_CELLS \\ [get_object_name [sort_collection -descending \\ [get_lib_cells ref_lib /* -filter \"design_type==filler\"] area]] For more information, see Controlling Standard Filler Cell Insertion 5.\n Connect the inserted filler cells to the power and ground (PG) network by using the connect_pg_net -automatic command.\n 6.\n Remove the metal filler cells with DRC violations by using the remove_stdcell_fillers_with_violation command.\n Removing the filler cells can expose new violations; therefore, you must sometimes run this command multiple times to remove all violating filler cells.\n For more information, see Checking for Filler Cell DRC Violations 638 Inserting Filler Cells Feedback 7.\n Insert nonmetal filler cells by using the create_stdcell_fillers command.\n Use the -lib_cells option to specify the nonmetal filler library cells to insert.\n The tool tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n For more information, see Controlling Standard Filler Cell Insertion 8.\n Connect the inserted filler cells to the PG network by using the connect_pg_net -automatic command.\n See Also Generic ECO Flow for Timing or Functional Changes Removing Filler Cells"}
{"instruction": "How do I Using Routing Guides to Control the Routing Density", "input": "", "output": "By default, the maximum track utilization is 100 percent.\n You can use a routing guide to control the routing density within the routing guide boundary.\n To set the maximum track utilization for layers with a horizontal preferred direction, use the -horizontal_track_utilization option with the create_routing_guide command.\n To set the maximum track utilization for layers with a vertical preferred direction, use the -vertical_track_utilization option with the create_routing_guide command.\n By default, when you create these routing guides, they apply to all layers within the routing guide boundary.\n To set the routing density only for specific layers, use the -layers option to specify the affected layers.\n For example, to set a maximum track utilization of 50 percent for all layers with a horizontal preferred direction and a maximum track utilization of 30 percent for all layers with a vertical preferred direction within the rectangle with its lower-left corner at (0, 0) and its upper-right corner at (100, 100), use the following command: fc_shell> create_routing_guide -boundary {{0.0 0.0} {100.0 100.0}} \\ -horizontal_track_utilization 50 -vertical_track_utilization 30"}
{"instruction": "How do I Improving Latency-Driven Clock-Gate Splitting", "input": "", "output": "The latency-driven clock-gate (CG) splitting now automatically identifies and evaluates different CG cloning moves.\n This improves clock insertion delay to meet the maximum level constraint.\n To enable level driven CG splitting, set the cts.icg.latency_driven_cloning application option to true Figure 80 Latency Driven Clock-Gate Splitting"}
{"instruction": "How do I Checking Designs With Abstracts for Top-Level-Closure Issues", "input": "", "output": "You can check a hierarchical design that contains abstracts for possible issues such as the application option consistency issues and the design issues related to top-level closure by using the check_hier_design command.\n Identifying issues and fixing them before you perform top-level closure can help reduce turnaround time.\n When you use the check_hier_design command, you can specify The references to check by using the -reference option.\n If you do not specify this option, the command checks all the references in the physical hierarchy.\n The type of checks to perform by using the -stage option as follows: Use the -stage timing option to perform timing related checks.\n If you do not specify the -stage option, by default, the tool performs timing related checks.\n Use the -stage pre_placement to perform both timing and preplacement related checks.\n The check_hier_design command can check the consistency between the top-level constraints and the constraints of every lower-level instance linked to an abstract.\n To enable this feature, set the abstract.check_constraints_consistency application option to true before you run the check_hier_design command.\n The tool saves the settings of the predetermined list of timer application options during the create_abstract command.\n At the top-level design, the check_hier_design command compares these timer application option settings with those of the block-level design.\n The following application options are automatically saved during the create_abstract command and verified by the check_hier_design command: time.case_analysis_propagate_through_icg time.case_analysis_sequential_propagation time.clock_gating_propagate_enable time.clock_gating_user_setting_only 843 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback time.clock_marking time.clock_reconvergence_pessimism time.create_clock_no_input_delay time.crpr_remove_clock_to_data_crp time.delay_calc_waveform_analysis_mode time.delay_calculation_style time.disable_case_analysis_ti_hi_lo time.disable_clock_gating_checks time.disable_cond_default_arcs time.disable_internal_inout_net_arcs time.disable_recovery_removal_checks time.edge_specific_source_latency time.enable_auto_mux_clock_exclusivity time.enable_ccs_rcv_cap time.enable_clock_propagation_through_preset_clear time.enable_clock_propagation_through_three_state_enable_pins time.enable_clock_to_data_analysis time.enable_non_sequential_checks time.enable_preset_clear_arcs time.enable_si_timing_windows time.gclock_source_network_num_master_registers time.special_path_group_precedence time.use_lib_cell_generated_clock_name time.use_special_default_path_groups For more information about the issues the check_hier_design command identifies and how to fix them, see the man page for the corresponding message ID.\n In addition to generating a report, the check_hier_design command generates an enhanced messaging system (EMS) database that you can view by using the message 844 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback browser in the Fusion Compiler GUI.\n Create the EMS database before you run the check_hier_design command, as shown in the following example: fc_shell> create_ems_database check_hier.ems fc_shell> check_hier_design -stage timing fc_shell> save_ems_database In the Fusion Compiler GUI message browser, you can sort, filter, and link the messages to the corresponding man page, as shown in the following figure.\n Figure 194 Viewing the EMS Database in the Message Browser You can also output the information in the EMS database in ASCII format by using the report_ems_database command.\n The checks performed by the check_hier_design command are also available in the check_design command.\n You can perform Timing checks specific to top-level closure by using the check_design -checks hier_timing command All timing checks, including those specific to top-level closure, by using the check_design -checks timing command Preplacement checks specific to top-level closure by using the check_design -checks hier_preplacement command All preplacement checks, including those specific to top-level closure, by using the check_design -checks preplacement command 845 Checking Designs With Abstracts for Top-Level-Closure Issues Feedback You can generate an EMS database for the check_design command and view it in the GUI, similar to the check_hier_design command."}
{"instruction": "How do I Defining a Customized Via Mapping Table", "input": "", "output": "To define a customized via mapping, use the add_via_mapping command.\n At a minimum, you must specify the source via and its replacement vias by using the -from and -to options.\n The vias listed in these options must be either vias defined in the technology file or design-specific vias created by the create_via_def command.\n The vias listed in the -from option must be simple vias or via arrays.\n The vias listed in the -to option can be simple vias, simple via arrays, or custom vias.\n For information about creating design- specific vias, see Defining Vias Use the following options to refine the via mapping: -weight By default, all mappings have the same priority, and Zroute selects the redundant vias to use based on routability.\n To set the priority for a mapping, use the -weight option to assign an integer weight value between 1 and 10 to the mapping.\n If you do not assign a weight, the tool assigns a weight of 1.\n During redundant via insertion, Zroute uses the higher weighted redundant vias first.\n -transform By default, Zroute can rotate or flip the via arrays during redundant via insertion (the -transform all option).\n To allow only rotation of the via arrays during redundant via insertion, use the -transform rotate option.\n To allow only flipping of the via arrays during redundant via insertion, use the -transform flip option.\n To allow only the specified orientation of the via array during redundant via insertion, use the -transform none option.\n The tool saves the mappings defined by the add_via_mapping command in a via mapping table in the design library.\n By default, if you try to add a via mapping that already exists in the table, the command fails.\n To overwrite an existing mapping definition, use the -force option.\n Example 28 shows an example of using the add_via_mapping command to define a customized via mapping table.\n Example 28 Customized Via Mapping Table fc_shell> add_via_mapping \\ -from {VIA12 1x1} -to {VIA12T 2x1} -weight 5 fc_shell> add_via_mapping \\ -from {VIA12 1x1} -to {VIA12 2x1} -weight 1 625 Inserting Redundant Vias Feedback To see the customized via mappings associated with a block, use the report_via_mapping command.\n By default, this command shows all user-defined via mappings.\n To show the via mappings for specific source vias, use the -from option.\n To show the via mappings for specific replacement vias, use the -to option.\n To remove mappings from the via mapping table, use the remove_via_mappings command.\n To remove all via mappings, use the -all option.\n To remove the via mappings for specific source vias, use the -from option.\n To remove the via mappings for specific replacement vias, use the -to option.\n Using a Subset of the Via Mapping Table for Redundant Via Insertion To use a subset of the via mapping table for redundant via insertion, specify which weight groups from the via mapping table to use by setting one or both of the route.common.redundant_via_include_weight_group_by_layer_name and route.common.redundant_via_exclude_weight_group_by_layer_name application options.\n If you set only the route.common.redundant_via_include_weight_group_by_layer_name application option, Zroute selects redundant vias only from the specified weight groups.\n If you do not specify an entry for a layer, redundant via insertion is not performed on that layer.\n If you set only the route.common.redundant_via_exclude_weight_group_by_layer_name application option, Zroute selects redundant vias from all weight groups in the original via mapping table, except the specified weight groups.\n If you do not specify an entry for a layer, all weight groups are used for that layer.\n If you set both application options, Zroute selects redundant vias from the weight groups specified in the route.common.redundant_via_include_weight_group_by_layer_name application, excluding the weight groups specified in the route.common.redundant_via_exclude_weight_group_by_layer_name application option."}
{"instruction": "How do I Inserting Metal Shapes in the Preferred Direction", "input": "", "output": "To insert rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this object type, the command creates one or more rectangular metal shapes parallel to each preferred-direction boundary edge.\n The metal shapes are floating; they are not connected to any logical nets.\n If your technology does not specify a maximum area for these floating shapes, you can insert continuous metal shapes along the preferred-direction boundary edges, as described in Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges If your technology specifies a maximum area for these floating shapes or you need more flexibility in placing the metal shapes, insert multiple metal shapes, called metal stubs, along the preferred-direction boundary edges, as described in Inserting Metal Stubs Parallel to Preferred-Direction Edges In addition to inserting metal shapes along the preferred-direction edges, you can insert short metal shapes perpendicular to the nonpreferred-direction edges, as described in Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges 482 Routing Constraints Feedback Inserting Continuous Metal Shapes Parallel to Preferred-Direction Edges To insert continuous rectangular metal shapes along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred option.\n When you specify this option, the command creates a single rectangular metal shape parallel to each preferred-direction boundary edge.\n By default, The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual The metal shapes abut the nonpreferred-direction edges To specify an offset from the nonpreferred-direction edges, use the -spacing_from_boundary option.\n Use the following format to specify the offset for each layer: {{ layer_name offset_value }...} The offset value must be a positive value.\n The metal shapes are placed on the closest wire track to the preferred-direction edge Figure 101 shows the metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed on the closest track to the edge.\n W is the default width for the layer and S is the spacing specified for the layer by the -spacing_from_boundary option.\n 483 Routing Constraints Feedback Figure 101 Continuous Metal Shape Perimeter Constraint Objects Inserting Metal Stubs Parallel to Preferred-Direction Edges To insert metal stubs along the preferred-direction edges of the current block, use the derive_perimeter_constraint_objects command with the -perimeter_objects metal_preferred and -stub options.\n When you specify both of these options, the command creates rectangular metal shapes parallel to each preferred-direction boundary edge based on the parameters you specify with the -stub option.\n Use the following format to specify the shape parameters in microns: offset_value start_value length_value spacing_value By default, The metal shapes are offset from the preferred-direction edge by the value specified in the offset_value argument The offset value is measured from the block edge to the center of the metal shape.\n It can be a positive value, zero, or a negative value.\n The absolute value of a negative value must be greater than the stub width.\n A positive value must be less than half of the smaller of the width or height of the block boundary.\n The first metal shape is offset from the nonpreferred-direction edge by the value specified in the start_value argument The start value must be greater than or equal to 0 and less than the smaller of the width or height of the block boundary.\n For horizontal shapes, the metal shapes start at the left edge.\n For vertical shapes, the metal shapes start at the bottom edge.\n Note: When you use the -stub option, the command uses the specified start_value and ignores the -spacing_from_boundary option.\n 484 Routing Constraints Feedback The metal shapes have the length specified by the length_value argument The length value must be greater than 0 and less than or equal to the smaller of the width or height of the block boundary.\n The metal shapes have the default metal width specified for the routing layer in the technology file For information about specifying the default metal width for a layer, see the \"Default Width Rule\" topic in the Synopsys Technology File and Routing Rules Reference Manual The metal shapes are separated the space specified by the spacing_value argument The spacing value must be greater than or equal to 0.\n The metal shapes are inserted only in the top-level block To insert metal shapes in all soft macros in a hierarchical block, use the -hierarchical option.\n The metal shapes are inserted on all routing layers To insert the metal shapes only on specific routing layers, use the -layers option.\n Figure 102 shows the metal stubs inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape is placed at the specified offset, O, from the horizontal (preferred-direction) edge, where O is measured from the boundary to the center of the shape.\n The first metal stub is placed at the specified offset, S, from the vertical (nonpreferred-direction) edge.\n Each metal shape has a width of W, the default width for the layer and the specified length, L.\n The spacing between metal stubs is the specified spacing, SP.\n Figure 102 Metal Stub Perimeter Constraint Objects SP SP SP SP SP SP SP SP 485 Routing Constraints Feedback Inserting Short Metal Shapes Perpendicular to Nonpreferred-Direction Edges To insert additional short metal shapes in the preferred direction perpendicular to the nonpreferred-direction boundary edges, Specify the length of the metal shapes by using the -short_metal_length option Specify the distance between the metal shapes by using the -metal_spacing option For both of these options, you use the following format to specify the value for each layer: {{ layer_name value }...} Figure 103 shows the short metal shapes inserted for an L-shaped block on a layer whose preferred direction is horizontal.\n Each metal shape has a width of W, which is the default width for the layer, and a length of L, which is the length specified for the layer by the -short_metal_length option.\n The offset from the nonpreferred-direction edge is S, which is the spacing specified for the layer by the -spacing_from_boundary option.\n The distance between short metal shapes is SS, which is specified for the layer by the -metal_spacing option.\n Figure 103 Metal Shape Perimeter Constraint Objects With Additional Short Shapes SS"}
{"instruction": "How do I Preparing the Design", "input": "", "output": "The Fusion Compiler tool uses a design library to store your design and its associated library information.\n This topic describes how to create a design library and how to prepare and save your design.\n These steps are explained in the following topics: Defining the Search Path Setting Up Libraries Using Pin Access Checker Utility Analyzing Libraries Reading the Design Mitigating Design Mismatches Importing the Floorplan Information Setting Up Multivoltage Designs Specifying Timing Constraints and Settings Specifying Logical Design Rule Constraints Specifying Clock Gating Constraints Specifying Physical Constraints for Placement and Legalization Specifying Placement Settings Specifying Legalization Settings Controlling the Optimization of Cells, Nets, Pins, and Ports Specifying Settings for Preroute Optimization Setting Up for Power-Related Features Specifying the Routing Resources 72 Defining the Search Path Feedback Handling Design Data Using the Early Data Check Manager Applying Mega-Switch Command Settings"}
{"instruction": "How do I Avoiding Overlapping Repeaters With Existing Tap Cells", "input": "", "output": "Use the -honor_special_cell option to avoid overlapping with existing tap cells when inserting repeaters."}
{"instruction": "How do I Analyzing Libraries", "input": "", "output": "The Fusion Compiler tool provides the following library analysis capabilities, which can help achieve the performance, power, and area goals of your design: Identify redundant, outlier, and equivalent cells in library cell families, which you can exclude from optimization during the subsequent steps in the implementation flow.\n Identify gaps in library cell families, which you can provide as feedback to your library vendor with the goal of improving the reference libraries.\n Compare the delay, power, area, and other characteristics of equivalent cells in different libraries or different versions of the same library, which can help you identify the appropriate libraries to use for design implementation.\n A family of library cells is a collection of cells that share some common properties.\n The tool can identify a family of library cells based on User-identified library cells properties, such function, threshold voltage, and so on User-defined library cells lexical attributes and settings User-specified custom library cell families The following figure shows the high-level flow for performing library analysis.\n 83 Analyzing Libraries Feedback Figure 8 Library Analysis Flow For more information about the different types of library analysis flows, see the following topics: Introduction to Redundancies, Outliers, Equivalences, and Gaps in Library Cell Families Identifying Redundancies, Outliers, Equivalences, and Gaps in Library Cell Families Comparing Libraries"}
{"instruction": "How do I Abutting Standard Cells With Specific Filler Cells", "input": "", "output": "If your technology requires specific filler cells on the left or right sides of certain standard cells, use the create_left_right_filler_cells command to insert these filler cells.\n After you run the create_left_right_filler_cells command, perform standard filler cell insertion to fill the remaining gaps in the design.\n You must use the -lib_cells option to specify the rules for filler cell insertion.\n Each rule uses the following format: standard_cells } { left_filler_cells } { right_filler_cells For the standard_cells argument, You must specify a list of one or more standard cells You can use wildcards to specify the cell names If you specify multiple rules for the same standard cell, the command uses only the last rule specified for that cell.\n For the left_filler_cells and right_filler_cells arguments, At least one of these arguments must contain one or more filler library cells If only one of the arguments contains filler library cells, the tool inserts filler cells only on that side of the standard cells.\n The specified filler cells must meet the following requirements: They must have a design_type attribute of lib_cell or filler They must use the same site definition as the standard cells.\n The height of the standard cells must be an integer multiple of the filler cell heights.\n The command tries to insert the filler cells in the order that you specify; for the best results, specify them from the largest to the smallest.\n 655 Inserting Filler Cells Feedback You can use wildcards for the filler cell names.\n When you use wildcards, the order of the cells is the same as that returned by the get_lib_cells command.\n The following example inserts filler cells on the left and right sides of the SC1 standard cells and only on the left side of the SC2 standard cells.\n The left and right filler cells are specified in decreasing size order, so that the command inserts the largest possible filler cell.\n fc_shell> create_left_right_filler_cells \\ -lib_cells { { {mylib/SC1} {mylib/LF4X mylib/LF2X} {mylib/RF2X mylib/RF1X} } { {mylib/SC2} {mylib/LF2X mylib/LF1X} {} } } When the create_left_right_filler_cells command inserts the filler cells, It checks for legal locations for the filler cells, but does not check advanced rules such as minimum threshold voltage, oxide-diffusion (OD), or trimpoly (TPO) rules.\n It inserts the filler cells immediately next to the standard cells; it does not consider the intercell spacing rules.\n See Also Standard Filler Cell Insertion Controlling Cell-Based Filler Cell Insertion You can control the following aspects of the filler cell insertion with the create_left_right_filler_cells command: The region in which to insert the filler cells By default, the command inserts filler cells next to the specified standard cells in the entire block.\n Use the -boundaries option to restrict filler cell insertion to the specified regions.\n You can specify one or more rectangular or rectilinear regions.\n Use the -voltage_areas option to restrict filler cell insertion to the specified voltage areas.\n The orientation of the filler cells By default, the command uses the allowable orientations of the row to place the filler cells.\n To use the same orientation as the standard cell, use the -follow_stdcell_orientation option.\n When you use this option, the tool swaps the right and left filler cells when the cell is flipped.\n 656 Inserting Filler Cells Feedback The handling of one-unit-tile gaps By default, the command does not consider the one-unit-tile rule.\n To prevent the tool from inserting filler cells that would leave a one-unit-tile gap, use the -rules no_1x option.\n When you enable this rule, do not include filler library cells with a width of one- unit tile in the -lib_cells option; otherwise, the tool ignores this rule.\n The naming convention used to identify the inserted filler cell instances By default, the command uses the following naming convention for inserted filler cells: xofiller!\n filler_library_cell_name number To identify the filler cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the command uses the following naming convention: xofiller!\n prefix filler_library_cell_name number"}
{"instruction": "How do I Using an IC Validator Parameter File", "input": "", "output": "_step application option.\n When you use this application option, it uses the specified value for the step size in both the x- and y-directions."}
{"instruction": "How do I Running Concurrent Clock and Data Optimization", "input": "", "output": "Changing clock latencies can balance the slack in successive timing path stages to optimize clock and data paths.\n This capability is called concurrent clock and data (CCD) optimization, which can reduce total negative slacks (TNS), worst negative slacks (WNS), area, and leakage power.\n In addition, it can improve correlation between physical synthesis and place-and-route."}
{"instruction": "How do I Reducing Critical Areas", "input": "", "output": "A critical area is a region of the block where, if the center of a random particle defect falls there, the defect causes circuit failure, thereby reducing yield.\n A conductive defect causes a short fault, and a nonconductive defect causes an open fault.\n 632 Reducing Critical Areas Feedback The following topics describe how to Reduce critical area short faults by performing wire spreading Reduce critical area open faults by performing wire widening"}
{"instruction": "How do I Specifying Clock Gating Constraints", "input": "", "output": "By default, the tool identifies preexisting clock-gating cells during the execution of the analyze and elaborate commands.\n During compile, the tool inserts one more level of clock-gating cells at the leaf level and implements clock-gating logic using the default 135 Specifying Clock Gating Constraints Feedback clock-gating settings if you do not specify any clock-gating constraints.\n You cannot disable clock gating.\n Before you set up clock-gating constraints, load your design and libraries in memory and then use the following commands to set up the constraints: The set_clock_gate_style command To select the type of integrated clock-gating cell, specify the following options: Option Description -test_point Specifies the test control position with respect the to integrated clock-gating cell.\n The valid values are none before, and after -observation_output Specifies the observation output pin.\n -target Specifies the target sequential elements to be clock-gated.\n The valid values are pos_edge_flip_flop and neg_edge_flip_flop -objects Specifies the objects to which the clock gate applies.\n The set_clock_gating_options command To define the netlist structure of the inserted clock-gating cells, specify the following options: Option Description minimum_bitwidth Specifies the minimum number of bits to gate together.\n The default is three.\n max_fanout Specifies the maximum number of cells gated by the same clock-gating cell.\n The default is infinite.\n The set_clock_gating_objects command To control clock gating for specified objects and override the default clock-gating behavior that is set during compile, specify the following options.\n An object can be a hierarchical cell, register, power domain, or module.\n Option Description -include Specifies a list of objects to gate as per the clock-gating style and clock-gating options.\n -exclude Specifies a list of objects to exclude from clock gating.\n 136 Specifying Physical Constraints for Placement and Legalization Feedback Option Description -clear Specifies to remove all clock-gating inclusion or exclusion for the specified list of objects.\n -reset Specifies to remove all criteria previously set by the set_clock_gating_objects command.\n The default During clock-gating optimization, the tool uses the following setup defaults: Setup Default Maximum fanout Infinite Minimum bit-width Three Clock-gating cell Latch-based cells for both positive-edge and negative-edge triggered flip-flops.\n If only one type of cell is available, the tool inserts inverters on both sides of the clock-gating cell.\n For more information, see Setting Up Clock Gating"}
{"instruction": "How do I Checking and Fixing Isolated Vias", "input": "", "output": "By default, the signoff_fix_isolated_via command both checks for and fixes isolated vias.\n The command performs the following tasks: 1.\n Checks for isolated vias by using the ranges defined in the signoff.fix_isolated_via.isolated_via_max_range application option 2.\n (Optional) Performs track-based metal fill insertion to insert dummy fill shapes within the specified range around each detected isolated via By default, the signoff_fix_isolated_via command ignores the existing fill data and performs track-based metal fill insertion to insert the fill shapes to use for fixing the isolated vias.\n The fill shapes are inserted on-track following the design rules defined in the technology file.\n Some foundries have additional design rules, which you enable by setting the appropriate TRACK_FILL_FOUNDARY_ name IC Validator variable.\n To set this variable, set the signoff.create_metal_fill.user_defined_options application option, as shown in the following example: fc_shell> set_app_options \\ -name signoff.create_metal_fill.user_defined_options \\ -value {-D TRACK_FILL_FOUNDARY_ name If you have already performed track-based metal fill insertion, you can use the existing fill shapes to fix isolated vias by using the -update_track_fill true option.\n When you use this option, you must use the -track_fill_runset_include_file option to specify the parameter file used for the initial track-based metal fill insertion.\n This parameter file is named track_fill_params.rh and is located in the run directory for the initial run.\n For example, if the run directory for the initial track-based metal fill insertion run is named init_fill, use the following command to fix isolated vias using the existing fill shapes: fc_shell> signoff_fix_isolated_via -update_track_fill true \\ -track_fill_runset_include_file init_fill/track_fill_params.rh For information about performing track-based metal fill insertion, see Track-Based Metal Fill Insertion 744 Automatically Fixing Isolated Vias Feedback 3.\n Inserts fixing vias within the specified range by using one of the following methods, in order of priority: a.\n Inserting a via between an existing non-wide net shape and a fill shape b.\n Extending the line end of an existing non-wide net shape and inserting a via between the extension and a fill shape c.\n Inserting a via between a wide metal shape and a fill shape When inserting the fixing vias, the tool considers the routing rules, including double- patterning rules and nondefault spacing rules, to prevent the introduction of DRC violations.\n Note: If the block is either very congested or very sparse, the signoff_fix_isolated_via command might not be able to fix all isolated vias.\n 4.\n Removes the unused dummy fill shapes 5.\n (Optional) Saves the updated block to disk By default, the signoff_fix_isolated_via command does not save the updated block to disk.\n After running the command, you must use the save_block command to save the updated block to disk.\n To save the block at the end of the signoff_fix_isolated_via run, use the -save_design true option with the signoff_fix_isolated_via command.\n 6.\n Saves the results to disk The signoff_fix_isolated_via command generates the following results files: A summary report This report specifies the number of isolated vias for each via layer before and after fixing.\n An error data file By default, the error data generated by the signoff_fix_isolated_via command is saved in a file named signoff_fix_isolated_via.err.\n To specify the name for the error data file, use the -error_data option.\n To report or display the information in the error data file, use the error browser, as described in the Fusion Compiler Graphical User Interface User Guide 745 Feedback"}
{"instruction": "How do I Specifying Optimization Targets at the Postroute Stage", "input": "", "output": "At the final stages of your design flow, you can use the route_opt command to perform concurrent clock and data optimization on specific critical path groups or endpoints by using the following steps: 1.\n Enable targeted concurrent clock and data optimization for the route_opt command by setting the route_opt.flow.enable_targeted_ccd_wns_optimization application option to true 2.\n Specify the optimization target by using one or both of the following settings: Specify the path groups to optimize by using the ccd.targeted_ccd_path_groups application option Note: If a path group you specify with this application option is also specified as a path group to skip by using the ccd.skip_path_groups application option, the path group is skipped during targeted concurrent clock and data optimization.\n Specify the endpoints to optimize by using the ccd.targeted_ccd_end_points_file application option You must specify at least one of these settings.\n If you specify both, the tool optimizes the specified endpoints of the specified paths groups.\n 3.\n (Optional) Specify the type of optimization to perform by using the ccd.targeted_ccd_select_optimization_moves application option.\n The valid values are 381 Implementing Clock Trees and Performing Post-CTS Optimization Feedback auto, the default, which enables all optimization types, including buffering size_only, which enables sizing only equal_or_smaller_sizing, which enables sizing only to cells that are the same size or smaller footprint_sizing, which enables sizing only to cells with the same footprint 4.\n (Optional) Specify an optimization effort by using the ccd.targeted_ccd_wns_optimization_effort application option.\n The valid values are high (default), medium, and low.\n The higher the effort, the more timing QoR improvement you will see in the targeted paths, but at the expense of the timing QoR of other paths.\n 5.\n (Optional) Specify a threshold beyond which the slack for the path groups that are not targeted can be degraded by using the ccd.targeted_ccd_threshold_for_nontargeted_path_groups application option.\n By default, if the path groups that are not targeted have positive slack, the tool can degrade this slack until it reaches zero.\n For the route_opt command, you can enable both regular concurrent clock and data optimization by using the route_opt.flow.enable_ccd application option and targeted concurrent clock and data optimization by using the route_opt.flow.enable_targeted_ccd_wns_optimization application option.\n If you enable both, the tool performs regular concurrent clock and data optimization first, followed by targeted concurrent clock and data optimization.\n The following script performs targeted concurrent clock and data optimization on a block that has already undergone routing and postroute optimization: open_lib design1 open_block blk.post_route #Disable regular CCD optimization, which was previously performed set_app_options \\ -name route_opt.flow.enable_ccd -value false #Enable targeted CCD optimization set_app_options \\ -name route_opt.flow.enable_targeted_ccd_wns_optimization \\ -value true #Specify the path group and endpoints to target set_app_options -name ccd.targeted_ccd_path_groups -value clkA set_app_options -name ccd.targeted_ccd_end_points_file \\ -value clkA_ep.txt 382 Implementing Clock Trees and Performing Post-CTS Optimization Feedback #Specify the optimization type and effort set_app_options \\ -name ccd.targeted_ccd_select_optimization_moves -value size_only set_app_options -name ccd.targeted_ccd_wns_optimization_effort \\ -value medium # Perform the targeted CCD optimization route_opt"}
{"instruction": "How do I Defining Insertion Delay Requirements", "input": "", "output": "To override the default phase delay of zero for sink pins (derived or user-specified), use the -delay option with the set_clock_balance_points command to specify the 345 Defining the Clock Trees Feedback insertion delay requirements.\n The tool adds the specified delay (positive or negative) to the calculated insertion delay up to the specified sink pin.\n The syntax to define the insertion delay requirement for one or more sink pins is set_clock_balance_points [-clock clock -delay delay [-rise] [-fall] [-early] [-late] -balance_points pins [-corners corners The -clock option is not required.\n If you do not use it, the insertion delay requirement applies to all clocks.\n Clock tree synthesis uses the specified delay value for the path delay calculations used to build the clock tree.\n By default, the specified delay value is used for both longest-path and shortest-path calculations for both rising-edge and falling-edge paths.\n To control when the specified delay value is used, use the -rise -fall -early, and -late options.\n When you define insertion delay requirements, by default, they apply to all corners.\n To apply the definition to specific corners, use the -corners option.\n For example, to specify that clock tree synthesis should use an insertion delay of 2.0 ns for rising-edge shortest-path calculations for the U2/CLK pin for the CLK clock in the current corner, use the following command: fc_shell> set_clock_balance_points -clock [get_clocks CLK] \\ -rise -early -delay 2.0 -balance_points [get_pins U2/CLK] To report the user-defined insertion delay for sink pins, use the report_clock_balance_points command.\n This command reports the user-defined sink pins, the derived sink pins with user-specified insertion delay, and the user-defined ignore pins."}
{"instruction": "How do I Using the create_cell_array Command", "input": "", "output": "ad_tap_cel_aray comandcomandsad_tap_cel_aray To add a tap cell array with specific placement, use the create_cell_array command.\n You must specify the name of the library cell to use for tap cell insertion ( -lib_cell option), and the x- and y-pitches.\n For example, fc_shell> create_cell_array -lib_cell myreflib/mytapcell \\ -x_pitch 10 -y_pitch 10 By default, the create_cell_array command inserts a tap cell in each location in the specified grid for the entire block.\n The tool starts inserting the tap cells at the bottom-left of the core area and uses the specified x- and y-pitches to determine the location of the subsequent tap cells.\n The inserted tap cells are snapped to the site rows and placed in the default orientation for the site row.\n If a location is occupied by a fixed cell, hard macro, soft macro, or power-switch cell, the command does not insert a tap cell at that location.\n You can modify the following aspects of the default behavior: The region in which to insert tap cells Use the -voltage area option to restrict the tap cell insertion to the specified voltage areas.\n Use the -boundary option to restrict the tap cell insertion to the specified region.\n If you use both options, the command inserts tap cells only in the overlapping region.\n The offset from the insertion region boundary Use the -x_offset option to shift the pattern startpoint to the right by the specified distance in microns.\n Use the -y_offset option to shift the pattern startpoint up by the specified distance in microns.\n 586 Inserting Tap Cells Feedback The insertion pattern Use the -checkerboard option to insert a tap cell in every other location in the specified grid.\n To place a tap cell in the lower-left corner, use the -checkerboard even option.\n To keep the lower-left corner empty, use the -checkerboard odd option.\n In some design methodologies, you must insert a tap cell in empty spaces in the checkerboard pattern that are above or below specific cells, such as critical area breaker cells or boundary cells.\n To enable the insertion of these extra tap cells, use the -preserve_boundary_row_lib_cells option to specify the affected library cells.\n The snapping behavior To disable snapping of the inserted tap cells to the site rows, set the -snap_to_site_row false option.\n When you set this option to false, the tool uses R0 as the default orientation for the inserted cells.\n The orientation of the inserted tap cell instances To specify the orientation of the inserted tap cells, use the -orient option to specify one of the following orientation values: R0 R90 R180 R270 MX MY MXR90, or MYR90 The naming convention used to identify the inserted tap cell instances By default, the tool uses the following naming convention for inserted tap cells: headerfooter__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string.\n When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number 587 Inserting Tap Cells Feedback"}
{"instruction": "How do I Self-Gating Optimization", "input": "", "output": "The tool supports self-gating optimization, which occurs at the compile_fusion command.\n This feature reduces dynamic power consumption by turning off the clock signal of certain registers during clock cycles when the data remains unchanged.\n 328 Self-Gating Optimization Feedback Figure 66 Example of a Self-Gating Cell CLK Registers with an enable condition that cannot be inferred from the existing logic can only be gated using the self-gating technique.\n They cannot be gated using traditional clock gating.\n By default, the tool supports self-gating only on registers that are not gated.\n You can use the set_self_gating_options command to allow self-gating on these registers.\n However, the time duration that the clock signal is turned off might increase for these registers,.\n To ensure QoR improvements, the self-gating algorithm takes timing and power into consideration.\n A self-gating cell is inserted for the registers if There is enough timing slack available in the register's data pin.\n For designs with multiple scenarios, the algorithm considers the timing of the worst case among active scenarios enabled for setup.\n Internal dynamic power of the circuit is reduced.\n For designs with mutiple scenarios, the algorithm uses the average internal dynamic power among active scenarios enabled for dynamic power.\n To minimize the area and power overhead, a self-gating cell can be shared across a few registers by creating a combined enable condition with a tree of comparator cells.\n If the self-gated registers are driven by synchronous set or synchronous clear signals, these signals are also included in the construction of the enable signal so that the circuit remains functionally unchanged.\n Figure 67 is an example of a self-gating cell that is shared across two registers (4 bits).\n Note that one of the self-gated registers is a multibit register and the other register is a single-bit register.\n The tool can also self-gate a group of multibit registers or a group of single-bit registers.\n 329 Self-Gating Optimization Feedback Figure 67 Self-Gating Tree CLK D0 Q0 D2 Q2 D1 Q1 EN The tool does not support the following types of sequential cells for self-gate insertion: Level-sensitive sequential cells Level-sensitive scan design registers Master-slave flip-flops Retention registers Single-bit and multibit registers that belong to shift registers Multibit registers with multiple clock paths For more information, see the following topics: Self-Gating Flow Library Requirements for Self-Gating Setting Up for Self-Gating Reporting and Querying Self-Gating Cells"}
{"instruction": "How do I Removing Filler Cells", "input": "", "output": "Filler cells inserted by the Fusion Compiler tool have instance names that start with the string xofiller.\n To remove all the filler cells from a block, use the remove_cells command, as shown in the following example: fc_shell> remove_cells [get_cells xofiller*] If you used the standard filler cell insertion flow and want to remove only those filler cells with DRC violations, use the remove_stdcell_fillers_with_violation command, as described in Checking for Filler Cell DRC Violations"}
{"instruction": "How do I Controlling MUX Optimization", "input": "", "output": "The Fusion Compiler tool can map combinational logic representing multiplexers in the HDL code directly to a single multiplexer (MUX) or a tree of multiplexer cells from the target logic library.\n Multiplexers are commonly modeled with if and case statements.\n To implement the mutliplexer logic, the HDL Compiler uses SELECT_OP cells, which the Fusion Compiler tool map to combinational logic or multiplexers in the logic library.\n 226 Controlling Mapping and Optimization Feedback User-specified Tool evaluated Implemented using MUX gates Implemented using MUX or non MUX gates based on area costing analyze elaborate Infers Select_OP cells compile_fusion"}
{"instruction": "How do I Preserving Cells and Nets During Optimization", "input": "", "output": "To preserve design objects during optimization, use the set_dont_touch command.\n The command places the dont_touch attribute on cells, nets, references, and subdesigns in the current design to prevent these objects from being modified or replaced during optimization.\n This table shows how the tool preserves the design objects during optimization.\n Design objects Tool behavior Cells Excludes the cells from optimization.\n Nets Preserves the connectivity of all pins to the nets.\n Modules, designs, library cells Prevents optimization of all instances that reference them.\n Hierarchical cells or modules Excludes the cells and all child cells from optimization.\n When you use the set_dont_touch command, keep the following in mind: The command prevents the ungrouping of hierarchy.\n A child cell must inherit the same dont_touch attribute from its parent module.\n For example, you cannot remove the dont_touch attribute from a child cell when its parent module is marked with the dont_touch attribute.\n Use the command on fully mapped logic only, including cells, modules, and designs, as well as nets with fully mapped surrounding logic.\n The dont_touch attribute has higher precedence over the boundary_optimization and the size_only attributes.\n To report design objects marked with the dont_touch attribute, use the report_dont_touch command.\n This command sets the dont_touch attribute on cell A.\n fc_shell> set_dont_touch [get_cells A] true 170 Controlling the Optimization of Cells, Nets, Pins, and Ports Feedback To remove the dont_touch attribute, use the remove_attributes command or the set_dont_touch command set to false, as shown in the following two commands: fc_shell> remove_attributes [get_cells A] dont_touch fc_shell> set_dont_touch [get_cells A] false The following table summaries the commands that you can use to set, remove, or report the dont_touch attribute on design objects, including modules, cells, nets, and library cells.\n Yes denotes the command operation of the dont_touch attribute is supported, while No denotes the command operation is not supported.\n Table 13 Command Support for the dont_touch Attribute on Design Objects Command Module Cell (Instance) Net Library cell set_dont_touch Yes Yes Yes Yes set_attribute Yes Yes Yes Yes define_user_attribute No No No No get_attribute Yes Yes Yes Yes remove_attributes Yes Yes Yes Yes report_dont_touch Yes Yes Yes No set_dont_touch unmapped_object No No Yes NA"}
{"instruction": "How do I Voltage Hotspot Analysis", "input": "", "output": "When rail analysis is complete, there might be hundreds to thousands of voltage drop violations reported in the analysis report, which might make it difficult to identify the root causes for the violations.\n Use the voltage hotspot analysis capability to generate hotspots for a power or ground net by dividing the whole chip into small grid boxes, and report rail-related information for the generated grid boxes.\n In addition, you can query cell- or geometry-based rail results only for the specific analysis type by using the get_instance_result and get_geometry_result commands.\n 939 Voltage Hotspot Analysis Feedback Hotspot analysis provides the following features: Identify the root cause of aggressors with high voltage drop, such as large current from the aggressor itself or from the neighboring cells due to simultaneous switching by the overlapping timing windows.\n Determine which design technique to use for fixing voltage violations based on the report, such as choosing a candidate reference cell for cell sizing replacement, moving or relocating cells to reduce voltage drops, or applying PG augmentation to solve a voltage drop issue.\n This section contains the following topics: Generating Hotspots Reporting Hotspots Removing Hotspots Voltage Hotspot Analysis Examples To write rail results only for the cell instances or geometries that reside in the hotspot area, use the get_instance_result and get_geometry_result commands.\n For more information, see Generating Instance-Based Analysis Reports and Generating Geometry- Based Analysis Reports"}
{"instruction": "How do I Specifying Block-Level Power Intent", "input": "", "output": "You must provide power intent of the subblock for the top-level design implementation when running hierarchical synthesis.\n To do so, you can provide full block-level UPF for the tool to automatically extract power intent interface.\n The following figure shows a subblock named U1, and the top-level power intent script loads the block-level power intent by using the load_upf command.\n Note: The block-level power intent specification is required only for hierarchical synthesis using ETMs.\n In the abstract flow, the UPF constraints are handled automatically by the tool.\n 830 Overview of Abstract Views Feedback U1 as an ETM in the PD_Top design Top-Level power intent create_power_domain PD_TOP -include_scope create_supply_net VDD_AO...\n load_upf block.upf -scope U1...\n connect_supply_net VDD_AO -port U1/VDD_AO Block-level power intent: block.upf create_power_domain PD_BLK -include_scope create_power_switch sw1 -domain PD_BLK \\ -input_supply_port {in VDD_AO} \\ -output_supply_port {out VDD_SW}...\n...\n add_port_state sw1/out -state {ON 1.08} -state {OFF off}...\n create_pst pst -supplies {VDD_SW...}"}
{"instruction": "How do I Making ECO Changes Using the eco_netlist Command", "input": "", "output": "You can make ECO changes to a block by using the eco_netlist command.\n If you are using the freeze silicon ECO flow, enable ECO changes in the freeze silicon mode by setting the design.eco_freeze_silicon_mode application option to true before you run the eco_netlist command.\n When you use the eco_netlist command, use one of the following two methods to make the ECO changes: Specify a golden Verilog netlist that includes the ECO changes by using the -by_verilog_file option Specify a golden block that includes the ECO changes by using the -block option When you use the -block option, by default, The tool assumes the golden block is in the current design library.\n To specify a different design library, use the -golden_lib option.\n The tool makes the ECO changes to the current design.\n To make the ECO changes to a different design, use the -working_block option.\n To specify the design library that contains the design specified by the -working_block option, use the -working_lib option.\n The tool compares the working design to the input Verilog netlist or the golden design and generates a change file containing netlist editing Tcl commands that implements the functional changes.\n You must specify the name of the output file by using the -write_changes option.\n By default, the tool ignores the following: Differences in the physical-only cells To consider the differences in the physical-only cells, use the -compare_physical_only_cells option.\n Timing ECO changes, such as cells that are resized or repeaters that are added or removed.\n To consider the timing ECO changes, in addition to the functional ECO changes, use the -extract_timing_eco_changes option.\n Differences in power and ground objects.\n 961 Making ECO Changes Using Netlist Editing Commands Feedback To make the ECO changes to the working design, source the change file that the eco_netlist command generates, as shown in the following example: fc_shell> eco_netlist -by_verilog_file eco.v \\ -compare_physical_only_cells -write_changes eco_changes.tcl fc_shell> source eco_changes.tcl"}
{"instruction": "How do I An Overview for RedHawk Fusion and RedHawk-SC Fusion", "input": "", "output": "Both RedHawk Fusion and RedHawk-SC Fusion support gate-level rail analysis capabilities, including static and dynamic rail analysis.\n You can use RedHawk Fusion and RedHawk-SC Fusion to perform the following types of checking and analysis in the Fusion Compiler environment: Missing via and unconnected pin shape checking To check for missing vias or unconnected pin shapes in the design, you first configure the checking-related settings by using the set_missing_via_check_options command, and then perform the check by using the analyze_rail -check_missing_via command.\n For more information, see Missing Via and Unconnected Pin Checking Voltage drop analysis To perform voltage drop analysis, use the analyze_3d_rail -voltage_drop -electromigration command.\n To perform voltage drop analysis, use the analyze_rail -voltage_drop command or choose Rail > Analyze Rail and select \"Voltage drop analysis\" in the GUI.\n Set the -voltage_drop option to static dynamic dynamic_vcd, or dynamic_vectorless to choose the type of analysis you want to perform.\n For more information, see Performing Voltage Drop Analysis PG electromigration analysis To perform PG electromigration analysis, use the analyze_rail -electromigration command.\n For more information, see Performing PG Electromigration Analysis 870 An Overview for RedHawk Fusion and RedHawk-SC Fusion Feedback Minimum path resistance analysis To perform minimum path resistance analysis, use the analyze_rail -min_path_resistance command.\n In the RedHawk-SC analysis flow, you must use the -voltage_drop option together with the -min_path_resistance option for minimum path resistance analysis.\n For more information, see Performing Minimum Path Resistance Analysis Depending on the type of analysis you run, the tool generates visual displays (maps) of the results that you can view in the Fusion Compiler GUI, as well as error data that you can display in the Fusion Compiler error browser.\n These maps and error data help you discover problem areas and determine corrective action without leaving the Fusion Compiler environment.\n Note: RedHawk Fusion in the Fusion Compiler tool does not support RedHawk signoff analysis features, such as hierarchical analysis or dynamic analysis with lumped or SPICE packages.\n For more information, see Preparing Design and Input Data for Rail Analysis By default, RedHawk Fusion analyzes only the current design scenario when analyzing a multicorner-multimode design.\n For more information about how to create and specify a rail scenario for rail analysis, see Running Rail Analysis with Multiple Rail Scenarios Figure 198 shows where you would use these analysis capabilities in a typical design flow.\n Figure 198 Using RedHawk Fusion in the Fusion Compiler Design Flow Find missing vias Design planning place_opt Initial placement Static voltage clock_opt Static voltage Filler cell insertion drop analysis drop analysis Power-switch cell insertion Dynamic voltage drop analysis route_opt PG electromigration analysis and fixing 871 An Overview for RedHawk Fusion and RedHawk-SC Fusion Feedback"}
{"instruction": "How do I Grouping a list of repeaters", "input": "", "output": "To automatically group a list of repeaters or repeaters of supernets, use the create_repeater_groups command.\n This command takes a list of repeaters, a list of supernets, or bundles of supernets and returns a list of repeater groups created by the set_repeater_group command.\n The command supports both single load and multiple loads supernets.\n create_repeater_groups -supernets supernet_list | \\ -supernet_bundles supernet_bundle_list | \\ -cells cell_list -lib_cells lib_cell_list [-lib_cell_input lib_pin ] \\ [-lib_cell_output lib_pin ] \\ [-group_pin_spacing spacing ] \\ [-ignore_pin_layers]"}
{"instruction": "How do I Arrays During Placement", "input": "", "output": "A sequential array, which is commonly used in storage devices, is a group of registers that are arranged as a two-dimensional array.\n The clock pins of the registers along a row of a sequential array are usually driven by a single clock-gating cell.\n To consider the clock-gating cells of a sequential array during placement, set the place.coarse.seq_array_icg_aware application option to true.\n Doing so can reduce the congestion caused by the clock nets."}
{"instruction": "How do I Defining Blockages That Exclude Registers", "input": "", "output": "To define partial blockages that exclude registers, specify the boundary, type ( -type register option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage.\n For example, to define a partial blockage that excludes registers, but allows a cell density of 50 percent for other cells, use the following commands: create_placement_blockage -boundary {{10 20} {100 200}} \\ -type register -blocked_percentage 50 Note: Register blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis.\n 143 Specifying Physical Constraints for Placement and Legalization Feedback"}
{"instruction": "How do I Generating a Congestion Map", "input": "", "output": "To display the global route congestion map, choose View > Map > Global Route Congestion in the GUI.\n If the design library contains global route congestion information for the block, the tool generates the congestion map based on this information; otherwise, you must click Reload to generate the congestion map.\n When you click Reload, the tool opens a dialog box that contains the following command: route_global -congestion_map_only true Note: By default, only the hard congestion data is saved in the design library.\n To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing.\n When you click OK in this dialog box, the tool generates a new congestion map.\n If you want to use different options for the route_global command, you can modify this command before clicking OK.\n 566 Analyzing the Routing Results Feedback Figure 118 shows an example of a congestion map.\n Figure 118 Global Route Congestion Map By default, the congestion map displays only the hard congestion data.\n To display soft congestion data, select the desired rule level in the Rule level drop-down list.\n The rule level refers to the spacing weight level of the soft nondefault spacing rules.\n The congestion map displays the sum of the hard and soft congestion with a weight level of at least the selected rule level.\n The congestion map shows the borders between global routing cells highlighted with different colors that represent the congestion values.\n The congestion map supports two methods for calculating the congestion value: Sum of overflow for each layer (the default) In this mode, the tool calculates the congestion value as the sum of the overflow for all selected layers.\n Underflow is not considered; if a layer has underflow, it contributes zero overflow to the total overflow calculation.\n Total demand minus total supply In this mode, the tool calculates the congestion value by subtracting the supply for all selected layers from the demand for all selected layers.\n Note that because this calculation considers the underflow, it produces a more optimistic congestion result in regions that contain both overflow and underflow.\n For example, assume that the METAL2 layer is heavily congested with a demand of 13 routing tracks and a supply of only 7 tracks for an overflow of 6.\n The METAL4 is 567 Analyzing the Routing Results Feedback moderately congested with an overflow of 4, and the METAL6 layer is not congested and contains an underflow of 3.\n Other layers are not used in the congestion calculation in this example.\n The sum of overflow calculation results in a congestion value of 6+4=10.\n The underflow of 3 for the METAL4 layer is not used in the calculation.\n The total demand calculation results in a congestion value of 6+4-3=7.\n In this case, the underflow of 3 for the METAL4 layer is used in the calculation.\n To select the mode, select either \"Sum of overflow for each layer\" or \"Total demand minus total supply\" in the \"Congestion calculation\" section of the Map Mode panel.\n By default, all metal layers are selected in the congestion map, except those specified as ignored layers with the set_ignored_layers command.\n To display the congestion map for a subset of layers, select (or deselect) the layers on the Map Mode panel.\n For example, if the global routing report shows that the maximum overflow occurs on the METAL2 layer, you can deselect all layers, except for METAL2, to display only the METAL2 congestion.\n The Map Mode panel also displays a histogram showing the number of global routing cells in different ranges (bins) of congestion values for the selected layers.\n If your block contains global routing cells that have no available routing resources, an additional bin named Blocked is displayed that shows the number of global routing cells with no routing resources.\n You can select which bins to display in the congestion map by selecting or deselecting them on the Map Mode panel.\n If the block shows congested areas, zoom into the congested area to see the congestion value on the global routing cell.\n For example, in Figure 119, the red highlight on the edge of the global routing cell shows 18/9.\n This means there are 9 wire tracks available, but 18 tracks are needed.\n 568 Analyzing the Routing Results Feedback Figure 119 Global Route Overflow on Global Routing Cell"}
{"instruction": "How do I Restricting the Target Libraries Used", "input": "", "output": "You can restrict the libraries used during clock tree synthesis for the top level or a lower level of the logical hierarchy of a design by using the set_target_library_subset -clock command.\n To enable the use of the target library subset, you must set the opt.common.enable_target_library_subset_opt application option to The following example specifies the buf1 and buf2 cells from the HVT_lib and LVT_lib libraries as clock tree references.\n However, it restricts the lower-level block named TSK_BLK to use only the cells from the LVT_lib library for its clock nets.\n Therefore, only buf1 and buf2 cells from the LVT_lib library are used as clock references for that block.\n fc_shell> set_lib_cell_purpose -include cts \\ {HVT_lib/buf1 HVT_lib/buf2 LVT_lib/buf1 LVT_lib/buf2} fc_shell> set_target_library_subset -clock {LVT_lib} \\ -objects [TOP/TSK_BLK] fc_shell> set_app_options \\ -name opt.common.enable_target_library_subset_opt -value 1 359 Specifying the Clock Tree Synthesis Settings Feedback"}
{"instruction": "How do I Intra-shield Placement", "input": "", "output": "The custom.route.bus_intra_shield_placement application option specifies how the bus trunk will be shielded.\n Valid values are: Valid Value Description double_interleave Shields each wire individually.\n half_interleave Inserts shared shielding every two wires.\n interleave Inserts shared shielding between adjacent wires.\n outside (Default) Places shields on the outside of the trunk or group.\n 767 Using Custom Routing Application Options Feedback"}
{"instruction": "How do I Performing Preroute Shielding", "input": "", "output": "To provide the most protection for critical clock nets, perform shielding on those nets after clock tree routing but before signal net routing.\n To add shielding to the routed clock nets based on the assigned shielding rules, use the create_shields command.\n By default, the create_shields command Performs shielding on all nets that have predefined shielding rules, except those marked as frozen To explicitly specify the nets on which to perform shielding, use the -nets option.\n Does not perform shielding on wires that are less than four pitches long To specify the minimum wire length in microns on which to perform shielding for each layer, set the route.common.min_shield_length_by_layer_name application option.\n Use the following syntax to set this option: { { layer wire_length }...\n } Specify the routing layers by using the layer names from the technology file.\n If you do not specify a value for a layer, Zroute uses the default minimum length of four pitch lengths for that layer.\n Note: Wires that are less than the minimum length are not considered when computing the shielding ratio.\n 541 Shielding Nets Feedback Ties the shielding wires to the ground net If the block contains multiple ground nets or you want to tie the shielding wires to the power net, use the -with_ground option to specify the power or ground net to which to tie the shielding wires.\n If the shielding wires can be tied to multiple power or ground nets, specify the nets by setting the route.common.shielding_nets application option before running the create_shields command.\n Note: If you specify both the create_shields -with_ground option and the route.common.shielding_nets option, the tool issues a warning message and uses the route.common.shielding_nets setting.\n Performs same-layer shielding To perform coaxial shielding, use the -coaxial_above and -coaxial_below options.\n By default, the create_shields command leaves one routing track open between each used track.\n To change the default behavior, use one of the following methods: Specify the number of open tracks between coaxial shielding segments by using the following options: -coaxial_above_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding above the shielded net segment layer ( -coaxial_above true ).\n -coaxial_below_skip_tracks This option specifies the number of open tracks between used tracks for coaxial shielding below the shielded net segment layer ( -coaxial_below true ).\n For either of these options, you can specify an integer between zero and seven.\n Specify the number of open tracks between coaxial shielding segments on a per- layer basis by using the -coaxial_skip_tracks_on_layers option To disable shielding on a specific layer, set the value to -1; otherwise, specify an integer between 0 and 7 to specify the number of tracks to skip.\n Specify the spacing between coaxial shielding segments by using the following options: -coaxial_above_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding above the shielded net segment layer ( -coaxial_above true ).\n 542 Shielding Nets Feedback -coaxial_below_user_spacing This option specifies the spacing in microns between shielding segments for coaxial shielding below the shielded net segment layer ( -coaxial_below true ).\n You cannot use this method when performing incremental shielding.\n Note: You cannot mix these methods of specifying coaxial shielding.\n If the generated coaxial shielding wires violate minimum area or minimum length rules, Zroute automatically patches the wires to satisfy these design rules.\n Connects the shielding wires to the standard-cell power or ground pins and the standard-cell rails To prevent connections to the standard-cell power and ground pins, set the -ignore_shielding_net_pins option to true.\n To prevent connections to the standard-cell rails, set the -ignore_shielding_net_rails option to true Creates the shielding wires such that they surround the shielded routing shape To trim the shielding wires so that they align with the shielded routing shape ends, set the -align_to_shape_end option to true.\n To force Zroute to create shielding wires only in the preferred direction, set the -preferred_direction_only option to true Note that the -preferred_direction_only option does not honor route guides to change the preferred routing direction.\n When you set either of these options to true extra effort is required to connect the shielding wires to the power and ground network and any shielding wires that are not connected to the power and ground network are deleted.\n For example, to perform coaxial shielding below the shielded net segment layer on the clock nets, prevent signal routing below the shielded net segment layer, and tie the shielding wires to VSS, use the following command: fc_shell> create_shields -nets $clock_nets \\ -coaxial_below true -coaxial_below_skip_tracks 0 \\ -with_ground VSS When you run the create_shields command, it reports both the net-based and length- based average shielding ratios, as shown in the following example: Shielded 82% side-wall of (reset) Shielded 96% side-wall of (clk) Shielded 2 nets with average ratio as follows.\n 1) 89.00% (total shield ratio/number of shielded nets) 2) 87.92% (total shield length/total shielded net length) 543 Shielding Nets Feedback Note: In some cases there is a slight difference in the shielding ratios reported by the create_shields and report_shields commands.\n This is due to graph connectivity differences between the two commands.\n When the reported values differ, use the values reported by the report_shields command.\n The difference in reported values is typically less than three percent, but can be up to five percent.\n If you use the -preferred_direction_only true option when running the create_shields command, but Zroute must use some nonpreferred direction wires for shielding, the shielding ratio report specifies the percentage of nonpreferred direction wires.\n By default, the power and ground structure is not included in the shielding ratio calculation.\n To include the power and ground structure within a threshold distance in the shielding ratio calculation, set the route.common.pg_shield_distance_threshold application option, which specifies the distance threshold in microns.\n fc_shell> set_app_options \\ -name route.common.pg_shield_distance_threshold -value distance Note that this option affects only the shielding ratio calculation and does not change the routing behavior."}
{"instruction": "How do I Starting the CLI", "input": "", "output": "The CLI interface is a text-only environment in which you enter commands at the command-line prompt.\n It is typically used for scripts, batch mode, and push-button operations.\n Before you start the command-line interface, ensure that the path to the bin directory is included in your $PATH variable.\n To start fc_shell, Enter the fc_shell command in a Linux shell.\n fc_shell You can include other options on the command line when you start the shell.\n For example, you can use -file script_file_name to execute a script -x command to execute a command -output_log_file file_name to create a log file of your session -help to display a list of the available options (without starting the shell) At startup, the tool : 1.\n Creates a command log file.\n 2.\n Reads and executes the setup files.\n 3.\n Executes any script files or commands specified by the -file and -x options, respectively, on the command line.\n 4.\n Displays the program header and fc_shell> prompt in the shell.\n See Also Using the Command Log File Using Setup Files Using Tcl Scripts 45 Entering fc_shell Commands Feedback"}
{"instruction": "How do I Controlling Register Replication", "input": "", "output": "You can perform logic optimization by running the compile_fusion -to logic_opto command.\n To identify registers that you want the tool to replicate during logic optimization, use the set_register_replication command.\n This command sets the register_replication attribute on the specified registers and improves the timing by balancing fanout.\n During logic optimization, the specified registers are replicated and the loads of the original registers are evenly distributed among the new replicated registers when the -num_copies option is used.\n When you use the -max_fanout option, the tool computes the number of copies and attempts to distribute loads evenly without violating the maximum fanout constraints.\n You can control the number of copies that are created by using one of the following methods: Specify the total number of registers after replication, including the original, by using the -num_copies option.\n Specify the maximum fanout of the replicated registers by using the -max_fanout option.\n If you specify both options, the -max_fanout option is ignored.\n The following example specifies that the tool should replicate the regA and regB registers by creating one additional copy of each register: fc_shell> set_register_replication -num_copies 2 regA fc_shell> set_register_replication -num_copies 2 regB Figure 33 shows the regA and regB registers before and after optimization.\n Figure 33 Before and After Register Replication r1 r2 r3 Out1 Out2 r1 r2 r3 RegB regA RegA regB regA regB Out2 Out1 238 Controlling Mapping and Optimization Feedback You can include logic in the fanin or fanout of the specified register by using the -include_fanin_logic or -include_fanout_logic option.\n You can specify any startpoint in the fanin or endpoint in the fanout of the register.\n The following example specifies that the tool should replicate the A_reg register and the logic in the path from this register to the U1 cell: fc_shell> set_register_replication -num_copies 2 A_reg \\ -include_fanout_logic U1 To specify endpoint registers or primary output ports that must be driven by the original register after replication, as shown in Figure 34, use the -driven_by_original_register option.\n The following example specifies that after replication, the r0 register must drive the r1, r2, and r3 registers: fc_shell> set_register_replication -num_copies 3 r0 \\ -driven_by_original_register {r1 r2 r3} Figure 34 Using the -driven_by_original_register Option r0 r1 r2 r3 Out1 Out2 Out3 r0 r1 r2 r3 Out1 Out2 Out2 r0_rep1 r0_rep2"}
{"instruction": "How do I Multiple-Patterning Concepts", "input": "", "output": "At the 20-nm process node and below, printing the required geometries is extremely difficult with the existing photolithography tools.\n To address this issue, a new technique, multiple patterning, is used to partition the layout mask into two or more separate masks, each of which has an increased manufacturing pitch to enable higher resolution and better printability.\n Figure 4 shows an example of double-patterning, where the layout mask is partitioned into two separate masks, MASK A and MASK B.\n Figure 4 Double-Patterning Example To use multiple patterning, you must be able to decompose the layout into two or more masks, each of which meets the multiple-patterning spacing requirements.\n A multiple- patterning violation occurs if your layout contains a region with an odd number of neighboring shapes where the distance between each pair of shapes is smaller than the multiple-patterning minimum spacing.\n This type of violation, which is called an odd cycle is shown in Figure 5 41 Fusion Compiler Concepts Feedback Figure 5 Odd-Cycle Violation If the spacing between any pair in the loop is greater than the multiple-patterning minimum spacing, no violation occurs and the layout can be decomposed.\n For example, in Figure 6 if the spacing,, between segments B and C is greater than the multiple-patterning minimum spacing, there is no odd cycle and the layout can be decomposed.\n Figure 6 No Odd-Cycle Violation The Fusion Compiler tool ensures that the generated layout is conducive to double patterning by considering the multiple-patterning spacing requirements during placement and routing and preventing odd cycles.\n In general, double patterning is performed only on the bottom (lowest) metal layers, which are referred to as multiple-patterning layers.\n The metal shapes on the multiple-patterning layers must meet the multiple-patterning spacing requirements, whether they are routing shapes or metal within the standard cells and macros.\n The metal shapes on other layers do not need to meet the stricter multiple-patterning spacing requirements.\n 42 Fusion Compiler Concepts Feedback Multiple-patterning considerations affect all parts of the place and route flow.\n Depending on your standard cell library, you follow either an uncolored or precolored multiple- patterning flow.\n You use the uncolored flow if the cells in your standard cell library have sufficient spacing to the cell boundaries to ensure that multiple-patterning violations do not occur during placement.\n This type of library is referred to as a correct-by-construction library most multiple-patterning libraries are correct-by-construction libraries.\n In the uncolored flow, the tool determines the appropriate mask settings for the pins and net shapes.\n You use the precolored flow if the cells in your standard cell library have assigned masks on the metal shapes inside the cells.\n These assigned masks are often referred to as colors and this type of library is referred to as a precolored library In the precolored flow, the tool must consider these mask assignments to ensure that multiple-patterning violations do not occur during placement.\n The tool also uses the mask assignments to determine the appropriate mask settings for the pins and net shapes.\n The mask assignments are represented as mask constraints in the Fusion Compiler tool.\n You must ensure that the mask constraints are properly set before starting place and route.\n For information about the mask constraints, see Mask Constraints"}
{"instruction": "How do I Working With the 3DIC Compiler User Interfaces", "input": "", "output": "The Fusion Compiler tool operates in the X Window environment on Linux.\n IThe tool provides a flexible working environment with both a shell command-line interface and a GUI.\n The CLI is always available during a Fusion Compiler session.\n You can start or exit a session in either the shell or the GUI, and you can open or close the GUI during a session.\n The tool uses Tcl, which is used in many applications in the EDA industry.\n Using Tcl, you can extend the fc_shell command language by writing reusable procedures and scripts (see the Using Tcl With Synopsys Tools manual).\n The following topics describe how to start and exit the tool using the command-line interface.\n Starting the CLI Exiting the Fusion Compiler Tool For information about using the GUI, see the Fusion Compiler Graphical User Interface User Guide The following topics describe how to use the user interfaces of the Fusion Compiler tool: Starting the GUI Closing the GUI 44 Working With the 3DIC Compiler User Interfaces Feedback"}
{"instruction": "How do I Performing Multibit Optimization", "input": "", "output": "The Fusion Compiler tool can combine (bank) single-bit registers or smaller multibit registers and replace them with equivalent larger multibit registers.\n For example, the tool can combine eight 1-bit registers or four 2-bit register banks and replace them with one 8-bit register bank or two 4-bit register banks.\n The tool merges single-bit registers only if they have the same timing constraints, and it copies the timing constraints to the resulting multibit register.\n 243 Performing Multibit Optimization Feedback Figure 35 Replacing Multiple Single-Bit Register Cells With a Multibit Register Cell Two 1-bit register cells One 2-bit register cell Replace with SI SE SI SE SI SE Replacing single-bit registers with multibit registers reduces Area due to shared transistors and optimized transistor-level layout The total clock tree net length The number of clock tree buffers and clock tree power The tool can also split (debank) large multibit registers into smaller multibit registers or single-bit registers, if it improves the total negative slack.\n Some logic libraries have mixed-drive-strength multibit registers where some bits have a higher drive strength than others.\n For designs that use such cells, if a violating path goes through a lower-drive-strength bit, the tool can rewire the mixed-drive-strength multibit cell such that the violating path goes through a higher-drive-strength bit.\n 244 Performing Multibit Optimization Feedback"}
{"instruction": "How do I Inserting Via Ladders", "input": "", "output": "via ladder, which is also referred to as a via pillar, is a stacked via that starts from the pin layer and extends into an upper layer where the router connects to it.\n Via 446 Inserting Via Ladders Feedback ladders reduce the via resistance, which can improve performance and electromigration robustness.\n To use via ladders, Via ladder rules must be defined in the technology data for the design For information about defining via ladder rules, see Defining Via Ladder Rules You must insert the via ladders before you perform global routing The Fusion Compiler tool provides the following methods for inserting via ladders: Automatic insertion during preroute optimization, as described in Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization Constraint-based insertion by using the insert_via_ladders command, as described in Constraint-Based Via Ladder Insertion Manual insertion by using the create_via_ladder command, as described in Manual Via Ladder Insertion See Also Querying Via Ladders Removing Via Ladders Controlling Via Ladder Connections"}
{"instruction": "How do I UPF Flows", "input": "", "output": "The Fusion Compiler tool supports both the traditional UPF flow and the golden UPF flow.\n The golden UPF flow is an optional method of maintaining the UPF multivoltage power intent of the design.\n It uses the original \"golden\" UPF file throughout the synthesis, physical implementation, and verification steps, along with supplemental UPF files generated by the Fusion Compiler tool.\n 39 Fusion Compiler Concepts Feedback Figure 3 compares the traditional UPF flow with the golden UPF flow.\n Figure 3 UPF-Prime (Traditional) and Golden UPF Flows The golden UPF flow maintains and uses the same, original \"golden\" UPF file throughout the flow.\n The Fusion Compiler tool writes power intent changes into a separate \"supplemental\" UPF file.\n Downstream tools and verification tools use a combination of the golden UPF file and the supplemental UPF file, instead of a single UPF' or UPF'' file.\n The golden UPF flow offers the following advantages: The golden UPF file remains unchanged throughout the flow, which keeps the form, structure, comment lines, and wildcard naming used in the UPF file as originally written.\n You can use tool-specific conditional statements to perform different tasks in different tools.\n Such statements are lost in the traditional UPF-prime flow.\n Changes to the power intent are easily tracked in the supplemental UPF file.\n You can optionally use the Verilog netlist to store all PG connectivity information, making connect_supply_net commands unnecessary in the UPF files.\n This can significantly simplify and reduce the overall size of the UPF files.\n To enable the golden UPF flow, use the following application option setting before you load the UPF: fc_shell> set_app_options -as_user_default \\ -list {mv.upf.enable_golden_upf true} To load supplemental UPF files, use the -supplemental option with the load_upf command.\n For more information about using the golden UPF flow, see SolvNet article 1412864, \"Golden UPF Flow Application Note.\" 40 Fusion Compiler Concepts Feedback"}
{"instruction": "How do I Inserting Clock Drivers", "input": "", "output": "Before you insert clock drivers, Specify all clock tree synthesis settings, including clock routing rules Specify that the inserted clock drivers should be aligned with the clock straps of the mesh structure by setting the cts.multisource.enable_clock_driver_snapping application option to true During multisource clock tree synthesis, you can use the create_clock_drivers command for the following: Insert mesh drivers for both regular or structural multisource clock trees.\n Tap drivers for regular multisource clock trees.\n When you insert mesh or tap drivers, Specify the loads to drive by using the -loads option.\n The load can be a net or a set of pins or ports connected to the same net.\n Specify where to add the clock drivers as exact locations by using the -location option.\n Alternatively, you can add the clock drivers in an X by Y grid pattern over the entire core area by using the -boxes option.\n You can limit the X by Y grid pattern to a specific area by using the -boundary option with the -boxes option.\n Specify a list of cells that can be used as clock drivers by using the -lib_cells option.\n You can specify both single-rail and dual-rail library cells.\n Alternatively, you can select the existing driver of the load net as a template for the clock drivers by using the -template option.\n If the template cell you specify is a buffer or inverter, you can also specify different versions of this buffer or inverter as clock drivers by using the -lib_cells option with the -template option.\n When you insert mesh drivers, to specify that the outputs of all the clock drivers must be connected together to drive the mesh net, use the -short_outputs option.\n The following example creates a grid of eight by eight mesh drivers, places them in a regular pattern that covers the full core area, shorts the outputs of the clock drivers and connects to the net named clk_mesh, and transfers preexisting routing shapes and vias from the net named clk to this net: fc_shell> create_clock_drivers -loads [get_nets clk1_mesh] \\ -boxes {8 8} -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -short_outputs -output_net_name clk_mesh \\ -transfer_wires_from [get_nets clk] 410 Implementing Multisource Clock Trees Feedback The following example creates a grid of five by five tap drivers that are placed within the rectangle bounded at the lower-left by (200, 200) and upper right by (1000, 1000).\n fc_shell> create_clock_drivers -loads [get_nets clkA] -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -boxes {5 5} -boundary [list {{200 200} {1000 1000}} ] In this example, one of the tap drivers drives all the loads of the original clock net named clkA.\n To distribute the loads among all the clock drivers, you must subsequently perform automated multisource tap assignment by using the synthesize_multisource_clock_taps command, as described in Specifying Tap Assignment Options and Settings You can use the create_clock_drivers to add multiple levels of clock drivers by using the -configuration option and specifying the configuration of drivers at each level.\n The following example inserts three levels of clock drivers.\n The first level consists of one buffer, the second level consists of four inverters in a 2x2 grid, and the third level consists of 16 inverters in a 4x4 grid.\n fc_shell> create_clock_drivers -loads [get_nets clk] \\ -configuration [list \\ [list -level 1 -boxes {1 1} -lib_cells buf32x ] \\ [list -level 2 -boxes {2 2} -lib_cells inv16x ] \\ [list -level 3 -boxes {4 4} -lib_cells inv8x ]] For this example, because there is no bounding box specified at any level, the drivers at each level are evenly distributed in the core area.\n The buffer in the first level is placed at the center of the core area, the four buffers in the next level are placed at the center of the four quadrants of the core area, and so on, resulting in an evenly placed clock drivers that can be routed to form an H-tree structure as shown in Figure 88 Figure 88 Clock Drivers Placed in an H-Tree Structure After it inserts the clock drivers, the tool marks the clock drivers that it inserts as fixed and don't touched.\n The tool avoids overlapping the clock drivers with other fixed cells, blockages, and macros.\n However, the clock drivers can overlap with cells that are not 411 Implementing Multisource Clock Trees Feedback fixed.\n The create_clock_drivers command does not legalize the design.\n To do so, run the legalize_placement command.\n If you run the create_clock_drivers command multiple times, to reduce runtime, run the legalize_placement command one time, after you complete all the create_clock_drivers command runs.\n When routing the H-trees, the tool uses the highest routing layers available, based on the routing rules specified for the clock nets.\n These same layers can contain prerouted nets such as power and ground nets.\n To prevent placing clock drivers under these preroutes, which can cause pin accessibility issues, the create_clock_drivers command creates temporary placement blockages for the preroutes on the same layers it uses for routing.\n After it completes routing, it removes these temporary placement blockages, as shown in the following example output.\n...\n Net: clk; Rule: htree_ndr; Min Layer: M8; Max Layer: M9...\n Information: Using routing H/V layer pair 'M9'/'M8' for net 'clk'.\n (CTS-659)...\n Converting metal shapes in horizontal layer M9 and vertical layer M8 into placement blockages.\n In total 703 placement blockages created.\n...\n Successfully deleted all temporary placement blockages and the cell map.\n If you specify multirow-height cells with the -lib_cell option of the create_clock_drivers command, the tool might not be able to place them due to the temporary placement blockages it creates for the preroutes.\n If so, you can prevent the tool from creating the temporary placement blockages by setting the cts.multisource.enable_pin_accessibility_for_global_clock_trees application option to false To remove clock drivers inserted by the create_clock_drivers command, use the remove_clock_drivers command."}
{"instruction": "How do I Defining a Soft Placement Blockage", "input": "", "output": "To define a soft blockage, specify the boundary, type ( -type soft option), and optionally the name for the placement blockage.\n For example, to define a soft blockage enclosed by a rectangle with corners at (120, 75) and (230, 200), use the following command: create_placement_blockage -boundary {120 75 230 200} \\ -type soft A soft blockage prevents the initial placement from placing cells within the specified area, but allows legalization, optimization, and clock tree synthesis to do so.\n However, after placement and optimization, during subsequent incremental placement, the tool can move the cells added during legalization, optimization, and clock tree synthesis out of the soft blockage area.\n To prevent this, use the following application option setting: set_app_options -name place.coarse.enable_enhanced_soft_blockages \\ -value true 141 Specifying Physical Constraints for Placement and Legalization Feedback Note: Soft placement blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Defining Matching Wire Lengths", "input": "", "output": "To define a group of nets or pin-to-pin connections that must have the same wire length, use the create_wire_matching command.\n By matching wire lengths, you can minimize clock skews and timing violations.\n Two types of length-matching methods are available: Pin-based: Wire lengths between pins must match.\n Figure 157 and Figure 158 show examples of pin-based wire length matching.\n In both examples, all the receivers have a matched length constraint from driver D.\n Net-based: Total length of wires of specified nets must match.\n Figure 159 shows an example of net-based wire length matching.\n In the example, the total wire length of nets pr1 and pr2 are within the specified 10-um tolerance.\n Figure 157 Receivers With Matched Wire Length From Driver D 758 Defining Routing Constraints Feedback Figure 158 Receivers With Matched Wire Length From Driver D' Figure 159 Net-Based Wire Length Matching Syntax: fc_shell> create_wire_matching -for objects -tolerance float -match_type type -exclude objects -relative -driver pin or port -force intent_name Command or Options Description create_wire_matching Creates a length-matching constraint.\n -for Name of the driver pin or port ( Figure 157 and Figure 158 ), or net group ( Figure 159 ) that must comply with the constraint.\n -tolerance Length tolerance.\n The float value must be >= 0.\n To specify the tolerance as a percentage, use the -relative option.\n -relative (Optional) Interprets a -tolerance value <=1 as a percentage.\n The option must always be used with the -tolerance option.\n 759 Defining Routing Constraints Feedback Command or Options Description -match_type (Optional) Type of length matching.\n Valid values are: length : (Default) Compares the length of each object in the constraint group to make sure they have the same total length.\n length_per_layer : Compares the per-layer length.\n -exclude (Optional) Excludes the specified pins or ports from the length matching constraint.\n -driver (Optional) Name of the driver pin or port.\n -force (Optional) Overwrites the existing constraint.\n Use the option to delete existing constraint groups.\n intent_name (Optional) Name of the constraint.\n If you do not specify a name, the command assigns a name.\n By default, the command returns an error if the assigned name already exists.\n To delete an existing constraint, use the -force option.\n After routing, a matched-length summary report is generated.\n You can use the report to troubleshoot and resolve the lengths that do not meet the set tolerance.\n The content of the report depends on the -for option that you specified: If the -for option specifies pin-based length matching, a Length Constraint Report is generated.\n See Figure 160 If the -for option specifies net-based length matching, a Routed Length report is generated.\n See Figure 161 Figure 160 Pin-Based Length Matching Report 760 Defining Routing Constraints Feedback Figure 161 Net-Based Length Matching Report In Example 34, the commands create wire matching constraints for the scenario shown in Figure 157.\n All receivers (R) have a matched length constraint from the balanced driver (D).\n Example 34 Wire Matching Constraints for All Receivers to Driver D fc_shell> create_wire_matching -for [get_nets -physical_context $net] \\ -relative -tolerance 0.01 -driver [get_pins -physical_context D/o1] fc_shell> create_wire_matching -for [get_pins \\ -physical_context {R1/a R2/a R3/a}] -tolerance 0.01 -relative In Example 35, the commands create wire matching constraints for the example in Figure 158 Example 35 Wire Matching Constraints for Receivers Connected to Driver D' fc_shell> create_wire_matching -for [get_nets -physical_context $net] \\ -tolerance 0.01 -relative -driver $driver_full_name fc_shell> create_wire_matching \\ -for [get_pins -physical_context -of_objects $net] \\ -exclude $driver_full_name -tolerance 0.01 -relative In Example 36, the command creates a constraint group named abc for the nets and bundles that match the pattern pr*.\n An absolute tolerance of 10 um is set to match the length of each object in the constraint group.\n See Figure 159 Example 36 Wire Matching Constraints for pr* Nets fc_shell> create_wire_matching abc \\ -for [get_nets -physical_context pr*] \\ -tolerance 10 {abc} In Example 37, the command creates a constraint group named def for the nets and bundles that match the pattern pr*.\n A tolerance of 10 percent is set to match the length of each object in the constraint group.\n 761 Defining Routing Constraints Feedback Example 37 Wire Matching Constraints for pr* Nets With Percent Tolerance fc_shell> create_wire_matching def \\ -for [get_nets -physical_context pr*] \\ -tolerance 0.10 -relative {def} In Example 38, the command creates a wire matching constraint named clk_match for the clk net.\n Each of the endpoints that connect to the clk net has an individual matching constraint.\n Example 38 Wire Matching Constraints for the clk Net fc_shell> create_wire_matching -for [get_pins -physical_context \\ -of_objects [get_nets -physical_context {clk}]] \\ -tolerance 0.01 -match_type length_per_layer -relative \\ -force clk_match In Example 39, the command creates a wire matching constraint named clk_match2 for all the nets in the block, except the pins whose names match the keyword u1/a.\n Example 39 Wire Matching Constraints With Exclusions fc_shell> create_wire_matching -for $nets -tolerance 0.05 \\ -exclude [get_pins -physical_context u1/a] -force clk_match2 In Example 40, the script creates a net-based wire matching constraint for the scenario shown in Figure 162.\n The cell instance has an o1 terminal that servers as an inverter pin, driving signals on net1 and net1p to the pins.\n The I2 and I3 pins are excluded from the length matching constraint.\n Example 40 Net-Based Wire Matching Constraints With Pin Exclusions # set nets to match length set nets [get_nets -physical_context {net1 net1p}] # set allowed layers set_routing_rule -min_routing_layer m7 -max_routing_layer m8 \\ -min_layer_mode allow_pin_connection -max_layer_mode hard $nets # setup Custom Router wire match constraint set exclude_pin_names [get_pins -physical_context {i2/a i3/a}] create_wire_matching -for $nets -tolerance 0.01 -relative \\ -exclude $exclude_pin_names # run Custom Router route_custom -nets $nets 762 Managing Constraint Groups Feedback Figure 162 Net-Based Wire Matching Constraints With Pin Exclusions"}
{"instruction": "How do I Synthesizing the Global Clock Trees", "input": "", "output": "Before you insert clock drivers, ensure that all clock tree synthesis settings, including clock routing rules, are specified.\n To perform clock tree synthesis and detail routing to build an H-tree style global clock tree, use the synthesize_multisource_global_clock_trees command.\n When building the H-tree, the tool tries to minimize the skew between the endpoints, which is essential for multisource clock tree synthesis.\n When you use this command to synthesize and detail route a global clock tree, you must specify The clock net to synthesize by using the -nets option.\n The library cells to use by using the -lib_cells option.\n You can specify both single- rail and dual-rail library cells.\n By default, the tool uses the Custom Router to route the H-tree structure and connect to the pins of the clock tree cells.\n If the Custom Router is unable to resolve all routing DRC violation when making pin connections, use the Zroute to make the pin connections by using the -use_zroute_for_pin_connections options.\n To stop the routes at the highest available metal layer close to the pin shape, use the -skip_pin_connections option.\n The following example synthesizes and detail routes a global clock tree for the clock net named clkA.\n fc_shell> synthesize_multisource_global_clock_trees \\ -nets [get_nets clkA] -lib_cells [get_lib_cells my_lib/CKBUF8X] \\ -use_zroute_for_pin_connections You can also use the synthesize_multisource_global_clock_trees command to only perform clock detail routing for an H-tree style clock structure that has already been synthesized.\n 413 Implementing Multisource Clock Trees Feedback When doing so, you must specify The startpoint of the global clock structure, by using the -roots option.\n The endpoints of the global clock structure by using the -leaves option.\n The following example detail routes an existing H-tree style clock structure.\n The startpoint is the port named clk1 and the endpoints are the inputs of a group of mesh drivers.\n fc_shell> synthesize_multisource_global_clock_trees \\ -roots [get_ports clk1] -leaves [get_pins mesh_buf*/A] \\ -use_zroute_for_pin_connections When routing the H-trees, the tool uses the highest routing layers available, based on the routing rules specified for the clock nets.\n These same layers can contain prerouted nets such as power and ground nets.\n To prevent placing clock drivers under these preroutes, which can cause pin accessibility issues, the synthesize_multisource_global_clock_trees command creates temporary placement blockages for the preroutes on the same layers it uses for routing.\n After it completes routing, it removes these temporary placement blockages, as shown in the following example output.\n...\n Net: clk; Rule: htree_ndr; Min Layer: M8; Max Layer: M9...\n Information: Using routing H/V layer pair 'M9'/'M8' for net 'clk'.\n (CTS-659)...\n Converting metal shapes in horizontal layer M9 and vertical layer M8 into placement blockages.\n In total 703 placement blockages created.\n...\n Successfully deleted all temporary placement blockages and the cell map.\n If you specify multirow-height cells with the -lib_cell option of the synthesize_multisource_global_clock_trees command, the tool might not be able to place them due to the temporary placement blockages it creates for the preroutes.\n If so, you can prevent the tool from creating the temporary placement blockages by setting the cts.multisource.enable_pin_accessibility_for_global_clock_trees application option to false To remove a clock structure created by the synthesize_multisource_global_clock_trees command, use the remove_multisource_global_clock_trees command.\n 414 Implementing Multisource Clock Trees Feedback"}
{"instruction": "How do I Enabling the Power Integrity Features", "input": "", "output": "The Fusion Compiler tool provides the following techniques for ensuring power integrity of the design: Dynamic power shaping (DPS), which reduces transient power by utilizing concurrent clock and data optimization (useful skew) techniques.\n Voltage-drop-aware placement, which use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values to reduce the power density of such areas.\n 195 Setting Up for Power-Related Features Feedback To set up for the recommended power integrity flow, perform the following steps: 1.\n Enable the power integrity flow by setting the opt.common.power_integrity application option to true When you do so, the Fusion Compiler uses the following techniques during the different stages of the design flow: a.\n Dynamic power shaping (DPS) during the final_opto stage of the compile_fusion command b.\n Voltage-drop-aware placement during the clock_opt command 2.\n (Optional) Specify that the tool should not reduce the voltage drop at the expense of the timing QoR by reducing the power integrity effort level by setting the opt.common.power_integrity_effort application option to low The default is high, and by default the tool tries to reduce the voltage drop to less than eight percent of the supply voltage at the expense of the timing QoR.\n 3.\n (Optional) Specify a maximum voltage drop threshold by using the opt.common.ir_drop_threshold application option.\n The default is eight percent of the supply voltage.\n If you change the default effort level by setting the opt.common.power.integrity_effort application option to low the tool ignores the threshold specified with the opt.common.ir_drop_threshold application option.\n 4.\n Specify settings for dynamic power shaping as described in Setting Up for Dynamic Power Shaping 5.\n Specify settings for voltage-drop-aware placement as described in Setting Up for Voltage-Drop-Aware Placement 6.\n (Optional) Enable IR-driven sizing, which uses the RedHawk dynamic voltage drop analysis results to identify cells involved in voltage drop violations, and then tries to replace those cells with cells having smaller leakage current.\n To enable this feature, set the clock_opt.flow.enable_irdrivenopt application option to true, in addition to setting the opt.common.power_integrity application option to true Instead of using the recommended power integrity flow setting, you can manually enable dynamic power shaping or voltage-drop-aware placement for the compile_fusion or clock_opt commands as described in Manually Enabling Dynamic Power Shaping and Voltage-Drop-Aware Placement 196 Setting Up for Power-Related Features Feedback"}
{"instruction": "How do I Analyzing Multivoltage Information", "input": "", "output": "To ensure that the design does not have any multivoltage design violations, use the check_mv_design command.\n You can restrict the types of rules to check with the check_mv_design command.\n For example, the -isolation option specifies to check isolation strategy and isolation cell rules, while the -pg_pin option specifies to check rules associated with PG pins.\n To report multivoltage information for your design, use the commands shown in the following table.\n 132 Specifying Timing Constraints and Settings Feedback Table 6 Commands for Reporting Multivoltage Information To do this Use this command Report a summary of multivoltage information report_mv_design Report information about the multivoltage cells report_mv_cells Report information about the multivoltage library cells report_mv_lib_cells Report paths with multivoltage constraints and the associated multivoltage cells report_mv_path Report the power domains report_power_domains Check whether the specified power domains are equivalent check_equivalent_power_domains Display a list of equivalent power domains get_equivalent_power_domains Report the voltage areas report_voltage_areas"}
