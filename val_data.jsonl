{"instruction": "How do I Using Tcl Scripts", "input": "", "output": "To display the man page for a Fusion Compiler command or application option, enter the man command followed by the command or application option name. For example, to see the man page for the report_timing command, use the following command: fc_shell> man report_timing To display the man page for a Fusion Compiler application option, enter the man command followed by the option name. You can also view the following types of summary pages for application options: Category summaries To view a man page that summarizes all of the application options for a specific category, enter the man command followed by category _options. For example, to see the man page that summarizes all timer application options, use the following command: fc_shell> man timer_options Subcategory summaries To view a man page the summarizes all of the application options for a specific subcategory, enter the man command followed by category subcategory _options. For example, to see the man page that summarizes all common route application options, use the following command: fc_shell> man route.common_options Command summaries To view a man page the summarizes all of the application options for a specific command, enter the man command followed by command _options. For example, to see the man page that summarizes all application options that affect the report_timing command, use the following command: fc_shell> man report_timing_options If you enter the man command on the fc_shell command line, the man page is displayed in the Fusion Compiler shell and in the console log view if the GUI is open. If you enter this command on the console command line in the GUI, the man page is displayed in the GUI man page viewer."}
{"instruction": "How do I Adding Leaf Cells", "input": "", "output": "After you create a relative placement group by using the create_rp_group command, you can add the following types of objects to it by using the add_to_rp_group command: Leaf cells, as described in Adding Leaf Cells Leaf cells, as described in Adding Hard Macro Cells Relative placement groups, as described in Adding Relative Placement Groups Blockages, as described in Adding Blockages When you add an object to a relative placement group, The relative placement group to which you are adding the object must exist. The object must be added to an empty location in the relative placement group. Only one object can be added in one location of relative placement group. To remove objects from a relative placement group, use the remove_from_rp_group command. You can remove leaf cells ( -cells ), relative placement groups ( -rp_group ), and blockages ( -blockage ). When you remove objects from a group, the space previously occupied by the removed objects is left unoccupied."}
{"instruction": "How do I Recording the Changes Made to a Layout", "input": "", "output": "To update the supply nets for ECO cells, use the eco_update_supply_net command. By default, it updates the supply nets for all cell added by using the following ECO commands: size_cell in freeze-silicon mode add_buffer add_eco_repeater split_fanout add_buffer_on_route To update the supply nets for specific cells, use the eco_update_supply_net -cells command."}
{"instruction": "How do I Specifying Logical Design Rule Constraints", "input": "", "output": "Timing constraints describe the timing requirements of a design. An essential part of timing constraints are accurately specified clocks and clock effects, such as latency and uncertainty. When you specify clocks, the tool automatically constrains the paths between the registers driven by these clocks. However, you can change the default behavior of these timing paths by specifying timing exceptions such as paths that should not be analyzed (false paths), paths that require multiple clock cycles (multicycle paths), and so on. In addition, you can constrain the boundary timing paths by specifying input and output delays for input and output ports. The Fusion Compiler tool uses on-chip variation (OCV) mode to perform timing analysis, which models the effects of variation in operating conditions across the chip. This mode performs a conservative timing analysis that allows both minimum and maximum delays to apply to different paths at the same time. For a setup check, it uses maximum delays for the launch clock path and data path and minimum delays for the capture clock path. For a hold check, it uses minimum delays for the launch clock path and data path and maximum delays for the capture clock path. A block might operate under several different conditions, such as different temperatures and voltages, and might operate in several different functional modes. For timing analysis, each set of conditions is represented by a corner and each functional mode is represented by a mode. A scenario is a combination of a corner and mode used to perform timing analysis and optimization. Before you start working with a block, you must define the modes, corners, and scenarios that are used for the block, as well as the delay calculation model and routing layers to use. The routing layer information you specify is used for RC estimation during timing analysis. For detailed information about specifying Clock and clock effects, see the \"Defining Clocks\" topic in the Fusion Compiler Timing Analysis User Guide Exceptions for timing paths and constraints for boundary paths, see the \"Constraining Timing Paths\" topic in the Fusion Compiler Timing Analysis User Guide Modes, corners, and scenarios, see the \"Defining Modes, Corners, and Scenarios\" topic in the Fusion Compiler Timing Analysis User Guide Operating conditions and on-chip variation (OCV) related settings, see the \"Specifying Operating Conditions\" topic in the Fusion Compiler Timing Analysis User Guide Parasitic information for RC estimation and extraction, see the \"Performing Parasitic Extraction\" topic in the Fusion Compiler Timing Analysis User Guide Routing layers, see Specifying the Routing Resources"}
{"instruction": "How do I Checking and Fixing Isolated Vias", "input": "", "output": "To check for isolated vias without fixing them, run the signoff_fix_isolated_via command with the -check_only true option. fc_shell> signoff_fix_isolated_via -check_only true When run you run the signoff_fix_isolated_via command in check-only mode, it generates a summary report that specifies the number of isolated vias detected on each via layer."}
{"instruction": "How do I Deriving Pin Access Routing Guides", "input": "", "output": "Routing guides provides routing directives for specific areas of a block. Some types of routing guides are user-defined; others are derived from the block data. This topic described how to derive the following types of routing guides: Deriving Pin Access Routing Guides Deriving Metal Cut Routing Guides See Also Defining Routing Guides"}
{"instruction": "How do I Prerequisites for Handling Early Design Data", "input": "", "output": "While you identify the issues related to top-level closure and fix them, the tool enables you to explore the top-level flow in the presence of design data violations. The hierarchical checks can detect different types of mismatched, incomplete, and inconsistent data in designs. You can configure the following policies for the hierarchical checks to manage the design data violations: Error: When you apply this policy, the tool does not mitigate the violation, but issues an error message. Tolerate: When you apply this policy, the tool makes predictable and explainable assumptions to continue with the flow. No changes are made to the design or setup. Repair: When you apply this policy, the tool mitigates the violation using one or more repair strategies and records it. Repair can include changes in design and setup. Strict: When you apply this policy, depending on the policy supported by the check, the tool applies the policies in this order \u2013 error, tolerate, repair. Lenient: When you apply this policy, depending on the policy supported by the check, the tool applies the policies in this order \u2013 repair, tolerate, error. Note: Quality of results of the top-level flow might get impacted due to the toleration and repair of errors. Error toleration and repair is mainly provided for managing data violations during the early design exploration phases. In the implementation flow, you should use the strict policy for all checks."}
{"instruction": "How do I Restricting Library Cell Usage", "input": "", "output": "Library configuration allows you to specify which vendor libraries to use as reference libraries for the current design. You specify the technology file, physical libraries, and logic libraries by using the search_path and link_library variables, and then you use the create_lib or set_ref_libs command to assemble the cell libraries. During library configuration, The Fusion Compiler tool automatically calls the Library Manager tool without user intervention to generate cell libraries, as shown in the following figure:.frame files ASCII technology file.db files Cell libraries Synthesis The tool saves the generated cell libraries to disk and adds them to the reference library list of the design library. These cell libraries are the same as when the cell libraries are created during library preparation in the Library Manager tool. For more information, see the Configuring Cell Libraries topic in the Fusion Compiler Data Model User Guide"}
{"instruction": "How do I Performing Test Insertion and Scan Synthesis", "input": "", "output": "To transfer the clock latencies and balance points from the front-end tool to the back-end tool, use the write_ascii_files command. The command writes the design.MCMM directory, which contains timing contexts in Tcl files for. For example, The design.MCMM/scenario_ scenario.tcl file contains the following clock latency settings: set_clock_latency -clock [get_clocks {CLK}] -0.3 [get_pins {d_reg[4]/CP}] set_clock_latency -clock [get_clocks {CLK}] 0.1 [get_pins {d_reg[7]/CP}] The design.MCMM/mode_ mode.tcl file contains the following balance points: set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[4]/CP}] \\ -consider_for_balancing true \\ -rise -delay 0.3 -corners [get_corners {default}] set_clock_balance_points -clock [get_clocks {CLK}] \\ -balance_points [get_pins {d_reg[7]/CP}] \\ -consider_for_balancing true -rise -delay -0.1 -corners [get_corners {default}]"}
{"instruction": "How do I Setting Up for Self-Gating", "input": "", "output": "To perform self-gating, the logic library should contain AND and OR gates to build the self- gating tree. The library should also contain XOR, NAND, and OR gates for the comparator gate. The integrated clock-gating cells in the library must have the following settings: Sequential cell: latch Control point: before Control signal: scan_enable Observation point: none If the library does not contain cells with these configurations for the corresponding operating conditions, the tool does not insert self-gating cells. If an integrated clock gate compatible with self-gating is specified by the set_clock_gate_style command, the self- gating feature uses the same integrated clock gate or the clock gate that is most similar to the one specified."}
{"instruction": "How do I Merging Voltage Area Shapes", "input": "", "output": "A voltage area is a physical placement area for the cells associated with a power domain. For multivoltage designs, the power domains are defined in the UPF specification. For single-voltage designs, the tool creates a default power domain when you read the Verilog netlist and associates it with a default voltage area, which comprises the core area of the block. The placer treats a voltage area the same as an exclusive move bound; it must place the cells in a voltage area within a specified region and it must place all other cells outside of the voltage area. Voltage areas can be rectangular or rectilinear. In addition, they can be disjoint, nested, or overlapping. For overlapping voltage areas, the effective shape of each voltage area is determined by the stacking order of the voltage area shapes. To define a voltage area, use the create_voltage_area command. When you define a voltage area, at a minimum, you must specify the power domains associated with the voltage area. To specify the power domains, use the -power_domains option. You can specify one or more power domains; however, all specified power domains must have the same primary supply net. If you specify a single power domain, the name of the voltage area is derived from the name of the power domain. If you specify multiple power domains, you must specify a name for the voltage area by using the -name option. A voltage area consists of one or more rectangular or rectilinear shapes, which can be abutted, disjoint, or overlapping. To define the boundaries of these shapes, use the -region option with the create_voltage_area command (if you are creating a new voltage area) or the create_voltage_area_shape command (if you are adding shapes to an existing voltage area). Note that you can specify one or more shapes when using the create_voltage_area command, but only a single shape in each create_voltage_area_shape command. To specify the boundary of a rectangle shape, use the following format to specify its lower-left and upper-right corners: {{ llx lly } { urx ury }} To specify the boundary of a rectilinear shape, use the following format to specify the coordinates of its vertices: {{ x1 y1 } { x2 y2 } { x3 y3 } { x4 y4 }...} If a voltage area consists of multiple abutting or overlapping shapes, you can merge the shapes into a minimum set of disjoint shapes based on the stacking order of the shapes. For information about how to merge the voltage area shapes, see Merging Voltage Area Shapes The tool also uses the stacking order to resolve overlapping shapes from different voltage areas. For information about resolving overlapping voltage areas, see Resolving Overlapping Voltage Areas To ensure that no shorts occur at the boundaries of the voltage areas, you can define guard bands for the voltage areas, which act as hard keepout margins surrounding the voltage areas. If you define guard bands for a voltage area shape, the guard bands are included in the effective boundary of the shape; however, they are not included in the effective placement area of the voltage area. For information about defining guard bands, see Defining Guard Bands To modify an existing voltage area, use the set_voltage_area command, as described in Modifying Voltage Areas Multivoltage designs typically have power domains that are shut down and powered up during the operation of the chip while other power domains remain powered up. When dealing with shutdown domains, there can be some situations in which certain cells in the shutdown portion need to continuously stay active, such as for implementing retention registers, isolation cells, retention control paths, and isolation enable paths. These cells are referred to as always-on cells. To define a special placement area for always-on cells (an always-on well) within a voltage area, define an exclusive move bound within the boundary of the voltage area. For information about defining exclusive move bounds, see Defining Move Bounds After creating the voltage areas, run the check_mv_design command to verify that the design does not have any multivoltage violations."}
{"instruction": "How do I Specifying the Clock Tree Synthesis Settings", "input": "", "output": "The Fusion Compiler tool supports the following design rule constraints for clock tree synthesis: clock tre synthesismaximum capacitanceclock tre design rule constraintmaximum capacitance Maximum capacitance To specify maximum capacitance constraints for clock tree synthesis, use the -clock_path option with the set_max_capacitance command. If you do not specify this constraint, the clock tree synthesis default is 0.6 pF. clock tre synthesismaximum transition timeclock tre design rule constraintmaximum transition time Maximum transition time To specify maximum transition time constraints for clock tree synthesis, use the -clock_path option with the set_max_transition command. If you do not specify this constraint, the clock tree synthesis default is 0.5 ns. By default, these constraints apply to all corners associated with the current mode. To set the constraint for a specific mode, use the -mode option with the get_clocks command to identify the clocks. To set the constraint for specific corners associated with the specified mode, use the -corners option with the constraint command. Be careful to apply the correct constraints across all the modes and their associated corners. For example, to set a maximum transition time of 0.20 ns on all pins in the CLK clock path for all corners of the current mode, use the following command: fc_shell> set_max_transition 0.20 -clock_path [get_clocks CLK] To set different maximum transition time constraints for different corners associated with a specific mode, use the -mode option with the get_clocks command to specify the mode and use the -corners option to specify the corner. For example, to set the maximum transition time to 0.15 ns for corner1 in mode1 and 0.10 ns for corner2 in mode1, use the following commands: fc_shell> set_max_transition 0.15 -corners corner1 \\ -clock_path [get_clocks -mode mode1] fc_shell> set_max_transition 0.10 -corners corner2 \\ -clock_path [get_clocks -mode mode1] To set the same maximum capacitance constraint for different corners associated with a specific mode, use the following command: fc_shell> set_max_capacitance 0.6 \\ -clock_path [get_clocks -mode mode2] \\ -corners [get_corner \\ [get_attribute [get_modes mode2] associated_corners]]"}
{"instruction": "How do I Viewing Man Pages", "input": "", "output": "In general, the Fusion Compiler tool modifies default behavior by using application options rather than application variables; however it does support user-defined Tcl variables, as well as a minimal number of application variables, such as the search_path variable. To list the variables and their values, use the printvar command. For example, to list all variables defined in the current session, use the following command: fc_shell> printvar * To print the value of the search_path variable, use the following command: fc_shell> printvar search_path See Also Defining the Search Path"}
{"instruction": "How do I Clock-Gating Setup Condition", "input": "", "output": "The enable condition of a register or clock gate is a combinational function of nets in the design. The enable condition of a register represents the states for which a clock signal must be passed to the register. The enable condition of a clock gate corresponds to the states for which a clock is passed to the registers in the fanout of the clock gate. The tool uses the enable condition of the registers for clock-gate insertion. Enable conditions are represented by Boolean expressions for nets. For example: module TEST (en1, en2, en3, in, clk, dataout); input en1, en2, en3, clk; input [5:0] in; output [5.0] dataout; reg [5.0] dataout; wire enable; assign enable = (en1 | en3) & en2; always @( posedge clk ) begin if( enable ) dataout <= in; else dataout <= dataout; end endmodule In this example, the enable condition for the register bank dataout_reg* can be expressed as en1 en2 + en3 en2."}
{"instruction": "How do I Verifying the Boundary Cell Placement", "input": "", "output": "The Fusion Compiler tool provides several methods for inserting boundary cells, depending on where you want to insert the boundary cells. To insert boundary cells around the core area, hard macros, and placement blockages, use the compile_boundary_cells command. To insert boundary cells only around one or more voltage areas, use the compile_boundary_cells command with the -voltage_area option. To insert boundary cells only around specific objects, use the compile_targeted_boundary_cells command with the -target_objects option. You can use this command to insert boundary cells around specific macros, voltage areas, voltage area shapes, placement blockages, routing blockages, and the core area. The set_boundary_cell_rules command configures boundary cell insertion for both the compile_boundary_cells and compile_targeted_boundary_cells commands. However, some rules are honored only by the compile_boundary_cells command. For details, see Specifying the Boundary Cell Insertion Requirements"}
{"instruction": "How do I Getting Information About Commands", "input": "", "output": "If you enter the wrong options for a command or enter the wrong command, you can interrupt command processing and remain in fc_shell. interupting comandscomandsinteruptingterminatingterminating comands To interrupt or terminate a command, press Ctrl+C. Some commands and processes cannot be interrupted. To stop these commands or processes, you must terminate fc_shell at the system level. When you terminate a process or the shell, no data is saved. When you use Ctrl+C, keep the following points in mind: If a script file is being processed and you interrupt one of its commands, the script processing is interrupted and no further script commands are processed. If you press Ctrl+C three times before a command responds to your interrupt, fc_shell is interrupted and exits with this message: Information: Process terminated by interrupt."}
{"instruction": "How do I Clock-Gate Collapsing", "input": "", "output": "It is difficult to determine the optimum number of clock-gate levels manually. The Fusion Compiler tool can analyze all clock gates and insert additional clock gates to take advantage of shared enable signals. Inserting additional clock gates might improve power, area, or other metrics, depending on the design. If six or more clock gates share an enable signal, the tool inserts an additional level of clock gates. The new clock gates are then considered for further level expansion. As a result, the tool might insert multiple levels of clock gates during this operation. To allow the tool to expand the number of clock-gate levels, set the compile.clockgate.enable_level_expansion application option to true (the default is false ) and set the compile.clockgate.max_number_of_levels application option to a nonzero value (the default is 0). In this case, the tool adds clock gates until either of the following conditions is met: All common enable signals are identified and used for multilevel clock-gate expansion. The user-specified maximum number of clock-gate levels is reached. The tool names a newly-inserted clock gate as follows, based on the status of the set of clock gates whose enable functions are modified by the new clock gate: If at least one of the clock gates is a tool-inserted clock gate, the base name is clock_gate_ml. The name is appended with the register base name, similar to the naming convention for other tool-inserted clock gates. If all of the clock gates are preexisting clock gates, the tool uses the name of the preexisting clock gate with the largest fanout and appends _ml_pe The compile.clockgate.max_number_of_levels application option specifies the maximum number of allowed clock-gate levels. The default is 0, which allows an infinite number of levels. However, to use the clock-gate level expansion capability, you must set this application option to a nonzero value (in addition to setting the compile.clockgate.enable_level_expansion application option to true ). If you specify clock-gate level expansion, but the maximum number of allowed levels is low, the expansion operation cannot take full advantage of the tool's ability to analyze common enable signals. To enable or disable clock-gate level expansion for specific clock gates, use the set_clock_gate_transformations -expand_levels command. The following usage notes apply: New clock gates inherit the constraints set by the set_clock_gate_transformations set_clock_gate_style set_dont_touch set_size_only set_lib_cell_purpose and set_boundary_optimization commands. Clock-gate latency estimations are updated after the insertion operation. When the insertion operation modifies the enable signal of a clock gate, the gate retains its original designation of being either preexisting or tool-inserted. Self-gating is restricted from adding another clock-gate level if the maximum number of levels is already reached. Integrated clock gates inside multibit cells are counted as part of the clock-gate level count. However, they are not candidates for clock-gate level expansion. New clock gates do not inherit timing exceptions."}
{"instruction": "How do I Automatically Adding Spare Cells", "input": "", "output": "You can manually instantiate spare cells in a block by using one of the following methods: Instantiating them in the Verilog netlist Adding them by using netlist editing commands such as create_cell connect_pin s, and so on When manually instantiating spare cells, you should Evenly distribute the spare cells through the logical hierarchy to better handle ECO changes anywhere in the block Tie their inputs to power or ground, as appropriate, to prevent the spare cells from creating noise and consuming power If a cell meets the following criteria, the tool automatically identifies it as a spare cell: It is not a physical-only cell All inputs except for the clock pin are unconnected or tied to a logic constant The clock pin of the spare cell, if any, can be connected to the clock network. All outputs are unconnected If you instantiate the spare cells before you perform physical synthesis on a block, the tool places and legalizes the spare cells during the subsequent physical synthesis steps. However, if you instantiate the spare cells in a block that is optimized, placed and legalized, you must place and legalize the spare cells by using the following steps: 1. Spread the spare cells by using the spread_spare_cells command. By default, this command distributes and places all the spare cells evenly throughout the core area. You can specify the spare cells to place by using one of the following two methods: To place specific spare cells, use the -cells option. To place all the spare cells that belong to specific voltage areas, use the -voltage_areas option. You can control the placement of the spare cells as follows: Specify an area within which to place the spare cells by using the -boundary option. Ignore specific types of placement blockages by using the -ignore_blockage_types option. By default, the add_spare_cells command honors all placement blockage types. Ignore the current cell density and place the spare cells randomly by using the -random_distribution option. Specify a percentage of spare cells to be placed based on the cell density distribution by using the -density_aware_ratio option. The rest of the spare cells are placed randomly throughout the design. By default, all the spare cells are placed based on the cell density distribution. For example, if you specify a setting of -density_aware_ratio 80, the tool places 80 percent of the spare cells based on the cell density distribution and 20 percent randomly across the design. 2. Legalize the spare cells by using the place_eco_cells -legalize_only -cells command."}
{"instruction": "How do I Deriving Clock Tree Exceptions From Ideal Clock Latencies", "input": "", "output": "You can specify that the tool copies clock tree exceptions from one mode to one or more equivalent modes by using the set_clock_tree_options command with the -copy_exceptions_across_modes -from_mode, and -to_mode options. The following example specifies that during clock tree synthesis the clock tree exceptions in the mode name M1 should be copied to the modes name M2 and M3: fc_shell> set_clock_tree_options -copy_exceptions_across_modes \\ -from_mode M1 -to_mode {M2 M3}"}
{"instruction": "How do I Using Routing Guides to Control the Routing Density", "input": "", "output": "You can use a routing guide to limit the number of occurrences of a specific routing pattern within the routing guide boundary on specific layers. Zroute tries to route the nets within the routing guide to meet this constraint; however, if the number of edges in the nonpreferred direction exceeds the specified threshold, Zroute reports a violation. To create this type of routing guide, use the -max_patterns option with the create_routing_guide command. Use the following syntax to specify the routing pattern and its threshold for each affected layer: { { layer pattern limit }... } In addition to using the -max_patterns option, you must also use the -layers option when you create this type of routing guide. Specify the same layers in the -layers option as those specified in the -max_patterns option. If you do not specify a pattern threshold for a layer, the routing pattern has no limit for that layer. Currently, the only supported pattern is non_pref_dir_edge, which represents the edges in the nonpreferred direction. For example, to limit the number of edges in the nonpreferred direction to two on M2 and to three on M4, with no limits on other layers, use the following command: fc_shell> create_routing_guide -boundary {{50 50} {200 200}} \\ -max_patterns {{M2 non_pref_dir_edge 2} {M4 non_pref_dir_edge 3}} \\ -layers {M2 M4}"}
{"instruction": "How do I Timing Driven Sink Transition Target", "input": "", "output": "I/O ports are usually constrained using real or virtual clocks. After clock tree synthesis, the latencies of the clocks constraining the I/O ports need to be updated to ensure that the boundary constraints are accurate. When you run clock tree synthesis with the clock_opt command, the tool automatically updates the latencies of the clocks constraining the I/O ports. You can control these latency adjustments by using the set_latency_adjustment_options command. The following example specifies that the clock latencies of the VCLK1 and VCLK2 clocks should be updated based on the latency of the PC_CLK clock, and that the latency of the VCLK3 clock should not be updated: fc_shell> set_latency_adjustment_options \\ -reference_clock PC_CLK -clocks_to_update {VCLK1 VCLK2} \\ -exclude_clocks VCLK3 If you perform clock tree synthesis with the synthesize_clock_trees command, the tool does not automatically update the clock latencies. To do so, use the compute_clock_latency command after clock tree synthesis. This command honors the settings you specify with the set_latency_adjustment_options command."}
{"instruction": "How do I Controlling Pin Tapering", "input": "", "output": "By default, Zroute connects a signal route to a pin by using wires or vias anywhere on the pin. To restrict the allowed types of pin connections on a per-layer basis, use the following syntax to set the route.common.connect_within_pins_by_layer_name application option: set_app_options -name route.common.connect_within_pins_by_layer_name -value { { layer mode }... } Valid values for the mode argument are off (the default) There are no restrictions on pin connections. via_standard_cell_pins Only the connections to standard cell pins by using a via are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. There are no restrictions on signal routes connected to macro cell and pad cell pins by using a via or to any pins by using wires. via_wire_standard_cell_pins The connections to standard cell pins by using a via or a wire are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. When using a wire, the wire must be contained within the pin shape. via_all_pins The connections to any pins (standard cell, macro cell, or pad cell) by using a via are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. There are no restrictions on signal routes connected to any pins by using wires. via_wire_all_pins The connections to any pins by using a via or a wire are restricted. When using a via connection, the via's metal enclosure must be contained within the pin shape. When using a wire, the wire must be contained within the pin shape. For example, if you use the following command (or use the default settings), all of the connections shown in are valid and no DRC violations are reported: fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 off}} Unrestricted Pin Connections If you set the mode for M1 to via_all_pins, as shown in the following example, the via enclosures must be inside the pin shape. The connections shown on the left side of are valid; however, the connections on the right side of the figure cause DRC violations. fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_all_pins}} Restricted Via-to-Pin Connections No DRC Violations DRC Violations If you set the mode for M1 to via_wire_standard_cell_pins, as shown in the following example, both the via enclosures and wires must be inside the pin shape. The connections shown on the left side of are valid; however the connections on the right side of the figure cause DRC violations. fc_shell> set_app_options \\ -name route.common.connect_within_pins_by_layer_name \\ -value {{M1 via_wire_standard_cell_pins}} Restricted Via-to-Pin and Wire-to-Pin Connections DRC Violations No DRC Violations"}
{"instruction": "How do I Avoiding Overlapping Repeaters With Existing Tap Cells", "input": "", "output": "Use the -lib_cell option to specify a library cell as a repeater. This option supports the following additional options: -lib_cell_input specifies the input pin of the library cell to connect, if it has multiple inputs. -lib_cell_output specifies the output pin of the library cell to connect, if it has multiple outputs."}
{"instruction": "How do I Viewing Voltage Drop Analysis Results", "input": "", "output": "Note: Before running the analyze_rail command to calculate voltage drops and current violations, ensure you have provided the input files required by each analysis mode. For more information about preparing input files, see Preparing Design and Input Data for Rail Analysis Voltage drop analysis is supported in both RedHawk Fusion and RedHawk-SC Fusion analysis flows. To invoke the RedHawk/RedHawk-SC tool for calculating voltage drops of the specified power and ground networks, use the analyze_rail command with the following options: Use the -voltage_drop option to specify the analysis mode. static : Performs static voltage drop analysis. dynamic : Performs dynamic voltage drop analysis. dynamic_vectorless : Performs dynamic voltage drop analysis without Verilog Change Dump (VCD) inputs. dynamic_vcd : Performs dynamic voltage drop analysis with VCD inputs. When enabled, use the -switching_activity option to specify a switching activity file. Use the -nets option to specify the power and ground supply nets to analyze. The tool considers all the switched or internal power nets of the specified power nets in the analysis. You do not need to explicitly specify the internal power nets. (Optional) Use the -switching_activity option to specify a switching activity file. The supported file formats are: VCD SAIF, and ICC_ACTIVITY. When not specified, by default the tool uses the toggle rate for rail analysis. Note: If you are using the dynamic vector-free mode, you do not need to provide switching activity information. To specify a switching activity file, use the -switching_activity option by using the following syntax: -switching_activity { type file_name strip_path ] [ start_time end_time ]} VCD : Specifies a VCD file that is generated from a gate-level simulation. By default, rail analysis reads and uses all time values in the VCD file. To specify the time window to read from the VCD file, use the optional start_time and end_time arguments with the -switching_activity option. When specified, the tool reads all time values from the VCD file, but uses only the specified time window for rail analysis. SAIF : Specifies one or more SAIF files generated from a gate-level simulation. icc_activity : Runs the Fusion Compiler write_saif command to generate a SAIF file that contains the user-annotated and simulated switching activity (including state-dependent and path-dependent information) for the complete design without running the propagation engine. The strip_path argument removes the specified string from the beginning of the object names. Using this option modifies the object names in the VCD or SAIF file to make them compatible with the object names in the block. The strip_path argument is case- sensitive. (Optional) By default, the tool uses the RedHawk/RedHawk-SC power analysis feature to calculate the power consumption of the specified power and ground network. If you prefer having the Fusion Compiler tool generate the necessary power data for rail analysis, set the -power_analysis option to icc2 For a detailed description about how to run power analysis using the Fusion Compiler report_power command. (Optional) By default, the analyze_rail command automatically generates a GSR file for running RedHawk rail analysis. To specify an external GSR file to append to the GSR file generated in the current run, use the -extra_gsr_option_file option. (Optional) Use the -redhawk_script_file option to specify an existing RedHawk script file generated in an earlier analyze_rail run. When using an existing script file for rail analysis, the tool honors the settings in this file and ignores all other currently enabled options. For example, if you run the analyze_rail -voltage_drop static -redhawk_script_file myscript.tcl command, the tool ignores the -voltage_drop option setting. When the -redhawk_script_file option is not specified, you must specify the nets to analyze by using the -nets option. The following example performs static voltage drop analysis on the VDD and VSS nets with the optional settings defined in a GSR configuration file. fc_shell> analyze_rail -voltage_drop static -nets {VDD VSS} \\ -extra_gsr_option_file add_opt.gsr"}
{"instruction": "How do I Specifying Settings for Multivoltage Designs", "input": "", "output": "By default, the add_buffer_on_route command Adds buffers over all placement blockages, soft macros, and hard macros. To prevent buffers from being placed over specific macro cells, use the -dont_allow_insertion_over_cell option. Alternatively, you can prevent the buffers from being placed over all blockages and macro cells by using the -respect_blockages option. When you use this option, you can specify a list of macro cells over which buffers are allowed by using the -allow_insertion_over_cell option. Adds buffers on both global routed and detail routed nets. To add buffers only on nets that are global routed only, without assigned tracks or detail routing, use the -only_global_routed_nets option. Adds buffers at the lowest common level of hierarchy of the pins being driven by the buffers. To add the buffers on the highest possible level of hierarchy, use the -on_top_hierarchy option. Does not add buffers on a route segment if it is necessary to create new ports because of a difference in the logical and physical topology of the net. To add buffers on such route segments by creating new ports, use the -punch_port option."}
{"instruction": "How do I Voltage Hotspot Analysis", "input": "", "output": "When you use the RedHawk mesh add command to add virtual PG meshes in the top block for the current subblock, by default the virtual PG meshes created by the RedHawk mesh add command are not shown as layout objects in the GUI. Therefore, these GUI shapes cannot be queried using layout object collection commands (such as, get_shapes ), and are not saved to the design library when you save the block. To save ECO shapes along with rail results and display them in the GUI, enable the rail.display_eco_shapes application option, like set_app_options -name rail.display_eco_shapes -value true Note: The mesh add command is available only in RedHawk, not in RedHawk SC. Therefore, the tool issues an error message when you enable both the rail.enable_redhawk_sc and rail.display_eco_shapes application options. To display ECO shapes in GUI, you must first enable the RedHawk signoff license key by setting the rail.allow_redhawk_license_checkout application option to true. Otherwise, an error message is issued. To add virtual PG meshes and display the created ECO shapes in the GUI, 1. Prepare a script file (such as, mesh.tcl) that contains the mesh add command. 2. Run design setup with the mesh.tcl script file. fc_shell> set_rail_command_options -script_file mesh.tcl \\ -command setup_design -order after_the_command The tool generates the RedHawk script file and sources the mesh.tcl file after design setup. 3. Perform rail analysis using the following command: fc_shell> analyze_rail -nets -voltage_drop 4. Run the open_rail_result command to load the design data and analysis results. 5. Run the gui_start command to open the Fusion Compiler GUI. In the GUI layout window, choose View > Map and select the map to display. You can now display and query the ECO shapes that are created by the RedHawk mesh add command in the GUI. Script Examples The following script displays ECO shapes in the GUI by using the set_rail_command_option command. ## Open design ## open_block link_block ## Specify taps ## create_taps ## Specify RedHawk Fusion input files or variables ## set_app_options -name rail.enable_redhawk -value 1 set_app_options -name rail.redhawk_path -value set_app_options -name rail.disable_timestamps -value true set_app_options -name rail.display_eco_shapes -value true set_rail_command_options -script_file mesh.tcl -command \\ setup_design... ## Analyze## analyze_rail -voltage_drop... -nets {VDD VSS} ## Check GUI ## open_rail_result The following script displays ECO shapes in the GUI by using a RedHawk script. ## Open design ## open_block link_block ## Specify taps ## create_taps ## Specify RedHawk Fusion input files or variables ## set_app_options -name rail.enable_redhawk -value 1 set_app_options -name rail.redhawk_path -value set_app_options -name rail.disable_timestamps -value true set_app_options -name rail.display_eco_shapes -value true ## Analyze ## analyze_rail -voltage_drop... -nets {VDD VSS} -script_only ## Modify the script.tcl containing mesh add command ## analyze_rail -redhawk_script_file ## Check GUI ## open_rail_result"}
{"instruction": "How do I Marking Clock Trees as Synthesized", "input": "", "output": "The voltage level of a design is determined by the technology node (at device level) and the performance requirement. The Fusion Compiler tool can perform voltage optimization, which tries to achieve better performance, power, and area (PPA) at a lower voltage level. To perform voltage optimization, you need Scaled library panes Voltage optimization works on the fundamental principle of scaling the voltage, Therefore, scaled library panes with different voltages are required. A signoff methodology with a scaled library setup The voltage optimization flow consists of the following high-level steps: 1. Perform physical synthesis at the original design voltage using the compile_fusion command. 2. Perform clock tree synthesis and optimization at the original design voltage by using the clock_opt command. 3. Associate a set of related library panes to form a scaling group by using the define_scaling_lib_group command. 4. Specify voltage ranges for specific corners by using the set_vopt_range command, as shown in the following example: fc_shell> set_vopt_range -corner C1 \\ -low_voltage 0.81 -high_voltage 1.0 fc_shell> set_vopt_range -corner C2 \\ -low_voltage 0.81 -high_voltage 1.0 5. Specify a total negative slack (TNS) and power target and tolerance for voltage optimization by using the set_vopt_target command. The following example specifies a total negative slack target for voltage optimization and specifies that I/O paths should be excluded from the total negative slack costing: fc_shell> set_vopt_target -tns -1.0 -excludeIO 6. Perform voltage optimization by using the voltage_opt command. 7. Perform routing at the optimized voltage by using the route_auto command. 8. Perform postroute optimization at the optimized voltage by using the route_opt command."}
{"instruction": "How do I Optimizing Pin Access During Legalization", "input": "", "output": "To minimize large displacements of cells during legalization, enable Orientation optimization by setting the place.legalize.optimize_orientations application option to true When you do so, the tool considers flipping the orientations of cells to reduce the displacements during legalization. Stream placement by setting the place.legalize.stream_place application option to true When you do so, the tool moves many cells a small distance, to avoid moving a single cell a large distance during legalization. You can further control stream placement by using the place.legalize.stream_effort and place.legalize.stream_effort_limit application options."}
{"instruction": "How do I Specifying Switching Probability for Supply Nets", "input": "", "output": "If the clock frequency used in the SAIF file is different from the clock frequency used in the Fusion Compiler tool, you can scale the switching activity by performing the following steps: 1. Read in the SAIF file by using the read_saif command. 2. Enable scaling by setting the power.use_generated_clock_scaling_factor application option to on 3. Scale the switching activity by using the set_power_clock_scaling command. When you use this command, you must specify the following: The clock objects associated with the switching activity you want to scale The clock period used in the SAIF file by using the -period option or the ratio between the clock period used in the SAIF file and the clock period used in the Fusion Compiler tool by using the -ratio option In addition, you can specify the scenario for which to apply the scaling by using the -scenario option. The following example reads in a SAIF file, enables scaling, scales the switching activity associated with clocks named CLK1 and CLK2 by a ratio of five, and scales the switching activity associated with clock named CLK3 by a ratio of two: fc_shell> read_saif top.saif fc_shell> set_app_options -list \\ {power.use_generated_clock_scaling_factor true} fc_shell> set_power_clock_scaling -ratio 5 {CLK1 CLK2} fc_shell> set_power_clock_scaling -ratio 2 {CLK3} If you run the set_power_clock_scaling command again for the same clock, the tool scales the already scaled switching activity. When you use the set_power_clock_scaling command, the tool scales only the switching activity applied with the read_saif command. The tool does not scale the following: Switching activity applied with the set_switching_activity command Switching activity within block abstracts The scaled switching activity is persistent in the design. You can write it out by using the write_saif command and use it in the subsequent steps of the design flow."}
{"instruction": "How do I Sorting and Filtering the Data", "input": "", "output": "By default, the comparison tables show the QoR values for all runs. For example, the NVE number for the following run is 2374: To cycle through different display styles of the data, right-click anywhere in the table. You can view the data as a percentage delta against the baseline as an absolute delta against the baseline (shown in For example, as a percentage delta, the NVE number shows 2.7% fewer failing endpoints than the baseline: As an absolute delta, the NVE number shows 65 fewer failing endpoints than the baseline: See Also Sorting and Filtering the Data Exploring the Detailed Comparison Data"}
{"instruction": "How do I Introduction to Multisource Clock Trees Structures", "input": "", "output": "The following topics introduce the different types of multisource clock trees and provides detailed information about the different multisource clock tree implementation flows and steps: Introduction to Multisource Clock Trees Structures Implementing a Regular Multisource Clock Tree Implementing a Regular Multisource Clock Tree Using Integrated Tap Assignment Implementing a Regular Multisource Clock Tree With an H-Tree-Only Global Clock Tree Structure Implementing MSCTS Multiple H-Tree Implementing Power Aware Flexible H-Tree Implementing a Structural Multisource Clock Tree Implementing a Structural Multisource Clock Tree Using Integrated Subtree Synthesis Improving the Correlation Between the SMSCTS and CCD Inserting Clock Drivers Synthesizing the Global Clock Trees Creating Clock Straps Routing to Clock Straps Analyzing the Clock Mesh Performing Automated Tap Insertion and H-Tree Synthesis Specifying Tap Assignment Options and Settings Building the Local Clock Subtree Structures"}
{"instruction": "How do I Routing Using Custom Router", "input": "", "output": "By default, the signoff_fix_isolated_via command both checks for and fixes isolated vias. The command performs the following tasks: 1. Checks for isolated vias by using the ranges defined in the signoff.fix_isolated_via.isolated_via_max_range application option 2. (Optional) Performs track-based metal fill insertion to insert dummy fill shapes within the specified range around each detected isolated via By default, the signoff_fix_isolated_via command ignores the existing fill data and performs track-based metal fill insertion to insert the fill shapes to use for fixing the isolated vias. The fill shapes are inserted on-track following the design rules defined in the technology file. Some foundries have additional design rules, which you enable by setting the appropriate TRACK_FILL_FOUNDARY_ name IC Validator variable. To set this variable, set the signoff.create_metal_fill.user_defined_options application option, as shown in the following example: fc_shell> set_app_options \\ -name signoff.create_metal_fill.user_defined_options \\ -value {-D TRACK_FILL_FOUNDARY_ name If you have already performed track-based metal fill insertion, you can use the existing fill shapes to fix isolated vias by using the -update_track_fill true option. When you use this option, you must use the -track_fill_runset_include_file option to specify the parameter file used for the initial track-based metal fill insertion. This parameter file is named track_fill_params.rh and is located in the run directory for the initial run. For example, if the run directory for the initial track-based metal fill insertion run is named init_fill, use the following command to fix isolated vias using the existing fill shapes: fc_shell> signoff_fix_isolated_via -update_track_fill true \\ -track_fill_runset_include_file init_fill/track_fill_params.rh For information about performing track-based metal fill insertion, see Track-Based Metal Fill Insertion 3. Inserts fixing vias within the specified range by using one of the following methods, in order of priority: a. Inserting a via between an existing non-wide net shape and a fill shape b. Extending the line end of an existing non-wide net shape and inserting a via between the extension and a fill shape c. Inserting a via between a wide metal shape and a fill shape When inserting the fixing vias, the tool considers the routing rules, including double- patterning rules and nondefault spacing rules, to prevent the introduction of DRC violations. Note: If the block is either very congested or very sparse, the signoff_fix_isolated_via command might not be able to fix all isolated vias. 4. Removes the unused dummy fill shapes 5. (Optional) Saves the updated block to disk By default, the signoff_fix_isolated_via command does not save the updated block to disk. After running the command, you must use the save_block command to save the updated block to disk. To save the block at the end of the signoff_fix_isolated_via run, use the -save_design true option with the signoff_fix_isolated_via command. 6. Saves the results to disk The signoff_fix_isolated_via command generates the following results files: A summary report This report specifies the number of isolated vias for each via layer before and after fixing. An error data file By default, the error data generated by the signoff_fix_isolated_via command is saved in a file named signoff_fix_isolated_via.err. To specify the name for the error data file, use the -error_data option. To report or display the information in the error data file, use the error browser, as described in the Fusion Compiler Graphical User Interface User Guide"}
{"instruction": "How do I Using a DDR Routing Flow", "input": "", "output": "In the hybrid flow, Custom Router is used to perform trunk routing without completing some pin connections, and then Zroute is used to complete the pin connections. This flow enables the use of Custom Router for prerouting while avoiding or reducing inconsistency and DRC violations associated with differences in the pin connection behavior between the two tools. To enable the hybrid routing flow, set the custom.route.skip_connect_pin_type application option to one or more of the following values, depending on your routing requirements. By default, this application option is set to none, which disables the hybrid routing flow. auto Custom Router identifies the routability of the pins in the block, and then completes the pin connections for the pins that can be connected. all Custom Router does not complete the pin connections for all pins in the block. stdcell Custom Router completes the pin connections for all pins in the block, except for standard cell pins. io Custom Router completes the pin connections for all pins in the block, except for I/O cell pins. macro Custom Router completes the pin connections for all pins in the block, except for macro pins. By default, when the hybrid flow is enabled, Custom Router determines how much space to leave between a route and an unconnected pin. To specify the maximum distance, use the custom.route.distance_to_net_pin application option. Set the value in the following format: net_name distance The following script uses Custom Router for trunk routing and Zroute for all pin connections. set_app_options -name custom.route.skip_connect_pin_type -value all route_custom -nets {net1 net2} route_eco -nets {net1 net2} remove_redundant_shapes -nets {net1 net2} route_detail -incremental true The following script uses Custom Router for trunk routing and pin connections except standard cell pins, and then uses Zroute for standard cell pin connections. set_routing_rule -min_routing_layer m3 \\ -max_routing_layer m9 \\ -min_layer_mode allow_pin_connection \\ -max_layer_mode hard {net1 net2} set_app_options -name custom.route.skip_connect_pin_type \\ -value stdcell set_app_options -name custom.route.distance_to_net_pin \\ -value {{{net1 5.0} {net2 3.0}}} route_custom -nets {net1 net2} route_eco -nets {net1 net2} remove_redundant_shapes -nets {net1 net2} route_detail -incremental true"}
{"instruction": "How do I Aligning by the Right Edges", "input": "", "output": "By default, the Fusion Compiler tool aligns the leaf cells by aligning the left edges. To explicitly specify this alignment method, use the -alignment left option of the set_rp_group_options command. shows cells that are left aligned. Bottom-Left-Aligned Relative Placement Group U4 U3 U2 U1 row 3 row 2 row 1 row 0 col 0"}
{"instruction": "How do I Performing Top-Level Closure With Abstract Views", "input": "", "output": "You can generate a report of check records from a design by using the get_early_data_check_records command. Using the -hierarchical option with this command enables to you get check records for all subblocks. The report generated is in the following format: check_name object For example, fc_shell> get_early_data_check_records -hierarchical {hier.block.missing_leaf_cell_location@eco_cell} You can use the -filter option to filter the results of this command by various parameters such as object class and check name. For example, fc_shell> get_early_data_check_records \\ -filter \"checked_object_class==port\" {place.port_type_mismatch@clk route.missing_layer_direction@feed_in route.layer_name_mismatch@out}"}
{"instruction": "How do I Routing Application Options", "input": "", "output": "By default, Zroute can reroute nets as needed. You can prevent rerouting or limit rerouting to minor changes by setting the physical_status attribute on the nets. To freeze the net and prevent rerouting, set the attribute to locked To limit rerouting to minor changes, set the attribute to minor_change To allow Zroute to reroute the nets as needed, set the attribute to unrestricted For example, to prevent rerouting of the net1 net, which uses the default routing rule, use the following command: fc_shell> set_attribute -objects [get_nets net1] \\ -name physical_status -value locked"}
{"instruction": "How do I Defining Global Via Ladder Constraints", "input": "", "output": "The via ladder constraints define the pins on which to insert via ladders and the via ladder templates that can be used for those pins. You can define both global and instance- specific via ladder constraints; if the constraints conflict, the instance-specific constraints override the global constraints. To define global via ladder constraints, which are referred to as via ladder rules, use the set_via_ladder_rules command, as described in Defining Global Via Ladder Constraints To define instance-specific via ladder constraints, use the set_via_ladder_constraints command, as described in Defining Instance-Specific Via Ladder Constraints In addition, you can specify via ladder candidates for specific pins by using the set_via_ladder_candidate command. This command is used by preroute optimization to insert via ladders on timing-critical paths, as described in Specifying Automatic Via Ladder Insertion Settings for Preroute Optimization To report the via ladder constraints, use the report_via_ladder_constraints command. See Also Inserting Via Ladders"}
{"instruction": "How do I Creating Collections of Clock Network Pins", "input": "", "output": "To report the power of a clock tree, use the report_clock_power command. By default, it reports the power for all clock trees in all modes and corners of all active scenarios. To report the power Only for specific clocks, use the -clocks option Only for specific modes, use the -modes option Only for specific corners, use the -corners option Only for specific scenarios, use the -scenario option On a per-segment or per-subtree basis, use the -type per_segment or -type per_subtree option A segment is the clock buffer tree from one integrated-clock-gating (ICG) cell to the next ICG cells or sinks in its fanout For example, in the following figure, the buffer tree from the output of the ICG1 cell to the inputs of the ICG2, ICG3, and ff2 cells is considered a segment. A subtree is a clock tree from an ICG cell all the way to the sinks in its fanout. For example, in the following figure, the clock tree from the output of the ICG1 cell to the inputs of the ff1, ff2, and ff3 cells is considered a subtree. Segments and Subtrees of a Clock Tree"}
{"instruction": "How do I Specifying Ideal Voltage Sources as Taps", "input": "", "output": "_scenario true set_app_options -name rail.generate_file_type -value python #Use user-defined test_def_files for DEF variable to match #with customized python set_app_options -name rail.generate_file_variables \\ -value {DEF test_def_files } create_rail_scenario -name func.ss_125c -scenario func.ss_125c set_rail_scenario -name func.ss_125c -voltage_drop dynamic create_rail_scenario -name func.ff_125c_ -scenario func.ff_125c set_rail_scenario -name func.ff_125c \\ -generate_file {PLOC DEF SPEF TWF LEF} \\ -custom_script_file./customized.py set_host_options -submit_protocol sge \\ -submit_command {qsub -V -notify -b y -cwd -j y \\ -P bnormal -l mfree=16G} # Enable IR-driven CCD analysis before running route_opt set_app_options -name opt.common.power_integrity -value true route_opt See Also Specifying RedHawk and RedHawk-SC Working Directories"}
{"instruction": "How do I Updating Activity for Improved Power Optimization", "input": "", "output": "The Fusion Compiler tool can perform percentage-LVT-based optimization. By limiting the percentage of LVT cells in a block, you can improve yield of your design. You can also use this feature during the early design phases to get an idea of the quality of the RTL. To set up for percentage-LVT-based optimization, 1. Specify the LVT library cell group as shown in the following example: fc_shell> remove_attributes -quiet \\ [get_lib_cells -quiet */*] threshold_voltage_group fc_shell> set_attribute [get_lib_cells -quiet *lvt*/*] \\ threshold_voltage_group LVT fc_shell> set_threshold_voltage_group_type \\ -type low_vt LVT Ensure that the LVT library cells you specify Have a valid purpose defined by using the set_lib_cell_purpose command and are included in the appropriate target-library subsets defined by using the set_target_library_subset command Do not have a dont_touch or dont_use attribute setting 2. Specify the percentage limit for LVT cells by using the set_multi_vth_constraint -low_vt_percentage command. To specify the limit as a percentage of the Cell count, use the -cost cell_count option Cell area, use the -cost area option To reset this constraint, use the reset_multi_vth_constraint command, and to report it, use the report_multi_vth_constraint command. After you set up percentage-LVT-based optimization, when you run the compile_fusion clock_opt, or route_opt command, the tool uses the specified LVT cell percentage constraint for the data path cells in the block. However, to minimize QoR disturbance, the tool limits the percentage-LVT-based optimization performed during the route_opt command. Therefore, it is important to enable this feature earlier in the design flow. Note: LVT cells have a smaller cell delay, but higher leakage power dissipation. Therefore, limiting the number of LVT cells reduces leakage-power dissipation. However, to further reduce leakage power, enable leakage power optimization for the different stages of the design flow."}
{"instruction": "How do I Defining Blockages That Allow Buffers Only", "input": "", "output": "To define partial blockages that allow relative placement cells only, specify the boundary, type ( -type allow_rp_only option), blockage percentage ( -blocked_percentage option), and optionally the name for the placement blockage. For example, to defines a partial blockage that allows relative placement cells only, with a maximum allowed cell density of 80 percent (a blocked percentage of 20), and enclosed by the rectangle with corners at (10, 20) and (100,200), use the following command: create_placement_blockage -name rp_only -type allow_rp_only \\ -boundary {10 20 100 200} -blocked_percentage 20 These blockages allows the tool to place relative placement groups, which are usually large structures, without disturbing the placement of other cells. After the tool places and legalizes the relative placement groups, you can remove these blockages and allow the tool to place other cells in them. Note: Relative-placement-cells-only blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Creating New Relative Placement Groups in a Placed Design", "input": "", "output": "You can improve the placement of relative placement groups in a placed design by legalizing only the relative placement groups. To legalize the placement of only the relative placement groups, but not nonrelative placement cells, use the legalize_rp_groups command. You can also specify a list of relative placement groups to be legalized. To perform a fast legalization of the relative placement groups, use the -prototype option. When you use this option, the tool does not ensure that all legalization constraints are met. Therefore, use it during the prototyping stages of the design flow when you are developing relative placement groups. To specify that relative placement groups can overlap with each other, use the -legalize_over_rp option. For example, the following command legalizes the RP3 relative placement group over the RP1 and RP2 relative placement groups. fc_shell> legalize_rp_groups -legalize_over_rp RP3 shows the placement before and after running the command. Legalizing the RP3 Relative Placement Group Over Other Groups RP1 RP2 RP1 RP2 RP3 After you legalize one or more relative placement groups by using the legalize_rp_groups command, there might be overlaps with cells in other relative placement groups or cells that are not in relative placement groups. Use the check_legality command to identify any cell overlaps and use the legalize_placement command to resolve any remaining cell overlaps."}
{"instruction": "How do I Performing Hierarchical Synthesis Using Abstracts", "input": "", "output": "The following topics describe how to perform synthesis, placement, optimization, clock tree synthesis, routing, and postroute optimization on hierarchical designs. Performing Hierarchical Synthesis Using Abstracts Performing Hierarchical Synthesis Using ETMs Performing Prechecks for Hierarchical Synthesis Flows Providing Block-Level Test Models Specifying Block-Level Power Intent Overview of Abstract Views Creating Abstract Views Reporting Abstract Inclusion Reasons Making Changes to a Block After Creating an Abstract Creating a Frame View Linking to Abstract Views at the Top-Level Changing the Block From Abstract to Design View Linking to Subblocks With Multiple Labels Specifying the Editability of Blocks From the Top-Level Preparing for Top-Level Closure With Abstracts Checking Designs With Abstracts for Top-Level-Closure Issues Performing Top-Level Closure With Abstract Views Creating ETMs and ETM Cell Libraries Linking to ETMs at the Top Level Performing Top-Level Closure With ETMs Transparent Hierarchy Optimization"}
{"instruction": "How do I Applying Required Settings for Improving Specific QoR Metrics", "input": "", "output": "You can apply tool settings required for achieving the best QoR for high performance cores by using the set_hpc_options command. The applied settings affect placement, legalization, optimization, clock tree synthesis, routing, extraction, and timing analysis. To List the supported high performance core types and implementation stages, use the -list option Specify the type of high performance core, use the -core option Specify the stage of the implementation flow, use the -stage option If your design uses a 12 or 7 nanometer technology node, apply the node-specific tool settings by using the set_technology command before you run the set_hpc_options command, as shown in the following example script: set_technology -node 7 set_hpc_options -core A72 -stage clock_opt_cts... clock_opt -from build_clock -to route_clock... set_hpc_options -core A72 -stage clock_opt_opto... clock_opt -from final_opto... set_hpc_options -core A72 -stage route_auto... route_auto... set_hpc_options -core A72 -stage route_opt... route_opt..."}
{"instruction": "How do I Reporting the Constraints Assigned to a Group of a Repeaters", "input": "", "output": "Voltage area aware group repeaters choose legal library cells for repeaters based on the corresponding voltage area and updates supply nets for repeaters to meet multivoltage constraints. You can use the add_group_repeaters command with specific options to add voltage area aware group repeaters in three different ways, depending on the design methodology: When the design is single-rail buffer only, use the -va_aware option fc_shell> add_group_repeaters -lib_cell <lib_cell> -va_aware When the design is single-rail buffer based on voltage area, use the -voltage_area_specific_lib_cell option fc_shell> add_group_repeaters -lib_cell <default_lib_cell> \\ -voltage_area_specific_lb_cell {{VA1 libcell1}} {{VA2 libcell2}} When the design is single- and dual-rail buffers, use the -select_mv_buffer option fc_shell> add_group_repeaters -lib_cell <default_lib_cell> \\ -select_mv_buffer {{VA1 SingleRail1 DualRail1}} \\ {{VA1 SingleRail2 DualRail2}} Voltage area aware group repeaters help resolve multivoltage violations by choosing the library cell based on voltage area and repeater location."}
{"instruction": "How do I Inserting Filler Cells", "input": "", "output": "A metal-insulator-metal (MiM) capacitor is made of two special-purpose conducting layers separated by an insulator. This capacitor is inserted between two regular metal layers, as shown in Cross-Section View of MiM Capacitor Layers maskName = \"mimtop\" M9 M9 M9 M8 maskName = \"mimbottom\" via via via M9 layer M8 layer MBOT layer MTOP layer MiM capacitor maskName = \"viaMimtop\" maskName = \"viaMimbottom\" MiM capacitors are typically connected between power and ground to help maintain a constant supply voltage in the presence of electrical noise. The dimensions of a MiM capacitor are usually customized to fit the power strap geometry of a specific power plan. To insert an array of MiM capacitors into a block and connect them to the power rails, use the create_mim_capacitor_array command. At a minimum, you must specify the MiM capacitor library cell, as well as the x- and y-increments of the array. For example, fc_shell> create_mim_capacitor_array \\ -lib_cell my_lib/mim_ref_cell -x_increment 20 -y_increment 20 By default, the create_mim_capacitor_array command Inserts MiM capacitors for the entire block To restrict the insertion to a specific region, use the -boundary option to specify the rectangular or rectilinear region. You can specify only a single region. The command does not consider standard cells, macros, placement blockages, or voltage areas when inserting the MiM capacitors. Inserts the MiM capacitors in the R0 orientation To change the orientation, use the -orientation option. When you change the orientation, it affects all MiM capacitor cells in the inserted array. Uses the following naming convention for the inserted MiM capacitor cells: mimcap! library_cell_name number To identify the MiM capacitor cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: mimcap! prefix library_cell_name number"}
{"instruction": "How do I Running Commands in Parallel", "input": "", "output": "To improve runtime, you can run checking and reporting commands in the background while you run other commands in the foreground. This is useful in interactive sessions when you want to continue your work while the tool generates a report. To run commands in the background, use the redirect command with the -bg option. When you use this command, fc_shell returns immediately to execute the next command. If you issue an exit command in the parent process, the tool waits for all redirect -bg commands to complete before exiting. To list the commands supported by the redirect -bg command, use the list_commands -bg command. You can run either a single command or source a Tcl script that contains only supported commands. If the command or script includes a redirect -bg command, the -bg option is ignored. You can run at most two jobs in the background. If you specify more than two background jobs, they are queued. To specify the maximum number of cores to use for the background jobs, use the -max_cores option with the redirect command. The number of cores available for the parent process (as specified by the -max_cores option of the set_host_options command) is reduced by the number of cores allocated for background jobs. The following example redirects a Tcl script to run in the background: fc_shell> set_host_options -max_cores 8 fc_shell> redirect -bg -max_cores 3 -file bg_log.out \\ {source bg_script.tcl} Information: redirect -bg with max_cores 3 started. The maximum number of cores available in parent is reduced to 5. (BGE-004) Reporting Background Jobs To report the background jobs submitted with the redirect -bg command, use the report_background_jobs command. This command reports both the completed jobs and the jobs currently running in the background, as shown in the following example: fc_shell> report_background_jobs JOB'redirect -bg -file {background.log} source bg_script.tcl -max_cores 4'completed JOB(pid:13010)'redirect -bg -file {background_1.log} source bg_script_1.tcl -max_cores 3'is running To omit the completed jobs, use the -reset option with the report_background_jobs command."}
{"instruction": "How do I Defining an Inner Keepout Margin", "input": "", "output": "You can define an outer keepout margin on a hard macro, a hierarchical cell, or a leaf cell. When you define an outer keepout margin, you can either specify the keepout distance explicitly or, for hard macros, you can have the tool derive the keepout distance based on the macro pin count. To explicitly specify an outer keepout margin, use the -outer option to specify the margin distance for each side. You specify the left, bottom, right, and top margins using the following format: lx by rx ty. A value of 0 results in no keepout margin for that side. For example, to create a hard outer keepout margin with a margin of 10 on each side for a macro named my_macro, use the following command: fc_shell> create_keepout_margin -outer {10 10 10 10} my_macro To have the tool derive the outer keepout distance for a hard macro based on its pin count, use the -tracks_per_macro_pin option to specify the track-to-pin ratio. When you use this option, the tool calculates the keepout margin from the track width, the number of macro pins, and the specified track-to-pin ratio, which is typically set to a value near 0.5. A larger value results in larger keepout margins. The derived keepout margin is always hard; the -type setting is ignored. The derived margins are subject the minimum and maximum values specified by the -min_padding_per_macro and -max_padding_per_macro options. For example, to have the tool derive the outer keepout margin for a macro named my_macro by using a track-to-pin ratio of 0.6 with a minimum keepout distance of 0.1 and a maximum keepout distance of 0.2, use the following command: fc_shell> create_keepout_margin -tracks_per_macro_pin 0.6 \\ -min_padding_per_macro 0.1 -max_padding_per_macro 0.2 my_macro"}
{"instruction": "How do I Controlling Hold Time Optimization Effort", "input": "", "output": "By default, the tool focuses on improving the timing and power QoR during concurrent clock and data optimization. You can change the effort level for timing optimization by setting the ccd.timing_effort application option to low or high. The default is medium This setting affects concurrent clock and data optimization performed during the final_opt stage of the clock_opt command and the route_opt command."}
{"instruction": "How do I Verifying Via Ladders", "input": "", "output": "To prevent via ladders from being edited, set the design.enable_via_ladder_protection application option to true fc_shell> set_app_options -name design.enable_via_ladder_protection \\ -value true When the design.enable_via_ladder_protection application option is true, the following commands process only objects that do not belong to via ladders: remove_shapes remove_vias remove_objects set_attribute set_via_def add_to_edit_group If an object belongs to a via ladder, these commands issue a warning message and do not process the object. The following example sets the design.enable_via_ladder_protection application option to true and attempts to remove a collection of shapes: fc_shell> set_app_options -name design.enable_via_ladder_protection \\ -value true... fc_shell> sizeof_collection [get_shapes -of net1] 77 fc_shell> remove_shapes [get_shapes -of net1] -verbose Warning: Cannot PATH_32_7403 because it is part of via_ladder. (NDM-160) 76"}
{"instruction": "How do I Splitting Clock Cells", "input": "", "output": "To skew latches and discrete clock gates together, set the ccd.skew_opt_merge_dcg_cells_by_driver application option to true before compile_fusion or place_opt final_opto. By default, the application option is set to false. Setting the ccd.skew_opt_merge_dcg_cells_by_driver application option to true enhances the concurrent clock and data optimization to skew latches and gating element by the same offset. This ensures the latch and gate are at the same level and improves hold timing of discrete clock gates. fc_shell> set_attribute -name ccd.skew_opt_merge_dcg_cells_by_driver -value true"}
{"instruction": "How do I Handling Design Data Using the Early Data Check Manager", "input": "", "output": "The Fusion Compiler tool requires that the preferred routing direction is specified for the routing layers defined in the technology file. Typically this information is defined in the cell library. To set or change the preferred routing direction for a layer, use the following syntax to set its routing_direction attribute: set_attribute -objects layers -name routing_direction -value vertical | horizontal Specify the routing layers by using the layer names from the technology file. The layer direction set with this attribute applies only to the current block. For example, to set the preferred routing direction to vertical for the M5 and M7 layers, use the following command: fc_shell> set_attribute -objects [get_layers {M5 M7}] \\ -name routing_direction -value vertical Note: Settings made with the create_routing_guide -switch_preferred_direction command, which changes the preferred direction within the area that is covered by the routing guide, override the routing_direction attribute settings. To report the user-defined preferred routing direction for one or more routing layers, use the get_attribute command. To remove the user-defined preferred routing direction for one or more routing layers, use the remove_attributes command. See Also Preparing Routing Layers"}
{"instruction": "How do I Clock-Gate Levels and Stages", "input": "", "output": "The compile log file contains information about clock gating, which can help you debug simple setup issues. By default, the clock-gating information is displayed after Clock-gate insertion n the initial_map stage Clock-gate restructuring in the logic_opto stage Clock-gate restructuring in the initial_opto stage Self-gating insertion in the initial_opto stage, if enabled The reported information includes the following: The number of preexisting clock gates that have a dont_touch attribute, which prevents optimization and might lead to unsatistactory results The number of clock-gating library cells that have a CTS purpose, which is required for insertion Clock-gating metrics such as the number of elements and the number of gated registers A summary of reasons for registers that could not be gated If the self-gating or fanin-based sequential clock gating features are enabled, their metrics are displayed separately. An example of the compile log for a run that includes self-gating is as follows: Number of Pre-Exsting Clock Gates with dont_touch Attribute: 0 Number of ICG library cells with CTS purpose: 12 Tool Gated Register Summary Clock Gating Type | Number of Clock Gates | Register Count | Bitwidth | | | Equivalent Regular Clock Gating | 1 | 2 | 2 Self Gating | 0 | 0 | 0 Regular Clock Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Enable is Constant One | 2 | 2 Self Gating Ungated Register Summary Ungated Reason | Count | Bitwidth Register is clock gated, and ineraction | | is set to none | 2 | 2 The tool as not able to find enough registers | | that are compatible to this register | | in order to be gated. | 2 | 2"}
{"instruction": "How do I Routing Signal Nets by Using Automatic Routing", "input": "", "output": "Before you run detail routing, Define the common routing application options For information about the common routing application options, see the route.common_options man page. Define the detail routing application options For information about the detail routing application options, see the route.detail_options man page. Complete global routing and track assignment The detail router uses the general pathways suggested by global routing and track assignment to route the nets, and then it divides the block into partitions and looks for DRC violations in each partition. When the detail router finds a violation, it rips up the wire and reroutes it to fix the violation. During detail routing, Zroute concurrently addresses routing design rules and antenna rules and optimizes via count and wire length. For more information about antenna rules, see Finding and Fixing Antenna Violations To perform standalone detail routing, run the route_detail command. By default, the route_detail command Performs detail routing on the whole block You can restrict the routing to a specific area of the block by using the -coordinates option (or by specifying or selecting the bounding box in the GUI). Uses one uniform partition for the first iteration and adjusts the partitioning for subsequent iterations Zroute uses the single uniform partition for the first iteration to generate all DRC violations for the chip at the same time. At the beginning of each subsequent iteration, the router checks the distribution of the DRC violations. If the DRC violations are evenly distributed, the detail router uses a uniform partition. If the DRC violations are located in some local areas, the detail router uses nonuniform partitions. In some cases, such as when a design contains standard cells with long pins, you can improve the detail routing QoR and reduce the runtime by increasing the partition size. To enable this feature, set the route.detail.optimize_partition_size_for_drc application option to true Performs iterations until one of the following conditions exists: All of the violations have been fixed The maximum number of iterations has been reached By default, the maximum number of iterations is 40. You can change this limit by setting the -max_number_iterations option. fc_shell> route_detail -max_number_iterations 20 It cannot fix any of the remaining violations You can change the effort that the detail router uses for fixing the remaining violations before it gives up by setting the route.detail.drc_convergence_effort_level application option. fc_shell> set_app_options \\ -name route.detail.drc_convergence_effort_level -value high You can force the detail router to complete the maximum number of iterations, regardless of the DRC convergence status, by setting the route.detail.force_max_number_iterations application option to true fc_shell> set_app_options \\ -name route.detail.force_max_number_iterations -value true Is not timing-driven To enable timing-driven detail routing, set the route.detail.timing_driven application option to true fc_shell> set_app_options \\ -name route.detail.timing_driven -value true By default, when you enable timing-driving detail routing, Zroute uses medium effort to assign timing-critical nets to low-resistance metal layers. To change the extent to which timing-driven detail routing prefers lower-resistance metal layers when routing timing- critical nets, set the route.common.rc_driven_setup_effort_level application option. To increase the effort level to use more low-resistance metal layers for routing, set the option to high. To reduce the effort level, set the option to low. To disable resistance-based routing layer preferences, set the option to off Does not fix shorted nets over macro cells If default detail routing leaves shorted nets over macro cells, analyze the block to determine if the shorts are caused by the availability of only a single layer for routing over the macro cells. If so, use routing guides to encourage river routing over the macros with shorted nets and rerun detail routing. For details, see Using Routing Guides to Encourage River Routing If shorted nets remain after using river routing, enable the fixing of shorted nets over macro cells by automatically ripping up and rerouting the shorted nets by setting the route.detail.repair_shorts_over_macros_effort_level application option to low medium, or high and running incremental detail routing. The higher the effort level, the more ECO routing iterations are performed, which can reduce the number of DRC violations at the expense of runtime. fc_shell> set_app_options \\ -name route.detail.repair_shorts_over_macros_effort_level \\ -value high Does not fix soft DRC violations, such as bridge rule violations To enable the fixing of soft DRC violations after the final detail routing iteration, set the route.common.post_detail_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_detail_route_fix_soft_violations \\ -value true You can run additional detail routing iterations on a routed block by running incremental detail routing (the -incremental option). Be sure to use the -incremental option; otherwise, Zroute restarts at iteration 0 with a fixed-size partition. fc_shell> route_detail -incremental true By default, incremental detail routing does not fix soft DRC violations, such as bridge rule violations. To enable the fixing of soft DRC violations after the final incremental detail routing iteration, set the route.common.post_incremental_detail_route_fix_soft_violations application option to true fc_shell> set_app_options \\ -name route.common.post_incremental_detail_route_fix_soft_violations \\ -value true Note: Incremental detail routing does not fix open nets. To fix open nets, you must run ECO routing. For information about ECO routing, see Performing ECO Routing If you want to override certain runtime-intensive application options, you can run detail routing in early mode. To turn on the early mode in detail routing, use the set_qor_strategy command with the -mode option set as early fc_shell> set_qor_strategy -mode early -stage pnr Early mode detail routing automatically creates a new DRC type called skipped regions that can detect dirty regions with pin overflow. To identify the dirty regions, open the error browser and select Skipped region If you want to view the DRC violations before postroute optimization, you can save the block after a specified number of iterations by setting the route.detail.save_after_iterations application option. The saved block is called DR_itr, where n is the specified iteration. You can use a string other than DR as the prefix by setting the route.detail.save_cell_prefix application option. Zroute generates a DRC violations summary at the end of each iteration. After completing detail routing, Zroute outputs a final summary report. This report includes all violations detected by Zroute, as well as information about the redundant via conversion rates. If you want an additional report that excludes violations that are not of interest to you, specify the rules to exclude by setting the route.detail.report_ignore_drc application option. The syntax to set this option is set_app_options -name route.detail.report_ignore_drc -value list_of_drcs The values used in the list_of_drcs argument are the DRC names used in the summary report. If the DRC name includes a space, you must enclose the name in double quotation marks. For a complete list of the supported DRC names, see the man page. Example 21 shows a detail routing report. Example 21 Detail Routing Report Start DR iteration 0: uniform partition Routed 1/27405 Partitions, Violations = 0 Routed 137/27405 Partitions, Violations = 264 DR finished with 7398 violations DRC-SUMMARY: @@@@@@@ TOTAL VIOLATIONS = 7398 Diff net spacing : 194 Same net spacing : 4 Diff net via-cut spacing : 2328 Same net via-cut spacing : 1 Less than minimum width : 5 Less than minimum area : 36 Short : 87 End of line enclosure : 4742 Less than NDR width : 1 Total Wire Length = 23928849 micron Total Number of Contacts = 2932706 Total Number of Wires = 2878293 Total Number of PtConns = 88536 Total Number of Routed Wires = 2878293 Total Routed Wire Length = 23920011 micron Total Number of Routed Contacts = 2932706 Layer M1 : 962827 micron Layer M2 : 4233755 micron Via VIA78SQ_C : 1742 Via VIA78SQ_C(rot) : 9 Redundant via conversion report: Total optimized via conversion rate = 98.96% (2902130 / 2932706 vias) Layer VIA1 = 97.81% (1091973/ 1116367 vias) Weight 1 = 97.81% (1091973 vias) Un-optimized = 2.19% (24394 vias) Total double via conversion rate = 98.96% (2902130 / 2932706 vias) Layer VIA1 = 97.81% (1091973/ 1116367 vias) Layer VIA2 = 99.97% (1071650/ 1071978 vias) The optimized via conversion rate based on total routed via count = 98.96% (2902130 / 2932706 vias) Layer VIA1 = 97"}
{"instruction": "How do I Setting Up for Dynamic Power Shaping", "input": "", "output": "The Fusion Compiler tool provides the following techniques for ensuring power integrity of the design: Dynamic power shaping (DPS), which reduces transient power by utilizing concurrent clock and data optimization (useful skew) techniques. Voltage-drop-aware placement, which use the voltage (IR) drop values of cells to identify areas of high power density and spread the cells with high voltage drop values to reduce the power density of such areas. To set up for the recommended power integrity flow, perform the following steps: 1. Enable the power integrity flow by setting the opt.common.power_integrity application option to true When you do so, the Fusion Compiler uses the following techniques during the different stages of the design flow: a. Dynamic power shaping (DPS) during the final_opto stage of the compile_fusion command b. Voltage-drop-aware placement during the clock_opt command 2. (Optional) Specify that the tool should not reduce the voltage drop at the expense of the timing QoR by reducing the power integrity effort level by setting the opt.common.power_integrity_effort application option to low The default is high, and by default the tool tries to reduce the voltage drop to less than eight percent of the supply voltage at the expense of the timing QoR. 3. (Optional) Specify a maximum voltage drop threshold by using the opt.common.ir_drop_threshold application option. The default is eight percent of the supply voltage. If you change the default effort level by setting the opt.common.power.integrity_effort application option to low the tool ignores the threshold specified with the opt.common.ir_drop_threshold application option. 4. Specify settings for dynamic power shaping as described in Setting Up for Dynamic Power Shaping 5. Specify settings for voltage-drop-aware placement as described in Setting Up for Voltage-Drop-Aware Placement 6. (Optional) Enable IR-driven sizing, which uses the RedHawk dynamic voltage drop analysis results to identify cells involved in voltage drop violations, and then tries to replace those cells with cells having smaller leakage current. To enable this feature, set the clock_opt.flow.enable_irdrivenopt application option to true, in addition to setting the opt.common.power_integrity application option to true Instead of using the recommended power integrity flow setting, you can manually enable dynamic power shaping or voltage-drop-aware placement for the compile_fusion or clock_opt commands as described in Manually Enabling Dynamic Power Shaping and Voltage-Drop-Aware Placement"}
{"instruction": "How do I Defining Clock Cell Spacing Rules", "input": "", "output": "In the early stages of the implementation of a design, the constraints can be inaccurate or too restrictive. Running clock tree synthesis on such a design can lead to long runtime or poor clock tree QoR. You can run clock tree synthesis on such a design, but still get usable results in a reasonable runtime. To do so, set the following application variable before you begin clock tree synthesis: fc_shell> set_app_options \\ -name cts.common.enable_dirty_design_mode -value true When you use this application option setting, the tool Ignores dont_touch and dont_touch_network attribute settings on clock nets. Removes maximum transition and maximum capacitance constraints if they are too tight. Removes the maximum net length constraint if it is less than 50 microns. Ignores clock cell spacing rules if the horizontal spacing requirement is more than three times the site height and the vertical spacing requirement is more than twenty times the site height. Ignores nondefault routing rules if the width plus the spacing requirement of the routing rule is more than ten times the default width plus the default spacing. Reports balance point delay values that are large enough to cause an increase in clock insertion delay."}
{"instruction": "How do I Displaying Objects for Design Rule Checking", "input": "", "output": "The Live DRC feature performs interactive signoff design rule checking in the Fusion Compiler GUI. Note: This feature requires version P-2019.06 or later of the IC Validator tool. To perform interactive signoff design rule checking using Live DRC, 1. Set up the IC Validator environment as described in Setting Up the IC Validator Environment 2. Set the application options for interactive signoff design rule checking. At a minimum, you must specify the following information: The foundry runset to use for design rule checking by setting the signoff.check_drc_live.runset application option The layer mapping file that maps the technology file layers to the runset layers by setting the signoff.physical.layer_map_file application option For information about the options for interactive signoff design rule checking, see Setting Options for Interactive Design Rule Checking 3. Ensure that the layout window displays the objects on which you want to perform design rule checking. By default, interactive design rule checking uses the frame view of each cell. If you want more detail than what is provided in the frame view, use the GDSII or OASIS view for specific cells by specifying the files containing the cells in the signoff.physical.merge_stream_files application option. For example, fc_shell> set_app_options \\ -name signoff.physical.merge_stream_files \\ -value {stdcell.gds macro.oas} For information about controlling the objects displayed for design rule checking, see Displaying Objects for Design Rule Checking 4. Display the DRC toolbar by right-clicking in the GUI menu bar and selecting DRC Tools. For details about the icons in the DRC toolbar, see DRC Toolbar 5. Configure the rules to use for design rule checking by choosing Edit > Options > ICV- Live or by clicking the gear icon ( ) in the DRC toolbar. To exclude all density or connectivity rules from design rule checking, set the signoff.check_drc_live.exclude_command_class application option. 6. Run design rule checking by choosing Edit > ICV > Run ICV-Live on Current View or by clicking the ICV Run button ( ) in the DRC toolbar. The first time that you run Live DRC, the tool performs the following initialization steps, which can take a couple of minutes: Processes the IC Validator runset to get the list of available rules and caches the runset Processes the GDSII or OASIS files specified in the signoff.physical.merge_stream_files application option Unless the layers, rules, or stream files change, subsequent runs do not perform this caching and therefore are much quicker. To reduce the initial runtime, you can perform this initialization before running Live DRC by using the signoff_init_live_drc command. The tool displays the design rule checking results in the error browser. You can select errors in the error browser and then fix them interactively. For information about using the error browser, see Using the Error Browser See Also Running the signoff_check_drc Command"}
{"instruction": "How do I Removing Via Ladders", "input": "", "output": "To query the via ladders in a block, use the get_via_ladders command. To report on the via ladders in a block, use the report_via_ladders command."}
{"instruction": "How do I Specifying Synchronous Input Types for Library Cell Pins", "input": "", "output": "Fusion Compiler does not infer synchronous reset or preset flip-flops by default. To infer registers with synchronous reset or preset pins, use the sync_set_reset Synopsys compiler directive in the RTL. HDL Compiler then connects these signals to the synch_clear and synch_preset pins on the SEQGEN WVGTECH cell to communicate to the mapper that these are the synchronous control signals and they should be kept as close to the register as possible. To enable the tool to infer synchronous reset or preset flip-flops or preserve the synchronous reset or preset logic close to the flip-flop, use either of the following two methods: The sync_set_reset directive Specify the //synopsys sync_set_reset directive in the RTL. The hdlin.elaborate.ff_infer_sync_set_reset application option When the RTL does not contain the directive, set the hdlin.elaborate.ff_infer_sync_set_reset application option to true. The default is false During compile, the tool performs the following mapping based on the registers in your library: The library containing registers with synchronous reset (or preset) pins The tool connects the reset (or preset) net to the reset (or preset) pin of a register with a dedicated reset pin. The library containing no registers with synchronous reset (or preset) pins The tool adds extra logic to the data input to generate the reset (or preset) condition on a register without a reset (or preset) pin. The tool also attempts to map the logic as close as possible to the data pin. This figure shows examples of mapping to registers with and without a synchronous reset pin. ___ RST Using a reset pin ___ RST Using a gate on the data pin If your library has registers with synchronous reset (or preset) pins, you must still use the sync_set_reset directive in the RTL so that the tool can distinguish the reset (or preset) signals from other data signals and connect the reset signal as close to the register as possible. To connect the reset signal close to the register, set the compile.seqmap.honor_sync_set_reset application option to true Note: Synchronous reset and preset signals are not inferred for level-sensitive latches. A synchronous reset or preset coding style on a latch always results in combinational logic on the data signal even if the library has latches with synchronous reset or preset pins. Mapping of Asynchronous Reset or Preset Registers To enable the tool to map to registers with asynchronous reset or preset signals, you must Describe the registers correctly in the RTL Ensure the library contain the corresponding cells Ensure the hdlin.elaborate.ff_infer_async_set_reset application option is set to true (the default) If the library does not contain this type of registers, the tool leaves the cells unmapped."}
{"instruction": "How do I Checking if Library Cells Are Legally Placeable", "input": "", "output": "To enable variant-aware legalization, set the place.legalize.enable_variant_aware application option to true When variant-aware legalization is enabled, the tool tries to fix legalization DRC violations by swapping the violating cell with a variant, rather than moving it. If the cell has no variants, it is moved to a legal location. For pin-track and pin-color alignment during variant-aware legalization, set the following application options to true place.legalize.enable_prerouted_net_check place.legalize.enable_pin_color_alignment_check In addition, you must specify the layers to be aligned by using the place.legalize.pin_color_alignment_layers application option."}
{"instruction": "How do I Inserting Tap Meshes", "input": "", "output": "An interior tap wall is a row or column of tap cells that is placed inside the boundary of the standard cell placement area of a block, a macro, hard placement blockage, or nondefault voltage area. Note: You can insert interior tap walls only for designs with a single site definition. To insert an interior tap wall, use the create_interior_tap_walls command. You must specify the following information: The tap cell used in the tap wall (the -lib_cell option) The specified tap cell must be a single-height cell that matches the row height and site width. By default, the command inserts the tap cells with the row orientation. To place the cells with a different orientation, use the -orientation option. By default, the tool uses the following naming convention for inserted tap cells: tapfiller__ library_cell_name _R _C number To identify the tap cells inserted in a specific run, use the -prefix option to specify a prefix string. When you use this option, the tool uses the following naming convention: prefix __ library_cell_name _R _C number The side along which to insert the tap wall (the -side option) You can specify only a single side, top bottom right, or left. To insert a tap wall on more than one side, run the command multiple times. By default, the tap cells are placed along all edges on the specified side of the standard cell placement area with no gaps between the tap cells. To specify the tap insertion region, use the -bbox option to specify the lower-left and upper-right corners of its bounding box: -bbox {{ llx lly } { urx ury }} When you use this option, the command inserts a tap wall along the longest edge on the specified side of the placeable area encompassed by the bounding box. The alignment of the tap wall depends on the number of corners of the edge segment encompassed by the bounding box. If the edge segment does not contain a corner, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall. If the edge segment contains one corner, the tap wall starts at that corner. If the edge segment contains two corners along the specified side, the tap wall starts at the left edge for a horizontal tap wall or the bottom edge for a vertical tap wall. For a horizontal tap wall with two corners, the spacing between the last two cells might be shortened to align with the right corner. If there is not enough space, the last cell might not abut the right corner. For horizontal tap walls, you can specify a gap distance between tap cells by using the -x_spacing option. If you specify a value smaller than the tap cell width, the command uses a spacing of zero. If you specify a value that is not a multiple of the site width, the command rounds it down to a multiple of the site width. When inserting the tap wall, the command honors the standard cell rows and sites; if the rows and sites are not defined, the command does not insert tap cells. Obstructions such as placement blockages, fixed cells, and macros can prevent the insertion of the tap cells and result in an incomplete or missing tap wall. After insertion, the command fixes the placement of the inserted tap cells."}
{"instruction": "How do I Working With Macro Models", "input": "", "output": "The Fusion Compiler tool can resize power switch cells to reduce total power and to mitigate the voltage drop in the design. Power switch cells have different voltage thresholds (V ) and are classified as high, standard, low, and ultra-low. For a power cell with high threshold voltage, the power consumption and leakage current is low, but the timing is also slow with a smaller drive strength. For a power cell with a low threshold voltage, the timing is faster but the power consumption and leakage current is high. With power switch cell sizing, the tool supports different drive strength and voltage threshold to reduce IR (voltage) drop in the design. Note: When the tool switches power cells (swapping), it can only swap cells with the same footprint but with different threshold voltages. This means, the cell cannot be swapped if the cell size and pin shapes are different. To perform power switch cell swapping, you can use the size_power_switches command to set the maximum IR drop target. To meet this target when swapping power cells, the tool tries to find another cell with higher V, but lower R ON value, so that it can reduce the IR drop. You can set the ON resistance (R ON ) value to be considered by the tool for swapping using the set_power_switch_resistance command. Based on the IR drop target and the set R ON value of the power cell, the tool tries to replace power cells to meet the targeted voltage drop. Note: If the tool does not find any suitable power cell that matches the targeted voltage drop and R ON value, it skips cell resizing. To perform voltage driven cell sizing, 1. Perform a voltage drop analysis using RH Fusion to get the maximum voltage drop of the cells driven by the power switch in question. Refer Performing Voltage Drop Analysis for more information. 2. Set the RON value limit to be considered for cell switching using the set_power_switch_resistance command. Provide the following values as input, Lib cell name - specifies the name of the library cell. On resistance value - specifies the RON value limit to be considered for cell sizing. You can get this information from the switch model files. For example, fc_shell> set_power_switch_resistance saed32hvt_pg_ss0p_v125c/HEAD2X2_HVT 0.015 3. Run the size_power_switches command to perform cell size switching. Provide the value for -max_irdrop option which specifies the allowed maximum effective voltage drop on supply nets for standard cells driven by switches. This is a mandatory input. For example, fc_shell> size_power_switches -max_irdop 0.05 For the other non-mandatory inputs to further refine the command action, see the man page for the size_power_switches command. The tool also provides the following commands to further help with power switch resistance: get_power_switch_resistance - This command fetches the R ON value of a power switch cell. reset_power_switch_resistance - This command resets the R ON value specified for a power switch cell. report_power_switch_resistance - This command reports all power switch library cells with a set R ON. Use the -verbose option with the command to display the group of cells with the same footprint, the R on value and the number of cells instantiated in the design. When using the -verbose option, you can also use -same_vt option to report power switch cells and their R ON value from current library with same VT but different driving strength cells."}
{"instruction": "How do I Querying Attributes", "input": "", "output": "This topic provides examples about how to use the hotspot analysis capability to identify the root cause of voltage violations. Cells with overlapping timing windows might switch at the same time, leading to high voltage drops. shows how to identify if the cell has overlapping timing windows. Checking High Voltage Drop Caused by Overlapping Timing Window (I) Next, run the report_hot_spots command with the -index option to find which grid has overlapping timing windows that contribute to large current. As shown in when the -index option is set to 5, the grid 5 is reported with small total current. When the -index option is set to 2, the grid 2 is reported with large total current. In this case, overlapping time windows contribute to the high effective voltage drop in grid 2. Checking High Voltage Drop Caused by Overlapping Timing Window (II) See Also Generating Hotspots Reporting Hotspots Removing Hotspots"}
{"instruction": "How do I Considering DFT Connections During Placement", "input": "", "output": "To minimize many cells from being displaced during legalization, the tool should be aware of legalization limits and restrictions during coarse placement. For example, the tool should be aware that it cannot place a wide cell in a specific location due to the position of the power straps at that location. To consider legalization effects during placement, set the place.coarse.enhanced_legalizer_driven_placement application option to true Use this feature for blocks that have many cells with small to medium displacements during legalization and use the RMS displacement values reported during legalization to see if it reduces the displacement."}
{"instruction": "How do I Assigning Nondefault Routing Rules to Nets", "input": "", "output": "_to_pg true option when you define the nondefault spacing rule with the create_routing_rule command Note: When you ignore nondefault spacing rules between signal nets and PG nets, the rules are also ignored between the signal nets and the shield wires regardless of the setting of the route.common.ignore_var_spacing_to_shield and create_routing_rule -ignore_spacing_to_shield options. To ignore nondefault spacing rules between signal nets and blockages For all signal nets, set the route.common.ignore_var_spacing_to_blockage application option to true For specific signal nets, use the -ignore_spacing_to_blockage true option when you define the nondefault spacing rule with the create_routing_rule command You can relax the nondefault spacing checks for specific nondefault routing rules by ignoring violations for short parallel distances, as shown in. This technique increases the flexibility of DRC convergence without adversely affecting crosstalk. Ignoring Nondefault Spacing Rule Violations To define the length thresholds within which to ignore the nondefault spacing violations, use the -spacing_length_thresholds option when you create the nondefault routing rule with the create_routing_rule command. The length threshold values are in microns and must have a one-to-one correspondence with the spacing entries specified in the -spacings option. For example, fc_shell> create_routing_rule new_rule \\ -spacings { M1 {0.09 0.15 0.2} M2 {0.09 0.15 0.2} M3 {0.09 0.15 0.2} } \\ -spacing_weight_levels { M1 {hard medium low} M2 {hard medium low} M3 {hard medium low} } \\ -spacing_length_thresholds { M1 {0.01 0 0} M2 {0.01 0 0} M3 {0.01 0 0} } Specifying the Routing Effort for Soft Spacing Violations By default, Zroute does not fix soft spacing violations. To fix soft spacing violations, you must assign a routing effort to each of the soft weight levels. These assignments apply to all soft spacing rules. To assign a routing effort for each weight level, use the following syntax to set the route.common.soft_rule_weight_to_effort_level_map application option: set_app_options -name route.common.soft_rule_weight_to_effort_level_map -value { { weight effort }... } Each weight argument can be one of low medium, or high. You should specify each weight level only one time; if you specify a weight level multiple times, the router uses the last specification. Each effort argument can be one of the following values: off (the default) Zroute does not fix the soft spacing rule violations. low Zroute uses a small number of rip-up and reroute passes to resolve soft spacing rule violations. medium Zroute uses a medium number of rip-up and reroute passes to resolve soft spacing rule violations. Note that you cannot specify this effort level for the low weight level. high Zroute treats soft spacing rule violations the same as regular design rule violations during rip up and reroute. Note that you cannot specify this effort level for the low weight level. For example, to assign low routing effort to low-weight soft spacing rules, medium routing effort to medium-weight soft spacing rules, and high routing effort to high-weight soft spacing, use the following command: fc_shell> set_app_options \\ -name route.common.soft_rule_weight_to_effort_level_map \\ -value { {low low} {medium medium} {high high} } Defining Minimum Via Spacing Rules You can define nondefault minimum via spacing rules that are stricter than the rules defined in the technology file. Nondefault via spacing rules are hard constraints that must be met. To define a minimum via spacing rule, use the -via_spacings option with the create_routing_rule command using the following syntax: create_routing_rule rule_name -via_spacings { { layer1 layer2 spacing }... } Specify the routing layers by using the layer names from the technology file. You can define a single width value per layer pair. The minimum via spacing for vias between any unspecified layer combinations is determined from the technology file. For vias on the same layer, the router uses the minimum spacing defined in the Layer section for the via layer. For vias on different layers, the router uses the minimum spacing defined in the DesignRule section for the via layer combination. For example, to define a nondefault routing rule named via_spacing_rule that defines nondefault spacing rules between vias on the V1 layer and between vias on the V1 and V2 layers, and uses the minimum spacing rules defined in the technology file between vias on all other layer combinations, use the following command: fc_shell> create_routing_rule via_spacing_rule \\ -via_spacings {{V1 V1 2.3} {V1 V2 3.2}} Specifying Nondefault Vias By default, when routing nets with nondefault routing rules, Zroute selects vias based on the design rules. To specify the vias to use when routing nets with nondefault routing rules, use the create_routing_rule command. You can define the nondefault vias by using either the -cuts option or the -vias option. When you use the -cuts option, the tool determines the suitable via definitions from the technology file based on the specification in the -cuts option and the rules defined in the technology file. When you use the -vias option, you explicitly specify the nondefault via definitions, including the allowed cut numbers and rotation for each via definition. Specifying Nondefault Vias Using the -cuts Option The syntax for specifying nondefault vias using the -cuts option is create_routing_rule rule_name -cuts { { cut_layer1 cut_name1 ncuts } { cut_name2 ncuts } \u2026} cut_layer2 cut_name1 ncuts } { cut_name2 ncuts } \u2026}... cut_layern cut_name1 ncuts } { cut_name2 ncuts } \u2026} The cut_layer arguments refer to the via layer names in the technology file and the cut_name arguments refer to the cut names defined in the cutNameTbl attribute in the associated Layer section in the technology file. You can specify multiple cut names per layer. For each cut name, you must specify the minimum number of cuts, which must be an integer between 1 and 255. The tool searches for the vias defined in the ContactCode section of the technology file that meet the rules defined in the technology file for the specified cut name, such as the cutWidthTbl cutHeightTbl, and fatTblFatContactNumber rules. In addition, the width of the via enclosure must meet the nondefault width and the xLegalWidthTbl and yLegalWidthTbl rules defined in the technology file for the adjacent metal layers. If the fat metal contact rule is not defined for a via layer, the tool searches for the default vias that meet the cut width, cut height, and via enclosure width requirements. The minimum number of cuts required is the larger of the ncuts value in the -cuts option and the value defined in the fatTblFatContactMinCuts attribute. For the selected vias, the tool always allows both the rotated and unrotated orientations for the via. For example, assume the following information is defined in the technology file: Layer \"VIA1\" { fatTblThreshold = ( 0, 0.181, 0.411 ) fatTblFatContactNumber = ( \"2,3,4,5,6 \",\"5,6,20\", \"5,6,20\" ) fatTblFatContactMinCuts = ( \"1,1,1,1,1\", \"1,1,1\", \"2,2,2\" ) cutNameTbl = ( Vsq, Vrect ) cutWidthTbl = ( 0.05, 0.05 ) cutHeightTbl = ( 0.05, 0.13 ) ContactCode \"VIA12_LH\" { contactCodeNumber = 5 cutWidth = 0.13 cutHeight = 0.05 ContactCode \"VIA12_LV\" { contactCodeNumber = 6 cutWidth = 0.05 cutHeight = 0.13 ContactCode \"VIA12_P\" { contactCodeNumber = 20 cutWidth = 0.05 cutHeight = 0.05 If you use the following command, fc_shell> create_routing_rule cut_rule -cuts {VIA1 {Vrect 1}} The tool selects the following vias: {VIA12_LH 1x1 R}, {VIA12_LH 1x1 NR}, {VIA12_LV 1x1 R}, {VIA12_LV 1x1 NR}, {VIA12_LH 1x2 R}, {VIA12_LH 1x2 NR}, {VIA12_LH 2x1 R}, {VIA12_LH 2x1 NR}, {VIA12_LV 1x2 R}, {VIA12_LV 1x2 NR}, {VIA12_LV 2x1 R}, and {VIA12_LV 2x1 NR"}
{"instruction": "How do I Resolving Multiple References With the Uniquify Process", "input": "", "output": "The following topics describe how you can control the optimization of cells, nets, pins, and ports: Resolving Multiple References With the Uniquify Process Preserving Cells and Nets During Optimization Restricting Optimization to Cell Sizing Only Preserving Networks During Optimization Marking the Clock Networks Disabling Design Rule Checking (DRC) Preserving Pin Names During Sizing Preserving Ports of Existing Hierarchies Isolating Input and Output Ports Fixing Multiple-Port Nets Controlling the Addition of New Cells to Modules, Hierarchical Cells, and Voltage Areas Specifying a Cell Name Prefix for Optimization"}
{"instruction": "How do I Performing Manual Grouping Flow", "input": "", "output": "Auto repeater group creation allows you to derive virtual connections for register paths. For repeater group input mode, place_group_repeaters applies cutline based placement. You must specify cutline for each group. Repeaters are placed based on the intersection point between cutline and route. Build connectivity based on real connections for target cells. 1. To group a list of repeaters or repeaters of supernets, use the create_repeater_groups command. Also, specify the constraint option. The command automatically performs cell grouping and groups virtual connection with the following attributes: group_repeater_driver group_repeater_loads pin_pair group_id 2. Verify the path with the get_attribute report_repeater_group, and get_repeater_path_info commands. The get_attribute command reports the attributes of the group_repeater_driver or group_repeater_loads command. The command report_repeater_groups reports group information for specified groups or all groups, and reports repeater paths for all groups if -verbose is on. The get_repeater_paths_info command returns cells on repeater paths that include input cells. 3. Specify the cutline for a group manually with the set_repeater_group -group_id- cutline command. 4. Place interconnect repeaters on route with cutline for input repeater groups."}
{"instruction": "How do I Useful Skew", "input": "", "output": "Changing clock latencies can balance the slack in successive timing path stages to optimize clock and data paths. This capability is called concurrent clock and data (CCD) optimization, which can reduce total negative slacks (TNS), worst negative slacks (WNS), area, and leakage power. In addition, it can improve correlation between physical synthesis and place-and-route."}
{"instruction": "How do I Specifying Locations for Unmapped Cells", "input": "", "output": "A placement attraction is a constraint that you can use to specify that a large group of cells be placed together in the same vicinity of the placement area. It is a soft constraint that the tool considers during initial placement. However, it has less effect during subsequent incremental placement stages. To specify a more restrictive placement constraint for a smaller group of cells, create a move bound or group bound by using the create_bound command. To define a placement attraction, use the create_placement_attraction command. For example, to specify that the cells from the subblocks named add1 and mult1 be placed in the same vicinity, use the following command: fc_shell> set add1_cells [get_flat_cells add1/*] fc_shell> set mult1_cells [get_flat_cells mult1/*] fc_shell> create_placement_attraction -name add1_mult1 \\ \"$add1_cells $mult1_cells\" You can use the -region option to specify A region in which to place the cells To do so, specify the lower-left and upper-right coordinates of the region, as shown in the following example: fc_shell> set U1_cells [get_flat_cells U1/*] fc_shell> create_placement_attraction -name U1 \\ -region {{0 0} {2000 1500}} $U1_cells A straight line along which to place the cells, such as an edge of a macro cell To do so, specify the coordinates of the two ends of the line, as shown in the following example: fc_shell> set U2_cells [get_flat_cells U2/*] fc_shell> create_placement_attraction -name U2 \\ -region {{1000 200} {1000 800}} $U2_cells A location around which to place the cells, such as a port location To do so, specify the coordinates of the location, as shown in the following example: fc_shell> set U3_cells [get_flat_cells U3/*] fc_shell> create_placement_attraction -name U3 \\ -region {{0 700}} $U3_cells The following table shows additional commands available for changing, reporting, and removing placement attractions. For more information, see the command man pages. Table 9 Commands Related to Placement Attractions To do this Use this command create_placement_attraction add_to_placement_attraction remove_from_placement_attraction report_placement_attractions get_placement_attractions remove_placement_attractions See Also Defining Move Bounds"}
{"instruction": "How do I Creating Clock Straps", "input": "", "output": "To insert clock drivers from the top level of a design with multiple levels of physical hierarchy, 1. Enable the lower-level physical blocks for editing by using the set_editability command. 2. Enable clock driver insertion for multiple levels of physical hierarchy by setting the cts.multisource.enable_mlph_flow application option to true 3. Insert clock drivers by using the create_clock_drivers command. When inserting clock drivers to lower-level blocks, the tool reuses existing clock ports. If there are no existing clock ports, the tool creates new ports, if it is allowed. You can allow new ports to be added to a block by using use the set_freeze_ports command."}
{"instruction": "How do I Defining an Outer Keepout Margin", "input": "", "output": "A keepout margin is a region (the shaded portions in ) around the boundary of fixed cells in a block in which no other cells are placed. Placement Keepout Margins left bottom right top Fixed cell left bottom right top An outer keepout margin is a region outside the cell boundary, while an inner keepout margin is a region inside the cell boundary. The width of the keepout margin on each side of the fixed cell can be the same or different, depending on how you define the keepout margin. In addition, keepout margins can be defined as hard or soft. Keeping the placement of cells out of such regions avoids congestion and net detouring and produces better QoR. kepout marginscel-specific, seting To define a keepout margin, use the set_kepout_margin comandcomandset_kepout_margin create_keepout_margin command. By default, the command creates a hard keepout margin. To create a soft keepout margin, use the -type soft option."}
{"instruction": "How do I Enabling Buffer Removal at the Postroute Stage", "input": "", "output": "At the final stages of your design flow, you can use the route_opt command to perform concurrent clock and data optimization on specific critical path groups or endpoints by using the following steps: 1. Enable targeted concurrent clock and data optimization for the route_opt command by setting the route_opt.flow.enable_targeted_ccd_wns_optimization application option to true 2. Specify the optimization target by using one or both of the following settings: Specify the path groups to optimize by using the ccd.targeted_ccd_path_groups application option Note: If a path group you specify with this application option is also specified as a path group to skip by using the ccd.skip_path_groups application option, the path group is skipped during targeted concurrent clock and data optimization. Specify the endpoints to optimize by using the ccd.targeted_ccd_end_points_file application option You must specify at least one of these settings. If you specify both, the tool optimizes the specified endpoints of the specified paths groups. 3. (Optional) Specify the type of optimization to perform by using the ccd.targeted_ccd_select_optimization_moves application option. The valid values are auto, the default, which enables all optimization types, including buffering size_only, which enables sizing only equal_or_smaller_sizing, which enables sizing only to cells that are the same size or smaller footprint_sizing, which enables sizing only to cells with the same footprint 4. (Optional) Specify an optimization effort by using the ccd.targeted_ccd_wns_optimization_effort application option. The valid values are high (default), medium, and low. The higher the effort, the more timing QoR improvement you will see in the targeted paths, but at the expense of the timing QoR of other paths. 5. (Optional) Specify a threshold beyond which the slack for the path groups that are not targeted can be degraded by using the ccd.targeted_ccd_threshold_for_nontargeted_path_groups application option. By default, if the path groups that are not targeted have positive slack, the tool can degrade this slack until it reaches zero. For the route_opt command, you can enable both regular concurrent clock and data optimization by using the route_opt.flow.enable_ccd application option and targeted concurrent clock and data optimization by using the route_opt.flow.enable_targeted_ccd_wns_optimization application option. If you enable both, the tool performs regular concurrent clock and data optimization first, followed by targeted concurrent clock and data optimization. The following script performs targeted concurrent clock and data optimization on a block that has already undergone routing and postroute optimization: open_lib design1 open_block blk.post_route #Disable regular CCD optimization, which was previously performed set_app_options \\ -name route_opt.flow.enable_ccd -value false #Enable targeted CCD optimization set_app_options \\ -name route_opt.flow.enable_targeted_ccd_wns_optimization \\ -value true #Specify the path group and endpoints to target set_app_options -name ccd.targeted_ccd_path_groups -value clkA set_app_options -name ccd.targeted_ccd_end_points_file \\ -value clkA_ep.txt #Specify the optimization type and effort set_app_options \\ -name ccd.targeted_ccd_select_optimization_moves -value size_only set_app_options -name ccd.targeted_ccd_wns_optimization_effort \\ -value medium # Perform the targeted CCD optimization route_opt"}
{"instruction": "How do I Global Routing During Design Planning", "input": "", "output": "Before you run global routing, Define the common routing application options For information about the common routing application options, see the route.common_options man page. Define the global routing application options For information about the global routing application options, see the route.global_options man page. To perform standalone global routing, use the route_global command. By default, global routing is not timing-driven. For information about enabling timing-driven global routing, see Timing-Driven Global Routing The global router divides a block into global routing cells. By default, the width of a global routing cell is the same as the height of a standard cell and is aligned with the standard cell rows. For each global routing cell, the routing capacity is calculated according to the blockages, pins, and routing tracks inside the cell. Although the nets are not assigned to the actual wire tracks during global routing, the number of nets assigned to each global routing cell is noted. The tool calculates the demand for wire tracks in each global routing cell and reports the overflows, which are the number of wire tracks that are still needed after the tool assigns nets to the available wire tracks in a global routing cell. For advanced node designs, via density can be a concern. To enable via density modeling, set the route.global.via_cut_modeling application option to true. The tool then calculates the number of vias in each global routing cell and reports via overflows. Global routing is done in two phases: The initial routing phase (phase 0), in which the tool routes the unconnected nets and calculates the overflow for each global routing cell The rerouting phases, in which the tool tries to reduce congestion by ripping up and rerouting nets around global routing cells with overflows The tool might perform several rerouting phases. At the end of each rerouting phase, the tool recalculates the overflows. You should see a reduction in the total number of global routing cells with overflow and in the total overflow numbers. The global router stops and exits from the rerouting phase when the congestion is solved or cannot be solved further or after the maximum number of phases has occurred, as defined by the -effort_level option. You can force the global router to perform the maximum number of phases based on the specified effort level by setting the route.global.force_full_effort application option to true. By default, the tool uses medium effort and performs a maximum of three rerouting phases. You can perform up to six rerouting phases by specifying ultra effort. There are five global routing effort levels: minimum low medium high, and ultra Minimum ( -effort_level minimum The minimum effort level uses two times larger global routing cells relative to the other effort levels. It also has a much lower congestion cost and runs only one rerouting phase. It should only be used for prototype routing or for an initial congestion evaluation, not for detail routing. Low ( -effort_level low Low effort runs a maximum of two rerouting phases with very similar congestion cost. It is faster in comparison to medium effort and has reasonable QoR. If your block is not very congested, you can use the low effort level. Medium ( -effort_level medium Medium effort is the default effort level and runs a maximum of three rerouting phases. Global routing stops after the third phase or when the overflow is resolved, whichever occurs first. High ( -effort_level high High effort runs up to four rerouting phases. If your block is congested, use the high effort level. Ultra ( -effort_level ultra Ultra effort runs up to six rerouting phases. If your block is very congested, use the ultra effort level. At the end of global routing, the following information is stored in the design library: The g-links and g-vias on each routed net This information is used for the next routing steps. After Zroute performs track assignment and detail routing, it removes these g-links and g-vias from the design library. The congestion data This information is used to generate a congestion map. By default, only the hard congestion data is saved in the design library. To also save the soft congestion data, set the route.global.export_soft_congestion_maps application option to true before performing global routing. The soft congestion data includes demand from soft nondefault spacing rules, as well as tool-generated soft rules. The global router reports block statistics and congestion data after the initial routing phase and after each rerouting phase. When global routing is complete, the global router reports a summary of the wire length and via count. Example 19 shows a global routing report. In the congestion report, the Overflow value is the total number of wires in the block that do not have a corresponding track available. The Max value corresponds to the highest number of overutilized wires in a single global routing cell. The GRCs value is the total number of overcongested global routing cells in the block. Example 19 Global Routing Report Start Global Route...... Design statistics: Design Bounding Box (0.00,0.00,3180.00,1154.00) Number of routing layers = 10 layer M1, dir Hor, min width = 0.05, min space = 0.05 pitch = 0.15 layer M2, dir Ver, min width = 0.06, min space = 0.06 pitch = 0.15... Net statistics: Total number of nets = 255165 Number of nets to route = 248716 Number of single or zero port nets = 1721 4728 nets are fully connected, of which 4728 are detail routed and 0 are global routed. 1648 nets have non-default rule clock_spacing... phase3. Routing result: phase3. Both Dirs: Overflow = 3320 Max = 3 GRCs = 4405 (0.08%) phase3. H routing: Overflow = 1759 Max = 2 (GRCs = 1) GRCs = 2756 (0.10%) phase3. V routing: Overflow = 1560 Max = 3 (GRCs = 20) GRCs = 1649 (0.06%) phase3. M1 Overflow = 1475 Max = 2 (GRCs = 1) GRCs = 2426 (0.09%) phase3. M2 Overflow = 1265 Max = 3 (GRCs = 20) GRCs = 1343 (0.05%)... Overflow over macro areas phase3. Both Dirs: Overflow = 293 Max = 2 GRCs = 300 (0.04%) phase3. H routing: Overflow = 133 Max = 1 (GRCs = 129) GRCs = 139 (0.03%) phase3. V routing: Overflow = 160 Max = 2 (GRCs = 2) GRCs = 161 (0.04%) phase3. M1 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%) phase3. M2 Overflow = 0 Max = 0 (GRCs = 0) GRCs = 0 (0.00%)... Density distribution: Layer 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 > 1.2 M1 86.6 10.5 0.37 1.46 0.02 0.44 0.18 0.14 0.07 0.03 0.10 0.00 0.00 0.02 M2 68.2 14.4 7.71 4.54 2.07 1.55 0.66 0.28 0.13 0.03 0.33 0.00 0.00 0.02... phase3. Total Wire Length = 21154552.81 phase3. Layer M1 wire length = 947324.93 phase3. Layer M2 wire length = 3959478.25... phase3. Total Number of Contacts = 2530044 phase3. Via VIA12SQ_C count = 1050582 phase3. Via VIA23SQ_C count = 856311... phase3. completed. Before proceeding to detail routing, display the congestion map in the GUI and check the overflow distribution. The congestion report and map help you to identify congested areas. For more information about the congestion report, see Generating a Congestion Report For more information about the congestion map, see Generating a Congestion Map"}
{"instruction": "How do I Defining Blockages That Exclude Registers", "input": "", "output": "A category blockage is a special type of partial blockage that controls the placement of a predefined category of cells within the partial blockage. To create a category blockage, 1. Create the cell category by defining a user attribute for the category by using the define_user_attribute command and applying it to the affected cell references or instances by using the set_attribute command. To prevent the cell from being placed in the category blockage, set the attribute to true. To allow the cell in the category blockage, set the attribute to false When defining and applying attributes, observe the following rules: A blockage can only be controlled by a single attribute. Multiple blockages can be controlled by the same attribute. A cell can have multiple attributes, which could impact its placement in multiple category blockages. The same attribute can be applied to a reference and an instance. If a cell instance and its reference have different attributes, the attribute on the cell instance takes precedence. 2. Create the category blockage by using the create_placement_blockage command with the -type category -blocked_percentage, and -category options. The argument to the -category option is the name of the user attribute. The following example defines a blockage that prevents a certain category of cells from being placed within it: define_user_attribute -type boolean \\ -classes lib_cell dr_cells set_attribute [get_lib_cells mylib/dr*] dr_cells true create_placement_blockage -boundary {{4300 2400} {4500 2700}} \\ -type category -blocked_percentage 45 -category dr_cell The following example defines a blockage that allows only a certain category of cells to be placed within it: define_user_attribute -type boolean \\ -classes lib_cell non_iso set_attribute [get_lib_cells mylib/*] non_iso true set_attribute [get_lib_cells mylib/iso*] non_iso false create_placement_blockage -boundary {{4300 2400}{4500 2700}} \\ -type category -blocked_percentage 30 -category non_iso Note: Category blockages are honored during placement, but not during legalization, optimization, or clock tree synthesis."}
{"instruction": "How do I Datapath Extraction", "input": "", "output": "Datapath design is commonly used in applications that contain extensive data manipulation, such as 3-D, multimedia, and digital signal processing (DSP). By default, when you run the compile_fusion command, datapath optimization is enabled and both standard and DesignWare Foundation libraries are automatically linked. During datapath optimization, the tool performs the following tasks: Shares (or reverses the sharing) of datapath operators Uses the carry-save arithmetic technique Extracts the data path Performs high-level arithmetic optimization on the extracted data path Explores better solutions that might involve a different resource-sharing configuration Makes tradeoffs between resource sharing and datapath optimization Topics in this section Datapath Extraction Transforms arithmetic operators, such as addition, subtraction, and multiplication, into datapath blocks. Datapath Implementation Uses a datapath generator to generate the best implementations for the extracted components. Optimizing Datapaths"}
{"instruction": "How do I Corner Type", "input": "", "output": "The Custom Router bus routing application options allow you to specify: Corner Type Intra-shield Placement Pin-Trunk Offset Trunk Splitting Tapoffs"}
{"instruction": "How do I Controlling the Tapering Width", "input": "", "output": "You specify the tapering method for a nondefault routing rule when you define the rule with the create_routing_rule command. By default, Zroute uses distance-based pin tapering; it uses the default routing rule within the tapering distance from the pin and uses the nondefault routing rule beyond the tapering distance. However, advanced process nodes are very sensitive to jogs and fat metal, and sometimes the tapering distance is not sufficient to fix the routing DRC violations on nets with nondefault routing rules. In these cases, you can use layer-based tapering, which targets DRC violations on nets with nondefault routing rules. Note: Distance-based tapering and layer-based tapering are mutually exclusive. If you define a routing rule that uses both a distance-based tapering option and a layer-based tapering option, the tool uses the layer-based tapering settings and ignores the distance-based tapering settings. When Zroute performs distance-based pin tapering, it Determines the tapering distance, which is about 10 times the mean number of tracks for all routing layers. To explicitly specify the tapering distance, use the -taper_distance option when you create a nondefault routing rule with the create_routing_rule command. Uses the same tapering distance for all pins. To specify a different tapering distance for driver pins, use the -driver_taper_distance option when you create a nondefault routing rule with the create_routing_rule command. To perform layer-based pin tapering, use the -taper_over_pin_layers or -taper_under_pin_layers option when you create a nondefault routing rule with the create_routing_rule command. To specify a different layer-based tapering distance for driver pins, use the -driver_taper_over_pin_layers or -driver_taper_under_pin_layers option. For pins on the M1 or M2 layers, use the -taper_over_pin_layers option (or the -driver_taper_over_pin_layers option for driver pins) to specify the number of layers on or above the pin layer available for tapering. A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers above the pin layer. For pins on upper layers, use the -taper_under_pin_layers option (or the -driver_taper_under_pin_layers option for driver pins)to specify the number of layers on or below the pin layer available for tapering. A value of 1 enables pin tapering only on the pin layer; a larger value enables pin tapering on additional layers below the pin layer."}
{"instruction": "How do I Creating Logical Power and Ground Connections", "input": "", "output": "To learn about preparing the power network for physical implementation, see Creating Logical Power and Ground Connections Creating Floating Logical Supply Nets"}
{"instruction": "How do I Specifying Clock Gating Constraints", "input": "", "output": "Minimum capacitance, maximum capacitance, and maximum transition are logical design rule constraints that your design must meet to function as intended. They are technology- specific restrictions that are specified in the logic libraries. However, you can specify more restrictive design rule constraints by using the constraint commands given in Table 7 During optimization, the Fusion Compiler tries to meet the design rule constraints, even if it means violating optimization constraints such as timing, power, and area goals; these design rule constraints have a higher priority. After optimization, you can use the reporting commands given in Table 7 to identify design rule constraint violations in a block. Table 7 Design Rule Commands To do this Use this command set_min_capacitance set_max_capacitance set_max_transition remove_min_capacitance Table 7 Design Rule Commands (Continued) To do this Use this command remove_max_capacitance remove_max_transition report_constraints -min_capacitance report_constraints -max_capacitance report_constraints -max_transition set_connection_class set_attribute \\ -name connection_class Note: The maximum fanout design rule constraint is not honored by the Fusion Compiler tool. However, you can specify a maximum fanout for the data paths in a block by using the opt.common.max_fanout application option. This is a soft optimization constraint. During optimization the tool tries to ensure that data path cells do not drive more than the specified maximum fanout."}
{"instruction": "How do I Controlling Placement When Using the place_eco_cells Command", "input": "", "output": "For the unconstrained ECO flow, place the ECO cells by using the place_eco_cells command. This command derives the placement of each ECO cell based on the connectivity and the delays associated with the cell. The tool then legalizes each ECO cell to the closest unoccupied site. The existing cells are untouched to minimize the impact to their placement. To place All unplaced cells, use the -unplaced_cells option. Specific cells, use the -cells option. Only the cells that have changed due to ECO operations, use the -eco_changed_cells option. A cell is considered changed if the eco_change_status attribute of the cell has one of the following values: create_cell change_link add_buffer size_cell When you run the eco_netlist command, the tool automatically sets the eco_change_status attribute on the changed cells. If you update the design without using the eco_netlist command, you can manually set the eco_change_status attribute by using the set_attribute command."}
{"instruction": "How do I Multiple-Patterning Concepts", "input": "", "output": "The Fusion Compiler tool supports both the traditional UPF flow and the golden UPF flow. The golden UPF flow is an optional method of maintaining the UPF multivoltage power intent of the design. It uses the original \"golden\" UPF file throughout the synthesis, physical implementation, and verification steps, along with supplemental UPF files generated by the Fusion Compiler tool. compares the traditional UPF flow with the golden UPF flow. UPF-Prime (Traditional) and Golden UPF Flows The golden UPF flow maintains and uses the same, original \"golden\" UPF file throughout the flow. The Fusion Compiler tool writes power intent changes into a separate \"supplemental\" UPF file. Downstream tools and verification tools use a combination of the golden UPF file and the supplemental UPF file, instead of a single UPF' or UPF'' file. The golden UPF flow offers the following advantages: The golden UPF file remains unchanged throughout the flow, which keeps the form, structure, comment lines, and wildcard naming used in the UPF file as originally written. You can use tool-specific conditional statements to perform different tasks in different tools. Such statements are lost in the traditional UPF-prime flow. Changes to the power intent are easily tracked in the supplemental UPF file. You can optionally use the Verilog netlist to store all PG connectivity information, making connect_supply_net commands unnecessary in the UPF files. This can significantly simplify and reduce the overall size of the UPF files. To enable the golden UPF flow, use the following application option setting before you load the UPF: fc_shell> set_app_options -as_user_default \\ -list {mv.upf.enable_golden_upf true} To load supplemental UPF files, use the -supplemental option with the load_upf command. For more information about using the golden UPF flow, see SolvNet article 1412864, \"Golden UPF Flow Application Note.\""}
{"instruction": "How do I Reporting Routing Corridors", "input": "", "output": "You can make the following modifications to an existing routing corridor: Add new shapes to the routing corridor. To add new shapes, use the create_routing_corridor_shape command. Use the -routing_corridor option to specify the routing corridor that you want to update. You must specify the boundary of the routing corridor by using the -boundary or -path option (for details about these options, see Defining Routing Corridors ). You can also specify the minimum and maximum routing layers for the shape by using the -min_layer_name and -max_layer_name options. Remove rectangles from the routing corridor. To remove shapes, use the remove_routing_corridor_shapes command. Change the nets and supernets associated with the routing corridor. To add nets or supernets to a routing corridor, use the add_to_routing_corridor command. To remove nets or supernets from a routing corridor, use the remove_from_routing_corridor command. You can also modify routing corridors in the GUI by using the Create Route Corridor tool, the Move/Resize tool, or the Delete tool, or by editing the attributes in the Properties dialog box."}
{"instruction": "How do I Removing Cell Spacing Constraints", "input": "", "output": "To report the cell spacing rules, use the report_spacing_rules comandcomandsreport_spacing_rules report_placement_spacing_rules command. This command reports the cell spacing labels defined in the current session, the library cells (and their sides) to which they apply, and the rules defined for them."}
{"instruction": "How do I Fixing Diodes", "input": "", "output": "The -buffer option of the fix_mv_design command fixes isolation violations and illegal library cells in buffer trees throughout the design. The command can perform the following changes: Minimize the number of dual-rail buffers or inverters Fix isolation violations in buffer trees Fix buffers and inverters that have illegal settings, as follows: Process, voltage, and temperature settings Library cell purpose or subset settings Target library subset settings Bias voltages Fix a mismatch between a buffer's power domain and the voltage area in which the buffer or inverter is physically placed The command can change the netlist as follows: Swap buffer library cells to fix illegal settings Swap single-rail buffers for dual-rail buffers Swap dual-rail buffers for single-rail buffers Change the backup supplies of dual-rail buffers and inverters Change the input or output supplies of level shifters Fix a mismatch between a buffer's power domain and a voltage area by using a physical or logical feedthrough Fix a mismatch between a buffer's power domain and a gas station voltage area by using a physical or logical feedthrough The fix_mv_design command keeps the placement of the original buffers or inverters and honors the repeater strategies associated with existing buffers and inverters. In addition, the command only uses supplies that are available in the voltage area or voltage area region. The fix_mv_design command does not insert isolation cells or level-shifter cells to fix existing isolation or voltage violations. Netlist changes caused by the command do not introduce new isolation or voltage violations. To specify a buffer tree, use the -from option with the name of a net or driver pin. If you specify a net name, its driver pin is used. In both cases, the driver pin defines a full or partial buffer tree. Wildcards are supported. The -lib_cells option specifies a list of single-rail and dual-rail buffer or inverter library cells that the fix_mv_design command can use as replacement cells. By default, the command does not swap dual-rail and single-rail cells if the swap is not necessary to fix isolation violations. However, if you also specify the -minimize_dual_rail option, the tool tries to minimize the usage of dual-rail buffers to save area. If the tool inserts a new library cell as a result of the fix_mv_design command, the new cell is chosen according to the following rules, in priority order: A cell from the same library as the original library cell A cell from a library with a name similar to the original library A cell with a name similar to the original library cell name By default, buffer trees stop at level-shifter cells. Specify the -level_shifter option to allow the fix_mv_design command to modify the input or output supplies of level-shifter cells. However, the command does not change level-shifter library cells. To report the changes that the tool recommends without making any netlist changes, use the -report_only option."}
{"instruction": "How do I Reading Designs Using the -autoread Option", "input": "", "output": "Use the analyze and elaborate commands followed by the set_top_module command. The analyze command automatically creates HDL template libraries on disk based on the name of the library provided by the -hdl_library option. The location of the HDL template libraries is controlled by the hdlin.hdl_library.default_dirname application option. When the -hdl_library option is not specified, the default library name is WORK. To specify a different default library name, use the hdlin.hdl_library.default_name application option. Note: All of the application options that control the RTL reading behavior have the hdlin prefix. The elaborate command builds the module specified without linking the rest of the design. Design linking can be performed only after the entire design is in memory, so linking is not performed by the elaborate command. This allows multiple elaborate commands to be run before performing the single linking of the entire design. The top-level module must be one of the modules that is elaborated. Linking of the design and setting the top-level module is done using the set_top_module command. The top-level module is given as an argument to the set_top_module command. The top-level module must be a module that was previously elaborated with the elaborate command. The set_top_module command sets the specified module to be the top-level design, links the entire design, and creates a single block to be used for the remainder of the synthesis flow. The following script reads VHDL files using template libraries and creates a block called top. You do not need to specify the location of the template libraries on disk, which is automatically created by the analyze command based on the -hdl_library option. analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top If the top-level design is analyzed to an HDL template library other than the default library, you should provide the HDL template library name for the top-level design using the -hdl_library option. For example, analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl -hdl_library TOP_HDL_LIB top.vhd elaborate -hdl_library TOP_HDL_LIB top set_top_module top You can optionally specify the location of the HDL template libraries on disk by using the define_hdl_library command. For example, define_hdl_library BOT_HDL_LIB -path./TEMPLATES/BOT_HDL_LIB define_hdl_library MID_HDL_LIB -path./TEMPLATES/MID_HDL_LIB define_hdl_library WORK -path./TEMPLATES/WORK analyze -format vhdl -hdl_library BOT_HDL_LIB bot.vhd analyze -format vhdl -hdl_library MID_HDL_LIB mid.vhd analyze -format vhdl top.vhd elaborate top set_top_module top"}
{"instruction": "How do I Avoiding Crosstalk During Group Repeater Insertion", "input": "", "output": "Use the -honor_special_cell option to avoid overlapping with existing tap cells when inserting repeaters."}
{"instruction": "How do I Shielding the Nets", "input": "", "output": "Before performing custom routing on your block, you need to define routing constraints by using the commands described in Defining Routing Constraints, and setting the appropriate application options. To perform custom routing with Custom Router in the Fusion Compiler environment, run the route_custom command. By default, the tool routes all nets in the block. To route specific nets, use the -nets option. By default, the tool removes the configuration data when the command run is complete. To keep the data in the cache for running other Custom Router commands in the current session, set the -keep_session option to true. The default is false The following example specifies the bus routing style and then performs bus routing. fc_shell> create_bundle -name Bus1 {net0 net1} fc_shell> create_bus_routing_style -for {Bus1} \\ -valid_layers {M5 M6} \\ -layer_widths {M5 0.4 M6 0.44} -force bus1 fc_shell> create_net_shielding -for {Bus1} -shield_net VSS \\ -layer_gaps 0.21 -layer_widths 0.2 -sharing true -force sh1 fc_shell> set_app_options -name custom.route.bus_corner_type \\ -value river fc_shell> set_app_options \\ -name custom.route.bus_intra_shield_placement -value interleave fc_shell> route_custom -nets {net0 net1} The following example creates a constraint group and then performs routing on the nets with the same length. fc_shell> set matchNets {net1 net2 net3 net4} fc_shell> create_bundle -name MatchL1 $matchNets fc_shell> create_wire_matching -for MatchL1s \\ -match_type length -tolerance 1 -force matchL1_con fc_shell> route_custom -nets {net1 net2 net3 net4} The following example creates a differential group and then performs custom routing. fc_shell> create_differential_group -for {net1 net2} \\ -valid_layers {M3 M4} -layer_widths {M3 0.4 M4 0.4} \\ -layer_spacings {M3 0.4 M4 0.4} \\ -twist_style diagonal -twist_interval 80.0 -force Diff fc_shell> set_app_options\\ -name custom.route.diffpair_twist_jumper_offset -value 10 fc_shell> route_custom -nets {net1 net2}"}
{"instruction": "How do I Checking Missing Vias and Unconnected Pins", "input": "", "output": "Before checking for missing vias or unconnected pins in the design, use the set_missing_via_check_options command to specify the necessary options. To check or remove the option settings, use the report_missing_via_check_options or remove_missing_via_check_options command, respectively. Table 68 lists the commonly used options for the set_missing_via_check_options command. For a detailed description about each option, see the man page. Table 68 Commonly Used Options for the set_missing_via_check_options Command Option Description -redhawk_script_file Table 68 Commonly Used Options for the set_missing_via_check_options Command (Continued) Option Description exclude_stack_via check_valid_vias -exclude_cell -exclude_instance -exclude_regions sort_by_hot_inst -threshold -min_width -pitch -gds -ignore_inter_met -toplayer -bottomlayer"}
{"instruction": "How do I Specifying Optimization Targets at the Postroute Stage", "input": "", "output": "When performing concurrent clock and data optimization using the place_opt or clock_opt command, you can give a higher priority to the WNS optimization of Certain path groups by specifying them by using the ccd.targeted_ccd_path_groups application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_path_groups \\ -value {PG1 PG2} If a path group you specify with this application option is also specified as a path group to skip with the ccd.skip_path_groups application option, the path group is skipped during concurrent clock and data optimization. Certain endpoints by specifying a file containing the endpoints by using the ccd.targeted_ccd_end_points_file application option, as shown in the following example: fc_shell> set_app_options -name ccd.targeted_ccd_end_points_file \\ -value endpoint_targets.tcl If you specify both path groups and endpoints, the tool optimizes only the specified endpoints that are in the specified paths groups. The worst 300 timing paths by setting the ccd.enable_top_wns_optimization application option to true"}
{"instruction": "How do I Generating Rail Analysis Script Files", "input": "", "output": "Before analyzing voltage drop and current density violations in a design using the RedHawk/RedHawk-SC Fusion capability, use the set_app_options command to specify the location of the libraries and the required input files. Table 66 lists the application options for specifying design and input data for running RedHawk/RedHawk-SC rail analysis within the Fusion Compiler environment. Table 66 Application Options for Specifying Design and Input Data Application Option Description rail.lib_files fc_shell> set_app_options \\ -name rail.lib_files \\ -value {test1.lib test2.lib} rail.tech_file fc_shell> set_app_options \\ -name rail.tech_file \\ -value ChipTop.tech fc_shell> set_app_options \\ -name rail.3dic_enable_die\\ -value {DIE1 true DIE2 true...} Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description fc_shell> set_app_options \\ -name rail.instance_power_file\\ -value {E1 FILE1 DIE2 FILE2...} rail.apl_files fc_shell> set_app_options \\ -name rail.apl_files -value \\ {cell.current current \\ cell.cdev cap} rail.switch_model_files fc_shell> set_app_options \\ -name rail.switch_model_files \\ -value {switch.model} rail.macro_models fc_shell> set_app_options \\ -name rail.macro_models \\ -value {gds_cell1 mm_dir1 \\ gds_cell2 mm_dir2} rail.lef_files rail.def_files rail.pad_files create_taps rail.sta_file rail.spef_files Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.effective_resistance_ instance_file rail.generate_file_type tcl set_user_input.tcl python input_files.py fc_shell> set_app_options \\ -name rail.generate_file_type -value python rail.generate_file_variab les fc_shell> set_app_options \\ -name rail.generate_file_variables -value \\ {PLOC ploc LEF lef_files DEF def_files \\ SPEF spef_files TWF tw_files} rail.enable_new_rail_scena rio false rail.enable_parallel_run_r ail_scenario Table 66 Application Options for Specifying Design and Input Data (Continued) Application Option Description rail.scenario_name rail.dump_icc2_results_st yle -value 2.0"}
{"instruction": "How do I Generating a Report of Early Data Check Records", "input": "", "output": "You can report the policy set for all checks or for a specific set of checks by using the report_early_data_checks command. Use the following options to configure the report: -policy : Reports configuration details for all checks. It shows the selected policy and strategy for each check. Using the -hierarchical option with the -policy option reports the configuration of the subblocks. -checks : Reports the current policy, supported policies, strategies, and help text for each check. It supports an asterisk wildcard character (*) as the name of a check. Using the -hierarchical option with the -checks option reports the checks of the subblocks. -verbose : Reports a summary of all failed checks, policies, strategies applied, and checked objects with comments. Using the -hierarchical option with the -verbose option reports the records of all failed checks, policies, strategies applied, and checked objects from the subblocks. -hierarchical : Traverses the hierarchy and reports the check, policy, strategy, and fail count for each design in the hierarchy. In the following example, the report_early_data_checks -hierarchical -policy command reports the policy settings for the hierarchical checks set on the top-level design and the block-level designs: fc_shell> report_early_data_checks -policy **************************************** Report : report_early_data_checks Design : top Version: R-2020.09 Date : Thu Aug 20 23:53:54 2020 **************************************** Design Check Policy Strategy unit_des.nlib:top.design hier.block.instance_bound_to_frame error unit_des.nlib:top.design hier.block.instance_unlinked error unit_des.nlib:top.design hier.block.instance_with_design_type_macro error unit_des.nlib:top.design hier.top.estimated_corner error blk hier.block.abstract_missing_design_view error blk hier.block.abstract_target_use_non_implementation error blk hier.block.abstract_type_non_timing error blk hier.block.leaf_cell_outside_boundary error In the following example, the report_early_data_checks -hierarchical -verbose command reports the repair performed on the checked object and also provides the details of policies, strategies applied, and checked objects on the subblocks. fc_shell> report_early_data_checks -hierarchical -verbose ****************************************************** Design Check Policy Strategy Checked Comment Object blk hier.block.missing_leaf_cell_location repair eco_cell Instance location updated to X:150145 Y:69620 While running the top-level early flow, you might run into top-level errors or warnings because of the design data violations in the subblocks or top-level design. To use the data checks and policies capability for exploring early flows, you need to know the check name corresponding to the top-level errors seen on the design. The report_hier_check_description command provides the required information about the checks associated with each top-level error. The following example shows the report generated by the report_hier_check_description command: fc_shell> report_hier_check_description ********************************************* Report : Hier check description Design : top Version: R-2020.09 Date : Fri Aug 21 00:08:32 2020 ********************************************* Legend E - error R - repair T - tolerate TOP - Top-Design BLK - Respective Block-Ref Check Error Tolerate Repair Allowed Allowed Description ID ID ID Policies References hier.block.missing_frame_view TL-101 TL-401 TL-501 E|R|T BLK Missing frame view hier.block.abstract_missing_design_view TL-101 TL-401 N/A E|T BLK Missing design view for abstract hier.block.reference_missing_port_location TL-126 TL-426 TL-526 E|R|T BLK Missing location of physical hierarchy boundary pin hier.block.reference_port_outside_boundary TL-127 TL-427 TL-527 E|R|T BLK Location of physical hierarchy boundary pin outside physical hierarchy boundary"}
